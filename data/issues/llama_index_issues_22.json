[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7188",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7188/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7188/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7188/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7188",
        "id": 1840421545,
        "node_id": "I_kwDOIWuq585tspqp",
        "number": 7188,
        "title": "[Question]: does SubQuestionQueryEngine support streaming?",
        "user": {
            "login": "ibicdev",
            "id": 59773335,
            "node_id": "MDQ6VXNlcjU5NzczMzM1",
            "avatar_url": "https://avatars.githubusercontent.com/u/59773335?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ibicdev",
            "html_url": "https://github.com/ibicdev",
            "followers_url": "https://api.github.com/users/ibicdev/followers",
            "following_url": "https://api.github.com/users/ibicdev/following{/other_user}",
            "gists_url": "https://api.github.com/users/ibicdev/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ibicdev/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ibicdev/subscriptions",
            "organizations_url": "https://api.github.com/users/ibicdev/orgs",
            "repos_url": "https://api.github.com/users/ibicdev/repos",
            "events_url": "https://api.github.com/users/ibicdev/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ibicdev/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-08T01:34:16Z",
        "updated_at": "2023-08-08T17:05:45Z",
        "closed_at": "2023-08-08T17:05:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nDoes SubQuestionQueryEngine support streaming?  For example, how to stream response from `docs/examples/usecases/10k_sub_question.ipynb`?  Tried to add `streaming=True` to `llm`, `lyft_engine`, and `uber_engine`, but still couldn't get `s_engine` to produce streaming response.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7188/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7188/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7187",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7187/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7187/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7187/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7187",
        "id": 1840418397,
        "node_id": "PR_kwDOIWuq585XYvOU",
        "number": 7187,
        "title": "Add llama.cpp and HuggingFace Fallbacks",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-08T01:29:26Z",
        "updated_at": "2023-08-28T17:11:39Z",
        "closed_at": "2023-08-08T19:10:08Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7187",
            "html_url": "https://github.com/run-llama/llama_index/pull/7187",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7187.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7187.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nThis PR adds support for `llama.cpp`, as well as fallback support for local models.\r\n\r\nIf either the LLM or embedding  model fails to initialize (due to keys), we warn the user and fallback to local models.\r\n\r\nThis should be a better UX for people, especially when they switch the LLM and don't expect to have to switch the embedding model.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7187/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7187/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7186",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7186/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7186/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7186/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7186",
        "id": 1840358942,
        "node_id": "I_kwDOIWuq585tsaYe",
        "number": 7186,
        "title": "[Question]: I want to write my own prompt for TREE_SUMMARIZE",
        "user": {
            "login": "Orescout",
            "id": 27972463,
            "node_id": "MDQ6VXNlcjI3OTcyNDYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/27972463?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Orescout",
            "html_url": "https://github.com/Orescout",
            "followers_url": "https://api.github.com/users/Orescout/followers",
            "following_url": "https://api.github.com/users/Orescout/following{/other_user}",
            "gists_url": "https://api.github.com/users/Orescout/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Orescout/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Orescout/subscriptions",
            "organizations_url": "https://api.github.com/users/Orescout/orgs",
            "repos_url": "https://api.github.com/users/Orescout/repos",
            "events_url": "https://api.github.com/users/Orescout/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Orescout/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-08T00:01:05Z",
        "updated_at": "2023-09-10T21:38:25Z",
        "closed_at": "2023-09-10T21:38:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi!\r\nI'm trying to summarize a long document, using the (phenomenal) [TREE_SUMMARIZE](056cfb2d77666ba3c5659750b/llama_index/response_synthesizers/tree_summarize.py#L47) using Llama-2 from HuggingFace. The end command is: doc_summary_index.get_document_summary(documents[0].id_)\r\n\r\nTo my understanding, each chunk gets summarized in a tree manner. However, I have little control to the summarization prompt! Here's three different places where I need to be aware of the prompt passed in:\r\n- HuggingFaceLLM with parameter query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")\r\n- response_synthesizer with parameter text_qa_template = Prompt((\r\n                              \"Context information is below.\\n\"\r\n                              \"---------------------\\n\"\r\n                              \"{context_str}\\n\"\r\n                              \"---------------------\\n\"\r\n                              \"Given the context information and not prior knowledge, \"\r\n                              \"summarize it. \\n\"\r\n                          ), \r\n                          prompt_type=PromptType.QUESTION_ANSWER)\r\n- DocumentSummaryIndex.from_documents with parameter summary_query = (\r\n    \"Give a concise summary of this document. Also describe some of the questions \"\r\n    \"that this document can answer. \"\r\n)\r\n\r\nSo, the final prompt, ends up being a puzzle of all of the above, right? How can I write ONE prompt in ONE place that includes basically one thing: {context_str}. Cause the {query_str} doesn't change as far as my document summarization is concerned. The query str is already in my prompt which is used for every chunk. Does that make sense?\r\n\r\nWhat I've tried:\r\n- editing summary_query. For whatever reason, only the first line gets accepted. My summarization prompt is longer than one line/sentence.\r\n- Removing the query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\"). This causes the summarization to produce an empty string (!). no clue why. even the slightest edit, will cause it to pop out empty.\r\n- Editing text_qa_template and passing in empty or almost-empty summary_query. Doesn't seem to work, for whatever reason.\r\n\r\nAny advice or fixes or wisdom? Much appreciated :)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7186/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7186/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7185",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7185/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7185/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7185/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7185",
        "id": 1840153124,
        "node_id": "I_kwDOIWuq585troIk",
        "number": 7185,
        "title": "[Documentation]: Twitter link to GitHub is outdated",
        "user": {
            "login": "dtbuchholz",
            "id": 13358940,
            "node_id": "MDQ6VXNlcjEzMzU4OTQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/13358940?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dtbuchholz",
            "html_url": "https://github.com/dtbuchholz",
            "followers_url": "https://api.github.com/users/dtbuchholz/followers",
            "following_url": "https://api.github.com/users/dtbuchholz/following{/other_user}",
            "gists_url": "https://api.github.com/users/dtbuchholz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dtbuchholz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dtbuchholz/subscriptions",
            "organizations_url": "https://api.github.com/users/dtbuchholz/orgs",
            "repos_url": "https://api.github.com/users/dtbuchholz/repos",
            "events_url": "https://api.github.com/users/dtbuchholz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dtbuchholz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-07T20:22:03Z",
        "updated_at": "2023-08-07T23:13:17Z",
        "closed_at": "2023-08-07T23:08:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\r\n\r\nYour twitter profile is here: https://twitter.com/llama_index\r\n\r\nIt lists a GitHub link: https://github.com/jerryjliu/llam\r\n\r\nBut the correct link should be: https://github.com/jerryjliu/llama_index\r\n\r\n### Documenation Link\r\n\r\nhttps://twitter.com/llama_index",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7185/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7185/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7184",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7184/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7184/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7184/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7184",
        "id": 1840081613,
        "node_id": "PR_kwDOIWuq585XXlty",
        "number": 7184,
        "title": "OpenAIAgent callback_manager bug",
        "user": {
            "login": "sourabhdesai",
            "id": 3005241,
            "node_id": "MDQ6VXNlcjMwMDUyNDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3005241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sourabhdesai",
            "html_url": "https://github.com/sourabhdesai",
            "followers_url": "https://api.github.com/users/sourabhdesai/followers",
            "following_url": "https://api.github.com/users/sourabhdesai/following{/other_user}",
            "gists_url": "https://api.github.com/users/sourabhdesai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sourabhdesai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sourabhdesai/subscriptions",
            "organizations_url": "https://api.github.com/users/sourabhdesai/orgs",
            "repos_url": "https://api.github.com/users/sourabhdesai/repos",
            "events_url": "https://api.github.com/users/sourabhdesai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sourabhdesai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-07T19:24:30Z",
        "updated_at": "2023-08-07T19:52:31Z",
        "closed_at": "2023-08-07T19:52:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7184",
            "html_url": "https://github.com/run-llama/llama_index/pull/7184",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7184.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7184.patch",
            "merged_at": "2023-08-07T19:52:03Z"
        },
        "body": "# Description\r\n\r\nStarted seeing the following error when using `OpenAIAgent` constructed with `OpenAIAgent.from_tools`:\r\n\r\n```\r\n  File \".../llama_index/indices/query/base.py\", line 23, in query\r\n    with self.callback_manager.as_trace(\"query\"):\r\n         ^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'OpenAIAgent' object has no attribute 'callback_manager'\r\n```\r\n\r\nTurns out the super constructor for the `BaseQueryEngine` class wasn't being called. Adding a explicit call to the super constructor with the `callback_manager` attribute so the attribute is set.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7184/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7184/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7183",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7183/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7183/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7183/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7183",
        "id": 1840074262,
        "node_id": "PR_kwDOIWuq585XXkEu",
        "number": 7183,
        "title": "Add \"one click observability\" page to docs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-07T19:19:35Z",
        "updated_at": "2023-08-10T03:45:56Z",
        "closed_at": "2023-08-10T03:45:55Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7183",
            "html_url": "https://github.com/run-llama/llama_index/pull/7183",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7183.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7183.patch",
            "merged_at": "2023-08-10T03:45:55Z"
        },
        "body": "# Description\r\n\r\nIncludes W&B, Arize, TruEra right now.\r\n\r\nWIP because need to appropriately tag if this feature is fully ready (e.g. for arize/truera)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7183/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7183/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7182",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7182/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7182/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7182/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7182",
        "id": 1840063314,
        "node_id": "PR_kwDOIWuq585XXhq8",
        "number": 7182,
        "title": "Splitter refactor",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-07T19:11:05Z",
        "updated_at": "2023-08-09T04:50:18Z",
        "closed_at": "2023-08-09T04:50:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7182",
            "html_url": "https://github.com/run-llama/llama_index/pull/7182",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7182.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7182.patch",
            "merged_at": "2023-08-09T04:50:17Z"
        },
        "body": "# Description\r\n\r\nRefactor text splitters\r\n\r\n### Breaking changes\r\n* Set `SentenceSplitter` as default text splitter\r\n* no longer populate `start_char_idx` and `end_char_idx` in `Node` and `Document` classes\r\n* text splitter does not return additional metadata\r\n\r\n### Details\r\n* Simplify `TextSplitter` interface\r\n  * remove split_text_with_overlaps method\r\n  * remove TextSplit class \r\n  * this should directly support plugging in langchain text splitters\r\n* Add `MetadataAwareTextSplitter` interface\r\n> Users can code against `TextSplitter` by default, and get better support with classes that implement `MetadataAwareTextSplitter` \r\n* Rewrote `TokenTextSplitter`\r\n* Rewrote `SentenceSplitter`\r\n* Add a bunch of tests \r\n\r\n### Misc\r\n* Add a streamlit based splitter playground\r\n\r\n### Todo\r\n* generalize both `TokenTextSplitter` and `SentenceSplitter` to a hierarchical splitter that takes in a list of `split_by_*` functions",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7182/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7182/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7181",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7181/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7181/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7181/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7181",
        "id": 1839962128,
        "node_id": "PR_kwDOIWuq585XXLpG",
        "number": 7181,
        "title": "add llama 2 link to docs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-07T17:55:43Z",
        "updated_at": "2023-08-07T18:04:27Z",
        "closed_at": "2023-08-07T18:04:26Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7181",
            "html_url": "https://github.com/run-llama/llama_index/pull/7181",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7181.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7181.patch",
            "merged_at": "2023-08-07T18:04:26Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7181/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7181/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7180",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7180/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7180/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7180/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7180",
        "id": 1839917569,
        "node_id": "PR_kwDOIWuq585XXB-w",
        "number": 7180,
        "title": "Increase default temperature to 0.1",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-07T17:22:48Z",
        "updated_at": "2023-08-08T15:27:00Z",
        "closed_at": "2023-08-08T15:26:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7180",
            "html_url": "https://github.com/run-llama/llama_index/pull/7180",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7180.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7180.patch",
            "merged_at": "2023-08-08T15:26:59Z"
        },
        "body": "# Description\r\n\r\nSetting the temperature to zero by default is likely a bad idea, and is very restrictive to the token generation. Increasing slightly should allow for higher quality responses.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7180/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7180/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7179",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7179/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7179/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7179/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7179",
        "id": 1839911852,
        "node_id": "PR_kwDOIWuq585XXAvz",
        "number": 7179,
        "title": "Tree Summarize + Reduce Hallucination",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-07T17:18:12Z",
        "updated_at": "2023-08-08T17:03:36Z",
        "closed_at": "2023-08-08T17:03:35Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7179",
            "html_url": "https://github.com/run-llama/llama_index/pull/7179",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7179.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7179.patch",
            "merged_at": "2023-08-08T17:03:35Z"
        },
        "body": "# Description\r\n\r\nThis PR adds a specific prompt for `tree_summarize` to give more context to the actual task.\r\n\r\nFurthermore, the default `text_qa_templates` are modified to hallucinate less (i.e. inform the model to not make up an answer)\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested across all response modes\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7179/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7179/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7178",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7178/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7178/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7178/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7178",
        "id": 1839765493,
        "node_id": "PR_kwDOIWuq585XWhMH",
        "number": 7178,
        "title": "[version] bump version to 0.7.21",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-07T15:50:13Z",
        "updated_at": "2023-08-07T16:25:29Z",
        "closed_at": "2023-08-07T16:25:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7178",
            "html_url": "https://github.com/run-llama/llama_index/pull/7178",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7178.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7178.patch",
            "merged_at": "2023-08-07T16:25:28Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7178/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7178/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7177",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7177/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7177/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7177/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7177",
        "id": 1839475767,
        "node_id": "I_kwDOIWuq585tpCw3",
        "number": 7177,
        "title": "[Bug]: Agent callback_manager not called on .chat()",
        "user": {
            "login": "zeronyk",
            "id": 6384565,
            "node_id": "MDQ6VXNlcjYzODQ1NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6384565?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeronyk",
            "html_url": "https://github.com/zeronyk",
            "followers_url": "https://api.github.com/users/zeronyk/followers",
            "following_url": "https://api.github.com/users/zeronyk/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeronyk/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeronyk/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeronyk/subscriptions",
            "organizations_url": "https://api.github.com/users/zeronyk/orgs",
            "repos_url": "https://api.github.com/users/zeronyk/repos",
            "events_url": "https://api.github.com/users/zeronyk/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeronyk/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-07T13:36:29Z",
        "updated_at": "2023-08-07T15:30:00Z",
        "closed_at": "2023-08-07T15:28:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThe callback_manager of agents is not called correctly. When using TokenCountingHandler it does not count the tokens send to OpenAI. \r\n\r\nI found this issue #6594 but the bug also occurs at non async/streaming calls.\r\n\r\n\r\nAm i doing something wrong?\r\n\r\n### Version\r\n\r\nllama-index-0.7.20\r\n\r\n### Steps to Reproduce\r\n\r\nRun this code:\r\n\r\n```\r\nimport openai\r\nopenai.api_key = '<api_key>'\r\n\r\nfrom llama_index import GPTVectorStoreIndex, StorageContext, VectorStoreIndex, Document, ServiceContext\r\nfrom llama_index.query_engine import RetrieverQueryEngine\r\nfrom llama_index.tools import QueryEngineTool\r\nfrom llama_index.tools.types import ToolMetadata\r\nfrom llama_index.embeddings import OpenAIEmbedding\r\nfrom llama_index.llms import OpenAI\r\n\r\nfrom llama_index.callbacks import CallbackManager, TokenCountingHandler\r\nimport tiktoken\r\nwith open(\"<path/to/gatsby_part.txt>\", \"r\") as f: \r\n    text = f.read()\r\n    \r\ndocument = Document(text = text)\r\n# counts the query_engine tokens\r\ntoken_counter_query = TokenCountingHandler(tokenizer= tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode)\r\ncallback_manager_query = CallbackManager([token_counter_query])\r\nservice_context = ServiceContext.from_defaults(embed_model=OpenAIEmbedding(model = \"text-embedding-ada-002\"), llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.5),callback_manager = callback_manager_query)\r\n\r\nindex = VectorStoreIndex.from_documents([document], service_context = service_context)\r\nretriever = index.as_retriever()\r\nquery_engine = RetrieverQueryEngine.from_args(retriever,  service_context=service_context)\r\n\r\n\r\nquery_engine_tools = [\r\n            QueryEngineTool(\r\n                query_engine=query_engine, \r\n                metadata=ToolMetadata(\r\n                    name=f'Gatsby_index', \r\n                    description=\"Use this to retrieve more information about the narrator\"\r\n                )\r\n            )]\r\n\r\n# counts the agent tokens\r\ntoken_counter_agent = TokenCountingHandler(tokenizer= tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode)\r\nagent_callback_manager = CallbackManager([token_counter_agent])\r\n\r\n\r\n# Create the Agent with our tools\r\nagent = OpenAIAgent.from_tools(query_engine_tools, verbose=True, callback_manager = agent_callback_manager)\r\n\r\n\r\nresponse = agent.chat(\"What did the narrator do after getting back to Chicago?\")\r\n\r\n\r\nprint(\"Query Tokens is \" + str(token_counter_query.total_llm_token_count))\r\nprint(\"Agent Tokens is \" + str(token_counter_agent.total_llm_token_count))\r\n```\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n=== Calling Function ===\r\nCalling function: Gatsby_index with args: {\r\n  \"input\": \"narrator\"\r\n}\r\nGot output: The narrator of the given context is not explicitly mentioned.\r\n========================\r\nQuery Tokens is 1116\r\nAgent Tokens is 0\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7177/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7177/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7176",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7176/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7176/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7176/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7176",
        "id": 1839246709,
        "node_id": "I_kwDOIWuq585toK11",
        "number": 7176,
        "title": "[Bug]: ValueError: \"GPT4AllEmbeddings\" object has no field \"callback_manager\"",
        "user": {
            "login": "Ashish5869",
            "id": 131770947,
            "node_id": "U_kgDOB9qqQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/131770947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ashish5869",
            "html_url": "https://github.com/Ashish5869",
            "followers_url": "https://api.github.com/users/Ashish5869/followers",
            "following_url": "https://api.github.com/users/Ashish5869/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ashish5869/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ashish5869/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ashish5869/subscriptions",
            "organizations_url": "https://api.github.com/users/Ashish5869/orgs",
            "repos_url": "https://api.github.com/users/Ashish5869/repos",
            "events_url": "https://api.github.com/users/Ashish5869/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ashish5869/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-07T11:24:06Z",
        "updated_at": "2023-08-07T15:06:12Z",
        "closed_at": "2023-08-07T15:06:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI have downloaded gpt4all model. Using langchain gpt4all embedding and llm, when defining service context, i am defining embed model. then i am getting error that embed_model doesn't have callback manager.\r\nPlease look into this. \r\nAm i doing something wrong?\r\n\r\n### Version\r\n\r\n0.7.20\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index import (\r\n    LLMPredictor, \r\n    ServiceContext,\r\n    set_global_service_context\r\n)\r\nfrom langchain.llms import GPT4All\r\nfrom langchain.embeddings import GPT4AllEmbeddings\r\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\r\n\r\n   \r\ncallbacks = [StreamingStdOutCallbackHandler()]\r\nlocal_path = \"/path/to/gpt4 model/llama-2-7b-chat.ggmlv3.q4_0.bin\"\r\n\r\nllm = GPT4All(model=local_path, callbacks=callbacks, backend=\"gptj\", verbose=True)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm_predictor=LLMPredictor(llm=llm), \r\n    embed_model=GPT4AllEmbeddings()\r\n)\r\n\r\nOUTPUT:\r\nValueError                                Traceback (most recent call last)\r\n/tmp/ipykernel_83194/1998556855.py in <module>\r\n     53 # )\r\n     54 \r\n---> 55 service_context = ServiceContext.from_defaults(\r\n     56     llm_predictor=llm_predictor,\r\n\r\n~/anaconda3/lib/python3.10/site-packages/llama_index/indices/service_context.py in from_defaults(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, llama_logger, callback_manager, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\r\n    163         # NOTE: the embed_model isn't used in all indices\r\n    164         embed_model = embed_model or OpenAIEmbedding()\r\n--> 165         embed_model.callback_manager = callback_manager\r\n    166 \r\n    167         prompt_helper = prompt_helper or _get_default_prompt_helper(\r\n\r\n~/.local/lib/python3.10/site-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so in pydantic.main.BaseModel.__setattr__()\r\n\r\nValueError: \"GPT4AllEmbeddings\" object has no field \"callback_manager\"\r\n\r\n\r\n# Commented the line 165 in docs\r\n\r\nembed_model = embed_model or OpenAIEmbedding()\r\n- 165 embed_model.callback_manager = callback_manager\r\n\r\n# after commented 165 line. Got error while indexing\r\nindex = GPTVectorStoreIndex.from_documents(\r\n    document2,\r\n    storage_context=storage_context,\r\n    service_context=service_context\r\n)\r\n\r\n\r\n# Error\r\nAttributeError                            Traceback (most recent call last)\r\n/tmp/ipykernel_92161/889443836.py in <module>\r\n     22 ]\r\n     23 \r\n---> 24 index = GPTVectorStoreIndex.from_documents(\r\n     25 #     [],\r\n     26     document2,\r\n. . .\r\n~/anaconda3/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py in _get_node_embedding_results(self, nodes, show_progress)\r\n     99         for n in nodes:\r\n    100             if n.embedding is None:\r\n--> 101                 self._service_context.embed_model.queue_text_for_embedding(\r\n    102                     n.node_id, n.get_content(metadata_mode=MetadataMode.EMBED)\r\n    103                 )\r\n\r\nAttributeError: 'GPT4AllEmbeddings' object has no attribute 'queue_text_for_embedding'\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7176/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7176/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7175",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7175/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7175/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7175/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7175",
        "id": 1839176396,
        "node_id": "I_kwDOIWuq585tn5rM",
        "number": 7175,
        "title": "[Question]:  Is it possible   automatically update documents   after data addition or data update using lllamaindex on real time application?",
        "user": {
            "login": "iriye",
            "id": 47598555,
            "node_id": "MDQ6VXNlcjQ3NTk4NTU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/47598555?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iriye",
            "html_url": "https://github.com/iriye",
            "followers_url": "https://api.github.com/users/iriye/followers",
            "following_url": "https://api.github.com/users/iriye/following{/other_user}",
            "gists_url": "https://api.github.com/users/iriye/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iriye/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iriye/subscriptions",
            "organizations_url": "https://api.github.com/users/iriye/orgs",
            "repos_url": "https://api.github.com/users/iriye/repos",
            "events_url": "https://api.github.com/users/iriye/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iriye/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-07T10:38:53Z",
        "updated_at": "2023-10-24T06:30:11Z",
        "closed_at": "2023-10-24T06:30:11Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIs it possible   automatically update documents   after data addition or data update using lllamaindex on real time application?\r\n\"WillLlamaindex  be able to perform the necessary updates simultaneously when there are changes in documents or new documents added in real-time application usage with a lot of data?\"",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7175/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7175/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7174",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7174/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7174/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7174/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7174",
        "id": 1839001144,
        "node_id": "PR_kwDOIWuq585XT6Y2",
        "number": 7174,
        "title": "feat(observability): Migrate base components to pydantic (1/2)",
        "user": {
            "login": "jon-chuang",
            "id": 9093549,
            "node_id": "MDQ6VXNlcjkwOTM1NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jon-chuang",
            "html_url": "https://github.com/jon-chuang",
            "followers_url": "https://api.github.com/users/jon-chuang/followers",
            "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}",
            "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions",
            "organizations_url": "https://api.github.com/users/jon-chuang/orgs",
            "repos_url": "https://api.github.com/users/jon-chuang/repos",
            "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jon-chuang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-08-07T08:58:12Z",
        "updated_at": "2023-08-17T02:09:45Z",
        "closed_at": "2023-08-17T02:09:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7174",
            "html_url": "https://github.com/run-llama/llama_index/pull/7174",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7174.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7174.patch",
            "merged_at": null
        },
        "body": "## Description\r\n\r\nThis PR is an initial stab at moving core components (Embeddings, LLMs) to use a pydantic representation.\r\n\r\nThis enables more typing protection, as all as the ability to use `json()` and `dict()` methods on these components. \r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n## Future Work\r\n\r\nIf these changes are agreed on, the next components to migrate are the rest of the components that live on the service context\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7174/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7174/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7173",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7173/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7173/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7173/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7173",
        "id": 1838741441,
        "node_id": "I_kwDOIWuq585tmPfB",
        "number": 7173,
        "title": "[Question]: How to use custom chat history with reactChatEngine",
        "user": {
            "login": "AchintyaX",
            "id": 39014560,
            "node_id": "MDQ6VXNlcjM5MDE0NTYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/39014560?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AchintyaX",
            "html_url": "https://github.com/AchintyaX",
            "followers_url": "https://api.github.com/users/AchintyaX/followers",
            "following_url": "https://api.github.com/users/AchintyaX/following{/other_user}",
            "gists_url": "https://api.github.com/users/AchintyaX/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AchintyaX/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AchintyaX/subscriptions",
            "organizations_url": "https://api.github.com/users/AchintyaX/orgs",
            "repos_url": "https://api.github.com/users/AchintyaX/repos",
            "events_url": "https://api.github.com/users/AchintyaX/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AchintyaX/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-07T06:02:43Z",
        "updated_at": "2023-09-01T13:19:06Z",
        "closed_at": "2023-08-07T15:08:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am trying to build a chatbot, for managing concurrent chat sessions I am using redis to store the chat history.\r\nI was able to use `CondenseQuestionChatEngine` with custom chat history, but I wanted to reactChatEngine since in my experimentation it is generally performs better. \r\nI couldn't find any ways to do it in the documentation and on discord",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7173/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7173/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7172",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7172/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7172/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7172/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7172",
        "id": 1838460955,
        "node_id": "PR_kwDOIWuq585XSHwx",
        "number": 7172,
        "title": "[version] bump version to 0.7.20",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T23:31:09Z",
        "updated_at": "2023-08-06T23:39:24Z",
        "closed_at": "2023-08-06T23:39:23Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7172",
            "html_url": "https://github.com/run-llama/llama_index/pull/7172",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7172.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7172.patch",
            "merged_at": "2023-08-06T23:39:23Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7172/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7172/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7171",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7171/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7171/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7171/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7171",
        "id": 1838437122,
        "node_id": "PR_kwDOIWuq585XSDsE",
        "number": 7171,
        "title": "add router module docs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T22:13:39Z",
        "updated_at": "2023-08-06T22:38:45Z",
        "closed_at": "2023-08-06T22:29:33Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7171",
            "html_url": "https://github.com/run-llama/llama_index/pull/7171",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7171.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7171.patch",
            "merged_at": "2023-08-06T22:29:33Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7171/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7171/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7170",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7170/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7170/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7170/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7170",
        "id": 1838426738,
        "node_id": "I_kwDOIWuq585tlCpy",
        "number": 7170,
        "title": "[Bug]: Agent sometimes tries to use tools that do not exist and then crashes",
        "user": {
            "login": "buckmaxwell",
            "id": 6210452,
            "node_id": "MDQ6VXNlcjYyMTA0NTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6210452?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/buckmaxwell",
            "html_url": "https://github.com/buckmaxwell",
            "followers_url": "https://api.github.com/users/buckmaxwell/followers",
            "following_url": "https://api.github.com/users/buckmaxwell/following{/other_user}",
            "gists_url": "https://api.github.com/users/buckmaxwell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/buckmaxwell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/buckmaxwell/subscriptions",
            "organizations_url": "https://api.github.com/users/buckmaxwell/orgs",
            "repos_url": "https://api.github.com/users/buckmaxwell/repos",
            "events_url": "https://api.github.com/users/buckmaxwell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/buckmaxwell/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-06T21:31:00Z",
        "updated_at": "2023-10-12T15:44:48Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI have a data agent with a collection of tools attached to it. It usually functions fine. Sometimes it tries to use a tool that never existed (makes up a name for it matching some pattern) and then it crashes. My agent is OpenAI\r\n\r\nSome example output,\r\n```\r\nBot:  Hi there! I noticed that you haven't scheduled your FBI/BCI background check or connected your OCCRRA account yet. Since you have worked in child care before, let's start by connecting your OCCRRA account. You can do this by clicking on the profile tab at the bottom of the screen and then clicking on the \"Complete Basic Compliance\" button in the \"Basic Compliance\" section. Let me know if you need any assistance with that!\r\nYou: whats an occrra account\r\n=== Calling Function ===\r\nCalling function: occcra_information with args: {}\r\nTraceback (most recent call last):\r\n  File \"/Users/maxbuck/Documents/join-tandem/api/sitter/vendor/ai/llamaindex/agenttest.py\", line 55, in <module>\r\n    response = agent.chat(query)\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 145, in chat\r\n    function_message, tool_output = call_function(\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 42, in call_function\r\n    tool = get_function_by_name(tools, name)\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 29, in get_function_by_name\r\n    raise ValueError(f\"Tool with name {name} not found\")\r\nValueError: Tool with name occcra_information not found\r\n```\r\n\r\nPlease not there is a tool called occrra_information (note the difference in spelling). I see no misspelled version of the tool in my project.\n\n### Version\n\n0.7.17\n\n### Steps to Reproduce\n\nProvoke invocation of a custom tool or non existent tool; intermittently the agent tries to call a tool that does not exist and there is an error.\n\n### Relevant Logs/Tracbacks\n\n```shell\nCalling function: occcra_information with args: {}\r\nTraceback (most recent call last):\r\n  File \"/Users/maxbuck/Documents/join-tandem/api/sitter/vendor/ai/llamaindex/agenttest.py\", line 55, in <module>\r\n    response = agent.chat(query)\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 145, in chat\r\n    function_message, tool_output = call_function(\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 42, in call_function\r\n    tool = get_function_by_name(tools, name)\r\n  File \"/Users/maxbuck/Library/Caches/pypoetry/virtualenvs/ai-IvBGZgFJ-py3.10/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 29, in get_function_by_name\r\n    raise ValueError(f\"Tool with name {name} not found\")\r\nValueError: Tool with name occcra_information not found\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7170/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7170/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7169",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7169/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7169/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7169/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7169",
        "id": 1838287134,
        "node_id": "I_kwDOIWuq585tkgke",
        "number": 7169,
        "title": "[Bug]: ChatMemoryBuffer unpicklable since 0.7.18",
        "user": {
            "login": "SlapDrone",
            "id": 32279503,
            "node_id": "MDQ6VXNlcjMyMjc5NTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32279503?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SlapDrone",
            "html_url": "https://github.com/SlapDrone",
            "followers_url": "https://api.github.com/users/SlapDrone/followers",
            "following_url": "https://api.github.com/users/SlapDrone/following{/other_user}",
            "gists_url": "https://api.github.com/users/SlapDrone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SlapDrone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SlapDrone/subscriptions",
            "organizations_url": "https://api.github.com/users/SlapDrone/orgs",
            "repos_url": "https://api.github.com/users/SlapDrone/repos",
            "events_url": "https://api.github.com/users/SlapDrone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SlapDrone/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-06T17:37:20Z",
        "updated_at": "2023-08-10T23:24:43Z",
        "closed_at": "2023-08-10T23:24:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHey folks,\r\n\r\nSince 0.7.18 the `ChatMemoryBuffer` class is unpicklable. Looks like there was some refactoring/tweaks in this release. Pretty sure it's the tokenizer object. See e.g. https://github.com/huggingface/datasets/issues/5536.\r\n\r\n(FAO @logan-markewich)\r\n\r\n### Version\r\n\r\n0.7.18\r\n\r\n### Steps to Reproduce\r\n\r\n```python\r\nfrom copy import deepcopy\r\n\r\nfrom llama_index.memory import ChatMemoryBuffer\r\n\r\nbuffer = ChatMemoryBuffer(token_limit=5)\r\ndeepcopy(buffer)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nTraceback (most recent call last):\r\n    File \"<stdin>\", line 1, in <module>\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 172, in deepcopy\r\n      y = _reconstruct(x, memo, *rv)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 271, in _reconstruct\r\n      state = deepcopy(state, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 146, in deepcopy\r\n      y = copier(x, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 231, in _deepcopy_dict\r\n      y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 146, in deepcopy\r\n      y = copier(x, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 231, in _deepcopy_dict\r\n      y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 172, in deepcopy\r\n      y = _reconstruct(x, memo, *rv)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 265, in _reconstruct\r\n      y = func(*args)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 264, in <genexpr>\r\n      args = (deepcopy(arg, memo) for arg in args)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 146, in deepcopy\r\n      y = copier(x, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 238, in _deepcopy_method\r\n      return type(x)(x.__func__, deepcopy(x.__self__, memo))\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 172, in deepcopy\r\n      y = _reconstruct(x, memo, *rv)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 271, in _reconstruct\r\n      state = deepcopy(state, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 146, in deepcopy\r\n      y = copier(x, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 231, in _deepcopy_dict\r\n      y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    File \"/home/slapdrone/.pyenv/versions/3.10.8/lib/python3.10/copy.py\", line 161, in deepcopy\r\n      rv = reductor(4)\r\n  TypeError: cannot pickle 'builtins.CoreBPE' object\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7169/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7169/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7168",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7168/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7168/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7168/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7168",
        "id": 1838126753,
        "node_id": "PR_kwDOIWuq585XRE6u",
        "number": 7168,
        "title": "minor typo fix",
        "user": {
            "login": "tilleul",
            "id": 3061106,
            "node_id": "MDQ6VXNlcjMwNjExMDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3061106?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tilleul",
            "html_url": "https://github.com/tilleul",
            "followers_url": "https://api.github.com/users/tilleul/followers",
            "following_url": "https://api.github.com/users/tilleul/following{/other_user}",
            "gists_url": "https://api.github.com/users/tilleul/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tilleul/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tilleul/subscriptions",
            "organizations_url": "https://api.github.com/users/tilleul/orgs",
            "repos_url": "https://api.github.com/users/tilleul/repos",
            "events_url": "https://api.github.com/users/tilleul/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tilleul/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T09:25:12Z",
        "updated_at": "2023-08-06T16:02:12Z",
        "closed_at": "2023-08-06T16:02:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7168",
            "html_url": "https://github.com/run-llama/llama_index/pull/7168",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7168.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7168.patch",
            "merged_at": "2023-08-06T16:02:12Z"
        },
        "body": "properies -> properties",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7168/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7168/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7167",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7167/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7167/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7167/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7167",
        "id": 1838062488,
        "node_id": "I_kwDOIWuq585tjpuY",
        "number": 7167,
        "title": "[Bug]: SubQuestionQueryEngine getting openai.error.InvalidRequestError: Unrecognized request argument supplied: functions",
        "user": {
            "login": "Yackadaisical",
            "id": 134191941,
            "node_id": "U_kgDOB_-bRQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/134191941?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Yackadaisical",
            "html_url": "https://github.com/Yackadaisical",
            "followers_url": "https://api.github.com/users/Yackadaisical/followers",
            "following_url": "https://api.github.com/users/Yackadaisical/following{/other_user}",
            "gists_url": "https://api.github.com/users/Yackadaisical/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Yackadaisical/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Yackadaisical/subscriptions",
            "organizations_url": "https://api.github.com/users/Yackadaisical/orgs",
            "repos_url": "https://api.github.com/users/Yackadaisical/repos",
            "events_url": "https://api.github.com/users/Yackadaisical/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Yackadaisical/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-08-06T05:53:30Z",
        "updated_at": "2023-12-01T17:26:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nQuestion\r\nMy set up works for all other kinds of queries I been working on, but today I was trying to add SubQuestionQueryEngine to my code, and keep getting this error:\r\n\r\nopenai.error.InvalidRequestError: Unrecognized request argument supplied: functions\r\n\r\nThis is basic outline of my code:\r\n\r\n```\r\nllm = AzureOpenAI(engine=\"try2\", model=\"gpt-3.5-turbo-16k\", temperature=0.2)\r\n\r\nembedding_llm = LangchainEmbedding(\r\n    OpenAIEmbeddings(\r\n        model=\"text-embedding-ada-002\",\r\n        deployment=\"embedding_try1\",\r\n        openai_api_key=openai.api_key,\r\n        openai_api_base=openai.api_base,\r\n        openai_api_type=openai.api_type,\r\n        openai_api_version=openai.api_version,\r\n    ),\r\n    embed_batch_size=1,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embedding_llm,\r\n)\r\n\r\nset_global_service_context(service_context)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    persist_dir=\"docs_index_storage\"\r\n)\r\n\r\nvector_query_engine = load_index_from_storage(\r\n    storage_context=storage_context, \r\n    service_context=service_context\r\n    ).as_query_engine()\r\n\r\nquery_engine_tools = [\r\n    QueryEngineTool(\r\n        query_engine=vector_query_engine,\r\n        metadata=ToolMetadata(\r\n            name=\"tissue_research\", description=\"Provide information on consumer tissue paper.\"\r\n        ),\r\n    ),\r\n]\r\n\r\nquery_engine = SubQuestionQueryEngine.from_defaults(\r\n    query_engine_tools=query_engine_tools,\r\n    service_context=service_context\r\n)\r\n\r\nanswer = query_engine.query(\"What is the latest trends on tissue paper\")\r\n\r\nprint(answer.get_formatted_sources())\r\n```\r\n\r\nI am using gpt-3.5-turbo-16k,, changed to gpt-3.5-turbo, but still giving me the same error. Updated llama-index to latest version, still same issue. \r\n\r\nI have used the exact same initializations as the SubQuestionQueryEngine documentation, the only difference is that I'm using Azure OpenAI LLM and embedding, yet ihenever I run .query it would raise openai.error.InvalidRequestError: Unrecognized request argument supplied: functions\r\n\r\n### Version\r\n\r\n0.7.17",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7167/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7167/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7166",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7166/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7166/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7166/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7166",
        "id": 1838046123,
        "node_id": "PR_kwDOIWuq585XQ2Pw",
        "number": 7166,
        "title": "add retriever router",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T04:38:19Z",
        "updated_at": "2023-08-06T20:18:00Z",
        "closed_at": "2023-08-06T20:17:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7166",
            "html_url": "https://github.com/run-llama/llama_index/pull/7166",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7166.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7166.patch",
            "merged_at": "2023-08-06T20:17:59Z"
        },
        "body": "we have a retriever query engine so i figured we'd add something similar for the router\r\n\r\nTODO: make async work\r\n\r\nnext step: add docs on router as a first-class module ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7166/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7166/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7165",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7165/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7165/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7165/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7165",
        "id": 1838032775,
        "node_id": "PR_kwDOIWuq585XQzlR",
        "number": 7165,
        "title": "Jerry/fix llms callbacks issue",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T03:54:07Z",
        "updated_at": "2023-08-06T03:59:18Z",
        "closed_at": "2023-08-06T03:59:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7165",
            "html_url": "https://github.com/run-llama/llama_index/pull/7165",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7165.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7165.patch",
            "merged_at": "2023-08-06T03:59:17Z"
        },
        "body": "from #7112 we type function args as *args, **kwargs in the callback wrappers for `chat`. but when we call `llm.chat` sometimes we pass in messages as a kwarg instead of an arg e.g. `llm.chat(messages=messages, ...)`. This causes any references of `args[0]` to throw an error since args is blank.\r\n\r\nHere we explicitly define the messages signature. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7165/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7165/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7164",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7164/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7164/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7164/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7164",
        "id": 1838024245,
        "node_id": "PR_kwDOIWuq585XQyBp",
        "number": 7164,
        "title": "fix for concurrent OpenAIAgent streaming issue + notebook that was able to reproduce the issue",
        "user": {
            "login": "sourabhdesai",
            "id": 3005241,
            "node_id": "MDQ6VXNlcjMwMDUyNDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3005241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sourabhdesai",
            "html_url": "https://github.com/sourabhdesai",
            "followers_url": "https://api.github.com/users/sourabhdesai/followers",
            "following_url": "https://api.github.com/users/sourabhdesai/following{/other_user}",
            "gists_url": "https://api.github.com/users/sourabhdesai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sourabhdesai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sourabhdesai/subscriptions",
            "organizations_url": "https://api.github.com/users/sourabhdesai/orgs",
            "repos_url": "https://api.github.com/users/sourabhdesai/repos",
            "events_url": "https://api.github.com/users/sourabhdesai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sourabhdesai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-06T03:12:24Z",
        "updated_at": "2023-08-06T23:05:10Z",
        "closed_at": "2023-08-06T23:00:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7164",
            "html_url": "https://github.com/run-llama/llama_index/pull/7164",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7164.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7164.patch",
            "merged_at": "2023-08-06T23:00:34Z"
        },
        "body": "# Description\r\n\r\nRan into an issue where if I had multiple instances of `OpenAIAgent` streaming chat messages at the same time, we were getting really garbled up messages. Turns out thats because each of the responses from these `OpenAIAgent`s were using the same underlying `queue.Queue` instance to relay tokens from the OpenAI API. So the messages from the concurrent streams were getting interleaved with each other \ud83d\ude05\r\n\r\nLuckily this is a one line fix where we just instantiate a new `queue.Queue` instance on the instantiation of each new `StreamingAgentChatResponse` instance.\r\n\r\nI've also included a notebook that was able to reliably reproduce the issue before the fix and works fine after the fix.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7164/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7164/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7163",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7163/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7163/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7163/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7163",
        "id": 1837999068,
        "node_id": "PR_kwDOIWuq585XQtay",
        "number": 7163,
        "title": "Add entity metadata extractor",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-06T01:16:17Z",
        "updated_at": "2023-08-28T17:10:42Z",
        "closed_at": "2023-08-07T00:38:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7163",
            "html_url": "https://github.com/run-llama/llama_index/pull/7163",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7163.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7163.patch",
            "merged_at": "2023-08-07T00:38:17Z"
        },
        "body": "# Description\r\n\r\nThis uses the a new multilingual metadata extractor to extract entities. The original model card is [here](https://huggingface.co/tomaarsen/span-marker-xlm-roberta-base-multinerd).\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] Add extractor\r\n- [x] Add notebook\r\n- [x] Update docs\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7163/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7163/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7162",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7162/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7162/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7162/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7162",
        "id": 1837969975,
        "node_id": "PR_kwDOIWuq585XQoDQ",
        "number": 7162,
        "title": "docs: small typo",
        "user": {
            "login": "nickscamara",
            "id": 20311743,
            "node_id": "MDQ6VXNlcjIwMzExNzQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/20311743?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nickscamara",
            "html_url": "https://github.com/nickscamara",
            "followers_url": "https://api.github.com/users/nickscamara/followers",
            "following_url": "https://api.github.com/users/nickscamara/following{/other_user}",
            "gists_url": "https://api.github.com/users/nickscamara/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nickscamara/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nickscamara/subscriptions",
            "organizations_url": "https://api.github.com/users/nickscamara/orgs",
            "repos_url": "https://api.github.com/users/nickscamara/repos",
            "events_url": "https://api.github.com/users/nickscamara/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nickscamara/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-05T23:05:40Z",
        "updated_at": "2023-08-06T01:14:00Z",
        "closed_at": "2023-08-06T01:13:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7162",
            "html_url": "https://github.com/run-llama/llama_index/pull/7162",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7162.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7162.patch",
            "merged_at": "2023-08-06T01:13:59Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7162/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7162/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7161",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7161/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7161/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7161/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7161",
        "id": 1837713366,
        "node_id": "I_kwDOIWuq585tiUfW",
        "number": 7161,
        "title": "[Question]: Will NodeRelationship affect index building?",
        "user": {
            "login": "fisipro2",
            "id": 111398860,
            "node_id": "U_kgDOBqPPzA",
            "avatar_url": "https://avatars.githubusercontent.com/u/111398860?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fisipro2",
            "html_url": "https://github.com/fisipro2",
            "followers_url": "https://api.github.com/users/fisipro2/followers",
            "following_url": "https://api.github.com/users/fisipro2/following{/other_user}",
            "gists_url": "https://api.github.com/users/fisipro2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fisipro2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fisipro2/subscriptions",
            "organizations_url": "https://api.github.com/users/fisipro2/orgs",
            "repos_url": "https://api.github.com/users/fisipro2/repos",
            "events_url": "https://api.github.com/users/fisipro2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fisipro2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-05T11:34:57Z",
        "updated_at": "2023-10-24T06:30:09Z",
        "closed_at": "2023-10-24T06:30:09Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi\r\n\r\nI'm building the nodes (TextNode) maually, I also setup the child/parent relationships for the node.\r\nI want to know:\r\n\r\n1. Will the relationships be used when building up the index ( embeedings ), like if I don't setup the relationships, will there be a big difference in query ?\r\n\r\n2. Do I have to setup the SOURCE relationship as well? Will there be a difference if set/not set the SOURCE realtionship for the node?\r\n\r\nActually I'm using pinecode to hold the vector, I want to update just some nodes each time, I found the index.delete_nodes has been implemented yet, the only way to delele the node is to call delete_ref_doc, which will delete all the nodes belongs to the same doc_id, that' not what I want, I want to just delete specific nodes, not all of it, so my idea is that if I can assign the SOURCE relationship a unique random id/tag for each node, by doing this, the SOURCE realtionship will has nothing to do with the *relationship*, it will be just used for holding custom data). Later I can delete each node individually by calling the delete_ref_doc and passing the random id I generated, not sure if this will affect the query result ? )\r\n\r\nThanks for your help.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7161/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7161/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7160",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7160/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7160/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7160/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7160",
        "id": 1837450841,
        "node_id": "PR_kwDOIWuq585XPCch",
        "number": 7160,
        "title": "OpenInferenceCallbackHandler uses node IDs rather than hashes",
        "user": {
            "login": "axiomofjoy",
            "id": 15664869,
            "node_id": "MDQ6VXNlcjE1NjY0ODY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/15664869?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axiomofjoy",
            "html_url": "https://github.com/axiomofjoy",
            "followers_url": "https://api.github.com/users/axiomofjoy/followers",
            "following_url": "https://api.github.com/users/axiomofjoy/following{/other_user}",
            "gists_url": "https://api.github.com/users/axiomofjoy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axiomofjoy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axiomofjoy/subscriptions",
            "organizations_url": "https://api.github.com/users/axiomofjoy/orgs",
            "repos_url": "https://api.github.com/users/axiomofjoy/repos",
            "events_url": "https://api.github.com/users/axiomofjoy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axiomofjoy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-04T23:47:39Z",
        "updated_at": "2023-10-22T13:32:19Z",
        "closed_at": "2023-09-07T19:19:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7160",
            "html_url": "https://github.com/run-llama/llama_index/pull/7160",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7160.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7160.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nChange the `OpenInferenceCallbackHandler` to use node IDs rather than node hashes. Node hashes were originally chosen because of an issue reading in legacy LlamaIndex persisted indexes, but the node IDs work with newer versions.\r\n\r\nThis issue was initially investigated [here](https://github.com/jerryjliu/llama_index/issues/7101), where we found that the issue disppear after re-indexing with a newer version of LlamaIndex.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7160/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7160/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7159",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7159/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7159/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7159/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7159",
        "id": 1837328249,
        "node_id": "I_kwDOIWuq585tg2d5",
        "number": 7159,
        "title": "[Question]: How can I improve responses?",
        "user": {
            "login": "kylemassimilian",
            "id": 31603204,
            "node_id": "MDQ6VXNlcjMxNjAzMjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/31603204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylemassimilian",
            "html_url": "https://github.com/kylemassimilian",
            "followers_url": "https://api.github.com/users/kylemassimilian/followers",
            "following_url": "https://api.github.com/users/kylemassimilian/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylemassimilian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylemassimilian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylemassimilian/subscriptions",
            "organizations_url": "https://api.github.com/users/kylemassimilian/orgs",
            "repos_url": "https://api.github.com/users/kylemassimilian/repos",
            "events_url": "https://api.github.com/users/kylemassimilian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylemassimilian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-04T20:56:11Z",
        "updated_at": "2023-10-24T06:30:08Z",
        "closed_at": "2023-10-24T06:30:08Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI'm running into issues with the response quality I'm getting querying across documents. Currently testing out two batches of PDFs, one 11MB in size and the other 72. When I reference specific file names, such as \"October 2022 update,\" I'm getting answers w/ information from the wrong file. I also cannot get correct answers to questions like \"when was the last time we said something about x?\" or \"what date did we send xyz?\" They are not all date-related issues, however. Another example: If I say \"what have we said about y?\" I receive a description of the wrong entity. Just giving examples for color. \r\n\r\nCan someone help me understand the forces at play here? I know it's not probably possible to achieve correct answers 100% of the time, but my performance as of now is poor. I believe my index needs to be more robust to handle the complex queries I'm asking across many documents. Here is my current plan of things to try:\r\n\r\n1. Configure query settings/ vector index retriever (or use auto retriever) - Can I do anything here to influence the output such as specify top k embeddings or use metadata?\r\n3. Try different embedding models\r\n4. Test a custom retriever with keyword and vector indices\r\n5. Test a custom retriever with knowledge graph and vector indices\r\n\r\nAn additional idea I had was to use different indices/composability as I scale up knowledge base size, but that doesn't apply directly to the problem at hand since these issues are happening across a relatively small # of files.\r\n\r\nAre there other things I should try to test or incorporate? I'm a beginner but eager to learn more. Thank you.\r\n\r\n```\r\n`def generate_or_return_embeddings():\r\n    #Load files\r\n    documents = SimpleDirectoryReader('data').load_data()\r\n    \r\n    #Define embedding model\r\n    embed_model = LangchainEmbedding(\r\n        HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"),\r\n        embed_batch_size=10\r\n    )\r\n    #Define service context - bundle of commonly used resources using during indexing/querying stage in pipeline\r\n    service_context = ServiceContext.from_defaults(embed_model=embed_model) \r\n\r\n    #Connect to Chroma\r\n    chroma_db = chromadb.HttpClient(host=\"\", port=8000)\r\n    #Name the collection\r\n    collection_name = \"GPIF-mini-2\"\r\n    collections = [col.name for col in chroma_db.list_collections()]\r\n    \r\n    if collection_name in collections:\r\n        print(\"Collection exists. Building index..\")\r\n        chroma_collection = chroma_db.get_collection(collection_name)\r\n        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n        index = VectorStoreIndex.from_vector_store(vector_store=vector_store, service_context=service_context)\r\n        return index    \r\n    else:\r\n        print(\"New collection. Generating embeddings then building index...\")\r\n        chroma_collection = chroma_db.create_collection(collection_name)\r\n        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n        #Abstraction for storing Nodes, indices, and vectors\r\n        storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n        index = VectorStoreIndex.from_documents(\r\n            documents, storage_context=storage_context, service_context=service_context, embed_model=embed_model\r\n        )\r\n        return index\r\n\r\n\r\n\r\ndef query_chroma(index, query):\r\n    query_engine = index.as_query_engine()\r\n\r\n    response = query_engine.query(query)\r\n    return response`\r\n```\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7159/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7159/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7158",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7158/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7158/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7158/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7158",
        "id": 1837187337,
        "node_id": "PR_kwDOIWuq585XOJI4",
        "number": 7158,
        "title": "[version] bump to v0.7.19",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T18:37:27Z",
        "updated_at": "2023-08-04T18:44:54Z",
        "closed_at": "2023-08-04T18:44:53Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7158",
            "html_url": "https://github.com/run-llama/llama_index/pull/7158",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7158.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7158.patch",
            "merged_at": "2023-08-04T18:44:53Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7158/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7158/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7157",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7157/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7157/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7157/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7157",
        "id": 1837147922,
        "node_id": "PR_kwDOIWuq585XOAqo",
        "number": 7157,
        "title": "Logan/langchain wrapper",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T18:03:25Z",
        "updated_at": "2023-08-04T18:25:48Z",
        "closed_at": "2023-08-04T18:25:48Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7157",
            "html_url": "https://github.com/run-llama/llama_index/pull/7157",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7157.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7157.patch",
            "merged_at": "2023-08-04T18:25:48Z"
        },
        "body": "# Description\r\n\r\nRemoves the need for specifying the langchain wrapper for embedding models, at least for the service context.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7157/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7157/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7156",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7156/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7156/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7156/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7156",
        "id": 1837115555,
        "node_id": "I_kwDOIWuq585tgCij",
        "number": 7156,
        "title": "llama_index.text_splitter is not available ",
        "user": {
            "login": "oroojlooy",
            "id": 20797260,
            "node_id": "MDQ6VXNlcjIwNzk3MjYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/20797260?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/oroojlooy",
            "html_url": "https://github.com/oroojlooy",
            "followers_url": "https://api.github.com/users/oroojlooy/followers",
            "following_url": "https://api.github.com/users/oroojlooy/following{/other_user}",
            "gists_url": "https://api.github.com/users/oroojlooy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/oroojlooy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/oroojlooy/subscriptions",
            "organizations_url": "https://api.github.com/users/oroojlooy/orgs",
            "repos_url": "https://api.github.com/users/oroojlooy/repos",
            "events_url": "https://api.github.com/users/oroojlooy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/oroojlooy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-04T17:32:09Z",
        "updated_at": "2023-08-04T19:00:03Z",
        "closed_at": "2023-08-04T19:00:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nCell In[26], line 1\r\n----> 1 from llama_index.text_splitter import SentenceSplitter\r\n\r\nModuleNotFoundError: No module named 'llama_index.text_splitter'\n\n### Version\n\nllama_index-0.7.18\n\n### Steps to Reproduce\n\nfrom llama_index.text_splitter import SentenceSplitter\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7156/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7156/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7155",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7155/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7155/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7155/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7155",
        "id": 1836908600,
        "node_id": "PR_kwDOIWuq585XNM2R",
        "number": 7155,
        "title": "add references to typescript package ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T14:56:07Z",
        "updated_at": "2023-08-04T15:16:53Z",
        "closed_at": "2023-08-04T15:16:52Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7155",
            "html_url": "https://github.com/run-llama/llama_index/pull/7155",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7155.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7155.patch",
            "merged_at": "2023-08-04T15:16:52Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7155/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7155/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7154",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7154/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7154/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7154/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7154",
        "id": 1836856305,
        "node_id": "PR_kwDOIWuq585XNBQx",
        "number": 7154,
        "title": "change default router to pydantic",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T14:26:47Z",
        "updated_at": "2023-08-04T15:10:31Z",
        "closed_at": "2023-08-04T15:10:30Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7154",
            "html_url": "https://github.com/run-llama/llama_index/pull/7154",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7154.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7154.patch",
            "merged_at": "2023-08-04T15:10:30Z"
        },
        "body": "# Description\r\n\r\nChanges the router query engine to default to pydantic when possible.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] tested in a notebook\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7154/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7154/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7153",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7153/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7153/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7153/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7153",
        "id": 1836650265,
        "node_id": "I_kwDOIWuq585teQ8Z",
        "number": 7153,
        "title": "[Bug]: MongoDocumentStore document_exists(str) always return false, when it doesn't store document data ",
        "user": {
            "login": "luoning9",
            "id": 69835610,
            "node_id": "MDQ6VXNlcjY5ODM1NjEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/69835610?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/luoning9",
            "html_url": "https://github.com/luoning9",
            "followers_url": "https://api.github.com/users/luoning9/followers",
            "following_url": "https://api.github.com/users/luoning9/following{/other_user}",
            "gists_url": "https://api.github.com/users/luoning9/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/luoning9/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/luoning9/subscriptions",
            "organizations_url": "https://api.github.com/users/luoning9/orgs",
            "repos_url": "https://api.github.com/users/luoning9/repos",
            "events_url": "https://api.github.com/users/luoning9/events{/privacy}",
            "received_events_url": "https://api.github.com/users/luoning9/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-04T12:20:38Z",
        "updated_at": "2023-11-10T16:02:23Z",
        "closed_at": "2023-11-10T16:02:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am using MongoDB as document store and index store, Chromadb as vector store. \r\n\r\nmy code here, I have build all index of the sample document before run this:\r\n```\r\n# init Chroma collection\r\nchroma_client = chromadb.PersistentClient(path=\"./storage/chromadb/\")\r\nchroma_collection = chroma_client.create_collection(name=\"docs_first\",\r\n                                                    get_or_create=True)\r\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n\r\n# mongodb index store\r\n# create (or load) index store\r\nindex_store = MongoIndexStore.from_uri(uri=MONGODB_URI)\r\ndoc_store = MongoDocumentStore.from_uri(uri=MONGODB_URI)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore=doc_store,\r\n    index_store=index_store,\r\n    vector_store=vector_store\r\n)\r\n\r\nindex = load_index_from_storage(storage_context, index_id=INDEX_ID)\r\ndocuments = SimpleDirectoryReader('examples/paul_graham_essay/data',\r\n                                  filename_as_id=True).load_data()\r\nfor doc in documents:\r\n    doc_id = doc.get_doc_id()\r\n    print(f\"doc exists? {index.docstore.document_exists(doc_id)}\")\r\n\r\n```\r\nrun above codes always output \r\n`doc examples/paul_graham_essay/data/paul_graham_essay.txt exists? False`\r\n\r\nAfter repeated tests, I believe the reasons are as follows: \r\n1. The store_text parameter of ChromeVectorStore is set to True, so MongoDocumentStore does not store data. \r\n2. MongoDocumentStore.document_exists(str) calls KVDocumentStore.document_exists(str), which ultimately calls MongoDBKVStore.get(str, \"docstore/data\").\r\n3. since there is no \"docstore/data\" collection in the database instance, get() will always return None.\r\n\r\nHowever, at the same time, the output of get_document_hash(str) is as expected, because it uses the collection \"metadata\" instead of \"data\".\r\n\r\nClearly, these two functions of DocumentStore, get_document_hash(str) and document_exists(str) , should produce consistent results.  \r\n\r\n\n\n### Version\n\n0.7.18\n\n### Steps to Reproduce\n\nFirst, use the following code to generate an indices\uff1a\r\n```\r\nINDEX_ID = \"paul\"\r\n# init Chroma collection\r\nchroma_client = chromadb.PersistentClient(path=\"./storage/chromadb/\")\r\nchroma_collection = chroma_client.create_collection(name=\"docs_first\",\r\n                                                    get_or_create=True)\r\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n\r\n# mongodb index store\r\n# create (or load) index store\r\nindex_store = MongoIndexStore.from_uri(uri=MONGODB_URI)\r\ndoc_store = MongoDocumentStore.from_uri(uri=MONGODB_URI)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore=doc_store,\r\n    index_store=index_store,\r\n    vector_store = vector_store\r\n)\r\ndoc_store.get_document()\r\ndocuments = SimpleDirectoryReader('examples/paul_graham_essay/data',\r\n                                  filename_as_id=True).load_data()\r\n# create new indices\r\nindex = GPTVectorStoreIndex.from_documents(documents=documents,\r\n                                           storage_context=storage_context)\r\nindex.set_index_id(INDEX_ID)\r\nstorage_context.persist()\r\n```\r\nThen you can run the previous code.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7153/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7153/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7152",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7152/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7152/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7152/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7152",
        "id": 1836391727,
        "node_id": "PR_kwDOIWuq585XLb4F",
        "number": 7152,
        "title": "Updated response mode docs",
        "user": {
            "login": "tilleul",
            "id": 3061106,
            "node_id": "MDQ6VXNlcjMwNjExMDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3061106?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tilleul",
            "html_url": "https://github.com/tilleul",
            "followers_url": "https://api.github.com/users/tilleul/followers",
            "following_url": "https://api.github.com/users/tilleul/following{/other_user}",
            "gists_url": "https://api.github.com/users/tilleul/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tilleul/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tilleul/subscriptions",
            "organizations_url": "https://api.github.com/users/tilleul/orgs",
            "repos_url": "https://api.github.com/users/tilleul/repos",
            "events_url": "https://api.github.com/users/tilleul/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tilleul/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T09:25:29Z",
        "updated_at": "2023-08-04T15:00:55Z",
        "closed_at": "2023-08-04T15:00:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7152",
            "html_url": "https://github.com/run-llama/llama_index/pull/7152",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7152.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7152.patch",
            "merged_at": "2023-08-04T15:00:55Z"
        },
        "body": "# Description\r\n\r\nAdded details about the first three main response modes (how they work). \r\n\r\nWith the previously given description, it was particularly difficult to understand how the \"tree summarize\" mode was working under the hood. I hope this clarifies a bit.\r\n\r\nThe response modes probably deserve even more explanations as the differences are sometimes subtle and it's not always clear how it will impact the whole process.\r\n\r\nAlso replicated the \"response mode\" section of \"response synthesizers\" chapter in \"query engine\" chapter (was outdated).\r\n\r\n## Type of Change\r\n- [x] doc update/standardisation\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7152/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7152/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7151",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7151/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7151/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7151/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7151",
        "id": 1836275299,
        "node_id": "PR_kwDOIWuq585XLDLZ",
        "number": 7151,
        "title": "feat: Add Xorbits Inference for local deployment",
        "user": {
            "login": "Bojun-Feng",
            "id": 102875484,
            "node_id": "U_kgDOBiHBXA",
            "avatar_url": "https://avatars.githubusercontent.com/u/102875484?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Bojun-Feng",
            "html_url": "https://github.com/Bojun-Feng",
            "followers_url": "https://api.github.com/users/Bojun-Feng/followers",
            "following_url": "https://api.github.com/users/Bojun-Feng/following{/other_user}",
            "gists_url": "https://api.github.com/users/Bojun-Feng/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Bojun-Feng/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Bojun-Feng/subscriptions",
            "organizations_url": "https://api.github.com/users/Bojun-Feng/orgs",
            "repos_url": "https://api.github.com/users/Bojun-Feng/repos",
            "events_url": "https://api.github.com/users/Bojun-Feng/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Bojun-Feng/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-04T08:06:55Z",
        "updated_at": "2023-08-09T16:08:11Z",
        "closed_at": "2023-08-09T16:08:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7151",
            "html_url": "https://github.com/run-llama/llama_index/pull/7151",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7151.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7151.patch",
            "merged_at": "2023-08-09T16:08:00Z"
        },
        "body": "# Description\r\n\r\nThis PR adds Xorbits Inference (Xinference for short) as a custom LLM, together with proper tests and usage examples. Xorbits Inference is a distributed deployment framework so users can scale the local deployment of custom models.\r\n\r\nSee #6845 for a previous discussion regarding the integration of Xorbits Inference.\r\n\r\nHere is an excerpt from the discussion with performance [data and charts](https://github.com/jerryjliu/llama_index/issues/6845#issuecomment-1641488507).\r\n\r\n## Type of Change\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7151/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7151/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7150",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7150/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7150/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7150/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7150",
        "id": 1836010575,
        "node_id": "PR_kwDOIWuq585XKL1L",
        "number": 7150,
        "title": "Logan/migrate response synth v2 (redo AGAIN)",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T03:35:20Z",
        "updated_at": "2023-08-04T18:26:05Z",
        "closed_at": "2023-08-04T18:26:04Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7150",
            "html_url": "https://github.com/run-llama/llama_index/pull/7150",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7150.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7150.patch",
            "merged_at": "2023-08-04T18:26:04Z"
        },
        "body": "# Description\r\n\r\nThis PR migrates the response synthesizer to use GPT-3.5-Turbo. In addition, some other changes are included\r\n\r\n- remove templates from the wandb callback\r\n- stop silently failing on the wandb callback\r\n- stop using `from_prompt` in tree summarize (this was destroying the chat message template) \r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested on tons of response modes and top k's\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7150/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7150/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7149",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7149/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7149/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7149/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7149",
        "id": 1836006936,
        "node_id": "PR_kwDOIWuq585XKLEk",
        "number": 7149,
        "title": "(test, deleting soon)",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T03:30:12Z",
        "updated_at": "2023-08-28T17:11:39Z",
        "closed_at": "2023-08-04T03:30:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7149",
            "html_url": "https://github.com/run-llama/llama_index/pull/7149",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7149.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7149.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7149/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7149/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7148",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7148/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7148/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7148/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7148",
        "id": 1836006033,
        "node_id": "PR_kwDOIWuq585XKK32",
        "number": 7148,
        "title": "Migrate response synth to gpt-3.5 (redo)",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-04T03:29:03Z",
        "updated_at": "2023-08-28T17:11:40Z",
        "closed_at": "2023-08-04T03:29:18Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7148",
            "html_url": "https://github.com/run-llama/llama_index/pull/7148",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7148.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7148.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nThis PR migrates the response synthesizer to use GPT-3.5-Turbo. In addition, some other changes are included\r\n\r\n- remove templates from the wandb callback\r\n- stop silently failing on the wandb callback\r\n- stop using `from_prompt` in tree summarize (this was destroying the chat message template) \r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested on tons of response modes and top k's\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7148/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7148/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7147",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7147/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7147/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7147/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7147",
        "id": 1835920247,
        "node_id": "I_kwDOIWuq585tbet3",
        "number": 7147,
        "title": "[Bug]: Indexing error after deleting then re-adding a page",
        "user": {
            "login": "Audino723",
            "id": 73172722,
            "node_id": "MDQ6VXNlcjczMTcyNzIy",
            "avatar_url": "https://avatars.githubusercontent.com/u/73172722?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Audino723",
            "html_url": "https://github.com/Audino723",
            "followers_url": "https://api.github.com/users/Audino723/followers",
            "following_url": "https://api.github.com/users/Audino723/following{/other_user}",
            "gists_url": "https://api.github.com/users/Audino723/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Audino723/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Audino723/subscriptions",
            "organizations_url": "https://api.github.com/users/Audino723/orgs",
            "repos_url": "https://api.github.com/users/Audino723/repos",
            "events_url": "https://api.github.com/users/Audino723/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Audino723/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-04T01:11:11Z",
        "updated_at": "2023-11-10T16:01:41Z",
        "closed_at": "2023-11-10T16:01:41Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am exploring a CRUD system using the llama index. The system utilizes the refresh_ref_docs() function. First I tried to delete a page from a document, and the system works. But after re-adding the deleted page, the system crashed because of KeyError. crashed\n\n### Version\n\n0.6.31\n\n### Steps to Reproduce\n\n`from llama_index import SimpleDirectoryReader, LLMPredictor, GPTVectorStoreIndex, load_index_from_storage\r\nfrom llama_index.storage.storage_context import StorageContext\r\nfrom llama_index.indices.service_context import ServiceContext\r\nfrom llama_index import set_global_service_context\r\nfrom langchain.chat_models import ChatOpenAI\r\nimport openai\r\nimport gradio as gr\r\nimport sys, os\r\nimport logging\r\n\r\nfrom dotenv import load_dotenv\r\nload_dotenv()\r\n\r\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\r\n\r\n# enable INFO level logging\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\n#define LLM service\r\nllm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.0, model_name=\"gpt-3.5-turbo\"))\r\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\r\nset_global_service_context(service_context)\r\n\r\ndef load_index(directory_path):\r\n     \r\n    documents = SimpleDirectoryReader(directory_path, filename_as_id=True).load_data()\r\n    print(f\"loaded documents with {len(documents)} pages\")\r\n    \r\n    try:\r\n        # Rebuild storage context\r\n        storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\r\n        # Try to load the index from storage\r\n        index = load_index_from_storage(storage_context)\r\n        logging.info(\"Index loaded from storage.\")\r\n    except FileNotFoundError:\r\n        # If index not found, create a new one\r\n        logging.info(\"Index not found. Creating a new one...\")\r\n        index = GPTVectorStoreIndex.from_documents(documents)\r\n        # Persist index to disk\r\n        index.storage_context.persist()\r\n        logging.info(\"New index created and persisted to storage.\")\r\n\r\n    # Run refresh_ref_docs method to check for document updates\r\n    refreshed_docs = index.refresh_ref_docs(documents, update_kwargs={\"delete_kwargs\": {'delete_from_docstore': True}})\r\n    print(refreshed_docs)\r\n    print('Number of newly inserted/refreshed docs: ', sum(refreshed_docs))\r\n\r\n    index.storage_context.persist()\r\n    logging.info(\"Index refreshed and persisted to storage.\")\r\n\r\n    return index, documents\r\n\r\n\r\ndef data_querying(input_text):\r\n    # Load index\r\n    index, documents = load_index(\"data\")\r\n\r\n    #queries the index with the input text\r\n    response = index.as_query_engine().query(input_text)\r\n    \r\n    return response.response\r\n`\r\n1. Select a document\r\n2. Use it as initial document\r\n3. Delete a page\r\n4. Then re-add that page\r\n5. It will resulted in key error\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7147/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7147/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7146",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7146/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7146/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7146/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7146",
        "id": 1835868042,
        "node_id": "PR_kwDOIWuq585XJuMm",
        "number": 7146,
        "title": "DOCS: added local llama2 notebook",
        "user": {
            "login": "tjaffri",
            "id": 749277,
            "node_id": "MDQ6VXNlcjc0OTI3Nw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/749277?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tjaffri",
            "html_url": "https://github.com/tjaffri",
            "followers_url": "https://api.github.com/users/tjaffri/followers",
            "following_url": "https://api.github.com/users/tjaffri/following{/other_user}",
            "gists_url": "https://api.github.com/users/tjaffri/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tjaffri/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tjaffri/subscriptions",
            "organizations_url": "https://api.github.com/users/tjaffri/orgs",
            "repos_url": "https://api.github.com/users/tjaffri/repos",
            "events_url": "https://api.github.com/users/tjaffri/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tjaffri/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-03T23:56:45Z",
        "updated_at": "2023-08-07T18:05:42Z",
        "closed_at": "2023-08-07T17:22:11Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7146",
            "html_url": "https://github.com/run-llama/llama_index/pull/7146",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7146.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7146.patch",
            "merged_at": "2023-08-07T17:22:11Z"
        },
        "body": "Adds a simple notebook to docs, talking about how to use local llama2 (without replicate etc.)\r\n\r\nNote: I am not sure if something else needs to be done to get this to show up in the docs site, please let me know if so.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7146/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7146/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7145",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7145/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7145/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7145/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7145",
        "id": 1835791178,
        "node_id": "PR_kwDOIWuq585XJd3x",
        "number": 7145,
        "title": "[version] bump version to 0.7.18",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-03T22:05:02Z",
        "updated_at": "2023-08-03T22:10:08Z",
        "closed_at": "2023-08-03T22:10:07Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7145",
            "html_url": "https://github.com/run-llama/llama_index/pull/7145",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7145.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7145.patch",
            "merged_at": "2023-08-03T22:10:07Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7145/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7145/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7144",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7144/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7144/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7144/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7144",
        "id": 1835788317,
        "node_id": "PR_kwDOIWuq585XJdRq",
        "number": 7144,
        "title": "update docs on graphs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-03T22:01:49Z",
        "updated_at": "2023-08-03T23:28:22Z",
        "closed_at": "2023-08-03T23:28:22Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7144",
            "html_url": "https://github.com/run-llama/llama_index/pull/7144",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7144.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7144.patch",
            "merged_at": "2023-08-03T23:28:22Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7144/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7144/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7143",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7143/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7143/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7143/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7143",
        "id": 1835678555,
        "node_id": "I_kwDOIWuq585tajtb",
        "number": 7143,
        "title": "[Bug]: `load_github_repo` gets stuck when I test it on this very repo",
        "user": {
            "login": "leonardoventurini",
            "id": 17411182,
            "node_id": "MDQ6VXNlcjE3NDExMTgy",
            "avatar_url": "https://avatars.githubusercontent.com/u/17411182?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/leonardoventurini",
            "html_url": "https://github.com/leonardoventurini",
            "followers_url": "https://api.github.com/users/leonardoventurini/followers",
            "following_url": "https://api.github.com/users/leonardoventurini/following{/other_user}",
            "gists_url": "https://api.github.com/users/leonardoventurini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/leonardoventurini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/leonardoventurini/subscriptions",
            "organizations_url": "https://api.github.com/users/leonardoventurini/orgs",
            "repos_url": "https://api.github.com/users/leonardoventurini/repos",
            "events_url": "https://api.github.com/users/leonardoventurini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/leonardoventurini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-03T20:18:29Z",
        "updated_at": "2023-11-09T16:03:07Z",
        "closed_at": "2023-11-09T16:03:06Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI tried with different embedding models and I get the same result, if I exclude one file it gets stuck on another or perhaps it has nothing to do with files.\r\n\r\nThis is the exact point where it stops now:\r\n\r\n<img width=\"1229\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/17411182/00d99037-ea1f-4a71-be34-756f2f43ba46\">\r\n\r\nI even wrote a custom reader with the ability to exclude some things in the attempt to narrow it down to a single file, but no luck. The problem does not seem to be in the reader.\r\n\r\n```\r\n    documents = CustomGithubRepositoryReader(\r\n        github_token=os.environ.get(\"GITHUB_TOKEN\", \"\"),\r\n        owner=owner,\r\n        repo=repo,\r\n        verbose=True,\r\n        use_parser=False,\r\n        include_directories=include_directories,\r\n        ignore_file_extensions=ignore_extensions,\r\n        ignore_directories=ignore_directories,\r\n        ignore_files=ignore_files,\r\n    ).load_data(branch=branch)\r\n\r\n    # This runs fine\r\n    print(\"Loaded\", len(documents), \"documents\")\r\n\r\n    index.refresh_ref_docs(documents=documents, verbose=True)\r\n    index.storage_context.persist()\r\n\r\n    engine = index.as_query_engine(**query_engine_kwargs)\r\n```\r\n\r\nWhat am I doing wrong? Other files, websites work fine with other readers.\n\n### Version\n\n0.7.13\n\n### Steps to Reproduce\n\n1. Run `GithubRepositoryReader` on the `llama_index` repository.\r\n2. Refresh docs with `refresh_ref_docs`.\n\n### Relevant Logs/Tracbacks\n\n```shell\nTime to get blobs ([('example.html', 730874), ('pyproject.toml', 276), ('requirements.txt', 323), ('setup.py', 1199)]): 0.57 seconds\r\ngenerating document for example.html\r\ngot 729788 characters- adding to documents - example.html\r\ngenerating document for pyproject.toml\r\ngot 276 characters- adding to documents - pyproject.toml\r\ngenerating document for requirements.txt\r\ngot 323 characters- adding to documents - requirements.txt\r\ngenerating document for setup.py\r\ngot 1199 characters- adding to documents - setup.py\r\nLoaded 19 documents\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: .DS_Store\r\n# Byte-compiled / optimized / DLL fil...\r\n> Adding chunk: .DS_Store\r\n# Byte-compiled / optimized / DLL fil...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Unit test / coverage reports\r\nhtmlcov/\r\n.tox/\r\n.no...\r\n> Adding chunk: Unit test / coverage reports\r\nhtmlcov/\r\n.tox/\r\n.no...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:   According to pypa/pipenv#598, it is recommend...\r\n> Adding chunk:   According to pypa/pipenv#598, it is recommend...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Rope project settings\r\n.ropeproject\r\n\r\n# mkdocs do...\r\n> Adding chunk: Rope project settings\r\n.ropeproject\r\n\r\n# mkdocs do...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  3.10it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: repos:\r\n  - repo: https://github.com/charliermar...\r\n> Adding chunk: repos:\r\n  - repo: https://github.com/charliermar...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 134.16it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: version: 2\r\n\r\nsphinx:\r\n  configuration: docs/conf....\r\n> Adding chunk: version: 2\r\n\r\nsphinx:\r\n  configuration: docs/conf....\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 133.61it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # ChangeLog\r\n\r\n## Unreleased\r\n\r\n### New Features\r\n- ...\r\n> Adding chunk: # ChangeLog\r\n\r\n## Unreleased\r\n\r\n### New Features\r\n- ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: to support memory modules (minor breaking chang...\r\n> Adding chunk: to support memory modules (minor breaking chang...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: - 2023-07-28\r\n\r\n### New Features\r\n- Added HotpotQA...\r\n> Adding chunk: - 2023-07-28\r\n\r\n### New Features\r\n- Added HotpotQA...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: [0.7.13] - 2023-07-26\r\n\r\n### New Features\r\n- Suppo...\r\n> Adding chunk: [0.7.13] - 2023-07-26\r\n\r\n### New Features\r\n- Suppo...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Added `OpenInferenceCallback` for storing gener...\r\n> Adding chunk: Added `OpenInferenceCallback` for storing gener...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: query engine (#6935)\r\n- Add metadata filtering s...\r\n> Adding chunk: query engine (#6935)\r\n- Add metadata filtering s...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: (#6937)\r\n- Log embedding vectors to callback man...\r\n> Adding chunk: (#6937)\r\n- Log embedding vectors to callback man...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: explicitly setting `streaming=True` in the unde...\r\n> Adding chunk: explicitly setting `streaming=True` in the unde...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: graph querying w/ cypyer+nebula (#6642)\r\n- Added...\r\n> Adding chunk: graph querying w/ cypyer+nebula (#6642)\r\n- Added...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Breaking/Deprecated API Changes\r\n- Replace react...\r\n> Adding chunk: Breaking/Deprecated API Changes\r\n- Replace react...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: docs (#6833)\r\n- Fixes Azure gpt-35-turbo model n...\r\n> Adding chunk: docs (#6833)\r\n- Fixes Azure gpt-35-turbo model n...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: of sub questions in the callback manager (#6745...\r\n> Adding chunk: of sub questions in the callback manager (#6745...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Support prefix messages (e.g. system prompt) in...\r\n> Adding chunk: Support prefix messages (e.g. system prompt) in...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: 2023-07-05\r\n\r\n### New Features\r\n- Streaming suppor...\r\n> Adding chunk: 2023-07-05\r\n\r\n### New Features\r\n- Streaming suppor...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: for more details on new callback based token co...\r\n> Adding chunk: for more details on new callback based token co...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: - 2023-07-02\r\n\r\n### New Features\r\n\r\n- add optional ...\r\n> Adding chunk: - 2023-07-02\r\n\r\n### New Features\r\n\r\n- add optional ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: link to docs (#6660)\r\n- Allow null values for th...\r\n> Adding chunk: link to docs (#6660)\r\n- Allow null values for th...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: line with llama-hub (#6630)\r\n- Remove usage of S...\r\n> Adding chunk: line with llama-hub (#6630)\r\n- Remove usage of S...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Nits\r\n\r\n- Fix serialization for OpenSearch vector...\r\n> Adding chunk: Nits\r\n\r\n- Fix serialization for OpenSearch vector...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Nodes no longer require flat metadata dictionar...\r\n> Adding chunk: Nodes no longer require flat metadata dictionar...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: `Node`) has a `id_` or `node_id` property, rath...\r\n> Adding chunk: `Node`) has a `id_` or `node_id` property, rath...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: add SQL Schema Node Mapping + SQLTableRetriever...\r\n> Adding chunk: add SQL Schema Node Mapping + SQLTableRetriever...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: query engine (#6518)\r\n- pydantic selector suppor...\r\n> Adding chunk: query engine (#6518)\r\n- pydantic selector suppor...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: New Features\r\n\r\n- query planning tool with OpenAI...\r\n> Adding chunk: New Features\r\n\r\n- query planning tool with OpenAI...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Bug Fixes / Nits\r\n\r\n- update mongo interface (#65...\r\n> Adding chunk: Bug Fixes / Nits\r\n\r\n- update mongo interface (#65...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: which can be enabled as a query mode (#6446)\r\n\r\n#...\r\n> Adding chunk: which can be enabled as a query mode (#6446)\r\n\r\n#...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: - 2023-06-13\r\n\r\n### New Features\r\n\r\n- Added FLARE q...\r\n> Adding chunk: - 2023-06-13\r\n\r\n### New Features\r\n\r\n- Added FLARE q...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Mongo demo improvements (#6406)\r\n- Fix notebook ...\r\n> Adding chunk: Mongo demo improvements (#6406)\r\n- Fix notebook ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: all metadata from the docstore (#6192)\r\n- FIxed ...\r\n> Adding chunk: all metadata from the docstore (#6192)\r\n- FIxed ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Miscellaneous\r\n\r\n- Minor docs updates\r\n- Added git...\r\n> Adding chunk: Miscellaneous\r\n\r\n- Minor docs updates\r\n- Added git...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Minor doc updates\r\n\r\n## [v0.6.18] - 2023-06-02\r\n\r\n#...\r\n> Adding chunk: Minor doc updates\r\n\r\n## [v0.6.18] - 2023-06-02\r\n\r\n#...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 22.48it/s]\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 23.85it/s]\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 23.47it/s]\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 160.75it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: cff-version: 1.2.0\r\nmessage: \"If you use this so...\r\n> Adding chunk: cff-version: 1.2.0\r\nmessage: \"If you use this so...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 141.40it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # Contributing to LlamaIndex\r\n\r\nInterested in con...\r\n> Adding chunk: # Contributing to LlamaIndex\r\n\r\nInterested in con...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: welcome contributions in _all_ modules shown ab...\r\n> Adding chunk: welcome contributions in _all_ modules shown ab...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: takes arbitrary arguments as input (e.g. path t...\r\n> Adding chunk: takes arbitrary arguments as input (e.g. path t...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: LlamaHub data loader for it yet? Make a PR!\r\n\r\n--...\r\n> Adding chunk: LlamaHub data loader for it yet? Make a PR!\r\n\r\n--...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: [the API reference](https://gpt-index.readthedo...\r\n> Adding chunk: [the API reference](https://gpt-index.readthedo...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: outputs a sequence of `str`\r\n\r\n**Examples**:\r\n\r\n- [...\r\n> Adding chunk: outputs a sequence of `str`\r\n\r\n**Examples**:\r\n\r\n- [...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: ingested documents (i.e., `Node` objects) are s...\r\n> Adding chunk: ingested documents (i.e., `Node` objects) are s...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: given document IDs.\r\n- `query` retrieves top-k m...\r\n> Adding chunk: given document IDs.\r\n- `query` retrieves top-k m...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: for full details.\r\n\r\n---\r\n\r\n#### Retrievers\r\n\r\nOur re...\r\n> Adding chunk: for full details.\r\n\r\n---\r\n\r\n#### Retrievers\r\n\r\nOur re...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: [List Index Retriever](https://github.com/jerry...\r\n> Adding chunk: [List Index Retriever](https://github.com/jerry...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: in a `retriever` as input as well as a `BaseSyn...\r\n> Adding chunk: in a `retriever` as input as well as a `BaseSyn...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Transforms\r\n\r\nA query transform augments a raw qu...\r\n> Adding chunk: Transforms\r\n\r\nA query transform augments a raw qu...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: [guide](https://gpt-index.readthedocs.io/en/lat...\r\n> Adding chunk: [guide](https://gpt-index.readthedocs.io/en/lat...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: a list of retrieve nodes given configuration an...\r\n> Adding chunk: a list of retrieve nodes given configuration an...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: fetchs additional nodes to augment context base...\r\n> Adding chunk: fetchs additional nodes to augment context base...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: [Langchain Output Parser](https://github.com/je...\r\n> Adding chunk: [Langchain Output Parser](https://github.com/je...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: \ud83c\udf89 Add Usage Examples\r\n\r\nIf you have applied Llama...\r\n> Adding chunk: \ud83c\udf89 Add Usage Examples\r\n\r\nIf you have applied Llama...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: or what you thought of in the shower, we'd love...\r\n> Adding chunk: or what you thought of in the shower, we'd love...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: for more details\r\non how to fork the repo and cl...\r\n> Adding chunk: for more details\r\non how to fork the repo and cl...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: `example notebook`.\r\n\r\n#### Formatting/Linting\r\n\r\nY...\r\n> Adding chunk: `example notebook`.\r\n\r\n#### Formatting/Linting\r\n\r\nY...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: to showcase\r\nthis feature.\r\n\r\nExample notebooks ca...\r\n> Adding chunk: to showcase\r\nthis feature.\r\n\r\nExample notebooks ca...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 20.78it/s]\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 21.25it/s]\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 148.87it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: The MIT License\r\n\r\nCopyright (c) Jerry Liu\r\n\r\nPermi...\r\n> Adding chunk: The MIT License\r\n\r\nCopyright (c) Jerry Liu\r\n\r\nPermi...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLD...\r\n> Adding chunk: IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLD...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 107.35it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: include llama_index/py.typed\r\ninclude llama_inde...\r\n> Adding chunk: include llama_index/py.typed\r\ninclude llama_inde...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 156.07it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: GIT_ROOT ?= $(shell git rev-parse --show-toplev...\r\n> Adding chunk: GIT_ROOT ?= $(shell git rev-parse --show-toplev...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 127.77it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # \ud83d\uddc2\ufe0f LlamaIndex \ud83e\udd99\r\n\r\nLlamaIndex (GPT Index) is a ...\r\n> Adding chunk: # \ud83d\uddc2\ufe0f LlamaIndex \ud83e\udd99\r\n\r\nLlamaIndex (GPT Index) is a ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: README is not updated as frequently as the docu...\r\n> Adding chunk: README is not updated as frequently as the docu...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Provides an **advanced retrieval/query interfac...\r\n> Adding chunk: Provides an **advanced retrieval/query interfac...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: https://gpt-index.readthedocs.io/en/latest/. \r\n\r\n...\r\n> Adding chunk: https://gpt-index.readthedocs.io/en/latest/. \r\n\r\n...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: default, data is stored in-memory.\r\nTo persist t...\r\n> Adding chunk: default, data is stored in-memory.\r\nTo persist t...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: \ud83d\udcd6 Citation\r\n\r\nReference to cite if you use LlamaI...\r\n> Adding chunk: \ud83d\udcd6 Citation\r\n\r\nReference to cite if you use LlamaI...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 37.76it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # requirements for external data\r\n\r\nwikipedia\r\npym...\r\n> Adding chunk: # requirements for external data\r\n\r\nwikipedia\r\npym...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 138.67it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # Documentation Guide\r\n\r\n## A guide for docs cont...\r\n> Adding chunk: # Documentation Guide\r\n\r\n## A guide for docs cont...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: `sphinx` and its extension):\r\n\r\n\r\npip insta...\r\n> Adding chunk: `sphinx` and its extension):\r\n\r\nbash\r\npip insta...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: writing documentation.\r\n\r\nSimply run the followin...\r\n> Adding chunk: writing documentation.\r\n\r\nSimply run the followin...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 69.44it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: \"\"\"Configuration for sphinx.\"\"\"\r\n# Configuration...\r\n> Adding chunk: \"\"\"Configuration for sphinx.\"\"\"\r\n# Configuration...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:    version = f.read()\r\n\r\n# -- Project information...\r\n> Adding chunk:    version = f.read()\r\n\r\n# -- Project information...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:    \"sphinx.ext.mathjax\",\r\n    \"m2r2\",\r\n    \"myst_...\r\n> Adding chunk:    \"sphinx.ext.mathjax\",\r\n    \"m2r2\",\r\n    \"myst_...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: = [\"_static\"]\r\n\r\nhtml_css_files = [\r\n    \"css/cust...\r\n> Adding chunk: = [\"_static\"]\r\n\r\nhtml_css_files = [\r\n    \"css/cust...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 34.29it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: # Deprecated Terms\r\n\r\nAs LlamaIndex continues to ...\r\n> Adding chunk: # Deprecated Terms\r\n\r\nAs LlamaIndex continues to ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: has been renamed to `VectorStoreIndex`, but it ...\r\n> Adding chunk: has been renamed to `VectorStoreIndex`, but it ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: and max_input_size/\r\n\r\nThe `max_input_size` param...\r\n> Adding chunk: and max_input_size/\r\n\r\nThe `max_input_size` param...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 63.91it/s]\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: .. LlamaIndex documentation master file, create...\r\n> Adding chunk: .. LlamaIndex documentation master file, create...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: data can be distributed across siloed applicati...\r\n> Adding chunk: data can be distributed across siloed applicati...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: your data.\r\n- **Data agents** are LLM-powered kn...\r\n> Adding chunk: your data.\r\n- **Data agents** are LLM-powered kn...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: Started\r\n****************\r\n``pip install llama-in...\r\n> Adding chunk: Started\r\n****************\r\n``pip install llama-in...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: download or contribute, find LlamaIndex on:\r\n\r\n- ...\r\n> Adding chunk: download or contribute, find LlamaIndex on:\r\n\r\n- ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk: top of LlamaIndex\r\n\r\n.. toctree::\r\n   :maxdepth: 1...\r\n> Adding chunk: top of LlamaIndex\r\n\r\n.. toctree::\r\n   :maxdepth: 1...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:   core_modules/data_modules/connector/root.md\r\n ...\r\n> Adding chunk:   core_modules/data_modules/connector/root.md\r\n ...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:   core_modules/query_modules/query_engine/root....\r\n> Adding chunk:   core_modules/query_modules/query_engine/root....\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:   core_modules/supporting_modules/service_conte...\r\n> Adding chunk:   core_modules/supporting_modules/service_conte...\r\nDEBUG:llama_index.node_parser.node_utils:> Adding chunk:   :maxdepth: 1\r\n   :caption: API Reference\r\n   :h...\r\n> Adding chunk:   :maxdepth: 1\r\n   :caption: API Reference\r\n   :h...\r\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 21.88it/s]\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7143/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7143/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7142",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7142/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7142/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7142/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7142",
        "id": 1835662049,
        "node_id": "I_kwDOIWuq585tafrh",
        "number": 7142,
        "title": "[Question]: Better implementation/embedding takes too long.",
        "user": {
            "login": "kylemassimilian",
            "id": 31603204,
            "node_id": "MDQ6VXNlcjMxNjAzMjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/31603204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylemassimilian",
            "html_url": "https://github.com/kylemassimilian",
            "followers_url": "https://api.github.com/users/kylemassimilian/followers",
            "following_url": "https://api.github.com/users/kylemassimilian/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylemassimilian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylemassimilian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylemassimilian/subscriptions",
            "organizations_url": "https://api.github.com/users/kylemassimilian/orgs",
            "repos_url": "https://api.github.com/users/kylemassimilian/repos",
            "events_url": "https://api.github.com/users/kylemassimilian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylemassimilian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-03T20:04:05Z",
        "updated_at": "2023-09-12T02:09:10Z",
        "closed_at": "2023-09-12T02:09:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI'm trying to create a standard Q&A app over my documents. I am at the step of embedding these docs and am struggling with how slow the process is. At the time of this writing, I'm currently attempting to embed 29 files as a test, for a total of 150MB. It has been running for 24 minutes and is still not complete - Is this to be expected? I realize embedding is a resource intense process, but how do you realistically build an application with this bottleneck? This function currently works with 1-5 files. My target knowledge corpus size is 10GB. Is this feasible? I have yet to see a demo that shows an implementation of RAG using more than a few files. If there is a better way, could someone tell me what I should do differently? Thank you\r\n\r\n```\r\n`def generate_or_return_embeddings():\r\n    #Load files\r\n    documents = SimpleDirectoryReader('Investments', recursive=True).load_data()\r\n    \r\n    #Define embedding model\r\n    embed_model = LangchainEmbedding(\r\n        HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\r\n    )\r\n    #Define service context - bundle of commonly used resources using during indexing/querying stage in pipeline\r\n    service_context = ServiceContext.from_defaults(embed_model=embed_model) \r\n\r\n    #Connect to Chroma\r\n    chroma_db = chromadb.HttpClient(host=\"\", port=8000)\r\n    #Name the collection\r\n    collection_name = \"alpha-mini-1\"\r\n    collections = [col.name for col in chroma_db.list_collections()]\r\n    \r\n    if collection_name in collections:\r\n        print(\"Collection exists. Building index..\")\r\n        chroma_collection = chroma_db.get_collection(collection_name)\r\n        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n        index = VectorStoreIndex.from_vector_store(vector_store=vector_store, service_context=service_context)\r\n        return index    \r\n    else:\r\n        print(\"New collection. Generating embeddings then building index...\")\r\n        chroma_collection = chroma_db.create_collection(collection_name)\r\n        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n        #Abstraction for storing Nodes, indices, and vectors\r\n        storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n        index = VectorStoreIndex.from_documents(\r\n            documents, storage_context=storage_context, service_context=service_context, embed_model=embed_model\r\n        )\r\n        return index`\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7142/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7142/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7141",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7141/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7141/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7141/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7141",
        "id": 1835633103,
        "node_id": "PR_kwDOIWuq585XI9A1",
        "number": 7141,
        "title": "Migrate Response Synthesizer",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-03T19:39:36Z",
        "updated_at": "2023-08-28T17:11:39Z",
        "closed_at": "2023-08-04T03:35:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7141",
            "html_url": "https://github.com/run-llama/llama_index/pull/7141",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7141.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7141.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nThis PR migrates the response synthesizer to use GPT-3.5-Turbo. In addition, some other changes are included\r\n\r\n- remove templates from the wandb callback\r\n- stop silently failing on the wandb callback\r\n- stop using `from_prompt` in tree summarize (this was destroying the chat message template) \r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested on tons of response modes and top k's\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7141/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7141/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7140",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7140/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7140/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7140/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7140",
        "id": 1835375481,
        "node_id": "PR_kwDOIWuq585XIHO2",
        "number": 7140,
        "title": "RSS Feed / OPML reader and article parser",
        "user": {
            "login": "ruze00",
            "id": 3300000,
            "node_id": "MDQ6VXNlcjMzMDAwMDA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3300000?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ruze00",
            "html_url": "https://github.com/ruze00",
            "followers_url": "https://api.github.com/users/ruze00/followers",
            "following_url": "https://api.github.com/users/ruze00/following{/other_user}",
            "gists_url": "https://api.github.com/users/ruze00/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ruze00/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ruze00/subscriptions",
            "organizations_url": "https://api.github.com/users/ruze00/orgs",
            "repos_url": "https://api.github.com/users/ruze00/repos",
            "events_url": "https://api.github.com/users/ruze00/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ruze00/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-03T16:27:57Z",
        "updated_at": "2023-08-09T16:11:00Z",
        "closed_at": "2023-08-09T16:11:00Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7140",
            "html_url": "https://github.com/run-llama/llama_index/pull/7140",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7140.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7140.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nAdded RSSNewsReader which can traverse a list of RSS feed urls or use OPML, and then use  NewsArticleReader to load each article. NewsArticleReader uses the excellent OS package `newspaper3k`.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ x ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ x ] Added new unit/integration tests\r\n- [ x ] Added new notebook (that tests end-to-end)\r\n- [ x ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ x ] I have performed a self-review of my own code\r\n- [ x ] I have commented my code, particularly in hard-to-understand areas\r\n- [ x ] I have made corresponding changes to the documentation\r\n- [ x ] My changes generate no new warnings\r\n- [ x ] I have added tests that prove my fix is effective or that my feature works\r\n- [ x ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7140/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7140/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7139",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7139/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7139/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7139/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7139",
        "id": 1835323947,
        "node_id": "PR_kwDOIWuq585XH8ZM",
        "number": 7139,
        "title": "fix astream_chat for chat engines",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-03T15:52:29Z",
        "updated_at": "2023-08-03T17:24:55Z",
        "closed_at": "2023-08-03T17:24:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7139",
            "html_url": "https://github.com/run-llama/llama_index/pull/7139",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7139.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7139.patch",
            "merged_at": "2023-08-03T17:24:54Z"
        },
        "body": "# Description\r\n\r\nChat engines were not correctly setting achat_stream in the agent response, resulting in value errors.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7131\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested in a notebook\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7139/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7139/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7138",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7138/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7138/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7138/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7138",
        "id": 1835313933,
        "node_id": "PR_kwDOIWuq585XH6RW",
        "number": 7138,
        "title": "Move splitter to top-level",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-03T15:46:03Z",
        "updated_at": "2023-08-04T04:46:04Z",
        "closed_at": "2023-08-04T04:46:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7138",
            "html_url": "https://github.com/run-llama/llama_index/pull/7138",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7138.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7138.patch",
            "merged_at": "2023-08-04T04:46:03Z"
        },
        "body": "# Description\r\n\r\nMove splitter to top-level, but keep import at `langchain_helpers` for backward compatibility. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7138/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7138/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7137",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7137/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7137/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7137/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7137",
        "id": 1834988457,
        "node_id": "I_kwDOIWuq585tX7Op",
        "number": 7137,
        "title": "[Question]: llama_index supports NebulaGraph, what can I change to make it support neo4j?",
        "user": {
            "login": "xinkeyb",
            "id": 45843515,
            "node_id": "MDQ6VXNlcjQ1ODQzNTE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/45843515?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xinkeyb",
            "html_url": "https://github.com/xinkeyb",
            "followers_url": "https://api.github.com/users/xinkeyb/followers",
            "following_url": "https://api.github.com/users/xinkeyb/following{/other_user}",
            "gists_url": "https://api.github.com/users/xinkeyb/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xinkeyb/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xinkeyb/subscriptions",
            "organizations_url": "https://api.github.com/users/xinkeyb/orgs",
            "repos_url": "https://api.github.com/users/xinkeyb/repos",
            "events_url": "https://api.github.com/users/xinkeyb/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xinkeyb/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-03T12:41:47Z",
        "updated_at": "2023-08-09T11:23:10Z",
        "closed_at": "2023-08-03T15:38:49Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [x] I have searched both the documentation and discord for an answer.\n\n### Question\n\nllama_index supports NebulaGraph, what can I change to make it support neo4j?\r\n\uff08zh\uff1allama_index\u652f\u6301NebulaGraph\uff0c\u6211\u8be5\u600e\u4e48\u6539\u624d\u80fd\u8ba9\u5b83\u652f\u6301neo4j\u5462\uff09",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7137/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7137/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7136",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7136/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7136/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7136/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7136",
        "id": 1834916798,
        "node_id": "I_kwDOIWuq585tXpu-",
        "number": 7136,
        "title": "[Question]: Can I prioritize documents/nodes over others?",
        "user": {
            "login": "thedoor76",
            "id": 75886096,
            "node_id": "MDQ6VXNlcjc1ODg2MDk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/75886096?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thedoor76",
            "html_url": "https://github.com/thedoor76",
            "followers_url": "https://api.github.com/users/thedoor76/followers",
            "following_url": "https://api.github.com/users/thedoor76/following{/other_user}",
            "gists_url": "https://api.github.com/users/thedoor76/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thedoor76/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thedoor76/subscriptions",
            "organizations_url": "https://api.github.com/users/thedoor76/orgs",
            "repos_url": "https://api.github.com/users/thedoor76/repos",
            "events_url": "https://api.github.com/users/thedoor76/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thedoor76/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-03T11:56:58Z",
        "updated_at": "2023-10-24T06:30:06Z",
        "closed_at": "2023-10-24T06:30:06Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIn my setup, several PDF documents pertain to a legal case. We have hundreds of cases, resulting in thousands of PDF documents.\r\nI am currently successful in indexing each document, assigning the right metadata (such as case number), and querying them using filters.\r\n\r\nIn order to improve response accuracy, I have built a custom text document for each case called a \"fact sheet\". That document will contain key details about each case. We know that this \"fact sheet\" document will contain many answers to the questions asked.\r\n\r\nSo far, I was able to add this \"fact sheet\" document for each legal case, and index it. However, I am noticing that it is often passed over when questions are asked, even though it contains the answer.\r\n\r\nHow could I give my \"fact sheet\" documents a slight priority over the other PDF documents related to that case?\r\n\r\nI have looked at Composability, but I don't think that's quite what I need, as the fact sheet does not necessarily contain a written summary of the case; instead, it simply holds a lot of key facts about the case.\r\n\r\nThanks in advance.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7136/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7136/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7135",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7135/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7135/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7135/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7135",
        "id": 1834720230,
        "node_id": "I_kwDOIWuq585tW5vm",
        "number": 7135,
        "title": "[Question]:cannot import name 'GPTFaissIndex' from 'llama_index'",
        "user": {
            "login": "bankshotbandwidth",
            "id": 92348881,
            "node_id": "U_kgDOBYEh0Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/92348881?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bankshotbandwidth",
            "html_url": "https://github.com/bankshotbandwidth",
            "followers_url": "https://api.github.com/users/bankshotbandwidth/followers",
            "following_url": "https://api.github.com/users/bankshotbandwidth/following{/other_user}",
            "gists_url": "https://api.github.com/users/bankshotbandwidth/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bankshotbandwidth/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bankshotbandwidth/subscriptions",
            "organizations_url": "https://api.github.com/users/bankshotbandwidth/orgs",
            "repos_url": "https://api.github.com/users/bankshotbandwidth/repos",
            "events_url": "https://api.github.com/users/bankshotbandwidth/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bankshotbandwidth/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-03T09:57:01Z",
        "updated_at": "2023-08-03T15:40:29Z",
        "closed_at": "2023-08-03T15:40:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI have installed llama_index, but the process of import GPTFaissIndex keeps reporting [cannot import name 'GPTFaissIndex' from 'llama_index']",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7135/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7135/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7134",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7134/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7134/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7134/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7134",
        "id": 1834717015,
        "node_id": "I_kwDOIWuq585tW49X",
        "number": 7134,
        "title": "[Bug]: ImportError: cannot import name 'GPTFaissIndex' from 'llama_index'",
        "user": {
            "login": "bankshotbandwidth",
            "id": 92348881,
            "node_id": "U_kgDOBYEh0Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/92348881?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bankshotbandwidth",
            "html_url": "https://github.com/bankshotbandwidth",
            "followers_url": "https://api.github.com/users/bankshotbandwidth/followers",
            "following_url": "https://api.github.com/users/bankshotbandwidth/following{/other_user}",
            "gists_url": "https://api.github.com/users/bankshotbandwidth/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bankshotbandwidth/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bankshotbandwidth/subscriptions",
            "organizations_url": "https://api.github.com/users/bankshotbandwidth/orgs",
            "repos_url": "https://api.github.com/users/bankshotbandwidth/repos",
            "events_url": "https://api.github.com/users/bankshotbandwidth/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bankshotbandwidth/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-03T09:55:47Z",
        "updated_at": "2023-08-03T15:41:16Z",
        "closed_at": "2023-08-03T15:41:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n\r\nI have installed llama_index, but the process of import GPTFaissIndex keeps reporting [cannot import name 'GPTFaissIndex' from 'llama_index']\n\n### Version\n\n0.6.1\n\n### Steps to Reproduce\n\nI have no idea\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7134/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7134/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7133",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7133/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7133/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7133/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7133",
        "id": 1834468684,
        "node_id": "I_kwDOIWuq585tV8VM",
        "number": 7133,
        "title": "[Question]: openai.Getting error.InvalidRequestError on SubQuestionQueryEngine",
        "user": {
            "login": "Yackadaisical",
            "id": 134191941,
            "node_id": "U_kgDOB_-bRQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/134191941?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Yackadaisical",
            "html_url": "https://github.com/Yackadaisical",
            "followers_url": "https://api.github.com/users/Yackadaisical/followers",
            "following_url": "https://api.github.com/users/Yackadaisical/following{/other_user}",
            "gists_url": "https://api.github.com/users/Yackadaisical/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Yackadaisical/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Yackadaisical/subscriptions",
            "organizations_url": "https://api.github.com/users/Yackadaisical/orgs",
            "repos_url": "https://api.github.com/users/Yackadaisical/repos",
            "events_url": "https://api.github.com/users/Yackadaisical/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Yackadaisical/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-03T07:36:11Z",
        "updated_at": "2023-10-29T10:36:52Z",
        "closed_at": "2023-08-06T05:54:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nMy set up works for all other kinds of queries I been working on, but today I was trying to add SubQuestionQueryEngine to my code, and keep getting this error:\r\n\r\nopenai.error.InvalidRequestError: Unrecognized request argument supplied: functions\r\n\r\nThis is basic outline of my code:\r\n\r\n```\r\nllm = AzureOpenAI(engine=\"try2\", model=\"gpt-3.5-turbo-16k\", temperature=0.2)\r\n\r\nembedding_llm = LangchainEmbedding(\r\n    OpenAIEmbeddings(\r\n        model=\"text-embedding-ada-002\",\r\n        deployment=\"embedding_try1\",\r\n        openai_api_key=openai.api_key,\r\n        openai_api_base=openai.api_base,\r\n        openai_api_type=openai.api_type,\r\n        openai_api_version=openai.api_version,\r\n    ),\r\n    embed_batch_size=1,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embedding_llm,\r\n)\r\n\r\nset_global_service_context(service_context)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    persist_dir=\"docs_index_storage\"\r\n)\r\n\r\nvector_query_engine = load_index_from_storage(\r\n    storage_context=storage_context, \r\n    service_context=service_context\r\n    ).as_query_engine()\r\n\r\nquery_engine_tools = [\r\n    QueryEngineTool(\r\n        query_engine=vector_query_engine,\r\n        metadata=ToolMetadata(\r\n            name=\"tissue_research\", description=\"Provide information on consumer tissue paper.\"\r\n        ),\r\n    ),\r\n]\r\n\r\nquery_engine = SubQuestionQueryEngine.from_defaults(\r\n    query_engine_tools=query_engine_tools,\r\n    service_context=service_context\r\n)\r\n\r\nanswer = query_engine.query(\"What is the latest trends on tissue paper\")\r\n\r\nprint(answer.get_formatted_sources())\r\n```\r\n\r\nWhenever I run .query it would raise openai.error.InvalidRequestError: Unrecognized request argument supplied: functions",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7133/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7133/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7132",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7132/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7132/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7132/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7132",
        "id": 1834259185,
        "node_id": "I_kwDOIWuq585tVJLx",
        "number": 7132,
        "title": "[Bug]: llama_index.llms.OpenAI does not use api_type & api_key passed in",
        "user": {
            "login": "apptaro",
            "id": 998626,
            "node_id": "MDQ6VXNlcjk5ODYyNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/998626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apptaro",
            "html_url": "https://github.com/apptaro",
            "followers_url": "https://api.github.com/users/apptaro/followers",
            "following_url": "https://api.github.com/users/apptaro/following{/other_user}",
            "gists_url": "https://api.github.com/users/apptaro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apptaro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apptaro/subscriptions",
            "organizations_url": "https://api.github.com/users/apptaro/orgs",
            "repos_url": "https://api.github.com/users/apptaro/repos",
            "events_url": "https://api.github.com/users/apptaro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apptaro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-03T04:41:02Z",
        "updated_at": "2023-08-16T20:23:19Z",
        "closed_at": "2023-08-16T20:23:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI don't want to set OPENAI_API_TYPE & OPENAI_API_KEY environment variables because I use multiple ChatGPTs.\r\nSo I do this:\r\n```\r\nllm = OpenAI(api_type = \"open_ai\", api_key = \"sk-xxx\")\r\nllm.chat(...)\r\n```\r\nThen it raises `openai.error.AuthenticationError: No API key provided` error.\r\n\r\nActually, this works:\r\n```\r\nllm = OpenAI(api_type = \"open_ai\", api_key = \"sk-xxx\", additional_kwargs = { \"api_type\": \"open_ai\", \"api_key\": \"sk-xxx\" })\r\nllm.chat(...)\r\n```\r\n\r\nBut it's redundant. \r\n\r\nThis code checks top-level parameters, so I suppose you don't have to use additional_kwargs, correct?\r\nhttps://github.com/jerryjliu/llama_index/blob/535a05fdabf87c2a89be25a0eb8b433498d7c1f1/llama_index/llms/openai.py#L47\r\n\r\n\r\n### Version\r\n\r\n0.7.17\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\nfrom llama_index.llms import OpenAI\r\nfrom llama_index.llms.base import ChatMessage\r\nllm = OpenAI(api_type = \"open_ai\", api_key = \"sk-xxx\")\r\nllm.chat([ChatMessage(content = \"Who wrote Romeo and Juliet?\")])\r\n```\r\n\r\n**Do not set OpenAI environment variables!**\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7132/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7132/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7131",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7131/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7131/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7131/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7131",
        "id": 1834182110,
        "node_id": "I_kwDOIWuq585tU2Xe",
        "number": 7131,
        "title": "[Bug]: Chat engine astream chat error (ValueError: achat_stream is None. Cannot asynchronously write to history without achat_stream.)",
        "user": {
            "login": "hieutrluu",
            "id": 32662977,
            "node_id": "MDQ6VXNlcjMyNjYyOTc3",
            "avatar_url": "https://avatars.githubusercontent.com/u/32662977?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hieutrluu",
            "html_url": "https://github.com/hieutrluu",
            "followers_url": "https://api.github.com/users/hieutrluu/followers",
            "following_url": "https://api.github.com/users/hieutrluu/following{/other_user}",
            "gists_url": "https://api.github.com/users/hieutrluu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hieutrluu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hieutrluu/subscriptions",
            "organizations_url": "https://api.github.com/users/hieutrluu/orgs",
            "repos_url": "https://api.github.com/users/hieutrluu/repos",
            "events_url": "https://api.github.com/users/hieutrluu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hieutrluu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-03T02:48:46Z",
        "updated_at": "2023-08-03T17:24:55Z",
        "closed_at": "2023-08-03T17:24:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nError: (ValueError: achat_stream is None. Cannot asynchronously write to history without achat_stream.)\r\n\r\nI am guessing that the separate thread might be causing issues ?\r\nCan any one help me with this ?\r\n\r\n\r\n```\r\n\r\n    async def astream_chat(\r\n        self, message: str, chat_history: Optional[List[ChatMessage]] = None\r\n    ) -> StreamingAgentChatResponse:\r\n        if chat_history is not None:\r\n            self._memory.set(chat_history)\r\n        self._memory.put(ChatMessage(content=message, role=\"user\"))\r\n\r\n        context_str_template, nodes = await self._agenerate_context(message)\r\n        prefix_messages = self._get_prefix_messages_with_context(context_str_template)\r\n        all_messages = prefix_messages + self._memory.get()\r\n\r\n        chat_response = StreamingAgentChatResponse(\r\n            chat_stream=self._llm.stream_chat(all_messages),\r\n            sources=[\r\n                ToolOutput(\r\n                    tool_name=\"retriever\",\r\n                    content=str(prefix_messages[0]),\r\n                    raw_input={\"message\": message},\r\n                    raw_output=prefix_messages[0],\r\n                )\r\n            ],\r\n            source_nodes=nodes,\r\n        )\r\n        thread = Thread(\r\n            target=lambda x: asyncio.run(chat_response.awrite_response_to_history(x)),\r\n            args=(self._memory,),\r\n        )\r\n        thread.start()\r\n\r\n        return chat_response\r\n        \r\n```\r\n\r\n### Version\r\n\r\nv0.7.16\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\nimport openai\r\nimport os\r\n\r\nos.environ[\"OPENAI_API_KEY\"] = \"\"\r\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\r\n\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\nfrom llama_index.chat_engine.types import ChatMode\r\n\r\n# data = SimpleDirectoryReader(input_dir=\"../data/paul_graham/\").load_data()\r\nindex = VectorStoreIndex.from_documents([])\r\nchat_engine = index.as_chat_engine(chat_mode=ChatMode.CONTEXT, verbose=True)\r\n\r\nasync def tmp(index):\r\n    chat_engine = index.as_chat_engine(chat_mode=ChatMode.CONTEXT, verbose=True)\r\n    response = await chat_engine.astream_chat(\"Hello!\")\r\n    return response\r\n\r\nres = await tmp(index)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nException in thread Thread-6 (<lambda>):\r\nTraceback (most recent call last):\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\r\n    self.run()\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/threading.py\", line 975, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/site-packages/llama_index/chat_engine/context.py\", line 227, in <lambda>\r\n    target=lambda x: asyncio.run(chat_response.awrite_response_to_history(x)),\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/asyncio/runners.py\", line 190, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/asyncio/runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/Users/user/miniconda3/envs/synna-be/lib/python3.11/site-packages/llama_index/chat_engine/types.py\", line 92, in awrite_response_to_history\r\n    raise ValueError(\r\nValueError: achat_stream is None. Cannot asynchronously write to history without achat_stream.\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7131/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7131/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7130",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7130/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7130/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7130/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7130",
        "id": 1834021418,
        "node_id": "PR_kwDOIWuq585XDgzQ",
        "number": 7130,
        "title": "Add metadata filtering for Weaviate",
        "user": {
            "login": "erika-cardenas",
            "id": 110841617,
            "node_id": "U_kgDOBptPEQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/110841617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/erika-cardenas",
            "html_url": "https://github.com/erika-cardenas",
            "followers_url": "https://api.github.com/users/erika-cardenas/followers",
            "following_url": "https://api.github.com/users/erika-cardenas/following{/other_user}",
            "gists_url": "https://api.github.com/users/erika-cardenas/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/erika-cardenas/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/erika-cardenas/subscriptions",
            "organizations_url": "https://api.github.com/users/erika-cardenas/orgs",
            "repos_url": "https://api.github.com/users/erika-cardenas/repos",
            "events_url": "https://api.github.com/users/erika-cardenas/events{/privacy}",
            "received_events_url": "https://api.github.com/users/erika-cardenas/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T23:27:53Z",
        "updated_at": "2023-09-20T13:17:43Z",
        "closed_at": "2023-08-03T22:43:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7130",
            "html_url": "https://github.com/run-llama/llama_index/pull/7130",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7130.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7130.patch",
            "merged_at": "2023-08-03T22:43:32Z"
        },
        "body": "# Description\r\nAdded metadata filtering for the Weaviate vector store.\r\n\r\n## Type of Change\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7130/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7130/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7129",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7129/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7129/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7129/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7129",
        "id": 1833577475,
        "node_id": "PR_kwDOIWuq585XB_9k",
        "number": 7129,
        "title": "add flush to agent response stream",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T16:57:05Z",
        "updated_at": "2023-08-02T18:09:20Z",
        "closed_at": "2023-08-02T18:09:19Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7129",
            "html_url": "https://github.com/run-llama/llama_index/pull/7129",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7129.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7129.patch",
            "merged_at": "2023-08-02T18:09:19Z"
        },
        "body": "# Description\r\n\r\nThe agent response stream will sometimes not print properly without `flush=True`\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7129/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7129/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7128",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7128/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7128/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7128/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7128",
        "id": 1833518297,
        "node_id": "PR_kwDOIWuq585XByrQ",
        "number": 7128,
        "title": "add save and load to memory",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T16:26:17Z",
        "updated_at": "2023-08-02T18:17:06Z",
        "closed_at": "2023-08-02T18:17:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7128",
            "html_url": "https://github.com/run-llama/llama_index/pull/7128",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7128.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7128.patch",
            "merged_at": "2023-08-02T18:17:05Z"
        },
        "body": "# Description\r\n\r\nJust some QoL for saving/loading memory. In a later PR, this can be exposed in the agents/chat engines\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7128/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7128/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7127",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7127/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7127/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7127/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7127",
        "id": 1833329973,
        "node_id": "PR_kwDOIWuq585XBJQ8",
        "number": 7127,
        "title": "update allowed azure types",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T14:43:31Z",
        "updated_at": "2023-08-02T16:11:15Z",
        "closed_at": "2023-08-02T16:11:14Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7127",
            "html_url": "https://github.com/run-llama/llama_index/pull/7127",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7127.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7127.patch",
            "merged_at": "2023-08-02T16:11:14Z"
        },
        "body": "# Description\r\n\r\nAdds support for validating azure_ad LLMs\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7121\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7127/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7127/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7126",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7126/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7126/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7126/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7126",
        "id": 1833282245,
        "node_id": "I_kwDOIWuq585tRarF",
        "number": 7126,
        "title": "[Bug]: RouterQueryEngine not detecting AzureOpenAi ServiceContext",
        "user": {
            "login": "Matt-Scheetz",
            "id": 120581026,
            "node_id": "U_kgDOBy_rog",
            "avatar_url": "https://avatars.githubusercontent.com/u/120581026?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Matt-Scheetz",
            "html_url": "https://github.com/Matt-Scheetz",
            "followers_url": "https://api.github.com/users/Matt-Scheetz/followers",
            "following_url": "https://api.github.com/users/Matt-Scheetz/following{/other_user}",
            "gists_url": "https://api.github.com/users/Matt-Scheetz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Matt-Scheetz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Matt-Scheetz/subscriptions",
            "organizations_url": "https://api.github.com/users/Matt-Scheetz/orgs",
            "repos_url": "https://api.github.com/users/Matt-Scheetz/repos",
            "events_url": "https://api.github.com/users/Matt-Scheetz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Matt-Scheetz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-02T14:17:41Z",
        "updated_at": "2023-08-03T16:51:45Z",
        "closed_at": "2023-08-03T16:51:45Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI'm testing out using RouterQueryEngine's example from [the docs](https://gpt-index.readthedocs.io/en/latest/examples/query_engine/RouterQueryEngine.html).\r\n\r\nI've set my service context:\r\n```\r\n    def init_skds(self):\r\n        self.prompt_helper = PromptHelper(self.max_input_size, \r\n                                          self.num_output, \r\n                                          chunk_overlap_ratio=self.overlap_ratio)\r\n\r\n        self.llm=AzureChatOpenAI(temperature=self.temperature, \r\n                                 deployment_name=self.deployment_name,\r\n                                 model_name=self.deployment_model, \r\n                                 max_tokens=self.num_output,\r\n                                 openai_api_version=self.ai_api_version)\r\n\r\n        self.llm_predictor = LLMPredictor(self.llm)\r\n\r\n        self.aiEmbedding = OpenAIEmbeddings(model=self.embedding_model,\r\n                                            deployment=self.embedding_deployment,\r\n                                            chunk_size=self.embedding_chunk_size)\r\n\r\n        self.embedding = LangchainEmbedding(self.aiEmbedding)\r\n\r\n        self.service_context = ServiceContext.from_defaults(llm_predictor=self.llm_predictor, \r\n                                                            prompt_helper=self.prompt_helper,\r\n                                                            embed_model=self.embedding)\r\n\r\n        set_global_service_context(self.service_context)\r\n```\r\nAfter initializing my indexes, I'm creating the RouterQueryEngine:\r\n```\r\n    def _get_multi_query_engine(self):\r\n        list_qe = self._get_list_query_engine()\r\n        vector_qe = self._get_vector_query_engine()\r\n        \r\n        filenames = self.indexed_filenames_v2()\r\n        filenames_str = ','.join(filenames)\r\n\r\n        list_tool = QueryEngineTool.from_defaults(\r\n            query_engine=list_qe,\r\n            description=f\"Useful for summarization questions related to {filenames_str}\"\r\n        )\r\n\r\n        vector_tool = QueryEngineTool.from_defaults(\r\n            query_engine=vector_qe,\r\n            description=f\"Useful for retrieveing specific context from {filenames_str}\"\r\n        )\r\n\r\n        try:\r\n            query_engine = RouterQueryEngine(\r\n                selector=PydanticSingleSelector.from_defaults(),\r\n                query_engine_tools=[\r\n                    list_tool,\r\n                    vector_tool\r\n                ],\r\n                service_context=self.service_context\r\n            )\r\n\r\n            return query_engine\r\n        except Exception as e:\r\n            logging.error(e)\r\n            raise\r\n\r\n```\r\n\r\nHere is the error that is being thrown when i run `query_engine.query(input_text)`:\r\n\r\n```\r\n    def multi_chat(self, input_text: str):\r\n        query_engine = self._get_multi_query_engine()\r\n\r\n        try:\r\n            response = query_engine.query(input_text)\r\n\r\n            return response\r\n        except Exception as e:\r\n            logging.error(e)\r\n            raise\r\n```\r\n\r\n> No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\r\n\r\nWhile debugging, I can expand my `query_engine.service_context` and see my AzureOpenAi config settings for both the `llm` and `llm_predictor`\r\n\r\nI'm currently running similar code only using a VectorStoreIndex and a regular query_engine; this error is not getting thrown.\r\n\r\n### Version\r\n\r\n0.7.16\r\n\r\n### Steps to Reproduce\r\n\r\n* Initialize indexes: ListIndex + VectorStorageIndex\r\n* Create RouterQueryEngine\r\n* Query RouterQueryEngine\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7126/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7126/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7125",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7125/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7125/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7125/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7125",
        "id": 1833281082,
        "node_id": "PR_kwDOIWuq585XA-oy",
        "number": 7125,
        "title": "add hybrid search to columns",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T14:17:02Z",
        "updated_at": "2023-08-02T14:28:55Z",
        "closed_at": "2023-08-02T14:28:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7125",
            "html_url": "https://github.com/run-llama/llama_index/pull/7125",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7125.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7125.patch",
            "merged_at": "2023-08-02T14:28:54Z"
        },
        "body": "# Description\r\n\r\nJust a simple change to add a column to the vector db table in the docs\r\n\r\nSide note -- we should probably be more strict on vector db integrations going forward. If a DB supports hybrid search or metadata filtering, we should be sure support is added for it in llama-index before merging. I'm sure other DBs support these features, and we just haven't implemented them.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7125/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7125/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7124",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7124/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7124/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7124/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7124",
        "id": 1833179930,
        "node_id": "PR_kwDOIWuq585XAonY",
        "number": 7124,
        "title": "added column comments in sql query",
        "user": {
            "login": "radbrt",
            "id": 2789476,
            "node_id": "MDQ6VXNlcjI3ODk0NzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2789476?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/radbrt",
            "html_url": "https://github.com/radbrt",
            "followers_url": "https://api.github.com/users/radbrt/followers",
            "following_url": "https://api.github.com/users/radbrt/following{/other_user}",
            "gists_url": "https://api.github.com/users/radbrt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/radbrt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/radbrt/subscriptions",
            "organizations_url": "https://api.github.com/users/radbrt/orgs",
            "repos_url": "https://api.github.com/users/radbrt/repos",
            "events_url": "https://api.github.com/users/radbrt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/radbrt/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-02T13:21:29Z",
        "updated_at": "2023-08-03T19:56:04Z",
        "closed_at": "2023-08-03T19:56:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7124",
            "html_url": "https://github.com/run-llama/llama_index/pull/7124",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7124.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7124.patch",
            "merged_at": "2023-08-03T19:56:04Z"
        },
        "body": "# Description\r\n\r\nAdded use of column comments in `SQLDatabase.get_single_table_info()`. When column comments are present, the template produced looks like \r\n\r\n```\r\nTable 'f1' has columns: col1 (VARCHAR(16777216)): 'Name', col2 (DECIMAL(38, 0)): 'Age', and foreign keys: .\r\n```\r\n\r\nI have not iterated much on the formatting, but testing shows improvements when column names are uninformative.\r\n\r\nFor columns without comment, the template remains as before.\r\n\r\nFixes #6996 \r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\nNeither SQLite nor duckdb supports column comments, so it is difficult to provide real unit tests. It has been manually tested against Snowflake, and against a sqlite database to make sure it works as expected with and without column comments.\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7124/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7124/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7123",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7123/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7123/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7123/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7123",
        "id": 1833164664,
        "node_id": "PR_kwDOIWuq585XAlRk",
        "number": 7123,
        "title": "[version] bump version to 0.7.17",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T13:12:39Z",
        "updated_at": "2023-08-02T13:44:07Z",
        "closed_at": "2023-08-02T13:44:06Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7123",
            "html_url": "https://github.com/run-llama/llama_index/pull/7123",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7123.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7123.patch",
            "merged_at": "2023-08-02T13:44:06Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7123/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7123/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7122",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7122/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7122/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7122/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7122",
        "id": 1832887811,
        "node_id": "PR_kwDOIWuq585W_o6R",
        "number": 7122,
        "title": "Add Neo4j support",
        "user": {
            "login": "tomasonjo",
            "id": 19948365,
            "node_id": "MDQ6VXNlcjE5OTQ4MzY1",
            "avatar_url": "https://avatars.githubusercontent.com/u/19948365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tomasonjo",
            "html_url": "https://github.com/tomasonjo",
            "followers_url": "https://api.github.com/users/tomasonjo/followers",
            "following_url": "https://api.github.com/users/tomasonjo/following{/other_user}",
            "gists_url": "https://api.github.com/users/tomasonjo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tomasonjo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tomasonjo/subscriptions",
            "organizations_url": "https://api.github.com/users/tomasonjo/orgs",
            "repos_url": "https://api.github.com/users/tomasonjo/repos",
            "events_url": "https://api.github.com/users/tomasonjo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tomasonjo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2023-08-02T10:18:21Z",
        "updated_at": "2023-08-03T21:11:04Z",
        "closed_at": "2023-08-03T15:34:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7122",
            "html_url": "https://github.com/run-llama/llama_index/pull/7122",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7122.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7122.patch",
            "merged_at": "2023-08-03T15:34:37Z"
        },
        "body": "# Description\r\n\r\nAdd Neo4j support\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7122/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 2,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7122/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7121",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7121/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7121/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7121/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7121",
        "id": 1832739901,
        "node_id": "I_kwDOIWuq585tPWQ9",
        "number": 7121,
        "title": "[Bug]: Pydantic validator fails for valid configurations of AzureOpenAI",
        "user": {
            "login": "proschowsky",
            "id": 106142807,
            "node_id": "U_kgDOBlOcVw",
            "avatar_url": "https://avatars.githubusercontent.com/u/106142807?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/proschowsky",
            "html_url": "https://github.com/proschowsky",
            "followers_url": "https://api.github.com/users/proschowsky/followers",
            "following_url": "https://api.github.com/users/proschowsky/following{/other_user}",
            "gists_url": "https://api.github.com/users/proschowsky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/proschowsky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/proschowsky/subscriptions",
            "organizations_url": "https://api.github.com/users/proschowsky/orgs",
            "repos_url": "https://api.github.com/users/proschowsky/repos",
            "events_url": "https://api.github.com/users/proschowsky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/proschowsky/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-02T08:53:01Z",
        "updated_at": "2023-08-02T16:11:15Z",
        "closed_at": "2023-08-02T16:11:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAzureOpenAI from llama_index.llms does not work with Azure AD authentication. \r\n\r\nWhen authentication to Azure with AD, the api_type must be set to \"azure_ad\".\r\nThe validator only accepts \"azure\"\r\n\r\nValid values of the api_type is \"azure\", \"azure_ad\", \"azuread\"\r\n\r\nError:\r\n\r\n```\r\npydantic.error_wrappers.ValidationError: 1 validation error for AzureOpenAI\r\n__root__\r\n  You must set OPENAI_API_TYPE to `azure` for Azure OpenAI. (type=value_error)\r\n```\n\n### Version\n\n0.7.16\n\n### Steps to Reproduce\n\nExample of script that use Azure AD\r\n\r\n```\r\nimport openai\r\nfrom llama_index.llms import AzureOpenAI\r\n\r\n# config open ai\r\nopenai.api_type = \"azure_ad\"\r\nopenai.api_key = 123456\r\n...\r\n\r\nllm = AzureOpenAI(model=\"gpt-35-turbo\", engine=\"gpt-35-turbo\", temperature=0.2)\r\n\r\n```\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7121/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7121/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7120",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7120/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7120/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7120/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7120",
        "id": 1832685726,
        "node_id": "I_kwDOIWuq585tPJCe",
        "number": 7120,
        "title": "[Bug]: Keep getting OpenApi key requested",
        "user": {
            "login": "ChezzPlaya",
            "id": 76159073,
            "node_id": "MDQ6VXNlcjc2MTU5MDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/76159073?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ChezzPlaya",
            "html_url": "https://github.com/ChezzPlaya",
            "followers_url": "https://api.github.com/users/ChezzPlaya/followers",
            "following_url": "https://api.github.com/users/ChezzPlaya/following{/other_user}",
            "gists_url": "https://api.github.com/users/ChezzPlaya/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ChezzPlaya/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ChezzPlaya/subscriptions",
            "organizations_url": "https://api.github.com/users/ChezzPlaya/orgs",
            "repos_url": "https://api.github.com/users/ChezzPlaya/repos",
            "events_url": "https://api.github.com/users/ChezzPlaya/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ChezzPlaya/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-02T08:23:26Z",
        "updated_at": "2023-08-02T15:02:40Z",
        "closed_at": "2023-08-02T15:02:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nEventhough I provided the local embedding model, I keep getting API key request.\r\n\r\nWhy?\r\n\r\n```\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nValueError: No API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n```\n\n### Version\n\n0.7.16\n\n### Steps to Reproduce\n\n```\r\nimport os\r\nimport chromadb\r\nfrom llama_index import (\r\n    LangchainEmbedding,\r\n    SimpleDirectoryReader,\r\n    ServiceContext,\r\n    StorageContext,\r\n    VectorStoreIndex,\r\n)\r\nfrom llama_index.vector_stores import ChromaVectorStore\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index import set_global_service_context\r\n\r\n\r\ndef main():\r\n    # construct embed model\r\n    embed_model = LangchainEmbedding(\r\n        HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\r\n    )\r\n\r\n    service_context = ServiceContext.from_defaults(\r\n        chunk_overlap=200, chunk_size=1000, embed_model=embed_model\r\n    )\r\n    set_global_service_context(service_context=service_context)\r\n\r\n    # get current directory based on the file location\r\n    current_directory = os.path.dirname(os.path.abspath(__file__))\r\n\r\n    documents = SimpleDirectoryReader(\r\n        os.path.join(current_directory, \"resources\")\r\n    ).load_data()\r\n\r\n    db = chromadb.PersistentClient(path=\"./chroma_db\")\r\n    chroma_collection = db.get_or_create_collection(\"pdf_resources\")\r\n    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\n    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\r\n\r\n    query_engine = index.as_query_engine()\r\n    response = query_engine.query(\"Set the warning of the acoustic warning to 5\")\r\n    print(response)\r\n\r\n\r\n# main\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7120/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7120/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7119",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7119/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7119/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7119/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7119",
        "id": 1832420425,
        "node_id": "PR_kwDOIWuq585W-D90",
        "number": 7119,
        "title": "Support streaming in react agent",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T04:39:03Z",
        "updated_at": "2023-08-02T06:21:14Z",
        "closed_at": "2023-08-02T06:21:14Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7119",
            "html_url": "https://github.com/run-llama/llama_index/pull/7119",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7119.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7119.patch",
            "merged_at": "2023-08-02T06:21:14Z"
        },
        "body": "# Description\r\n\r\nSupport streaming in react agent\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7119/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7119/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7118",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7118/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7118/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7118/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7118",
        "id": 1832417996,
        "node_id": "I_kwDOIWuq585tOHrM",
        "number": 7118,
        "title": "[Bug]: Async prediction with ChatOpenAI worked until 0.6.38, but does not work after 0.7.0",
        "user": {
            "login": "apptaro",
            "id": 998626,
            "node_id": "MDQ6VXNlcjk5ODYyNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/998626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apptaro",
            "html_url": "https://github.com/apptaro",
            "followers_url": "https://api.github.com/users/apptaro/followers",
            "following_url": "https://api.github.com/users/apptaro/following{/other_user}",
            "gists_url": "https://api.github.com/users/apptaro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apptaro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apptaro/subscriptions",
            "organizations_url": "https://api.github.com/users/apptaro/orgs",
            "repos_url": "https://api.github.com/users/apptaro/repos",
            "events_url": "https://api.github.com/users/apptaro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apptaro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-02T04:36:18Z",
        "updated_at": "2023-09-12T02:10:49Z",
        "closed_at": "2023-09-12T02:10:49Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nLLMPredictor.apredict with ChatOpenAI works asynchronously until 0.6.38, but it works synchronously from 0.7.0 to 0.7.16.\n\n### Version\n\n0.7.16\n\n### Steps to Reproduce\n\nCode:\r\n```\r\nimport asyncio\r\nfrom typing import Tuple\r\nfrom langchain.chat_models import ChatOpenAI\r\nfrom llama_index import LLMPredictor, Prompt\r\n\r\nllm_predictor = LLMPredictor(ChatOpenAI(temperature = 0))\r\n\r\nasync def task1():\r\n  print(\"task1\")\r\n  response = await llm_predictor.apredict(Prompt(f\"who wrote The Great Gatsby\"))\r\n  print(response[0] if isinstance(response, Tuple) else response)\r\n\r\nasync def task2():\r\n  print(\"task2\")\r\n  response = await llm_predictor.apredict(Prompt(\"who wrote Romeo and Juliet?\"))\r\n  print(response[0] if isinstance(response, Tuple) else response)\r\n\r\nasync def do_tasks():\r\n  await asyncio.gather(*[task1(), task2()])\r\n\r\n#asyncio.run(do_tasks()) # for python script\r\nawait do_tasks() # type: ignore (for jupyter)\r\n```\r\n\r\nRun it on 0.6.38, the result is:\r\n```\r\ntask1\r\ntask2\r\nThe Great Gatsby was written by F. Scott Fitzgerald.\r\nWilliam Shakespeare wrote Romeo and Juliet.\r\n```\r\n\r\nRun it on 0.7.0 - 0.7.16, the result is:\r\n```\r\ntask1\r\nThe Great Gatsby was written by F. Scott Fitzgerald.\r\ntask2\r\nWilliam Shakespeare wrote Romeo and Juliet.\r\n```\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7118/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7118/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7117",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7117/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7117/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7117/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7117",
        "id": 1832396076,
        "node_id": "PR_kwDOIWuq585W9-yK",
        "number": 7117,
        "title": "add object streaming",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-02T04:11:38Z",
        "updated_at": "2023-08-02T13:11:29Z",
        "closed_at": "2023-08-02T13:11:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7117",
            "html_url": "https://github.com/run-llama/llama_index/pull/7117",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7117.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7117.patch",
            "merged_at": "2023-08-02T13:11:28Z"
        },
        "body": "fun example carried over from jason's repo here: https://github.com/jxnl/openai_function_call/tree/main/examples/streaming_multitask\r\n\r\nadded to `stream_list` function in OpenAI Pydantic Program.\r\n\r\nAll credits go to openai_function_call repo",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7117/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7117/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7116",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7116/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7116/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7116/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7116",
        "id": 1832352334,
        "node_id": "PR_kwDOIWuq585W91fR",
        "number": 7116,
        "title": "Support memory in react agent",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T03:13:11Z",
        "updated_at": "2023-08-02T04:38:50Z",
        "closed_at": "2023-08-02T04:38:49Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7116",
            "html_url": "https://github.com/run-llama/llama_index/pull/7116",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7116.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7116.patch",
            "merged_at": "2023-08-02T04:38:49Z"
        },
        "body": "# Description\r\n\r\nSupport memory in react agent\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7116/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7116/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7115",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7115/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7115/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7115/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7115",
        "id": 1832271616,
        "node_id": "PR_kwDOIWuq585W9kVc",
        "number": 7115,
        "title": "global variable for callbacks",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T01:37:36Z",
        "updated_at": "2023-08-03T14:31:09Z",
        "closed_at": "2023-08-03T14:31:08Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7115",
            "html_url": "https://github.com/run-llama/llama_index/pull/7115",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7115.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7115.patch",
            "merged_at": "2023-08-03T14:31:08Z"
        },
        "body": "This PR adds a `global_eval_handler` variable, that can be set through `set_global_eval_handler()`. What this does is it always gets injected into the Callback Manager if specified.\r\n\r\nAdded for W&B for now. \r\n\r\nThought: should I make the global_eval_handler plural / more general to all callback handlers? tradeoff is slightly more complex.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7115/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7115/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7114",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7114/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7114/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7114/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7114",
        "id": 1832193156,
        "node_id": "PR_kwDOIWuq585W9Teq",
        "number": 7114,
        "title": "Docs: Predibase Integration",
        "user": {
            "login": "Abhay-765",
            "id": 32989166,
            "node_id": "MDQ6VXNlcjMyOTg5MTY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/32989166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Abhay-765",
            "html_url": "https://github.com/Abhay-765",
            "followers_url": "https://api.github.com/users/Abhay-765/followers",
            "following_url": "https://api.github.com/users/Abhay-765/following{/other_user}",
            "gists_url": "https://api.github.com/users/Abhay-765/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Abhay-765/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Abhay-765/subscriptions",
            "organizations_url": "https://api.github.com/users/Abhay-765/orgs",
            "repos_url": "https://api.github.com/users/Abhay-765/repos",
            "events_url": "https://api.github.com/users/Abhay-765/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Abhay-765/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-02T00:00:46Z",
        "updated_at": "2023-08-02T02:15:12Z",
        "closed_at": "2023-08-02T02:15:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7114",
            "html_url": "https://github.com/run-llama/llama_index/pull/7114",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7114.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7114.patch",
            "merged_at": "2023-08-02T02:15:12Z"
        },
        "body": "This PR adds the Predibase Integration to the Llamaindex docs under the LLM section. Screenshots below: \r\n\r\n<img width=\"1036\" alt=\"Screen Shot 2023-08-01 at 4 56 32 PM\" src=\"https://github.com/jerryjliu/llama_index/assets/32989166/b84297dc-49e8-45ab-8555-8525a60b0cf0\">\r\n\r\n\r\n<img width=\"1321\" alt=\"Screen Shot 2023-08-01 at 4 56 44 PM\" src=\"https://github.com/jerryjliu/llama_index/assets/32989166/6eeb6418-078a-4a12-b180-d5f6ca1c95fa\">\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7114/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7114/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7113",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7113/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7113/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7113/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7113",
        "id": 1832024441,
        "node_id": "I_kwDOIWuq585tMnl5",
        "number": 7113,
        "title": "[Question]: ImportError: cannot import name 'GPTVectorStoreIndex' from 'llama_index' (unknown location)",
        "user": {
            "login": "mihirahuja1",
            "id": 56941061,
            "node_id": "MDQ6VXNlcjU2OTQxMDYx",
            "avatar_url": "https://avatars.githubusercontent.com/u/56941061?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mihirahuja1",
            "html_url": "https://github.com/mihirahuja1",
            "followers_url": "https://api.github.com/users/mihirahuja1/followers",
            "following_url": "https://api.github.com/users/mihirahuja1/following{/other_user}",
            "gists_url": "https://api.github.com/users/mihirahuja1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mihirahuja1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mihirahuja1/subscriptions",
            "organizations_url": "https://api.github.com/users/mihirahuja1/orgs",
            "repos_url": "https://api.github.com/users/mihirahuja1/repos",
            "events_url": "https://api.github.com/users/mihirahuja1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mihirahuja1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-01T21:01:10Z",
        "updated_at": "2023-08-04T15:51:26Z",
        "closed_at": "2023-08-04T15:51:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm facing this error after pip installing the requirements.\r\nI am using a virtual environment, and that doesn't seem to be resolving the issue.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7113/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7113/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7112",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7112/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7112/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7112/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7112",
        "id": 1831952496,
        "node_id": "PR_kwDOIWuq585W8fiF",
        "number": 7112,
        "title": "Move LLM callbacks to base class",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-01T20:06:30Z",
        "updated_at": "2023-08-04T12:31:07Z",
        "closed_at": "2023-08-04T12:31:06Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7112",
            "html_url": "https://github.com/run-llama/llama_index/pull/7112",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7112.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7112.patch",
            "merged_at": "2023-08-04T12:31:06Z"
        },
        "body": "# Description\r\n\r\nThis PR adds a decorator to the LLM endpoints to hook in API calls. Now, every LLM call is observable, including during agent usage. (This also adds token counting to agents!).\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested existing notebooks\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7112/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7112/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7111",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7111/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7111/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7111/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7111",
        "id": 1831850179,
        "node_id": "PR_kwDOIWuq585W8JkY",
        "number": 7111,
        "title": "Integrate Rockset as a vector store",
        "user": {
            "login": "gadhagod",
            "id": 69025547,
            "node_id": "MDQ6VXNlcjY5MDI1NTQ3",
            "avatar_url": "https://avatars.githubusercontent.com/u/69025547?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gadhagod",
            "html_url": "https://github.com/gadhagod",
            "followers_url": "https://api.github.com/users/gadhagod/followers",
            "following_url": "https://api.github.com/users/gadhagod/following{/other_user}",
            "gists_url": "https://api.github.com/users/gadhagod/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gadhagod/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gadhagod/subscriptions",
            "organizations_url": "https://api.github.com/users/gadhagod/orgs",
            "repos_url": "https://api.github.com/users/gadhagod/repos",
            "events_url": "https://api.github.com/users/gadhagod/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gadhagod/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-01T18:57:47Z",
        "updated_at": "2023-08-14T21:07:14Z",
        "closed_at": "2023-08-14T21:07:14Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7111",
            "html_url": "https://github.com/run-llama/llama_index/pull/7111",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7111.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7111.patch",
            "merged_at": "2023-08-14T21:07:14Z"
        },
        "body": "# Description\r\n\r\nAdded [Rockset](https://rockset.com/docs) as a vector store to llama index.\r\n\r\n> Rockset is a real-time analytics database which enables queries on massive, semi-structured data without operational burden. Rockset is serverless and fully managed. It offloads the work of managing configuration, cluster provisioning, denormalization, and shard / index management. Rockset is also SOC 2 Type II compliant and offers encryption at rest and in flight, securing and protecting any sensitive data. Most teams can ingest data into Rockset and start executing queries in less than 15 minutes.\r\n\r\nAdded example notebook and integration tests. \r\n\r\nRan `black` and `mypy` and everything's good.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7111/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7111/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7110",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7110/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7110/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7110/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7110",
        "id": 1831795944,
        "node_id": "I_kwDOIWuq585tLvzo",
        "number": 7110,
        "title": "[Question]: Embedding dimension 1536 does not match collection dimensionality 768",
        "user": {
            "login": "kylemassimilian",
            "id": 31603204,
            "node_id": "MDQ6VXNlcjMxNjAzMjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/31603204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylemassimilian",
            "html_url": "https://github.com/kylemassimilian",
            "followers_url": "https://api.github.com/users/kylemassimilian/followers",
            "following_url": "https://api.github.com/users/kylemassimilian/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylemassimilian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylemassimilian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylemassimilian/subscriptions",
            "organizations_url": "https://api.github.com/users/kylemassimilian/orgs",
            "repos_url": "https://api.github.com/users/kylemassimilian/repos",
            "events_url": "https://api.github.com/users/kylemassimilian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylemassimilian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-01T18:17:00Z",
        "updated_at": "2023-08-03T19:44:43Z",
        "closed_at": "2023-08-03T19:44:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n\r\nI'm trying to fix the case in which a Chroma collection already exists. Does anyone know how I can prevent a reembedding attempt and just build an index?\r\n\r\n```\r\n`Loading data...\r\nData loaded\r\n['Pavise-small', 'Pavise-small-768-3', 'IX-test', 'IX-Alpha-new-2', 'Pavise-small-768', 'IX-Alpha-new', 'Pavise-small-768-2', 'IX-Alpha-investments']\r\nCollection 'Pavise-small-768-2' already exists, getting existing collection...\r\nTraceback (most recent call last):\r\n  File \"/chroma/chromatest4.py\", line 80, in <module>\r\n    response = query_chroma(test)\r\n  File \"/chroma/chromatest4.py\", line 75, in query_chroma\r\n    response = chat_engine.chat(\"Tell me about Pavise\")\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/agent/react/base.py\", line 156, in chat\r\n    reasoning_steps, is_done = self._process_actions(output=chat_response)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/agent/react/base.py\", line 117, in _process_actions\r\n    tool_output = tool(**reasoning_step.action_input)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/tools/query_engine.py\", line 54, in __call__\r\n    response = self._query_engine.query(query_str)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 157, in _query\r\n    nodes = self.retrieve(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 115, in retrieve\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/base_retriever.py\", line 22, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 75, in _retrieve\r\n    return self._get_nodes_with_embeddings(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 151, in _get_nodes_with_embeddings\r\n    query_result = self._vector_store.query(query, **self._kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/vector_stores/chroma.py\", line 130, in query\r\n    results = self._collection.query(\r\n  File \"/chroma/chromadb/api/models/Collection.py\", line 223, in query\r\n    return self._client._query(\r\n  File \"/chroma/chromadb/api/fastapi.py\", line 340, in _query\r\n    raise_chroma_error(resp)\r\n  File \"/chroma/chromadb/api/fastapi.py\", line 405, in raise_chroma_error\r\n    raise chroma_error\r\nchromadb.errors.InvalidDimensionException: Embedding dimension 1536 does not match collection dimensionality 768`\r\n```\r\n\r\n```\r\nimport os, chromadb, openai, sys\r\nfrom dotenv import load_dotenv\r\nfrom llama_index import VectorStoreIndex, ServiceContext, load_index_from_storage\r\nfrom llama_index.vector_stores import ChromaVectorStore\r\nfrom llama_index.storage.storage_context import StorageContext\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index.embeddings import LangchainEmbedding\r\nfrom llama_index import download_loader\r\nload_dotenv()\r\nopenai.organization = os.getenv('OPENAI_ORGANIZATION')\r\nopenai.api_key = os.getenv('OPENAI_API_KEY')\r\n\r\n# Create AWS S3 Reader using download_loader class\r\nS3Reader = download_loader(\"S3Reader\")\r\n\r\n# Validate credentials\r\nbucket = os.getenv('BUCKET_NAME')\r\n#key = os.getenv('KEY_NAME')\r\naccess_id = os.getenv('ACCESS_ID')\r\nsecret_key = os.getenv('SECRET_KEY')\r\n\r\n# Load data from S3 w/ credentials\r\nloader = S3Reader(bucket=bucket, prefix='', aws_access_id=access_id, aws_access_secret=secret_key)\r\n    # Load data into document format\r\ntry:\r\n        print(\"Loading data...\")\r\n        documents = loader.load_data()\r\n        print(\"Data loaded\")\r\nexcept Exception as e:\r\n        print(\"Error loading data:\", e)\r\n\r\ndef index_chroma():\r\n    \r\n   # Create remote Chroma connection\r\n   remote_db = chromadb.HttpClient(host=\"\", port=8000)\r\n\r\n   collection_name = \"Pavise-small-768-2\"\r\n   collections = [col.name for col in remote_db.list_collections()]\r\n   print(collections)\r\n   \r\n   embed_model = LangchainEmbedding(\r\n            HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\r\n         )\r\n\r\n   # Check if collection exists and either retrieve or create it accordingly\r\n   if collection_name in collections:\r\n         print(f\"Collection '{collection_name}' already exists, getting existing collection...\")\r\n         chroma_collection = remote_db.get_collection(collection_name)\r\n         vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n         index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\r\n         #storage_context=StorageContext.from_defaults(vector_store=chroma_collection['embeddings'])\r\n         #index = load_index_from_storage(storage_context)\r\n         return index\r\n         \r\n   else:\r\n         print(\"Creating new collection...\")\r\n         chroma_collection = remote_db.create_collection(collection_name)\r\n         \r\n         # Create Chroma Vector Store\r\n         vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n         # Create the storage context and service context for the new collections\r\n         storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n         service_context = ServiceContext.from_defaults(embed_model=embed_model)\r\n\r\n         # Create index from documents for the new collection\r\n         index = VectorStoreIndex.from_documents(\r\n               documents, storage_context=storage_context, service_context=service_context, embed_model=embed_model)\r\n         return index\r\n   \r\n   \r\n\r\ndef query_chroma(index):\r\n    chat_engine = index.as_chat_engine()\r\n\r\n    response = chat_engine.chat(\"Tell me about Pavise\")\r\n    return response\r\n\r\n\r\ntest = index_chroma()\r\nresponse = query_chroma(test)\r\nprint(response)\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7110/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7110/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7109",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7109/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7109/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7109/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7109",
        "id": 1831648528,
        "node_id": "PR_kwDOIWuq585W7e07",
        "number": 7109,
        "title": "Remove popular column",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-01T16:31:17Z",
        "updated_at": "2023-08-01T16:45:50Z",
        "closed_at": "2023-08-01T16:45:49Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7109",
            "html_url": "https://github.com/run-llama/llama_index/pull/7109",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7109.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7109.patch",
            "merged_at": "2023-08-01T16:45:49Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7109/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7109/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7108",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7108/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7108/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7108/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7108",
        "id": 1831643393,
        "node_id": "I_kwDOIWuq585tLKkB",
        "number": 7108,
        "title": "[Question]: Trying to understand llama_index better",
        "user": {
            "login": "kylemassimilian",
            "id": 31603204,
            "node_id": "MDQ6VXNlcjMxNjAzMjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/31603204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylemassimilian",
            "html_url": "https://github.com/kylemassimilian",
            "followers_url": "https://api.github.com/users/kylemassimilian/followers",
            "following_url": "https://api.github.com/users/kylemassimilian/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylemassimilian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylemassimilian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylemassimilian/subscriptions",
            "organizations_url": "https://api.github.com/users/kylemassimilian/orgs",
            "repos_url": "https://api.github.com/users/kylemassimilian/repos",
            "events_url": "https://api.github.com/users/kylemassimilian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylemassimilian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-01T16:27:48Z",
        "updated_at": "2023-08-03T19:42:42Z",
        "closed_at": "2023-08-03T19:42:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI'm trying to create a Q&A app over a large set of documents. I'm currently using the s3 loader to retrieve my docs and load them in (is this pulling all the documents on to my local machine?). Currently, I cannot do this with close to 1GB of files without having my working code run extremely slow (5-10 minutes before timeout). My desired amount of file data is 10GB. Then, I am using Chroma to store these documents in a collection and build my index to then query. \r\n\r\n1. Is there a different method I can use to speed up this loading of documents? Perhaps with the Chroma reader? If I used the Chroma reader, would I do all of the embedding ahead of time, and would I only have to do this once?\r\n2. I think I'm embedding every time I run this but please let me know if I'm wrong. Is there a way to prevent this from happening/only do it once? I would like to embed my files one time, then add my vectordb using a Lambda function each time files are added to the bucket.\r\n3. Is the advantage of running Chroma in the cloud that I can store my embeddings in a way such that anyone can use them later for querying? If so, I do not understand how to implement this in code.\r\n\r\nThis code works, but only for a very small amount of data. I'm trying to create something others could use \r\n\r\n```\r\n`import os, chromadb, openai\r\nfrom dotenv import load_dotenv\r\nfrom llama_index import VectorStoreIndex, ServiceContext\r\nfrom llama_index.vector_stores import ChromaVectorStore\r\nfrom llama_index.storage.storage_context import StorageContext\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index.embeddings import LangchainEmbedding\r\nfrom llama_index import download_loader\r\nload_dotenv()\r\nopenai.organization = os.getenv('OPENAI_ORGANIZATION')\r\nopenai.api_key = os.getenv('OPENAI_API_KEY')\r\n\r\n# Create AWS S3 Reader using download_loader class\r\nS3Reader = download_loader(\"S3Reader\")\r\n\r\n# Validate credentials\r\nbucket = os.getenv('BUCKET_NAME')\r\n#key = os.getenv('KEY_NAME')\r\naccess_id = os.getenv('ACCESS_ID')\r\nsecret_key = os.getenv('SECRET_KEY')\r\n\r\n# Load data from S3 w/ credentials\r\nloader = S3Reader(bucket=bucket, prefix='', aws_access_id=access_id, aws_access_secret=secret_key)\r\n    # Load data into document format\r\ntry:\r\n        print(\"Loading data...\")\r\n        documents = loader.load_data()\r\n        print(\"Data loaded\")\r\nexcept Exception as e:\r\n        print(\"Error loading data:\", e)\r\n\r\ndef index_chroma():\r\n    \r\n   # Create remote Chroma connection\r\n   remote_db = chromadb.HttpClient(host=\"\", port=8000)\r\n\r\n   collection_name = \"Pavise-small-768-3\"\r\n   collections = [col.name for col in remote_db.list_collections()]\r\n   print(collections)\r\n   \r\n   embed_model = LangchainEmbedding(\r\n            HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\r\n         )\r\n   chroma_collection = remote_db.get_or_create_collection(collection_name)\r\n   \r\n   vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n   storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n   service_context = ServiceContext.from_defaults(embed_model=embed_model)\r\n   \r\n   index = VectorStoreIndex.from_documents(\r\n               documents, storage_context=storage_context, service_context=service_context, embed_model=embed_model)\r\n   return index\r\n  \r\ndef query_chroma(index):\r\n    chat_engine = index.as_chat_engine()\r\n\r\n    response = chat_engine.chat(\"Tell me about Pavise\")\r\n    return response\r\n\r\ntest = index_chroma()\r\nresponse = query_chroma(test)\r\nprint(response)`\r\n```\r\n\r\nI tried to create a check to see if the collection was new:\r\n\r\n```\r\n`import os, chromadb, openai, sys\r\nfrom dotenv import load_dotenv\r\nfrom llama_index import VectorStoreIndex, ServiceContext, load_index_from_storage\r\nfrom llama_index.vector_stores import ChromaVectorStore\r\nfrom llama_index.storage.storage_context import StorageContext\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index.embeddings import LangchainEmbedding\r\nfrom llama_index import download_loader\r\nload_dotenv()\r\nopenai.organization = os.getenv('OPENAI_ORGANIZATION')\r\nopenai.api_key = os.getenv('OPENAI_API_KEY')\r\n\r\n# Create AWS S3 Reader using download_loader class\r\nS3Reader = download_loader(\"S3Reader\")\r\n\r\n# Validate credentials\r\nbucket = os.getenv('BUCKET_NAME')\r\n#key = os.getenv('KEY_NAME')\r\naccess_id = os.getenv('ACCESS_ID')\r\nsecret_key = os.getenv('SECRET_KEY')\r\n\r\n# Load data from S3 w/ credentials\r\nloader = S3Reader(bucket=bucket, prefix='', aws_access_id=access_id, aws_access_secret=secret_key)\r\n    # Load data into document format\r\ntry:\r\n        print(\"Loading data...\")\r\n        documents = loader.load_data()\r\n        print(\"Data loaded\")\r\nexcept Exception as e:\r\n        print(\"Error loading data:\", e)\r\n\r\ndef index_chroma():\r\n    \r\n   # Create remote Chroma connection\r\n   remote_db = chromadb.HttpClient(host=\"\", port=8000)\r\n\r\n   collection_name = \"Pavise-small-768-2\"\r\n   collections = [col.name for col in remote_db.list_collections()]\r\n   print(collections)\r\n   \r\n   embed_model = LangchainEmbedding(\r\n            HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\r\n         )\r\n\r\n   # Check if collection exists and either retrieve or create it accordingly\r\n   if collection_name in collections:\r\n         print(f\"Collection '{collection_name}' already exists, getting existing collection...\")\r\n         chroma_collection = remote_db.get_collection(collection_name)\r\n         vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n         index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\r\n         #storage_context=StorageContext.from_defaults(vector_store=chroma_collection['embeddings'])\r\n         #index = load_index_from_storage(storage_context)\r\n         return index\r\n         \r\n   else:\r\n         print(\"Creating new collection...\")\r\n         chroma_collection = remote_db.create_collection(collection_name)\r\n         \r\n         # Create Chroma Vector Store\r\n         vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\n         # Create the storage context and service context for the new collections\r\n         storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n         service_context = ServiceContext.from_defaults(embed_model=embed_model)\r\n\r\n         # Create index from documents for the new collection\r\n         index = VectorStoreIndex.from_documents(\r\n               documents, storage_context=storage_context, service_context=service_context, embed_model=embed_model)\r\n         return index\r\n   \r\n   \r\n\r\ndef query_chroma(index, query):\r\n    chat_engine = index.as_chat_engine()\r\n\r\n    response = chat_engine.chat(\"Tell me about Pavise\")\r\n    return response\r\n\r\n\r\ntest = index_chroma()\r\nresponse = query_chroma(test)\r\nprint(response)\r\n```\r\n\r\nbut I received this error:\r\n\r\n```\r\nroot@38200e892614:/chroma# python chromatest4.py\r\nLoading data...\r\nData loaded\r\n['Pavise-small', 'Pavise-small-768-3', 'IX-test', 'IX-Alpha-new-2', 'Pavise-small-768', 'IX-Alpha-new', 'Pavise-small-768-2', 'IX-Alpha-investments']\r\nCollection 'Pavise-small-768-2' already exists, getting existing collection...\r\nTraceback (most recent call last):\r\n  File \"/chroma/chromatest4.py\", line 81, in <module>\r\n    response = query_chroma(test)\r\n  File \"/chroma/chromatest4.py\", line 76, in query_chroma\r\n    response = chat_engine.chat(\"Tell me about Pavise\")\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/agent/react/base.py\", line 156, in chat\r\n    reasoning_steps, is_done = self._process_actions(output=chat_response)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/agent/react/base.py\", line 117, in _process_actions\r\n    tool_output = tool(**reasoning_step.action_input)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/tools/query_engine.py\", line 54, in __call__\r\n    response = self._query_engine.query(query_str)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 157, in _query  \r\n    nodes = self.retrieve(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 115, in retrieve\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/base_retriever.py\", line 22, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 75, in _retrieve\r\n    return self._get_nodes_with_embeddings(query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 151, in _get_nodes_with_embeddings\r\n    query_result = self._vector_store.query(query, **self._kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/vector_stores/chroma.py\", line 130, in query\r\n    results = self._collection.query(\r\n  File \"/chroma/chromadb/api/models/Collection.py\", line 223, in query\r\n    return self._client._query(\r\n  File \"/chroma/chromadb/api/fastapi.py\", line 340, in _query\r\n    raise_chroma_error(resp)\r\n  File \"/chroma/chromadb/api/fastapi.py\", line 405, in raise_chroma_error\r\n    raise chroma_error\r\nchromadb.errors.InvalidDimensionException: Embedding dimension 1536 does not match collection dimensionality 768\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7108/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7108/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7107",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7107/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7107/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7107/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7107",
        "id": 1831527554,
        "node_id": "PR_kwDOIWuq585W7Ei3",
        "number": 7107,
        "title": "Add warning about eval to PandasQueryEngine",
        "user": {
            "login": "ajhofmann",
            "id": 10040285,
            "node_id": "MDQ6VXNlcjEwMDQwMjg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10040285?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajhofmann",
            "html_url": "https://github.com/ajhofmann",
            "followers_url": "https://api.github.com/users/ajhofmann/followers",
            "following_url": "https://api.github.com/users/ajhofmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajhofmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajhofmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajhofmann/subscriptions",
            "organizations_url": "https://api.github.com/users/ajhofmann/orgs",
            "repos_url": "https://api.github.com/users/ajhofmann/repos",
            "events_url": "https://api.github.com/users/ajhofmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajhofmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-01T15:26:01Z",
        "updated_at": "2023-08-01T16:02:14Z",
        "closed_at": "2023-08-01T16:02:14Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7107",
            "html_url": "https://github.com/run-llama/llama_index/pull/7107",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7107.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7107.patch",
            "merged_at": "2023-08-01T16:02:14Z"
        },
        "body": "# Description\r\n\r\nAdd a warning to the PandasQueryEngine about the use of eval.\r\n\r\nFixes # (issue)\r\n\r\nRelated to https://github.com/jerryjliu/llama_index/issues/7017 but not a fix!\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7107/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7107/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7106",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7106/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7106/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7106/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7106",
        "id": 1831325903,
        "node_id": "PR_kwDOIWuq585W6YyS",
        "number": 7106,
        "title": "Update usage_pattern.md",
        "user": {
            "login": "sheresaidon",
            "id": 21957184,
            "node_id": "MDQ6VXNlcjIxOTU3MTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/21957184?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sheresaidon",
            "html_url": "https://github.com/sheresaidon",
            "followers_url": "https://api.github.com/users/sheresaidon/followers",
            "following_url": "https://api.github.com/users/sheresaidon/following{/other_user}",
            "gists_url": "https://api.github.com/users/sheresaidon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sheresaidon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sheresaidon/subscriptions",
            "organizations_url": "https://api.github.com/users/sheresaidon/orgs",
            "repos_url": "https://api.github.com/users/sheresaidon/repos",
            "events_url": "https://api.github.com/users/sheresaidon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sheresaidon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-01T13:44:41Z",
        "updated_at": "2023-08-01T14:21:15Z",
        "closed_at": "2023-08-01T14:21:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7106",
            "html_url": "https://github.com/run-llama/llama_index/pull/7106",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7106.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7106.patch",
            "merged_at": "2023-08-01T14:21:15Z"
        },
        "body": "update usage_pattern for post processors to account for the new retrieve nodes method\r\n\r\n# Description\r\n\r\nupdate usage_pattern for post processors to account for the new retrieve nodes method\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7106/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7106/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7105",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7105/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7105/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7105/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7105",
        "id": 1830963271,
        "node_id": "PR_kwDOIWuq585W5Kra",
        "number": 7105,
        "title": "Update Prompt for SubQuestionQueryEngine",
        "user": {
            "login": "tutu-sol",
            "id": 138968066,
            "node_id": "U_kgDOCEh8Ag",
            "avatar_url": "https://avatars.githubusercontent.com/u/138968066?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tutu-sol",
            "html_url": "https://github.com/tutu-sol",
            "followers_url": "https://api.github.com/users/tutu-sol/followers",
            "following_url": "https://api.github.com/users/tutu-sol/following{/other_user}",
            "gists_url": "https://api.github.com/users/tutu-sol/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tutu-sol/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tutu-sol/subscriptions",
            "organizations_url": "https://api.github.com/users/tutu-sol/orgs",
            "repos_url": "https://api.github.com/users/tutu-sol/repos",
            "events_url": "https://api.github.com/users/tutu-sol/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tutu-sol/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-01T10:31:04Z",
        "updated_at": "2023-08-02T19:50:10Z",
        "closed_at": "2023-08-02T19:50:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7105",
            "html_url": "https://github.com/run-llama/llama_index/pull/7105",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7105.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7105.patch",
            "merged_at": "2023-08-02T19:50:10Z"
        },
        "body": "Explicitly instructs the LLM to output in json markdown, otherwise sometimes it only output as markdown without marking it as json, which will break the subsequent steps.\r\n\r\n# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] Local Testing\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7105/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7105/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7104",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7104/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7104/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7104/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7104",
        "id": 1830724345,
        "node_id": "PR_kwDOIWuq585W4YA6",
        "number": 7104,
        "title": "New community app showcase entry",
        "user": {
            "login": "PixellUp",
            "id": 4704339,
            "node_id": "MDQ6VXNlcjQ3MDQzMzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4704339?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PixellUp",
            "html_url": "https://github.com/PixellUp",
            "followers_url": "https://api.github.com/users/PixellUp/followers",
            "following_url": "https://api.github.com/users/PixellUp/following{/other_user}",
            "gists_url": "https://api.github.com/users/PixellUp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PixellUp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PixellUp/subscriptions",
            "organizations_url": "https://api.github.com/users/PixellUp/orgs",
            "repos_url": "https://api.github.com/users/PixellUp/repos",
            "events_url": "https://api.github.com/users/PixellUp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PixellUp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-01T08:21:55Z",
        "updated_at": "2023-08-01T18:48:21Z",
        "closed_at": "2023-08-01T18:48:20Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7104",
            "html_url": "https://github.com/run-llama/llama_index/pull/7104",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7104.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7104.patch",
            "merged_at": "2023-08-01T18:48:20Z"
        },
        "body": "# Description\r\n\r\nThis is a new entry in-app community showcase, showing the power of LLMAs and Llama index + LangChain. It is a service that exclusively uses Llama index and OpenAI ChatGPT to train on customer data and provide rich and personalized responses via chatbot. It showcases the ability of Language models to understand data and provide contextual information from it.  \r\n\r\n\r\n## Type of Change\r\n\r\n\r\n- [x] This change requires a documentation update\r\n\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7104/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7104/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7103",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7103/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7103/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7103/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7103",
        "id": 1830455122,
        "node_id": "PR_kwDOIWuq585W3eai",
        "number": 7103,
        "title": "changed argument name in vector_store/supabase",
        "user": {
            "login": "Moi1oM",
            "id": 101260709,
            "node_id": "U_kgDOBgkdpQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/101260709?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Moi1oM",
            "html_url": "https://github.com/Moi1oM",
            "followers_url": "https://api.github.com/users/Moi1oM/followers",
            "following_url": "https://api.github.com/users/Moi1oM/following{/other_user}",
            "gists_url": "https://api.github.com/users/Moi1oM/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Moi1oM/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Moi1oM/subscriptions",
            "organizations_url": "https://api.github.com/users/Moi1oM/orgs",
            "repos_url": "https://api.github.com/users/Moi1oM/repos",
            "events_url": "https://api.github.com/users/Moi1oM/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Moi1oM/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-01T04:45:57Z",
        "updated_at": "2023-08-13T18:27:42Z",
        "closed_at": "2023-08-13T18:27:42Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7103",
            "html_url": "https://github.com/run-llama/llama_index/pull/7103",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7103.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7103.patch",
            "merged_at": "2023-08-13T18:27:42Z"
        },
        "body": "# Description\r\n\r\nI was trying to do a vector store using llama index and supabase, but the following error occurred. \"TypeError: Collection.upsert() got an unexpected keyword argument 'vectors'.\" So I changed the named arguments from vectors to records and ran the code, and it worked properly. And collection. Among the named arguments in query, query_vector was replaced with data. The Dependency has not changed.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\nThe only part I changed was the argument, so I didn't write a new test.\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7103/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7103/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7102",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7102/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7102/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7102/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7102",
        "id": 1830434396,
        "node_id": "PR_kwDOIWuq585W3aFC",
        "number": 7102,
        "title": "changed superbase upsert named_arg vectors to records",
        "user": {
            "login": "Moi1oM",
            "id": 101260709,
            "node_id": "U_kgDOBgkdpQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/101260709?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Moi1oM",
            "html_url": "https://github.com/Moi1oM",
            "followers_url": "https://api.github.com/users/Moi1oM/followers",
            "following_url": "https://api.github.com/users/Moi1oM/following{/other_user}",
            "gists_url": "https://api.github.com/users/Moi1oM/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Moi1oM/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Moi1oM/subscriptions",
            "organizations_url": "https://api.github.com/users/Moi1oM/orgs",
            "repos_url": "https://api.github.com/users/Moi1oM/repos",
            "events_url": "https://api.github.com/users/Moi1oM/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Moi1oM/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-01T04:20:34Z",
        "updated_at": "2023-08-01T04:41:49Z",
        "closed_at": "2023-08-01T04:41:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7102",
            "html_url": "https://github.com/run-llama/llama_index/pull/7102",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7102.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7102.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nI was trying to do a vector store using llama index and supabase, but the following error occurred. \"TypeError: Collection.upsert() got an unexpected keyword argument 'vectors'.\" So I changed the named arguments from vectors to records and ran the code, and it worked properly. The Dependency has not changed.\r\n\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\nThe only part I changed was the argument, so I didn't write a new test.\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7102/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7102/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7101",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7101/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7101/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7101/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7101",
        "id": 1830285683,
        "node_id": "I_kwDOIWuq585tF_Fz",
        "number": 7101,
        "title": "[Bug]: Node IDs retrieved by callback are not found in docstore/ vector store/ index store",
        "user": {
            "login": "axiomofjoy",
            "id": 15664869,
            "node_id": "MDQ6VXNlcjE1NjY0ODY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/15664869?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axiomofjoy",
            "html_url": "https://github.com/axiomofjoy",
            "followers_url": "https://api.github.com/users/axiomofjoy/followers",
            "following_url": "https://api.github.com/users/axiomofjoy/following{/other_user}",
            "gists_url": "https://api.github.com/users/axiomofjoy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axiomofjoy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axiomofjoy/subscriptions",
            "organizations_url": "https://api.github.com/users/axiomofjoy/orgs",
            "repos_url": "https://api.github.com/users/axiomofjoy/repos",
            "events_url": "https://api.github.com/users/axiomofjoy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axiomofjoy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-01T01:05:36Z",
        "updated_at": "2023-08-04T22:04:08Z",
        "closed_at": "2023-08-04T22:04:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nWhile building a callback handler, the node IDs retrieved from the retrieval callback hook don't match any of the node IDs in the docstore/ vector store/ index store. I expected these node IDs to be the same as the IDs in the storage context. Is that a correct assumption?\r\n\r\nAs additional context, I would ideally like the node IDs collected by the callback at query time to match the IDs in the underlying vector store/ vector DB.\r\n\r\n### Version\r\n\r\nlatest `main` (773a6834)\r\n\r\n### Steps to Reproduce\r\n\r\nRun the notebook reproducing the issue [here](https://colab.research.google.com/drive/1ssL2FGI_ZLagmX6up4UKueeEYW8SkGbR?usp=sharing).\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nn/a\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7101/reactions",
            "total_count": 2,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7101/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7100",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7100/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7100/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7100/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7100",
        "id": 1830229651,
        "node_id": "PR_kwDOIWuq585W2vIM",
        "number": 7100,
        "title": "add code splitter",
        "user": {
            "login": "yisding",
            "id": 1209314,
            "node_id": "MDQ6VXNlcjEyMDkzMTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1209314?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yisding",
            "html_url": "https://github.com/yisding",
            "followers_url": "https://api.github.com/users/yisding/followers",
            "following_url": "https://api.github.com/users/yisding/following{/other_user}",
            "gists_url": "https://api.github.com/users/yisding/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yisding/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yisding/subscriptions",
            "organizations_url": "https://api.github.com/users/yisding/orgs",
            "repos_url": "https://api.github.com/users/yisding/repos",
            "events_url": "https://api.github.com/users/yisding/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yisding/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-07-31T23:54:26Z",
        "updated_at": "2023-08-03T01:08:02Z",
        "closed_at": "2023-08-01T03:28:27Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7100",
            "html_url": "https://github.com/run-llama/llama_index/pull/7100",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7100.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7100.patch",
            "merged_at": "2023-08-01T03:28:27Z"
        },
        "body": "# Description\r\n\r\nAdd code splitter to text splitters. Thanks to @kevinlu1248 from Sweep AI for the idea and push.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X ] New feature (non-breaking change which adds functionality)\r\n- [X ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X ] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [X ] I have performed a self-review of my own code\r\n- [X ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X ] My changes generate no new warnings\r\n- [X ] I have added tests that prove my fix is effective or that my feature works\r\n- [X ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7100/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7100/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7099",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7099/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7099/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7099/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7099",
        "id": 1830148929,
        "node_id": "PR_kwDOIWuq585W2dqA",
        "number": 7099,
        "title": "Predibase LLM Integration",
        "user": {
            "login": "Abhay-765",
            "id": 32989166,
            "node_id": "MDQ6VXNlcjMyOTg5MTY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/32989166?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Abhay-765",
            "html_url": "https://github.com/Abhay-765",
            "followers_url": "https://api.github.com/users/Abhay-765/followers",
            "following_url": "https://api.github.com/users/Abhay-765/following{/other_user}",
            "gists_url": "https://api.github.com/users/Abhay-765/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Abhay-765/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Abhay-765/subscriptions",
            "organizations_url": "https://api.github.com/users/Abhay-765/orgs",
            "repos_url": "https://api.github.com/users/Abhay-765/repos",
            "events_url": "https://api.github.com/users/Abhay-765/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Abhay-765/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-07-31T22:36:14Z",
        "updated_at": "2023-08-01T23:10:28Z",
        "closed_at": "2023-08-01T23:10:28Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7099",
            "html_url": "https://github.com/run-llama/llama_index/pull/7099",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7099.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7099.patch",
            "merged_at": "2023-08-01T23:10:28Z"
        },
        "body": "# Predibase LLM Integration\r\n\r\nThis PR adds a Predibase integration as a custom LLM. I've also added an example notebook for reference.\r\n\r\nPlease let me know if there's anything I can do to improve the PR. When it's merged, feel free to tag https://twitter.com/predibase and https://twitter.com/AbhayyM as contributors.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7099/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7099/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7098",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7098/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7098/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7098/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7098",
        "id": 1829786531,
        "node_id": "PR_kwDOIWuq585W1OVa",
        "number": 7098,
        "title": "Support forced function call in OpenAI agent",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-31T18:21:44Z",
        "updated_at": "2023-08-01T18:39:45Z",
        "closed_at": "2023-08-01T18:39:43Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7098",
            "html_url": "https://github.com/run-llama/llama_index/pull/7098",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7098.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7098.patch",
            "merged_at": "2023-08-01T18:39:43Z"
        },
        "body": "# Description\r\n\r\nSupport forced function call in OpenAI agent\r\n\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7098/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7098/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7097",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7097/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7097/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7097/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7097",
        "id": 1829722670,
        "node_id": "PR_kwDOIWuq585W1AZY",
        "number": 7097,
        "title": "Make OpenAI agent support empty list of tools",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-31T17:38:18Z",
        "updated_at": "2023-07-31T19:00:40Z",
        "closed_at": "2023-07-31T19:00:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7097",
            "html_url": "https://github.com/run-llama/llama_index/pull/7097",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7097.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7097.patch",
            "merged_at": "2023-07-31T19:00:39Z"
        },
        "body": "# Description\r\n\r\nMake OpenAI agent support empty list of tools\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7097/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7097/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7096",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7096/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7096/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7096/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7096",
        "id": 1829186033,
        "node_id": "PR_kwDOIWuq585WzJP-",
        "number": 7096,
        "title": "Fix path to jupyter notebook in metadata_extraction.md",
        "user": {
            "login": "tilleul",
            "id": 3061106,
            "node_id": "MDQ6VXNlcjMwNjExMDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3061106?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tilleul",
            "html_url": "https://github.com/tilleul",
            "followers_url": "https://api.github.com/users/tilleul/followers",
            "following_url": "https://api.github.com/users/tilleul/following{/other_user}",
            "gists_url": "https://api.github.com/users/tilleul/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tilleul/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tilleul/subscriptions",
            "organizations_url": "https://api.github.com/users/tilleul/orgs",
            "repos_url": "https://api.github.com/users/tilleul/repos",
            "events_url": "https://api.github.com/users/tilleul/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tilleul/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-31T13:24:38Z",
        "updated_at": "2023-07-31T14:20:34Z",
        "closed_at": "2023-07-31T14:20:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7096",
            "html_url": "https://github.com/run-llama/llama_index/pull/7096",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7096.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7096.patch",
            "merged_at": "2023-07-31T14:20:33Z"
        },
        "body": "# Description\r\n\r\nsimple path fix",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7096/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7096/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7095",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7095/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7095/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7095/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7095",
        "id": 1829147559,
        "node_id": "PR_kwDOIWuq585WzA1-",
        "number": 7095,
        "title": "Updated docs",
        "user": {
            "login": "anoopshrma",
            "id": 26565263,
            "node_id": "MDQ6VXNlcjI2NTY1MjYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/26565263?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anoopshrma",
            "html_url": "https://github.com/anoopshrma",
            "followers_url": "https://api.github.com/users/anoopshrma/followers",
            "following_url": "https://api.github.com/users/anoopshrma/following{/other_user}",
            "gists_url": "https://api.github.com/users/anoopshrma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anoopshrma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anoopshrma/subscriptions",
            "organizations_url": "https://api.github.com/users/anoopshrma/orgs",
            "repos_url": "https://api.github.com/users/anoopshrma/repos",
            "events_url": "https://api.github.com/users/anoopshrma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anoopshrma/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-31T13:02:50Z",
        "updated_at": "2023-07-31T14:20:54Z",
        "closed_at": "2023-07-31T14:20:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7095",
            "html_url": "https://github.com/run-llama/llama_index/pull/7095",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7095.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7095.patch",
            "merged_at": "2023-07-31T14:20:54Z"
        },
        "body": "\r\n\r\n# Description\r\n\r\nAdded missing `.load_data()` to the reader class\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7095/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7095/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7094",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7094/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7094/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7094/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7094",
        "id": 1829102438,
        "node_id": "I_kwDOIWuq585tBeNm",
        "number": 7094,
        "title": "[Feature Request]: Function-calling query engines",
        "user": {
            "login": "SlapDrone",
            "id": 32279503,
            "node_id": "MDQ6VXNlcjMyMjc5NTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32279503?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SlapDrone",
            "html_url": "https://github.com/SlapDrone",
            "followers_url": "https://api.github.com/users/SlapDrone/followers",
            "following_url": "https://api.github.com/users/SlapDrone/following{/other_user}",
            "gists_url": "https://api.github.com/users/SlapDrone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SlapDrone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SlapDrone/subscriptions",
            "organizations_url": "https://api.github.com/users/SlapDrone/orgs",
            "repos_url": "https://api.github.com/users/SlapDrone/repos",
            "events_url": "https://api.github.com/users/SlapDrone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SlapDrone/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-07-31T12:38:33Z",
        "updated_at": "2023-11-18T04:29:15Z",
        "closed_at": "2023-11-03T23:38:05Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nHey folks,\r\n\r\nIs there yet implemented a way to integrate function calling APIs with a good old fashioned query engine?\r\n\r\nIt would be amazing if we had (have?) something like the [OpenAI Pydantic Program](https://gpt-index.readthedocs.io/en/latest/examples/output_parsing/openai_pydantic_program.html), but where the function calling + pydantic native output templating was available for complex response synthesizers.\n\n### Reason\n\nI don't think there's anything stopping this. In fact it may be in already and just not well documented since things are moving so fast.\r\n\r\nI'm currently working with a use-case where I have a query engine that's refining an answer over a large corpus, where the answer is a complex JSON containing an array of objects (currently using the vanilla pydantic + output parser approach). The formatting instructions eat up a huge chunk of my token budget, so this would be a godsend.\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7094/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7094/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7093",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7093/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7093/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7093/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7093",
        "id": 1828357970,
        "node_id": "I_kwDOIWuq585s-odS",
        "number": 7093,
        "title": "[Bug]: 'HuggingFaceLLM' object has no attribute 'predict' ",
        "user": {
            "login": "ChuaCheowHuan",
            "id": 17569306,
            "node_id": "MDQ6VXNlcjE3NTY5MzA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/17569306?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ChuaCheowHuan",
            "html_url": "https://github.com/ChuaCheowHuan",
            "followers_url": "https://api.github.com/users/ChuaCheowHuan/followers",
            "following_url": "https://api.github.com/users/ChuaCheowHuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/ChuaCheowHuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ChuaCheowHuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ChuaCheowHuan/subscriptions",
            "organizations_url": "https://api.github.com/users/ChuaCheowHuan/orgs",
            "repos_url": "https://api.github.com/users/ChuaCheowHuan/repos",
            "events_url": "https://api.github.com/users/ChuaCheowHuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ChuaCheowHuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-07-31T03:59:37Z",
        "updated_at": "2023-08-02T02:21:55Z",
        "closed_at": "2023-08-01T20:56:00Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHi, \r\n\r\nI'm following this official [example](https://gpt-index.readthedocs.io/en/latest/examples/customization/llms/SimpleIndexDemo-Huggingface_camel.html) from the docs but I'm getting `'HuggingFaceLLM' object has no attribute 'predict'` error when attempting query with the LLM. The only difference between my code and the example is that I'm not using embedding model from OpenAI.\r\n\r\nThe code is able to generate the index without complaining but is giving the above error **only** when I run the query:\r\n```\r\nresponse = query_engine.query(\"What did the author do growing up?\")\r\n```\r\n\r\nThe embedding model used is `\"sentence-transformers/all-mpnet-base-v2\"`.\r\nThe LLM used is `\"Writer/camel-5b-hf\"`.\r\n\r\n\r\n\r\nIs this a bug or am I missing anything? Please help. Thank you.\r\n\r\nOther version information that might be useful:\r\n```\r\nPython 3.10.10\r\ntorch 2.0.0\r\nlangchain 0.0.247\r\nsentence-transformers 2.2.2\r\naccelerate 0.21.0\r\n```\r\n\r\n### Version\r\n\r\n0.7.16\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\nimport logging\r\nimport sys\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index import (\r\n    SimpleDirectoryReader,    \r\n    VectorStoreIndex,\r\n    LangchainEmbedding,\r\n    LLMPredictor,\r\n    ServiceContext,\r\n    set_global_service_context, \r\n    StorageContext,\r\n    load_index_from_storage,\r\n)\r\n\r\nfrom llama_index.llms import HuggingFaceLLM\r\nfrom llama_index.prompts.prompts import SimpleInputPrompt\r\n\r\nimport torch\r\n\r\n\r\nrequired_exts = [\".pdf\"]\r\nreader = SimpleDirectoryReader(\r\n    input_dir=\"data/pdf\", required_exts=required_exts, recursive=True\r\n)\r\ndocuments = reader.load_data()\r\n\r\nquery_wrapper_prompt = SimpleInputPrompt(\r\n    \"Below is an instruction that describes a task. \"\r\n    \"Write a response that appropriately completes the request.\\n\\n\"\r\n    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\r\n)\r\n\r\nllm = HuggingFaceLLM(\r\n    context_window=2048,\r\n    max_new_tokens=256,\r\n    generate_kwargs={\"temperature\": 0.25, \"do_sample\": False},\r\n    query_wrapper_prompt=query_wrapper_prompt,\r\n    tokenizer_name=\"Writer/camel-5b-hf\",\r\n    model_name=\"Writer/camel-5b-hf\",\r\n    device_map=\"auto\",\r\n    tokenizer_kwargs={\"max_length\": 2048},    \r\n    # uncomment this if using CUDA to reduce memory usage\r\n    # model_kwargs={\"torch_dtype\": torch.float16}\r\n)\r\n\r\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\r\nembed_model = LangchainEmbedding(\r\n    HuggingFaceEmbeddings(\r\n        model_name=model_name,\r\n    )\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm_predictor=llm, \r\n    embed_model=embed_model,\r\n)\r\n\r\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\nindex.storage_context.persist(persist_dir=\"index\")\r\n\r\nstorage_context = StorageContext.from_defaults(persist_dir=\"index\")\r\nindex = load_index_from_storage(storage_context, service_context=service_context)\r\n\r\nquery_engine = index.as_query_engine(service_context=service_context)\r\nresponse = query_engine.query(\"What did the author do growing up?\")\r\nresponse.print_response()\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nBatches: 100%\r\n1/1 [00:00<00:00, 13.40it/s]\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[25], line 2\r\n      1 query_engine = index.as_query_engine()\r\n----> 2 response = query_engine.query(\"What did the author do growing up?\")\r\n      3 response.print_response()\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/indices/query/base.py:23, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     21 if isinstance(str_or_query_bundle, str):\r\n     22     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 23 response = self._query(str_or_query_bundle)\r\n     24 return response\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py:175, in RetrieverQueryEngine._query(self, query_bundle)\r\n    169         nodes = self.retrieve(query_bundle)\r\n    171         retrieve_event.on_end(\r\n    172             payload={EventPayload.NODES: nodes},\r\n    173         )\r\n--> 175     response = self._response_synthesizer.synthesize(\r\n    176         query=query_bundle,\r\n    177         nodes=nodes,\r\n    178     )\r\n    180     query_event.on_end(payload={EventPayload.RESPONSE: response})\r\n    182 return response\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/response_synthesizers/base.py:125, in BaseSynthesizer.synthesize(self, query, nodes, additional_source_nodes)\r\n    120     query = QueryBundle(query_str=query)\r\n    122 with self._callback_manager.event(\r\n    123     CBEventType.SYNTHESIZE, payload={EventPayload.QUERY_STR: query.query_str}\r\n    124 ) as event:\r\n--> 125     response_str = self.get_response(\r\n    126         query_str=query.query_str,\r\n    127         text_chunks=[\r\n    128             n.node.get_content(metadata_mode=MetadataMode.LLM) for n in nodes\r\n    129         ],\r\n    130     )\r\n    132     additional_source_nodes = additional_source_nodes or []\r\n    133     source_nodes = list(nodes) + list(additional_source_nodes)\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/response_synthesizers/compact_and_refine.py:34, in CompactAndRefine.get_response(self, query_str, text_chunks, **response_kwargs)\r\n     30 # use prompt helper to fix compact text_chunks under the prompt limitation\r\n     31 # TODO: This is a temporary fix - reason it's temporary is that\r\n     32 # the refine template does not account for size of previous answer.\r\n     33 new_texts = self._make_compact_text_chunks(query_str, text_chunks)\r\n---> 34 response = super().get_response(\r\n     35     query_str=query_str, text_chunks=new_texts, **response_kwargs\r\n     36 )\r\n     37 return response\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py:49, in Refine.get_response(self, query_str, text_chunks, **response_kwargs)\r\n     45 for text_chunk in text_chunks:\r\n     46     if prev_response_obj is None:\r\n     47         # if this is the first chunk, and text chunk already\r\n     48         # is an answer, then return it\r\n---> 49         response = self._give_response_single(\r\n     50             query_str,\r\n     51             text_chunk,\r\n     52         )\r\n     53     else:\r\n     54         response = self._refine_response_single(\r\n     55             prev_response_obj, query_str, text_chunk\r\n     56         )\r\n\r\nFile ~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py:80, in Refine._give_response_single(self, query_str, text_chunk, **response_kwargs)\r\n     78 for cur_text_chunk in text_chunks:\r\n     79     if response is None and not self._streaming:\r\n---> 80         response = self._service_context.llm_predictor.predict(\r\n     81             text_qa_template,\r\n     82             context_str=cur_text_chunk,\r\n     83         )\r\n     84     elif response is None and self._streaming:\r\n     85         response = self._service_context.llm_predictor.stream(\r\n     86             text_qa_template,\r\n     87             context_str=cur_text_chunk,\r\n     88         )\r\n\r\nAttributeError: 'HuggingFaceLLM' object has no attribute 'predict'\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7093/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7093/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7092",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7092/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7092/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7092/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7092",
        "id": 1828279088,
        "node_id": "PR_kwDOIWuq585WwCpv",
        "number": 7092,
        "title": "Update usage_pattern.md",
        "user": {
            "login": "treize-khushrenada",
            "id": 78846238,
            "node_id": "MDQ6VXNlcjc4ODQ2MjM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/78846238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/treize-khushrenada",
            "html_url": "https://github.com/treize-khushrenada",
            "followers_url": "https://api.github.com/users/treize-khushrenada/followers",
            "following_url": "https://api.github.com/users/treize-khushrenada/following{/other_user}",
            "gists_url": "https://api.github.com/users/treize-khushrenada/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/treize-khushrenada/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/treize-khushrenada/subscriptions",
            "organizations_url": "https://api.github.com/users/treize-khushrenada/orgs",
            "repos_url": "https://api.github.com/users/treize-khushrenada/repos",
            "events_url": "https://api.github.com/users/treize-khushrenada/events{/privacy}",
            "received_events_url": "https://api.github.com/users/treize-khushrenada/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-31T02:46:06Z",
        "updated_at": "2023-07-31T10:52:20Z",
        "closed_at": "2023-07-31T10:52:20Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7092",
            "html_url": "https://github.com/run-llama/llama_index/pull/7092",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7092.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7092.patch",
            "merged_at": "2023-07-31T10:52:20Z"
        },
        "body": "wordings/ grammatical\r\n\r\n# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7092/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7091",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7091/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7091/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7091/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7091",
        "id": 1828111932,
        "node_id": "I_kwDOIWuq585s9sY8",
        "number": 7091,
        "title": "[Bug]: Setting Palm LLM Abstraction to ServiceContext still looks for OpenAI API Key",
        "user": {
            "login": "cmagorian",
            "id": 19879310,
            "node_id": "MDQ6VXNlcjE5ODc5MzEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/19879310?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cmagorian",
            "html_url": "https://github.com/cmagorian",
            "followers_url": "https://api.github.com/users/cmagorian/followers",
            "following_url": "https://api.github.com/users/cmagorian/following{/other_user}",
            "gists_url": "https://api.github.com/users/cmagorian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cmagorian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cmagorian/subscriptions",
            "organizations_url": "https://api.github.com/users/cmagorian/orgs",
            "repos_url": "https://api.github.com/users/cmagorian/repos",
            "events_url": "https://api.github.com/users/cmagorian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cmagorian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-07-30T22:41:13Z",
        "updated_at": "2023-09-29T13:40:47Z",
        "closed_at": "2023-07-31T20:57:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\main.py\", line 13, in <module>\r\n    service_context = ServiceContext.from_defaults(llm=model)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\indices\\service_context.py\", line 163, in from_defaults\r\n    embed_model = embed_model or OpenAIEmbedding()\r\n                                 ^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 248, in __init__\r\n    validate_openai_api_key(\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\llms\\openai_utils.py\", line 268, in validate_openai_api_key\r\n    raise ValueError(MISSING_API_KEY_ERROR_MESSAGE)\r\nValueError: No API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n```\r\n\r\nComing from:\r\n\r\n\r\n```\r\nimport google.generativeai as palm\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, set_global_service_context\r\nfrom llama_index.llms.palm import PaLM\r\nfrom llama_index.llms.openai import OpenAI\r\nimport gradio as gr\r\n\r\npalm.configure(api_key=<api-key>')\r\n\r\nmodel = PaLM('<api-key>')\r\n\r\ndocuments = SimpleDirectoryReader('docs').load_data()\r\nservice_context = ServiceContext.from_defaults(llm=model) # Bug comes from right here, it looks like `from_defaults()` needs `embed_model` to be something or defaults to OpenAI\r\nset_global_service_context(service_context)\r\nindex = VectorStoreIndex.from_documents(documents)\r\nquery_engine = index.as_query_engine()\r\n\r\n\r\ndef chatbot(input_text):\r\n    response = query_engine.query(input_text)\r\n    return response\r\n\r\niface = gr.Interface(fn=chatbot, inputs=gr.inputs.Textbox(lines=7, label=\"Talk to me...\"), outputs=\"text\", title=\"Creepy hand\")\r\n\r\niface.launch(share=True)\r\n```\r\n\r\n### Version\r\n\r\n0.7.16\r\n\r\n### Steps to Reproduce\r\n\r\nSetup LLM as PaLM abstraction and pass to the service_context globally.\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\main.py\", line 13, in <module>\r\n    service_context = ServiceContext.from_defaults(llm=model)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\indices\\service_context.py\", line 163, in from_defaults\r\n    embed_model = embed_model or OpenAIEmbedding()\r\n                                 ^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 248, in __init__\r\n    validate_openai_api_key(\r\n  File \"C:\\Users\\Crispy\\PycharmProjects\\chatbottest\\venv\\Lib\\site-packages\\llama_index\\llms\\openai_utils.py\", line 268, in validate_openai_api_key\r\n    raise ValueError(MISSING_API_KEY_ERROR_MESSAGE)\r\nValueError: No API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7091/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7091/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7090",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7090/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7090/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7090/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7090",
        "id": 1828076214,
        "node_id": "I_kwDOIWuq585s9jq2",
        "number": 7090,
        "title": "[Bug]: Async SubQuestionQueryEngine doesn't work with KeywordTableIndex",
        "user": {
            "login": "AdamAbate-6",
            "id": 19533514,
            "node_id": "MDQ6VXNlcjE5NTMzNTE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/19533514?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AdamAbate-6",
            "html_url": "https://github.com/AdamAbate-6",
            "followers_url": "https://api.github.com/users/AdamAbate-6/followers",
            "following_url": "https://api.github.com/users/AdamAbate-6/following{/other_user}",
            "gists_url": "https://api.github.com/users/AdamAbate-6/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AdamAbate-6/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AdamAbate-6/subscriptions",
            "organizations_url": "https://api.github.com/users/AdamAbate-6/orgs",
            "repos_url": "https://api.github.com/users/AdamAbate-6/repos",
            "events_url": "https://api.github.com/users/AdamAbate-6/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AdamAbate-6/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-07-30T20:19:37Z",
        "updated_at": "2023-11-05T16:01:36Z",
        "closed_at": "2023-11-05T16:01:35Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHi,\r\n\r\n**Summary**:\r\nA SubQuestionQueryEngine (with, as is default, self._aquery set to True) using KeywordTableIndex-based query engines returns None from its subquestions and therefore is unable to answer the original question. The cause for this was not immediately clear from documentation and took some digging. Even if we don't want to count this as a bug, I think it's worth people knowing why this behavior might happen.\r\n\r\n**Explanation of Cause**:\r\nIn llama_index/indices/keyword_table/retrievers.py, BaseKeywordTableRetriever and its children don't implement the_aretrieve() method. \r\n\r\nSo when you call as_query_engine() from a keyword table index, it creates a RetrieverQueryEngine (llama_index/query_engine/retriever_query_engine.py). That engine's _aquery() method calls self.aretrieve(), which in turn calls nodes = await self._retriever.aretrieve(query_bundle). That aretrieve() is not implemented except as an abstract method in BaseRetriever. I have confirmed this by printing the nodes retrieved by self.aretrieve(). It's an empty list. That empty list then gets passed to a rather disgruntled response synthesizer.\r\n\r\n\r\n### Version\r\n\r\n0.7.15\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\r\nfrom llama_index.query_engine import SubQuestionQueryEngine\r\n# setup base query engine as tool\r\nquery_engine_tools = [\r\n    QueryEngineTool(\r\n        query_engine=index.as_query_engine(),\r\n        metadata=ToolMetadata(name=name, description=f'Description of index with name {name}')\r\n    )\r\n    for index, name in zip(keyword_indices, index_names)\r\n]\r\n\r\nquery_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_engine_tools)\r\n\r\nresponse = query_engine.query('Compare and constrast x from index a with y from index b')\r\n# This also fails.\r\nresponse = query_engine.aquery('Compare and constrast x from index a with y from index b')\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7090/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7090/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7089",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7089/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7089/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7089/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7089",
        "id": 1828070755,
        "node_id": "PR_kwDOIWuq585WvWdB",
        "number": 7089,
        "title": "[version] bump version to 0.7.16",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-07-30T20:14:46Z",
        "updated_at": "2023-07-30T20:28:14Z",
        "closed_at": "2023-07-30T20:28:13Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7089",
            "html_url": "https://github.com/run-llama/llama_index/pull/7089",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7089.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7089.patch",
            "merged_at": "2023-07-30T20:28:13Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7089/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7089/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]