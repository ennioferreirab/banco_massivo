[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7688",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7688/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7688/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7688/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7688",
        "id": 1898773104,
        "node_id": "PR_kwDOIWuq585adZ1S",
        "number": 7688,
        "title": "Adding litellm to docs ",
        "user": {
            "login": "krrishdholakia",
            "id": 17561003,
            "node_id": "MDQ6VXNlcjE3NTYxMDAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/17561003?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/krrishdholakia",
            "html_url": "https://github.com/krrishdholakia",
            "followers_url": "https://api.github.com/users/krrishdholakia/followers",
            "following_url": "https://api.github.com/users/krrishdholakia/following{/other_user}",
            "gists_url": "https://api.github.com/users/krrishdholakia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/krrishdholakia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/krrishdholakia/subscriptions",
            "organizations_url": "https://api.github.com/users/krrishdholakia/orgs",
            "repos_url": "https://api.github.com/users/krrishdholakia/repos",
            "events_url": "https://api.github.com/users/krrishdholakia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/krrishdholakia/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-15T16:48:29Z",
        "updated_at": "2023-09-15T17:12:22Z",
        "closed_at": "2023-09-15T17:12:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7688",
            "html_url": "https://github.com/run-llama/llama_index/pull/7688",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7688.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7688.patch",
            "merged_at": null
        },
        "body": "Adding litellm to documentation",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7688/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7688/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7687",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7687/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7687/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7687/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7687",
        "id": 1898742114,
        "node_id": "PR_kwDOIWuq585adTKS",
        "number": 7687,
        "title": "update custom embeddings notebook",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T16:24:58Z",
        "updated_at": "2023-09-15T16:32:01Z",
        "closed_at": "2023-09-15T16:32:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7687",
            "html_url": "https://github.com/run-llama/llama_index/pull/7687",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7687.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7687.patch",
            "merged_at": "2023-09-15T16:32:01Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7687/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7687/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7686",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7686/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7686/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7686/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7686",
        "id": 1898572717,
        "node_id": "PR_kwDOIWuq585actxh",
        "number": 7686,
        "title": "[docs] Portkey explainer notebook updated with the recent changes",
        "user": {
            "login": "vrushankportkey",
            "id": 134934501,
            "node_id": "U_kgDOCArv5Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/134934501?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vrushankportkey",
            "html_url": "https://github.com/vrushankportkey",
            "followers_url": "https://api.github.com/users/vrushankportkey/followers",
            "following_url": "https://api.github.com/users/vrushankportkey/following{/other_user}",
            "gists_url": "https://api.github.com/users/vrushankportkey/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vrushankportkey/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vrushankportkey/subscriptions",
            "organizations_url": "https://api.github.com/users/vrushankportkey/orgs",
            "repos_url": "https://api.github.com/users/vrushankportkey/repos",
            "events_url": "https://api.github.com/users/vrushankportkey/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vrushankportkey/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-15T14:44:54Z",
        "updated_at": "2023-09-15T19:39:34Z",
        "closed_at": "2023-09-15T19:39:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7686",
            "html_url": "https://github.com/run-llama/llama_index/pull/7686",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7686.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7686.patch",
            "merged_at": "2023-09-15T19:39:33Z"
        },
        "body": "# Description\r\n\r\nRevamped the Portkey explainer notebook with the latest changes as per #7669 \r\n\r\n## Type of Change\r\n\r\n- [x] Documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7686/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7686/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7685",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7685/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7685/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7685/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7685",
        "id": 1897839639,
        "node_id": "PR_kwDOIWuq585aaOko",
        "number": 7685,
        "title": "add response synthesis tutorial notebook (build RAG from scratch)",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T07:06:29Z",
        "updated_at": "2023-09-15T15:09:43Z",
        "closed_at": "2023-09-15T15:09:42Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7685",
            "html_url": "https://github.com/run-llama/llama_index/pull/7685",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7685.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7685.patch",
            "merged_at": "2023-09-15T15:09:42Z"
        },
        "body": "this adds the third section on the \"build rag from scratch\" tutorial. \r\n- shows how to implement response synthesis, diff strategies\r\n- includes async\r\n- includes defining a light query engine ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7685/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7685/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7684",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7684/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7684/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7684/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7684",
        "id": 1897776171,
        "node_id": "I_kwDOIWuq585xHcQr",
        "number": 7684,
        "title": "[Bug]: KeyError in retriever.retrieve when sent index does not include all nodes in document store",
        "user": {
            "login": "c64er4ever",
            "id": 125486774,
            "node_id": "U_kgDOB3rGtg",
            "avatar_url": "https://avatars.githubusercontent.com/u/125486774?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/c64er4ever",
            "html_url": "https://github.com/c64er4ever",
            "followers_url": "https://api.github.com/users/c64er4ever/followers",
            "following_url": "https://api.github.com/users/c64er4ever/following{/other_user}",
            "gists_url": "https://api.github.com/users/c64er4ever/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/c64er4ever/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/c64er4ever/subscriptions",
            "organizations_url": "https://api.github.com/users/c64er4ever/orgs",
            "repos_url": "https://api.github.com/users/c64er4ever/repos",
            "events_url": "https://api.github.com/users/c64er4ever/events{/privacy}",
            "received_events_url": "https://api.github.com/users/c64er4ever/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-15T06:14:43Z",
        "updated_at": "2023-11-16T21:56:00Z",
        "closed_at": "2023-09-15T15:04:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHi,\r\nI have created multiple indexes, each covering different set of nodes. I am then using one of the indexes to retrieve nodes based on a query. However, it seems that the retriever is trying to process nodes that are out of the context of the specific index that I have provided, causing a KeyError exception in this line in llama_index/indices/vector_store/retrievers/retriever.py:\r\nself._index.index_struct.nodes_dict[idx] for idx in query_result.ids\r\n\r\nI noticed that it is possible to send list of node_ids to retrieve in order to constraint it. Haven't tried it yet and I guess that it will work. However, I believe that it is better if the retrieve function itself verifies that only nodes that are covered by the provided index are processed.\r\n\r\nThanks!\r\nGuy\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\n1. Create doc store with X nodes (e.g. 100)\r\n2. Create index that covers only part of the nodes (e.g. 10)\r\n3. Use the created index to create a Retriever: retriever = VectorIndexRetriever(my_index)\r\n4. Call retrieve with a question: nodes = retriever.retrieve(\"This is my question\")\r\n\r\nIf the query returns nodes that are excluded from the provided index, KeyError exception occurs\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7684/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7684/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7683",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7683/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7683/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7683/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7683",
        "id": 1897743642,
        "node_id": "I_kwDOIWuq585xHUUa",
        "number": 7683,
        "title": "Amazon S3 or Pinecone for Vector Store?",
        "user": {
            "login": "akshaysoni099",
            "id": 91545019,
            "node_id": "U_kgDOBXTduw",
            "avatar_url": "https://avatars.githubusercontent.com/u/91545019?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/akshaysoni099",
            "html_url": "https://github.com/akshaysoni099",
            "followers_url": "https://api.github.com/users/akshaysoni099/followers",
            "following_url": "https://api.github.com/users/akshaysoni099/following{/other_user}",
            "gists_url": "https://api.github.com/users/akshaysoni099/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/akshaysoni099/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/akshaysoni099/subscriptions",
            "organizations_url": "https://api.github.com/users/akshaysoni099/orgs",
            "repos_url": "https://api.github.com/users/akshaysoni099/repos",
            "events_url": "https://api.github.com/users/akshaysoni099/events{/privacy}",
            "received_events_url": "https://api.github.com/users/akshaysoni099/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-15T05:42:30Z",
        "updated_at": "2023-09-15T15:03:25Z",
        "closed_at": "2023-09-15T15:03:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm building a chatbot for document Q&A, for deployment I need an online store for vector storage. I can see 2 implementations in the document, one is with amazon s3 and other with pinecone vector store. Which one should I use and when is one required over other?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7683/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7683/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7682",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7682/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7682/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7682/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7682",
        "id": 1897502920,
        "node_id": "PR_kwDOIWuq585aZHzq",
        "number": 7682,
        "title": "use json.loads() with ast.literal_eval() as fallback option for the output_parser of the ReAct agent",
        "user": {
            "login": "simon-lund",
            "id": 41208671,
            "node_id": "MDQ6VXNlcjQxMjA4Njcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/41208671?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/simon-lund",
            "html_url": "https://github.com/simon-lund",
            "followers_url": "https://api.github.com/users/simon-lund/followers",
            "following_url": "https://api.github.com/users/simon-lund/following{/other_user}",
            "gists_url": "https://api.github.com/users/simon-lund/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/simon-lund/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/simon-lund/subscriptions",
            "organizations_url": "https://api.github.com/users/simon-lund/orgs",
            "repos_url": "https://api.github.com/users/simon-lund/repos",
            "events_url": "https://api.github.com/users/simon-lund/events{/privacy}",
            "received_events_url": "https://api.github.com/users/simon-lund/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T00:04:03Z",
        "updated_at": "2023-09-15T15:24:10Z",
        "closed_at": "2023-09-15T15:24:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7682",
            "html_url": "https://github.com/run-llama/llama_index/pull/7682",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7682.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7682.patch",
            "merged_at": "2023-09-15T15:24:09Z"
        },
        "body": "At the moment ast.literal_eval is used to decode a JSON string. However, if a tool uses booleans, ast fails because in the JSON format the boolean keywords are lowercase. \r\n\r\nTo fix this, we switch to json.loads as primary decoder and we use ast as fallback option when json.loads failes.\r\n\r\n# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7682/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7682/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7681",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7681/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7681/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7681/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7681",
        "id": 1897343362,
        "node_id": "PR_kwDOIWuq585aYkgu",
        "number": 7681,
        "title": "one click simple callback",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T21:41:04Z",
        "updated_at": "2023-09-15T15:14:42Z",
        "closed_at": "2023-09-15T15:14:41Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7681",
            "html_url": "https://github.com/run-llama/llama_index/pull/7681",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7681.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7681.patch",
            "merged_at": "2023-09-15T15:14:41Z"
        },
        "body": "# Description\r\n\r\nAn extremely simple callback to print LLM inputs/outputs to the terminal\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested in terminal\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n```\r\nimport llama_index\r\nllama_index.set_global_handler(\"simple\")   # name pending review!\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7681/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7681/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7680",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7680/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7680/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7680/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7680",
        "id": 1897324972,
        "node_id": "PR_kwDOIWuq585aYgnc",
        "number": 7680,
        "title": "Text Splitters Refactor: Separate Markdown splitter from Markdown Reader",
        "user": {
            "login": "ajhofmann",
            "id": 10040285,
            "node_id": "MDQ6VXNlcjEwMDQwMjg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10040285?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajhofmann",
            "html_url": "https://github.com/ajhofmann",
            "followers_url": "https://api.github.com/users/ajhofmann/followers",
            "following_url": "https://api.github.com/users/ajhofmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajhofmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajhofmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajhofmann/subscriptions",
            "organizations_url": "https://api.github.com/users/ajhofmann/orgs",
            "repos_url": "https://api.github.com/users/ajhofmann/repos",
            "events_url": "https://api.github.com/users/ajhofmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajhofmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-14T21:22:42Z",
        "updated_at": "2023-09-20T16:43:44Z",
        "closed_at": "2023-09-20T16:43:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7680",
            "html_url": "https://github.com/run-llama/llama_index/pull/7680",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7680.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7680.patch",
            "merged_at": "2023-09-20T16:43:44Z"
        },
        "body": "# Description\r\n\r\n- Separate the text splitting logic from MarkdownReader\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7680/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7680/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7679",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7679/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7679/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7679/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7679",
        "id": 1897322098,
        "node_id": "I_kwDOIWuq585xFtZy",
        "number": 7679,
        "title": "[Question]: Custom embedding max query length",
        "user": {
            "login": "austinmw",
            "id": 12224358,
            "node_id": "MDQ6VXNlcjEyMjI0MzU4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12224358?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/austinmw",
            "html_url": "https://github.com/austinmw",
            "followers_url": "https://api.github.com/users/austinmw/followers",
            "following_url": "https://api.github.com/users/austinmw/following{/other_user}",
            "gists_url": "https://api.github.com/users/austinmw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/austinmw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/austinmw/subscriptions",
            "organizations_url": "https://api.github.com/users/austinmw/orgs",
            "repos_url": "https://api.github.com/users/austinmw/repos",
            "events_url": "https://api.github.com/users/austinmw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/austinmw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-14T21:19:51Z",
        "updated_at": "2023-09-14T22:01:16Z",
        "closed_at": "2023-09-14T22:01:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, I'm using a langchain embedding model which has a max input length of 512, which is causing me to run into an error with `VectorStoreIndex.from_documents()`. What do I need to change to let the embedding pipeline know that my embedding model's max input length is 512?\r\n\r\n```python\r\nfrom langchain.embeddings import BedrockEmbeddings\r\nfrom langchain.llms.bedrock import Bedrock\r\n\r\nfrom llama_index.llms import LangChainLLM\r\nfrom llama_index import ServiceContext, set_global_service_context\r\n\r\nembed_model = BedrockEmbeddings(\r\n    client=bedrock,\r\n    model_id='amazon.titan-e1t-medium',\r\n\r\n)\r\nllm_model = Bedrock(\r\n    client=bedrock,\r\n    model_id='amazon.titan-tg1-large',\r\n)\r\n\r\nllm = LangChainLLM(llm_model)\r\n\r\nservice_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\r\ndata = SimpleDirectoryReader(input_dir=\"./data/\").load_data()\r\nindex = VectorStoreIndex.from_documents(data, service_context=service_context)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7679/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7679/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7678",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7678/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7678/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7678/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7678",
        "id": 1897043449,
        "node_id": "PR_kwDOIWuq585aXksP",
        "number": 7678,
        "title": "better selector support + fix query wrapper for completion models",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T17:50:48Z",
        "updated_at": "2023-09-15T15:16:10Z",
        "closed_at": "2023-09-15T15:16:09Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7678",
            "html_url": "https://github.com/run-llama/llama_index/pull/7678",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7678.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7678.patch",
            "merged_at": "2023-09-15T15:16:09Z"
        },
        "body": "# Description\r\n\r\nTwo bugs\r\n- Improprer usage of query-wrapper prompt when using output parsers. This PR simplifies how it works by operating on raw strings\r\n- More robust JSON parsing for the selector\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7678/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7678/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7677",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7677/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7677/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7677/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7677",
        "id": 1896981416,
        "node_id": "PR_kwDOIWuq585aXXXd",
        "number": 7677,
        "title": "llms/openai: fix Azure OpenAI streaming",
        "user": {
            "login": "ret2libc",
            "id": 562321,
            "node_id": "MDQ6VXNlcjU2MjMyMQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/562321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ret2libc",
            "html_url": "https://github.com/ret2libc",
            "followers_url": "https://api.github.com/users/ret2libc/followers",
            "following_url": "https://api.github.com/users/ret2libc/following{/other_user}",
            "gists_url": "https://api.github.com/users/ret2libc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ret2libc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ret2libc/subscriptions",
            "organizations_url": "https://api.github.com/users/ret2libc/orgs",
            "repos_url": "https://api.github.com/users/ret2libc/repos",
            "events_url": "https://api.github.com/users/ret2libc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ret2libc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-14T17:04:31Z",
        "updated_at": "2023-09-14T18:56:22Z",
        "closed_at": "2023-09-14T18:56:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7677",
            "html_url": "https://github.com/run-llama/llama_index/pull/7677",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7677.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7677.patch",
            "merged_at": "2023-09-14T18:56:21Z"
        },
        "body": "# Description\r\nThe Azure OpenAI API, when used with streaming, may return a response with just the content filtering information but no content in 'choices'. Instead of returning an empty ChatResponse (which would affect other users like StreamingAgentChatResponse), just skip that first response (there is nothing we do with that data after all).\r\n\r\nFixes # (issue)\r\n\r\nWhen using the Azure OpenAI streaming api with a OpenAI Agent, like this:\r\n```python\r\nindex_engine = index.as_query_engine(similarity_top_k=5)\r\nquery_engine_tools=[\r\n    QueryEngineTool.from_defaults(\r\n        query_engine=index_engine,\r\n        name=\"\",\r\n        description=\".\"\r\n    )\r\n]\r\nquery_engine = OpenAIAgent.from_tools(query_engine_tools, llm=llm, verbose=True)\r\nresponse = query_engine.stream_chat(message)\r\n\r\nfor token in response.response_gen:\r\n    partial_message += token\r\n    yield partial_message\r\n```\r\n\r\nI get the following error:\r\n```\r\nWARNING:llama_index.chat_engine.types:Encountered exception writing response to history: 'arguments'\r\n```\r\n\r\nSimply making sure that `arguments` key is in the `function_call` object (in `OpenAI:_stream_chat`) is not enough, because of `StreamingAgentChatResponse`:\r\n\r\n```python\r\n    def put_in_queue(self, delta: Optional[str]) -> None:\r\n        self._queue.put_nowait(delta)\r\n        self._is_function_not_none_thread_event.set()\r\n\r\n    def write_response_to_history(self, memory: BaseMemory) -> None:\r\n        [...]\r\n            for chat in self.chat_stream:\r\n                self._is_function = is_function(chat.message)\r\n                self.put_in_queue(chat.delta)\r\n                final_text += chat.delta or \"\"\r\n\r\n```\r\nThe first (empty) response from Azure OpenAI would set the `_is_function_not_none_thread_event`, which makes `BaseOpenAIAgent:_get_stream_ai_response` think there is no function call.\r\n\r\n## Type of Change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7677/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7677/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7676",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7676/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7676/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7676/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7676",
        "id": 1896753051,
        "node_id": "PR_kwDOIWuq585aWlxr",
        "number": 7676,
        "title": "[version] bump version to 0.8.27",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T14:54:56Z",
        "updated_at": "2023-09-14T15:11:17Z",
        "closed_at": "2023-09-14T15:11:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7676",
            "html_url": "https://github.com/run-llama/llama_index/pull/7676",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7676.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7676.patch",
            "merged_at": "2023-09-14T15:11:16Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7676/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7676/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7675",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7675/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7675/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7675/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7675",
        "id": 1896575407,
        "node_id": "PR_kwDOIWuq585aV_aX",
        "number": 7675,
        "title": "Bugfix CitationQueryEngine: excluded_llm_metadata_keys are not respected",
        "user": {
            "login": "tkreuder",
            "id": 385110,
            "node_id": "MDQ6VXNlcjM4NTExMA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/385110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tkreuder",
            "html_url": "https://github.com/tkreuder",
            "followers_url": "https://api.github.com/users/tkreuder/followers",
            "following_url": "https://api.github.com/users/tkreuder/following{/other_user}",
            "gists_url": "https://api.github.com/users/tkreuder/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tkreuder/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tkreuder/subscriptions",
            "organizations_url": "https://api.github.com/users/tkreuder/orgs",
            "repos_url": "https://api.github.com/users/tkreuder/repos",
            "events_url": "https://api.github.com/users/tkreuder/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tkreuder/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T13:26:08Z",
        "updated_at": "2023-09-15T15:26:22Z",
        "closed_at": "2023-09-15T15:26:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7675",
            "html_url": "https://github.com/run-llama/llama_index/pull/7675",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7675.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7675.patch",
            "merged_at": "2023-09-15T15:26:22Z"
        },
        "body": "# Description\r\n\r\nThe CitationQueryEngine does not exclude metadata keys, when some are set. This is due to the fact, that _create_citation_nodes creates new TextNode instances, which do not have the property of the old node.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7675/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7675/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7674",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7674/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7674/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7674/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7674",
        "id": 1896081486,
        "node_id": "I_kwDOIWuq585xA-hO",
        "number": 7674,
        "title": "[Question]: Connectiing multiple index to create one chat engine",
        "user": {
            "login": "Siddharth-1698",
            "id": 66638045,
            "node_id": "MDQ6VXNlcjY2NjM4MDQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/66638045?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Siddharth-1698",
            "html_url": "https://github.com/Siddharth-1698",
            "followers_url": "https://api.github.com/users/Siddharth-1698/followers",
            "following_url": "https://api.github.com/users/Siddharth-1698/following{/other_user}",
            "gists_url": "https://api.github.com/users/Siddharth-1698/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Siddharth-1698/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Siddharth-1698/subscriptions",
            "organizations_url": "https://api.github.com/users/Siddharth-1698/orgs",
            "repos_url": "https://api.github.com/users/Siddharth-1698/repos",
            "events_url": "https://api.github.com/users/Siddharth-1698/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Siddharth-1698/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-14T08:53:38Z",
        "updated_at": "2023-09-14T15:27:30Z",
        "closed_at": "2023-09-14T15:27:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi I have multiple index, I am using chromadb for storing vectors, Each collection is separate index. I want to create one chat engine combining all these collections or indexes, how do I do it?\r\nI tried  adding doc to the same collection to create one collection but it only stored 2 files and after that it did not store anything.\r\nHere's my chroma collection code:\r\nchroma_client = chromadb.PersistentClient(\r\n    path=\"./storage/vector_storage/chromadb/\"\r\n)\r\nchroma_collection = chroma_client.create_collection(\r\n            f\"{user_id}_{filename}_collection\")",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7674/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7674/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7673",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7673/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7673/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7673/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7673",
        "id": 1895893122,
        "node_id": "PR_kwDOIWuq585aTpoG",
        "number": 7673,
        "title": "add low-level tutorial section",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T07:17:58Z",
        "updated_at": "2023-09-15T06:07:39Z",
        "closed_at": "2023-09-14T14:51:26Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7673",
            "html_url": "https://github.com/run-llama/llama_index/pull/7673",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7673.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7673.patch",
            "merged_at": "2023-09-14T14:51:26Z"
        },
        "body": "Goal of this section is to encourage users to define their own modules in a RAG pipeline using lower-level components.\r\n\r\nStarted off with custom retrieval tutorial, will expand to custom ingest + custom response synthesis ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7673/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7673/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7672",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7672/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7672/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7672/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7672",
        "id": 1895858249,
        "node_id": "PR_kwDOIWuq585aTh7T",
        "number": 7672,
        "title": "hwp",
        "user": {
            "login": "sangwongenip",
            "id": 143418076,
            "node_id": "U_kgDOCIxi3A",
            "avatar_url": "https://avatars.githubusercontent.com/u/143418076?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sangwongenip",
            "html_url": "https://github.com/sangwongenip",
            "followers_url": "https://api.github.com/users/sangwongenip/followers",
            "following_url": "https://api.github.com/users/sangwongenip/following{/other_user}",
            "gists_url": "https://api.github.com/users/sangwongenip/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sangwongenip/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sangwongenip/subscriptions",
            "organizations_url": "https://api.github.com/users/sangwongenip/orgs",
            "repos_url": "https://api.github.com/users/sangwongenip/repos",
            "events_url": "https://api.github.com/users/sangwongenip/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sangwongenip/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-14T06:57:51Z",
        "updated_at": "2023-09-15T15:24:33Z",
        "closed_at": "2023-09-15T15:24:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7672",
            "html_url": "https://github.com/run-llama/llama_index/pull/7672",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7672.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7672.patch",
            "merged_at": "2023-09-15T15:24:33Z"
        },
        "body": "Added hwp reader module. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7672/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7672/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7671",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7671/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7671/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7671/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7671",
        "id": 1895732557,
        "node_id": "I_kwDOIWuq585w_pVN",
        "number": 7671,
        "title": "[Question]: I encountered while implementing streaming response with Flask and the AI response is returned all at once.",
        "user": {
            "login": "xxb0120",
            "id": 56210234,
            "node_id": "MDQ6VXNlcjU2MjEwMjM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/56210234?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xxb0120",
            "html_url": "https://github.com/xxb0120",
            "followers_url": "https://api.github.com/users/xxb0120/followers",
            "following_url": "https://api.github.com/users/xxb0120/following{/other_user}",
            "gists_url": "https://api.github.com/users/xxb0120/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xxb0120/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xxb0120/subscriptions",
            "organizations_url": "https://api.github.com/users/xxb0120/orgs",
            "repos_url": "https://api.github.com/users/xxb0120/repos",
            "events_url": "https://api.github.com/users/xxb0120/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xxb0120/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-14T05:35:22Z",
        "updated_at": "2023-10-24T06:31:28Z",
        "closed_at": "2023-10-24T06:31:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nPlease help me with an error I encountered while implementing streaming response with Flask and the AI response is returned all at once.\r\n\r\nDependencies:\r\n```\r\nFlask==2.2.3\r\nlangchain==0.0.266\r\nllama-index==0.8.7\r\nopenai==0.27.4\r\n```\r\n\r\nSample code:\r\n```\r\n@app.route('/stream', methods=['POST'])\r\ndef stream():\r\n    # load documents\r\n    def get_test():\r\n        documents = SimpleDirectoryReader(\"./test\").load_data()\r\n        index = VectorStoreIndex.from_documents(documents)\r\n        query_engine = index.as_query_engine(streaming=True, similarity_top_k=1)\r\n        response_stream = query_engine.query(\"\u4f60\u597d\")\r\n        for i in response_stream.response_gen:\r\n            yield i\r\n    return Response(stream_with_context(get_test()), mimetype=\"text/event-stream\", content_type=\"charset=UTF-8\", headers={'X-Accel-Buffering': \"no\"})\r\n\r\nif __name__ == '__main__':\r\n    app.run(port=6001, host='0.0.0.0')\r\n```\r\nThis is the request result:\r\n```\r\ncurl -X POST \"http://127.0.0.1:6001/stream\"\r\n\u4f60\u597d\uff01\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u52a9\u4f60\u7684\u5417\uff1f\r\n```\r\nHowever, the response is not streaming as expected.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7671/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7671/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7670",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7670/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7670/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7670/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7670",
        "id": 1895709643,
        "node_id": "PR_kwDOIWuq585aTAuZ",
        "number": 7670,
        "title": "add bottoms-up video series as a subsection in docs ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T05:22:31Z",
        "updated_at": "2023-09-14T05:35:00Z",
        "closed_at": "2023-09-14T05:35:00Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7670",
            "html_url": "https://github.com/run-llama/llama_index/pull/7670",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7670.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7670.patch",
            "merged_at": "2023-09-14T05:35:00Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7670/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7670/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7669",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7669/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7669/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7669/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7669",
        "id": 1895580275,
        "node_id": "PR_kwDOIWuq585aSkPw",
        "number": 7669,
        "title": "feat: enhancements and updates for portkey",
        "user": {
            "login": "noble-varghese",
            "id": 109506617,
            "node_id": "U_kgDOBobwOQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/109506617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noble-varghese",
            "html_url": "https://github.com/noble-varghese",
            "followers_url": "https://api.github.com/users/noble-varghese/followers",
            "following_url": "https://api.github.com/users/noble-varghese/following{/other_user}",
            "gists_url": "https://api.github.com/users/noble-varghese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noble-varghese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noble-varghese/subscriptions",
            "organizations_url": "https://api.github.com/users/noble-varghese/orgs",
            "repos_url": "https://api.github.com/users/noble-varghese/repos",
            "events_url": "https://api.github.com/users/noble-varghese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noble-varghese/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-14T03:11:23Z",
        "updated_at": "2023-09-14T19:00:34Z",
        "closed_at": "2023-09-14T19:00:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7669",
            "html_url": "https://github.com/run-llama/llama_index/pull/7669",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7669.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7669.patch",
            "merged_at": "2023-09-14T19:00:34Z"
        },
        "body": "# Description\r\n\r\n### Summary\r\n\r\nThis pull request introduces significant enhancements to the `portkey` LLM integration within the `llama_index` repository. The changes bring several new features, improvements, and a simplified interface to better serve the community's needs.\r\n\r\n### Changes \r\n\r\n1. **Virtual Keys**: We've introduced Virtual Keys to enhance security and control. Portkey now transforms your provider key into a virtual key, ensuring the safety of your original provider keys. Upcoming enhancements include cost limits, role-based access control, and usage settings to provide even more control and flexibility.\r\n\r\n2. **Azure OpenAI Model Support**: We've added support for Azure OpenAI models, expanding the range of models you can work with, making it easier to leverage Azure's capabilities.\r\n\r\n3. **Cache Enhancements**: We've incorporated features for `cache_status` and `cache_force_refresh` to improve caching functionality, helping you manage data efficiently.\r\n\r\n4. **Simplified Interface**: To make your experience smoother, we've simplified the interface of `portkey`, making it more user-friendly and accessible.\r\n\r\n### Why These Changes?\r\n\r\nThese updates have been made to enhance the usability, security, and versatility of the `portkey` package. We aim to empower users with better control over their keys, broader model support, improved caching, and a simpler interface for a more productive workflow.\r\n\r\n### Additional Notes\r\n\r\nThe development of `Rubeus` has been discontinued, and all new features and improvements are now part of the `Portkey-AI` SDK. This pull request reflects the ongoing development of the renamed SDK. We believe that these updates will greatly benefit the users of the `llama_index` and encourage you to explore the enhanced capabilities of the `portkey` package.\r\n\r\nLet me know if you have any feedback or questions.\r\n\r\nThank you for your continued support and collaboration!\r\n\r\n\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7669/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7669/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7668",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7668/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7668/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7668/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7668",
        "id": 1895382904,
        "node_id": "PR_kwDOIWuq585aR-ZI",
        "number": 7668,
        "title": "fix(fallback): fallback embedding to sync method if async fails",
        "user": {
            "login": "EmanuelCampos",
            "id": 16262455,
            "node_id": "MDQ6VXNlcjE2MjYyNDU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/16262455?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/EmanuelCampos",
            "html_url": "https://github.com/EmanuelCampos",
            "followers_url": "https://api.github.com/users/EmanuelCampos/followers",
            "following_url": "https://api.github.com/users/EmanuelCampos/following{/other_user}",
            "gists_url": "https://api.github.com/users/EmanuelCampos/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/EmanuelCampos/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/EmanuelCampos/subscriptions",
            "organizations_url": "https://api.github.com/users/EmanuelCampos/orgs",
            "repos_url": "https://api.github.com/users/EmanuelCampos/repos",
            "events_url": "https://api.github.com/users/EmanuelCampos/events{/privacy}",
            "received_events_url": "https://api.github.com/users/EmanuelCampos/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-13T23:12:20Z",
        "updated_at": "2023-09-14T15:41:55Z",
        "closed_at": "2023-09-14T15:41:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7668",
            "html_url": "https://github.com/run-llama/llama_index/pull/7668",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7668.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7668.patch",
            "merged_at": "2023-09-14T15:41:54Z"
        },
        "body": "# Description\r\n\r\nEmbeddings that don't have an async method, fallback to the sync method and warn the user.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7668/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7668/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7667",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7667/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7667/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7667/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7667",
        "id": 1895264297,
        "node_id": "PR_kwDOIWuq585aRkuo",
        "number": 7667,
        "title": "better query wrapper logic",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T21:04:57Z",
        "updated_at": "2023-09-13T21:14:04Z",
        "closed_at": "2023-09-13T21:14:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7667",
            "html_url": "https://github.com/run-llama/llama_index/pull/7667",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7667.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7667.patch",
            "merged_at": "2023-09-13T21:14:03Z"
        },
        "body": "# Description\r\n\r\nThe existing query wrapper logic in LLMPredictor makes some assumptions about what is in the `prompt.kwargs` attribute -- this PR makes it a bit more generic, so that it still works with selectors for example.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested local test case\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7667/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7667/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7666",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7666/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7666/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7666/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7666",
        "id": 1895044210,
        "node_id": "I_kwDOIWuq585w9BRy",
        "number": 7666,
        "title": "[Bug]: 'StorageContext' object has no attribute 'callback_manager' for DynamoDB stores",
        "user": {
            "login": "acastro2",
            "id": 5918765,
            "node_id": "MDQ6VXNlcjU5MTg3NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5918765?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/acastro2",
            "html_url": "https://github.com/acastro2",
            "followers_url": "https://api.github.com/users/acastro2/followers",
            "following_url": "https://api.github.com/users/acastro2/following{/other_user}",
            "gists_url": "https://api.github.com/users/acastro2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/acastro2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/acastro2/subscriptions",
            "organizations_url": "https://api.github.com/users/acastro2/orgs",
            "repos_url": "https://api.github.com/users/acastro2/repos",
            "events_url": "https://api.github.com/users/acastro2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/acastro2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-13T18:29:51Z",
        "updated_at": "2023-09-13T18:41:43Z",
        "closed_at": "2023-09-13T18:41:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI'm getting 'StorageContext' object has no attribute 'callback_manager' when setting DynamoDB as the store context.\r\n\r\n### Version\r\n\r\n0.8.26\r\n\r\n### Steps to Reproduce\r\n\r\nRunning it inside Docker:\r\n\r\n```dockerfile\r\nFROM public.ecr.aws/lambda/python:3.11\r\n\r\nRUN yum install -y gcc-c++ make cmake\r\n\r\n# Copy requirements.txt\r\nCOPY requirements.txt ${LAMBDA_TASK_ROOT}\r\n\r\n# Copy function code\r\nCOPY lambda_function.py ${LAMBDA_TASK_ROOT}\r\n\r\nENV OPENAI_API_KEY=xxx\r\nENV AWS_ACCESS_KEY_ID=yyy\r\nENV AWS_SECRET_ACCESS_KEY=zzz\r\nENV AWS_DEFAULT_REGION=us-east-1\r\n\r\n# Install the specified packages\r\nRUN pip install -r requirements.txt\r\n\r\n# Set the CMD to your handler (could also be done as a parameter override outside of the Dockerfile)\r\nCMD [ \"lambda_function.handler\" ]\r\n\r\n```\r\n\r\n```python\r\nfrom llama_index import VectorStoreIndex, StorageContext, ServiceContext, set_global_service_context, set_global_service_context, SummaryIndex, SimpleKeywordTableIndex, SimpleWebPageReader\r\nfrom llama_index.vector_stores.dynamodb import DynamoDBVectorStore\r\nfrom llama_index.storage.index_store.dynamodb_index_store import DynamoDBIndexStore\r\nfrom llama_index.storage.docstore.dynamodb_docstore import DynamoDBDocumentStore\r\nfrom llama_index.llms import OpenAI\r\n\r\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=200)\r\n\r\nservice_context = ServiceContext.from_defaults(llm=llm, chunk_size=600)\r\n\r\nset_global_service_context(service_context)\r\n\r\ndocuments = SimpleWebPageReader(html_to_text=True).load_data(\r\n    [\"https://www.cashnetusa.com/faq.html\", \"http://www.zappos.com/general-questions\"]\r\n)\r\n\r\ntable_name = \"LlamaIndexVectors\"\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore=DynamoDBDocumentStore.from_table_name(table_name=table_name),\r\n    index_store=DynamoDBIndexStore.from_table_name(table_name=table_name),\r\n    vector_store=DynamoDBVectorStore.from_table_name(table_name=table_name),\r\n)\r\n\r\nstorage_context.docstore.add_documents(documents)\r\n\r\nset_global_service_context(storage_context)\r\n\r\nvector_index = VectorStoreIndex.from_documents(documents)\r\nkeyword_table_index = SimpleKeywordTableIndex.from_documents(documents)\r\nsummary_index = SummaryIndex.from_documents(documents)\r\n\r\nstorage_context.persist()\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n[ERROR] AttributeError: 'StorageContext' object has no attribute 'callback_manager'\r\nTraceback (most recent call last):\r\n  File \"/var/task/lambda_function.py\", line 84, in handler\r\n    summary_index = SummaryIndex(documents, storage_context=storage_context)\r\n  File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/list/base.py\", line 56, in __init__\r\n    super().__init__(\r\n  File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/base.py\", line 61, in __init__\r\n    self._service_context = service_context or ServiceContext.from_defaults()\r\n  File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/service_context.py\", line 138, in from_defaults\r\n    return cls.from_service_context(\r\n  File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/service_context.py\", line 220, in from_service_context\r\n    callback_manager = callback_manager or service_context.callback_manager\r\n[ERROR] AttributeError: 'StorageContext' object has no attribute 'callback_manager' Traceback (most recent call last):   File \"/var/task/lambda_function.py\", line 84, in handler     summary_index = SummaryIndex(documents, storage_context=storage_context)   File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/list/base.py\", line 56, in __init__     super().__init__(   File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/base.py\", line 61, in __init__     self._service_context = service_context or ServiceContext.from_defaults()   File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/service_context.py\", line 138, in from_defaults     return cls.from_service_context(   File \"/var/lang/lib/python3.11/site-packages/llama_index/indices/service_context.py\", line 220, in from_service_context     callback_manager = callback_manager or service_context.callback_manager\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7666/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7666/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7665",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7665/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7665/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7665/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7665",
        "id": 1894959402,
        "node_id": "PR_kwDOIWuq585aQhyB",
        "number": 7665,
        "title": "default delta should be a dict",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T17:28:16Z",
        "updated_at": "2023-09-13T21:02:22Z",
        "closed_at": "2023-09-13T21:02:21Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7665",
            "html_url": "https://github.com/run-llama/llama_index/pull/7665",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7665.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7665.patch",
            "merged_at": "2023-09-13T21:02:21Z"
        },
        "body": "# Description\r\n\r\nSmall fix -- default delta should be a dict, not a string\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7657\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7665/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7665/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7664",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7664/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7664/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7664/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7664",
        "id": 1894867971,
        "node_id": "PR_kwDOIWuq585aQN9E",
        "number": 7664,
        "title": "refresh function corrected, deleting document working with opensearch",
        "user": {
            "login": "withub-TanmayAgrawal",
            "id": 129947138,
            "node_id": "U_kgDOB77WAg",
            "avatar_url": "https://avatars.githubusercontent.com/u/129947138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/withub-TanmayAgrawal",
            "html_url": "https://github.com/withub-TanmayAgrawal",
            "followers_url": "https://api.github.com/users/withub-TanmayAgrawal/followers",
            "following_url": "https://api.github.com/users/withub-TanmayAgrawal/following{/other_user}",
            "gists_url": "https://api.github.com/users/withub-TanmayAgrawal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/withub-TanmayAgrawal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/withub-TanmayAgrawal/subscriptions",
            "organizations_url": "https://api.github.com/users/withub-TanmayAgrawal/orgs",
            "repos_url": "https://api.github.com/users/withub-TanmayAgrawal/repos",
            "events_url": "https://api.github.com/users/withub-TanmayAgrawal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/withub-TanmayAgrawal/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-09-13T16:23:27Z",
        "updated_at": "2023-09-25T18:34:04Z",
        "closed_at": "2023-09-25T18:34:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7664",
            "html_url": "https://github.com/run-llama/llama_index/pull/7664",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7664.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7664.patch",
            "merged_at": "2023-09-25T18:34:04Z"
        },
        "body": "# Description\r\n\r\nThe refresh_ref_docs() function was not working, and delete_ref_doc() function (called by update_ref_doc()) was not working for opensearch Vector Store.\r\n\r\nFixes # (issue)\r\n\r\n- The refresh_ref_docs() function was not working, as is Python, (None!=\"ABC\") returns true. So if there is a new doc coming, its existing_doc_hash is None, which makes (existing_doc_hash != document.hash) true, resulting in calling of update() instead of insert(). Switching the order of if and elif resolves this issue.\r\n- The delete_ref_doc() function (called by update_ref_doc()) was not working for opensearch Vector Store. A doc_id was being passed to the OpenSearch node delete function instead of node_id. This has been corrected, and now all the node_ids are being passed to the OpenSearch node delete function in a for loop. They are retrieved from the docStore.\r\n- \r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7664/reactions",
            "total_count": 3,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7664/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7663",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7663/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7663/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7663/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7663",
        "id": 1894778619,
        "node_id": "PR_kwDOIWuq585aP6g5",
        "number": 7663,
        "title": "nit: edit doc link title for embedding fine-tuning tutorial",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T15:29:25Z",
        "updated_at": "2023-09-13T17:00:17Z",
        "closed_at": "2023-09-13T17:00:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7663",
            "html_url": "https://github.com/run-llama/llama_index/pull/7663",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7663.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7663.patch",
            "merged_at": "2023-09-13T17:00:16Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7663/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7663/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7662",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7662/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7662/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7662/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7662",
        "id": 1894279051,
        "node_id": "I_kwDOIWuq585w6GeL",
        "number": 7662,
        "title": "[Question]: I have a list of vectorstore indices how do i create one chat engine using those indices",
        "user": {
            "login": "Siddharth-1698",
            "id": 66638045,
            "node_id": "MDQ6VXNlcjY2NjM4MDQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/66638045?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Siddharth-1698",
            "html_url": "https://github.com/Siddharth-1698",
            "followers_url": "https://api.github.com/users/Siddharth-1698/followers",
            "following_url": "https://api.github.com/users/Siddharth-1698/following{/other_user}",
            "gists_url": "https://api.github.com/users/Siddharth-1698/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Siddharth-1698/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Siddharth-1698/subscriptions",
            "organizations_url": "https://api.github.com/users/Siddharth-1698/orgs",
            "repos_url": "https://api.github.com/users/Siddharth-1698/repos",
            "events_url": "https://api.github.com/users/Siddharth-1698/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Siddharth-1698/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-13T10:57:50Z",
        "updated_at": "2023-09-14T15:25:55Z",
        "closed_at": "2023-09-14T15:25:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nmemory = ChatMemoryBuffer.from_defaults(token_limit=2500)\r\n    timea = time.time()\r\n\r\n    collections = UserIndexes.objects.filter(\r\n        user_id=user_id)\r\n    timeb = time.time()\r\n    print(\"filtering collections\", timeb-timea)\r\n    indices = []\r\n    for collection in collections:\r\n        if collection.file_name != \"\":\r\n            timec = time.time()\r\n            index = get_indexes(collection)\r\n            indices.append(index)\r\n            timed = time.time()\r\n            print(\"getting index\", timed-timec)\r\n    timee = time.time()\r\n    index = GPTListIndex[indices]\r\n    print(\"getting all indices\", timee-timeb)\r\n  \r\n    return index.as_chat_engine()\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7662/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7662/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7661",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7661/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7661/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7661/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7661",
        "id": 1894042297,
        "node_id": "PR_kwDOIWuq585aNZJa",
        "number": 7661,
        "title": "Refactor evaluators and add correctness evaluator",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-13T08:44:58Z",
        "updated_at": "2023-09-15T20:47:40Z",
        "closed_at": "2023-09-15T20:47:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7661",
            "html_url": "https://github.com/run-llama/llama_index/pull/7661",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7661.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7661.patch",
            "merged_at": "2023-09-15T20:47:39Z"
        },
        "body": "## Description\r\n- Refactor existing evaluators to have consistent interface.\r\n  - Note that this is a breaking change for anyone currently using evaluators.\r\n- Add correctness evaluator (depends on labeled answer) \r\n\r\n## Additional unrelated fixes\r\n- update prompt templates to run output parser formatting if output parser is set.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7661/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7661/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7660",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7660/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7660/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7660/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7660",
        "id": 1893912311,
        "node_id": "PR_kwDOIWuq585aM9On",
        "number": 7660,
        "title": "edit notebook title, bump version",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T07:24:44Z",
        "updated_at": "2023-09-13T15:23:44Z",
        "closed_at": "2023-09-13T15:23:42Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7660",
            "html_url": "https://github.com/run-llama/llama_index/pull/7660",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7660.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7660.patch",
            "merged_at": "2023-09-13T15:23:42Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7660/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7660/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7659",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7659/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7659/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7659/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7659",
        "id": 1893853423,
        "node_id": "PR_kwDOIWuq585aMwfw",
        "number": 7659,
        "title": "[version] bump version to 0.8.26",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T06:43:27Z",
        "updated_at": "2023-09-13T07:04:44Z",
        "closed_at": "2023-09-13T07:04:44Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7659",
            "html_url": "https://github.com/run-llama/llama_index/pull/7659",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7659.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7659.patch",
            "merged_at": "2023-09-13T07:04:44Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7659/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7659/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7658",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7658/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7658/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7658/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7658",
        "id": 1893799964,
        "node_id": "PR_kwDOIWuq585aMk6Q",
        "number": 7658,
        "title": "add non-linear embedding adapter",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-13T05:59:46Z",
        "updated_at": "2023-09-13T06:41:55Z",
        "closed_at": "2023-09-13T06:41:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7658",
            "html_url": "https://github.com/run-llama/llama_index/pull/7658",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7658.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7658.patch",
            "merged_at": "2023-09-13T06:41:54Z"
        },
        "body": "This PR generalizes our black-box linear adapter so that you can specify any \"adapter\" to transform the query embedding, while keeping the document embeddings frozen.\r\n\r\nAdded a sample 2 layer network. Also added example in notebook of creating your own custom adapter ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7658/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7658/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7657",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7657/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7657/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7657/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7657",
        "id": 1893734772,
        "node_id": "I_kwDOIWuq585w4Bl0",
        "number": 7657,
        "title": "[Bug]: AzureOpenAI.stream_chat causes AttributeError",
        "user": {
            "login": "apptaro",
            "id": 998626,
            "node_id": "MDQ6VXNlcjk5ODYyNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/998626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apptaro",
            "html_url": "https://github.com/apptaro",
            "followers_url": "https://api.github.com/users/apptaro/followers",
            "following_url": "https://api.github.com/users/apptaro/following{/other_user}",
            "gists_url": "https://api.github.com/users/apptaro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apptaro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apptaro/subscriptions",
            "organizations_url": "https://api.github.com/users/apptaro/orgs",
            "repos_url": "https://api.github.com/users/apptaro/repos",
            "events_url": "https://api.github.com/users/apptaro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apptaro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-13T04:49:49Z",
        "updated_at": "2023-09-13T21:02:22Z",
        "closed_at": "2023-09-13T21:02:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nPR #7646 has introduced another issue instead of fixing the bug #7640\r\nNow, AzureOpenAI.stream_chat causes AttributeError.\r\n\r\nLook here:\r\nhttps://github.com/jerryjliu/llama_index/blob/276d976c1cadbee316e6a777b2b37cccfd1d59f0/llama_index/llms/openai.py#L229-L234\r\nand here:\r\nhttps://github.com/jerryjliu/llama_index/blob/276d976c1cadbee316e6a777b2b37cccfd1d59f0/llama_index/llms/openai.py#L448-L453\r\n\r\n\"delta\" is supposed to be something like { \"role\": \"\", content: \"\" } instead of \"\"\r\n\r\n### Version\r\n\r\n0.8.25\r\n\r\n### Steps to Reproduce\r\n\r\nRun the following code to reproduce the issue:\r\n\r\n```\r\nimport os\r\nfrom llama_index.llms import OpenAI, AzureOpenAI\r\nfrom llama_index.llms.base import ChatMessage\r\n\r\nuse_azure = True\r\n\r\nif use_azure:\r\n    os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\r\n    os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\r\n    os.environ[\"OPENAI_API_BASE\"] = \"https://xxxx.openai.azure.com/\"\r\n    os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxxxx\"\r\n    llm = AzureOpenAI(engine = \"gpt-35-turbo\")\r\nelse:\r\n    os.environ[\"OPENAI_API_TYPE\"] = \"open_ai\"\r\n    os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxx\"\r\n    os.environ[\"OPENAI_API_BASE\"] = \"https://api.openai.com/v1\"\r\n    llm = OpenAI()\r\n\r\nfor delta in llm.stream_chat([ChatMessage(content = \"Hello!\")]):\r\n    print(delta)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n$ python3 test.py\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntuuser/LlamaIndex_env/project/test.py\", line 19, in <module>\r\n    for delta in llm.stream_chat([ChatMessage(content = \"Hello!\")]):\r\n  File \"/home/ubuntuuser/LlamaIndex_env/lib/python3.10/site-packages/llama_index/llms/base.py\", line 157, in wrapped_gen\r\n    for x in f_return_val:\r\n  File \"/home/ubuntuuser/LlamaIndex_env/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 233, in gen\r\n    role = delta.get(\"role\", \"assistant\")\r\nAttributeError: 'str' object has no attribute 'get'\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7657/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 1,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7657/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7656",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7656/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7656/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7656/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7656",
        "id": 1893545791,
        "node_id": "I_kwDOIWuq585w3Tc_",
        "number": 7656,
        "title": "[Bug]: \"CustomWebPageReader\" object has no field \"url_metadata\"",
        "user": {
            "login": "Ma-Fukudama",
            "id": 76037787,
            "node_id": "MDQ6VXNlcjc2MDM3Nzg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76037787?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ma-Fukudama",
            "html_url": "https://github.com/Ma-Fukudama",
            "followers_url": "https://api.github.com/users/Ma-Fukudama/followers",
            "following_url": "https://api.github.com/users/Ma-Fukudama/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ma-Fukudama/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ma-Fukudama/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ma-Fukudama/subscriptions",
            "organizations_url": "https://api.github.com/users/Ma-Fukudama/orgs",
            "repos_url": "https://api.github.com/users/Ma-Fukudama/repos",
            "events_url": "https://api.github.com/users/Ma-Fukudama/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ma-Fukudama/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-13T00:58:39Z",
        "updated_at": "2023-09-13T02:12:51Z",
        "closed_at": "2023-09-13T01:40:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe following error occurs when creating an index with a file name in metadata.\r\nbut 0.8.13 creates indexes without problems.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"~/insertIndex.py\", line 62, in <module>\r\n    documents = CustomWebPageReader(html_to_text=True, url_metadata=url_metadata_fn).load_data(\r\n  File \"~/insertIndex.py\", line 27, in __init__\r\n    self.url_metadata = url_metadata  \r\n  File \"pydantic/main.py\", line 357, in pydantic.main.BaseModel.__setattr__\r\nValueError: \"CustomWebPageReader\" object has no field \"url_metadata\"\r\n```\r\n\r\n\n\n### Version\n\n0.8.25\n\n### Steps to Reproduce\n\nWhen I run the source below, an error always occurs\r\n\r\n```\r\nuser_input = sys.argv[1]\r\n\r\nclass CustomWebPageReader(SimpleWebPageReader):\r\n    def __init__(self, html_to_text=False, url_metadata=None):\r\n        self.url_metadata = url_metadata \r\n        super().__init__(html_to_text)\r\n\r\n    def load_data(self, urls):\r\n        documents = super().load_data(urls)\r\n        if self.url_metadata is not None:\r\n            for doc, url in zip(documents, urls):\r\n                metadata = self.url_metadata(url)\r\n                doc.metadata.update(metadata)\r\n        return documents\r\n\r\nfile_extension = os.path.splitext(user_input)[1].lower()\r\n\r\nurl_pattern = r'^https?://[^\\s/$.?#].[^\\s]*$'\r\n\r\nif file_extension in ('.pdf', '.docx', '.txt'):\r\n    filename_fn = lambda filename: {'file_name': filename}\r\n    documents = SimpleDirectoryReader(input_files=text_list,  file_metadata=filename_fn).load_data()\r\n\r\n# URL\r\nelif re.match(url_pattern, user_input):\r\n\r\n    url_metadata_fn = lambda url: {'file_name': url}\r\n\r\n    documents = CustomWebPageReader(html_to_text=True, url_metadata=url_metadata_fn).load_data(\r\n        [\r\n            user_input\r\n        ]\r\n    )\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7656/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7656/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7655",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7655/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7655/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7655/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7655",
        "id": 1893320412,
        "node_id": "PR_kwDOIWuq585aLEPO",
        "number": 7655,
        "title": "[version] bump to v0.8.25",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-12T21:42:28Z",
        "updated_at": "2023-09-12T21:46:53Z",
        "closed_at": "2023-09-12T21:46:52Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7655",
            "html_url": "https://github.com/run-llama/llama_index/pull/7655",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7655.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7655.patch",
            "merged_at": "2023-09-12T21:46:52Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7655/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7655/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7654",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7654/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7654/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7654/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7654",
        "id": 1893282993,
        "node_id": "PR_kwDOIWuq585aK7-T",
        "number": 7654,
        "title": "Remove pdb from llama_cpp",
        "user": {
            "login": "imartinez",
            "id": 721666,
            "node_id": "MDQ6VXNlcjcyMTY2Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/721666?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/imartinez",
            "html_url": "https://github.com/imartinez",
            "followers_url": "https://api.github.com/users/imartinez/followers",
            "following_url": "https://api.github.com/users/imartinez/following{/other_user}",
            "gists_url": "https://api.github.com/users/imartinez/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/imartinez/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/imartinez/subscriptions",
            "organizations_url": "https://api.github.com/users/imartinez/orgs",
            "repos_url": "https://api.github.com/users/imartinez/repos",
            "events_url": "https://api.github.com/users/imartinez/events{/privacy}",
            "received_events_url": "https://api.github.com/users/imartinez/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-12T21:13:45Z",
        "updated_at": "2023-09-12T22:42:56Z",
        "closed_at": "2023-09-12T21:35:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7654",
            "html_url": "https://github.com/run-llama/llama_index/pull/7654",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7654.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7654.patch",
            "merged_at": "2023-09-12T21:35:59Z"
        },
        "body": "# Description\r\n\r\nDuring the fix of https://github.com/jerryjliu/llama_index/issues/7547, a call to `pdb` was introduced, in https://github.com/jerryjliu/llama_index/commit/94912afd2c15fc10b7eddbe7f95cba8555fd1fc6. It should not be in the final code.\r\n\r\nFixes #7653  \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\nNo need to test. Just a minor clean up.\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7654/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 1,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7654/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7653",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7653/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7653/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7653/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7653",
        "id": 1893281521,
        "node_id": "I_kwDOIWuq585w2S7x",
        "number": 7653,
        "title": "[Bug]: pdb in llama_cpp code affects execution",
        "user": {
            "login": "imartinez",
            "id": 721666,
            "node_id": "MDQ6VXNlcjcyMTY2Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/721666?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/imartinez",
            "html_url": "https://github.com/imartinez",
            "followers_url": "https://api.github.com/users/imartinez/followers",
            "following_url": "https://api.github.com/users/imartinez/following{/other_user}",
            "gists_url": "https://api.github.com/users/imartinez/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/imartinez/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/imartinez/subscriptions",
            "organizations_url": "https://api.github.com/users/imartinez/orgs",
            "repos_url": "https://api.github.com/users/imartinez/repos",
            "events_url": "https://api.github.com/users/imartinez/events{/privacy}",
            "received_events_url": "https://api.github.com/users/imartinez/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-12T21:12:33Z",
        "updated_at": "2023-09-12T21:48:10Z",
        "closed_at": "2023-09-12T21:36:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nDuring the fix of https://github.com/jerryjliu/llama_index/issues/7547, a call to `pdb` was introduced, in https://github.com/jerryjliu/llama_index/commit/94912afd2c15fc10b7eddbe7f95cba8555fd1fc6. \r\n\r\nIt should not be in the final code, as it can affect production execution and affect the development work.\n\n### Version\n\nv0.8.24\n\n### Steps to Reproduce\n\nWhen LlamaCPP is created without specifying a model_path, the pdb is imported and stops the execution.\r\n\r\nIt can be found by checking llama_index/llms/llama_cpp.py L105\r\n\r\n`        else:\r\n            cache_dir = get_cache_dir()\r\n            import pdb\r\n\r\n            pdb.set_trace()\r\n            model_url = model_url or self._get_model_path_for_version()\r\n            model_name = os.path.basename(model_url)`\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7653/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7653/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7652",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7652/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7652/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7652/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7652",
        "id": 1893276056,
        "node_id": "PR_kwDOIWuq585aK6c3",
        "number": 7652,
        "title": "Add agent step callback type",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-12T21:08:36Z",
        "updated_at": "2023-09-13T04:59:17Z",
        "closed_at": "2023-09-12T21:36:15Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7652",
            "html_url": "https://github.com/run-llama/llama_index/pull/7652",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7652.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7652.patch",
            "merged_at": "2023-09-12T21:36:15Z"
        },
        "body": "# Description\r\n\r\nAgent steps did not have a proper event type. This PR adds that.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7639\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] Test script\r\n\r\n```python\r\nfrom llama_index.agent import OpenAIAgent\r\nfrom llama_index.tools import FunctionTool\r\nfrom llama_index.callbacks import LlamaDebugHandler, CallbackManager\r\nfrom llama_index.llms import OpenAI\r\n\r\n\r\ndef multiply(a: int, b: int) -> int:\r\n    \"\"\"Multiple two integers and returns the result integer\"\"\"\r\n    return a * b\r\n\r\n\r\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\r\n\r\n\r\ndef add(a: int, b: int) -> int:\r\n    \"\"\"Add two integers and returns the result integer\"\"\"\r\n    return a + b\r\n\r\n\r\nadd_tool = FunctionTool.from_defaults(fn=add)\r\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\r\ncb_handler = LlamaDebugHandler(print_trace_on_end=True)\r\ncallback_manager = CallbackManager(handlers=[cb_handler])\r\nagent = OpenAIAgent.from_tools(\r\n    [multiply_tool, add_tool], llm=llm, verbose=True, callback_manager=callback_manager\r\n)\r\nagent.chat(\"What is 2 * 3 + 1?\")\r\n```\r\n\r\nOutput:\r\n```\r\n**********\r\nTrace: chat\r\n    |_CBEventType.AGENT_STEP ->  2.914991 seconds\r\n      |_CBEventType.LLM ->  1.083966 seconds\r\n      |_CBEventType.FUNCTION_CALL ->  0.000165 seconds\r\n      |_CBEventType.LLM ->  1.03474 seconds\r\n      |_CBEventType.FUNCTION_CALL ->  0.000186 seconds\r\n      |_CBEventType.LLM ->  0.793178 seconds\r\n**********\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7652/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7652/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7651",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7651/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7651/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7651/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7651",
        "id": 1893253649,
        "node_id": "PR_kwDOIWuq585aK1UT",
        "number": 7651,
        "title": "update paths on .md files",
        "user": {
            "login": "Valentina-Frenkel",
            "id": 91087772,
            "node_id": "MDQ6VXNlcjkxMDg3Nzcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/91087772?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Valentina-Frenkel",
            "html_url": "https://github.com/Valentina-Frenkel",
            "followers_url": "https://api.github.com/users/Valentina-Frenkel/followers",
            "following_url": "https://api.github.com/users/Valentina-Frenkel/following{/other_user}",
            "gists_url": "https://api.github.com/users/Valentina-Frenkel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Valentina-Frenkel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Valentina-Frenkel/subscriptions",
            "organizations_url": "https://api.github.com/users/Valentina-Frenkel/orgs",
            "repos_url": "https://api.github.com/users/Valentina-Frenkel/repos",
            "events_url": "https://api.github.com/users/Valentina-Frenkel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Valentina-Frenkel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-12T20:58:14Z",
        "updated_at": "2023-09-13T21:17:22Z",
        "closed_at": "2023-09-13T21:17:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7651",
            "html_url": "https://github.com/run-llama/llama_index/pull/7651",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7651.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7651.patch",
            "merged_at": "2023-09-13T21:17:22Z"
        },
        "body": "Add `/docs` to the corresponding paths in the markdown file.\r\n\r\n# Description\r\n\r\nIt appears that some folders were moved to the `/docs` folder, which caused relative paths in markdown files referencing them to stop working. I ran a script to check all the relative paths in `.md` files that reference any of the folders inside `/docs`: `core_modules`, `community`, `getting_started`, `end_to_end_tutorials`, `examples`, `api_reference`, `development`, `_static`. The script checks all the .md files and verifies if a relative path to these folders is used. If so, it adds the corresponding prefix `/docs` to them. This action fixes broken links and images in the `.md` files.\r\n\r\n## Type of Change\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\nBroke links and images are now working.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7651/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7651/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7650",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7650/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7650/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7650/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7650",
        "id": 1893147466,
        "node_id": "PR_kwDOIWuq585aKd9R",
        "number": 7650,
        "title": "Fix  #7649: Make model_url optional llama-cpp",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-12T19:43:06Z",
        "updated_at": "2023-09-12T19:50:29Z",
        "closed_at": "2023-09-12T19:50:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7650",
            "html_url": "https://github.com/run-llama/llama_index/pull/7650",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7650.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7650.patch",
            "merged_at": "2023-09-12T19:50:29Z"
        },
        "body": "# Description\r\n\r\nQuick fix for #7649. Make `model_url` optional when initialising `LlamaCPP`.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7650/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7650/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7649",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7649/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7649/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7649/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7649",
        "id": 1893144171,
        "node_id": "I_kwDOIWuq585w1xZr",
        "number": 7649,
        "title": "[Bug]: LlamaCPP doesn't allow just passing in model_path",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-12T19:41:11Z",
        "updated_at": "2023-09-12T19:50:35Z",
        "closed_at": "2023-09-12T19:50:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen using `LlamaCPP` class, you are no longer allowed to just pass in the `model_path`. I think this was from [this commit](https://github.com/jerryjliu/llama_index/commit/94912afd2c15fc10b7eddbe7f95cba8555fd1fc6). To fix, I think we just need to change `str` to `Optional[str]` [here](https://github.com/jerryjliu/llama_index/blob/2216dca216bf703156fac8913c2095ea67308d58/llama_index/llms/llama_cpp.py#L42).\n\n### Version\n\n0.8.24post1\n\n### Steps to Reproduce\n\n```\r\nfrom llama_index.llms import LlamaCPP\r\nfrom llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\r\n\r\n# downloaded from https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF\r\nllama_2_path = \"llama-2-13b-chat.Q6_K.gguf\"\r\n\r\nllm = LlamaCPP(\r\n    model_path=llama_2_path,\r\n    temperature=0.1,\r\n    max_new_tokens=1024,\r\n    context_window=3900,\r\n    # kwargs to pass to __call__()\r\n    generate_kwargs={},\r\n    # kwargs to pass to __init__()\r\n    # set to at least 1 to use GPU\r\n    model_kwargs={\"n_gpu_layers\": 1},\r\n    # transform inputs into Llama2 format\r\n    messages_to_prompt=messages_to_prompt,\r\n    completion_to_prompt=completion_to_prompt,\r\n    verbose=True,\r\n)\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\n/Users/rchan/reginald/models/llama-index-hack/llama2_ccp_chat.ipynb Cell 17 line 1\r\n----> 1 llm = LlamaCPP(\r\n      2     model_path=llama_2_path,\r\n      3     temperature=0.1,\r\n      4     max_new_tokens=1024,\r\n      5     context_window=3900,\r\n      6     # kwargs to pass to __call__()\r\n      7     generate_kwargs={},\r\n      8     # kwargs to pass to __init__()\r\n      9     # set to at least 1 to use GPU\r\n     10     model_kwargs={\"n_gpu_layers\": 1},\r\n     11     # transform inputs into Llama2 format\r\n     12     messages_to_prompt=messages_to_prompt,\r\n     13     completion_to_prompt=completion_to_prompt,\r\n     14     verbose=True,\r\n     15 )\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/llama_cpp.py:129, in LlamaCPP.__init__(self, model_url, model_path, temperature, max_new_tokens, context_window, messages_to_prompt, completion_to_prompt, callback_manager, generate_kwargs, model_kwargs, verbose)\r\n    124 generate_kwargs = generate_kwargs or {}\r\n    125 generate_kwargs.update(\r\n    126     {\"temperature\": temperature, \"max_tokens\": max_new_tokens}\r\n    127 )\r\n--> 129 super().__init__(\r\n...\r\n    343     object_setattr(__pydantic_self__, '__dict__', values)\r\n\r\nValidationError: 1 validation error for LlamaCPP\r\nmodel_url\r\n  none is not an allowed value (type=type_error.none.not_allowed)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7649/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7649/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7648",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7648/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7648/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7648/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7648",
        "id": 1893005691,
        "node_id": "I_kwDOIWuq585w1Pl7",
        "number": 7648,
        "title": "[Bug]: Exceeding submit limit in ChromaVectorStore",
        "user": {
            "login": "ValMobYKang",
            "id": 115156261,
            "node_id": "U_kgDOBt0lJQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/115156261?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ValMobYKang",
            "html_url": "https://github.com/ValMobYKang",
            "followers_url": "https://api.github.com/users/ValMobYKang/followers",
            "following_url": "https://api.github.com/users/ValMobYKang/following{/other_user}",
            "gists_url": "https://api.github.com/users/ValMobYKang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ValMobYKang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ValMobYKang/subscriptions",
            "organizations_url": "https://api.github.com/users/ValMobYKang/orgs",
            "repos_url": "https://api.github.com/users/ValMobYKang/repos",
            "events_url": "https://api.github.com/users/ValMobYKang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ValMobYKang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-12T17:56:36Z",
        "updated_at": "2023-10-09T03:00:07Z",
        "closed_at": "2023-10-09T03:00:07Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThere are too many documents. When converting them into embeddings and loading them into chroma at once, chroma shows that they exceed the submit limit.\n\n### Version\n\nv0.8.24.post1 Latest\n\n### Steps to Reproduce\n\n```python\r\nself.index = VectorStoreIndex.from_documents(\r\n                                    documents,\r\n                                    storage_context=storage_context,\r\n                                    service_context=service_context,\r\n                                    show_progress=True,\r\n                                )\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nBatches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:03<00:00,  1.57s/it]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 293144/293144 [7:01:19<00:00, 11.60it/s]\r\nTraceback (most recent call last):\r\n  File \".../index/index.py\", line 147, in <module>\r\n    index = MobilityBuddyIndex()\r\n            ^^^^^^^^^^^^^^^^^^^^\r\n  File \".../index/index.py\", line 36, in __init__\r\n    self._setup_index()\r\n  File \".../index/index.py\", line 87, in _setup_index\r\n    self.index = VectorStoreIndex.from_documents(\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/base.py\", line 102, in from_documents\r\n    return cls(\r\n           ^^^^\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py\", line 46, in __init__\r\n    super().__init__(\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/base.py\", line 71, in __init__\r\n    index_struct = self.build_index_from_nodes(nodes)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py\", line 265, in build_index_from_nodes\r\n    return self._build_index_from_nodes(nodes)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py\", line 253, in _build_index_from_nodes\r\n    self._add_nodes_to_index(\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py\", line 214, in _add_nodes_to_index\r\n    new_ids = self._vector_store.add(nodes)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".../.venv/lib/python3.11/site-packages/llama_index/vector_stores/chroma.py\", line 146, in add\r\n    self._collection.add(\r\n  File \".../.venv/lib/python3.11/site-packages/chromadb/api/models/Collection.py\", line 99, in add\r\n    self._client._add(ids, self.id, embeddings, metadatas, documents)\r\n  File \".../.venv/lib/python3.11/site-packages/chromadb/api/segment.py\", line 249, in _add\r\n    self._producer.submit_embeddings(coll[\"topic\"], records_to_submit)\r\n  File \".../.venv/lib/python3.11/site-packages/chromadb/db/mixins/embeddings_queue.py\", line 127, in submit_embeddings\r\n    raise ValueError(\r\nValueError: \r\n                Cannot submit more than 41,666 embeddings at once.\r\n                Please submit your embeddings in batches of size\r\n                41,666 or less.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7648/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7648/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7647",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7647/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7647/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7647/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7647",
        "id": 1892918917,
        "node_id": "I_kwDOIWuq585w06aF",
        "number": 7647,
        "title": "[Feature Request]: SparQL database implementation just like SQL implementation via SQLAutovectorQueryEngine",
        "user": {
            "login": "LazyAIEnjoyer",
            "id": 131448743,
            "node_id": "U_kgDOB9W_pw",
            "avatar_url": "https://avatars.githubusercontent.com/u/131448743?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LazyAIEnjoyer",
            "html_url": "https://github.com/LazyAIEnjoyer",
            "followers_url": "https://api.github.com/users/LazyAIEnjoyer/followers",
            "following_url": "https://api.github.com/users/LazyAIEnjoyer/following{/other_user}",
            "gists_url": "https://api.github.com/users/LazyAIEnjoyer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LazyAIEnjoyer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LazyAIEnjoyer/subscriptions",
            "organizations_url": "https://api.github.com/users/LazyAIEnjoyer/orgs",
            "repos_url": "https://api.github.com/users/LazyAIEnjoyer/repos",
            "events_url": "https://api.github.com/users/LazyAIEnjoyer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LazyAIEnjoyer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            },
            {
                "id": 5860091515,
                "node_id": "LA_kwDOIWuq588AAAABXUnmew",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/stale",
                "name": "stale",
                "color": "dadada",
                "default": false,
                "description": "Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-12T17:00:52Z",
        "updated_at": "2023-12-12T16:02:15Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nWould it be possible to query with SparQL queries just like with SQL? I want to do joint text to sparQL and semantic search with local LLMs. \n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7647/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7647/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7646",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7646/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7646/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7646/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7646",
        "id": 1892805519,
        "node_id": "PR_kwDOIWuq585aJS80",
        "number": 7646,
        "title": "Fix azure streaming",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-12T15:50:54Z",
        "updated_at": "2023-09-12T16:48:59Z",
        "closed_at": "2023-09-12T16:48:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7646",
            "html_url": "https://github.com/run-llama/llama_index/pull/7646",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7646.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7646.patch",
            "merged_at": "2023-09-12T16:48:58Z"
        },
        "body": "# Description\r\n\r\nIn newer versions of the azure api, the first response when streaming has no content, only filtering/safety information. This PR fixes the index error that occurs because of this.\r\n\r\nFurthermore, I removed the default API version, as it is inconsistent with our docs and also breaks users who are specifying the API the old way.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7640\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7646/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7646/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7645",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7645/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7645/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7645/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7645",
        "id": 1892105226,
        "node_id": "PR_kwDOIWuq585aG46E",
        "number": 7645,
        "title": "add debug_truncate_chunk parameter in refine response kwargs",
        "user": {
            "login": "selfint",
            "id": 40059156,
            "node_id": "MDQ6VXNlcjQwMDU5MTU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/40059156?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/selfint",
            "html_url": "https://github.com/selfint",
            "followers_url": "https://api.github.com/users/selfint/followers",
            "following_url": "https://api.github.com/users/selfint/following{/other_user}",
            "gists_url": "https://api.github.com/users/selfint/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/selfint/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/selfint/subscriptions",
            "organizations_url": "https://api.github.com/users/selfint/orgs",
            "repos_url": "https://api.github.com/users/selfint/repos",
            "events_url": "https://api.github.com/users/selfint/events{/privacy}",
            "received_events_url": "https://api.github.com/users/selfint/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-12T09:42:23Z",
        "updated_at": "2023-09-12T19:50:02Z",
        "closed_at": "2023-09-12T19:50:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7645",
            "html_url": "https://github.com/run-llama/llama_index/pull/7645",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7645.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7645.patch",
            "merged_at": null
        },
        "body": "Useful for debugging refine prompts when chunks are larger than 50 chars.\r\nName of parameter is arbitrary, and should probably be changed.\r\n\r\n# Description\r\n\r\nAdd on option to set the truncate length for a chunk when logging intermediate refine results.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7645/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7645/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7644",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7644/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7644/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7644/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7644",
        "id": 1891955851,
        "node_id": "I_kwDOIWuq585wxPSL",
        "number": 7644,
        "title": "[Question]: Llamaindex supports Tapas or TaBERT to aim question answering for tabular data extraction?",
        "user": {
            "login": "iriye",
            "id": 47598555,
            "node_id": "MDQ6VXNlcjQ3NTk4NTU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/47598555?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iriye",
            "html_url": "https://github.com/iriye",
            "followers_url": "https://api.github.com/users/iriye/followers",
            "following_url": "https://api.github.com/users/iriye/following{/other_user}",
            "gists_url": "https://api.github.com/users/iriye/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iriye/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iriye/subscriptions",
            "organizations_url": "https://api.github.com/users/iriye/orgs",
            "repos_url": "https://api.github.com/users/iriye/repos",
            "events_url": "https://api.github.com/users/iriye/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iriye/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-12T08:26:47Z",
        "updated_at": "2023-10-24T06:31:27Z",
        "closed_at": "2023-10-24T06:31:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\ni want to wander how to use llamaindex  llm models as tapas? Please let know is there a support or plan to include TAPAS or TaBERT for tabular data extraction question answering purpose?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7644/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7644/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7643",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7643/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7643/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7643/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7643",
        "id": 1891821605,
        "node_id": "PR_kwDOIWuq585aF7Ve",
        "number": 7643,
        "title": "Add \"finetune + RAG\" evaluation to knowledge fine-tuning notebook",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-12T07:05:10Z",
        "updated_at": "2023-09-12T23:54:01Z",
        "closed_at": "2023-09-12T23:54:00Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7643",
            "html_url": "https://github.com/run-llama/llama_index/pull/7643",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7643.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7643.patch",
            "merged_at": "2023-09-12T23:54:00Z"
        },
        "body": "previously we showed fine-tuning result and RAG result but not both combined ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7643/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7643/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7642",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7642/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7642/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7642/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7642",
        "id": 1891746285,
        "node_id": "I_kwDOIWuq585wwcHt",
        "number": 7642,
        "title": "[Question]: Which LLM models can be used as open-source models for JSONQueryEngine with JSON data input?",
        "user": {
            "login": "iriye",
            "id": 47598555,
            "node_id": "MDQ6VXNlcjQ3NTk4NTU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/47598555?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iriye",
            "html_url": "https://github.com/iriye",
            "followers_url": "https://api.github.com/users/iriye/followers",
            "following_url": "https://api.github.com/users/iriye/following{/other_user}",
            "gists_url": "https://api.github.com/users/iriye/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iriye/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iriye/subscriptions",
            "organizations_url": "https://api.github.com/users/iriye/orgs",
            "repos_url": "https://api.github.com/users/iriye/repos",
            "events_url": "https://api.github.com/users/iriye/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iriye/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-12T06:14:33Z",
        "updated_at": "2023-09-21T20:10:57Z",
        "closed_at": "2023-09-21T20:10:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI want to use JSONQueryEngine with json data, but i do not want to gpt or openai, Which LLM models can be used as open-source models for JSONQueryEngine with JSON data input? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7642/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7642/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7641",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7641/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7641/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7641/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7641",
        "id": 1891741362,
        "node_id": "PR_kwDOIWuq585aFp5G",
        "number": 7641,
        "title": "added_concurrent_evaluation",
        "user": {
            "login": "siddhant01",
            "id": 31789669,
            "node_id": "MDQ6VXNlcjMxNzg5NjY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/31789669?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/siddhant01",
            "html_url": "https://github.com/siddhant01",
            "followers_url": "https://api.github.com/users/siddhant01/followers",
            "following_url": "https://api.github.com/users/siddhant01/following{/other_user}",
            "gists_url": "https://api.github.com/users/siddhant01/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/siddhant01/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/siddhant01/subscriptions",
            "organizations_url": "https://api.github.com/users/siddhant01/orgs",
            "repos_url": "https://api.github.com/users/siddhant01/repos",
            "events_url": "https://api.github.com/users/siddhant01/events{/privacy}",
            "received_events_url": "https://api.github.com/users/siddhant01/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-12T06:10:05Z",
        "updated_at": "2023-09-13T06:29:21Z",
        "closed_at": "2023-09-12T16:39:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7641",
            "html_url": "https://github.com/run-llama/llama_index/pull/7641",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7641.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7641.patch",
            "merged_at": "2023-09-12T16:39:40Z"
        },
        "body": "# Description\r\nIn this PR, a concurrent version of the evaluation has been created which helps in faster execution of evaluations. Earlier we were doing the evaluation of nodes synchronously but now we are using a concurrent evaluation, have also tried to use asyncio.Semaphore so that a fixed number of requests executes parallelly in the pool of requests.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7641/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7641/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7640",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7640/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7640/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7640/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7640",
        "id": 1891735463,
        "node_id": "I_kwDOIWuq585wwZen",
        "number": 7640,
        "title": "[Bug]: AzureOpenAI.stream_chat causes IndexError",
        "user": {
            "login": "apptaro",
            "id": 998626,
            "node_id": "MDQ6VXNlcjk5ODYyNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/998626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apptaro",
            "html_url": "https://github.com/apptaro",
            "followers_url": "https://api.github.com/users/apptaro/followers",
            "following_url": "https://api.github.com/users/apptaro/following{/other_user}",
            "gists_url": "https://api.github.com/users/apptaro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apptaro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apptaro/subscriptions",
            "organizations_url": "https://api.github.com/users/apptaro/orgs",
            "repos_url": "https://api.github.com/users/apptaro/repos",
            "events_url": "https://api.github.com/users/apptaro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apptaro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-12T06:04:31Z",
        "updated_at": "2023-09-12T16:48:59Z",
        "closed_at": "2023-09-12T16:48:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAzureOpenAI.stream_chat causes IndexError. Not happening with OpenAI.stream_chat.\r\n\r\nThis has just started happening today, so probably something has changed on Azure OpenAI service.\r\n\n\n### Version\n\n0.8.23.post1\n\n### Steps to Reproduce\n\nRun the following code to reproduce the issue:\r\n\r\n```\r\nimport os\r\nfrom llama_index.llms import OpenAI, AzureOpenAI\r\nfrom llama_index.llms.base import ChatMessage\r\n\r\nuse_azure = True\r\n\r\nif use_azure:\r\n    os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\r\n    os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\r\n    os.environ[\"OPENAI_API_BASE\"] = \"https://xxxx.openai.azure.com/\"\r\n    os.environ[\"OPENAI_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxxxx\"\r\n    llm = AzureOpenAI(engine = \"gpt-35-turbo\")\r\nelse:\r\n    os.environ[\"OPENAI_API_TYPE\"] = \"open_ai\"\r\n    os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxx\"\r\n    os.environ[\"OPENAI_API_BASE\"] = \"https://api.openai.com/v1\"\r\n    llm = OpenAI()\r\n\r\nfor delta in llm.stream_chat([ChatMessage(content = \"Hello!\")]):\r\n    print(delta)\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nTraceback (most recent call last):\r\n  File \"/home/ubuntuuser/LlamaIndex_env/project/test.py\", line 19, in <module>\r\n    for delta in llm.stream_chat([ChatMessage(content = \"Hello!\")]):\r\n  File \"/home/ubuntuuser/LlamaIndex_env/lib/python3.10/site-packages/llama_index/llms/base.py\", line 157, in wrapped_gen\r\n    for x in f_return_val:\r\n  File \"/home/ubuntuuser/LlamaIndex_env/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 229, in gen\r\n    delta = response[\"choices\"][0][\"delta\"]\r\nIndexError: list index out of range\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7640/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7640/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7639",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7639/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7639/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7639/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7639",
        "id": 1891467794,
        "node_id": "I_kwDOIWuq585wvYIS",
        "number": 7639,
        "title": "[Bug]: OpenAI agent execution doesn't propagate trace_ids to function calls",
        "user": {
            "login": "mikeldking",
            "id": 5640648,
            "node_id": "MDQ6VXNlcjU2NDA2NDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5640648?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mikeldking",
            "html_url": "https://github.com/mikeldking",
            "followers_url": "https://api.github.com/users/mikeldking/followers",
            "following_url": "https://api.github.com/users/mikeldking/following{/other_user}",
            "gists_url": "https://api.github.com/users/mikeldking/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mikeldking/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mikeldking/subscriptions",
            "organizations_url": "https://api.github.com/users/mikeldking/orgs",
            "repos_url": "https://api.github.com/users/mikeldking/repos",
            "events_url": "https://api.github.com/users/mikeldking/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mikeldking/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-12T00:20:39Z",
        "updated_at": "2023-09-12T21:36:16Z",
        "closed_at": "2023-09-12T21:36:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nInitialize an OpenAIAgent as follows:\r\n\r\n```python\r\n# Define very simple calculator tools for our agent\r\n\r\n    def multiply(a: int, b: int) -> int:\r\n        \"\"\"Multiple two integers and returns the result integer\"\"\"\r\n        return a * b\r\n\r\n    multiply_tool = FunctionTool.from_defaults(fn=multiply)\r\n\r\n    def add(a: int, b: int) -> int:\r\n        \"\"\"Add two integers and returns the result integer\"\"\"\r\n        return a + b\r\n\r\n    add_tool = FunctionTool.from_defaults(fn=add)\r\n    llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\r\n    cb_handler = OpenInferenceTraceCallbackHandler()\r\n    callback_manager = CallbackManager(handlers=[cb_handler])\r\n    agent = OpenAIAgent.from_tools(\r\n        [multiply_tool, add_tool], llm=llm, verbose=True, callback_manager=callback_manager\r\n    )\r\n    agent.query(\"What is 2 * 3?\")\r\n ```\r\n  \r\nwhere `OpenInferenceTraceCallbackHandler` can be any callback handler. even with `nested_asyncio` applied, the `start_trace` and `end_trace` don't get proper parent trace ids to correlate the function calls with the llm calls and vice versa\r\n    \n\n### Version\n\nllama-index==0.8.21\n\n### Steps to Reproduce\n\n1. define a data agent\r\n\r\n```python\r\n\r\n    def multiply(a: int, b: int) -> int:\r\n        \"\"\"Multiple two integers and returns the result integer\"\"\"\r\n        return a * b\r\n\r\n    multiply_tool = FunctionTool.from_defaults(fn=multiply)\r\n\r\n    def add(a: int, b: int) -> int:\r\n        \"\"\"Add two integers and returns the result integer\"\"\"\r\n        return a + b\r\n\r\n    add_tool = FunctionTool.from_defaults(fn=add)\r\n    llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\r\n    cb_handler = MyCallbackHander()\r\n    callback_manager = CallbackManager(handlers=[cb_handler])\r\n    agent = OpenAIAgent.from_tools(\r\n        [multiply_tool, add_tool], llm=llm, verbose=True, callback_manager=callback_manager\r\n    )\r\n    agent.query(\"What is 2 * 3?\")\r\n\r\n```\r\n\r\nwhere MyCallbackHander implements the `start_trace` and `end_trace` callback. \r\n\r\nNote that you will get distinct executions of `llm` and `function_call` but they will not be a part of the same trace.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7639/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7639/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7638",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7638/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7638/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7638/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7638",
        "id": 1891458230,
        "node_id": "I_kwDOIWuq585wvVy2",
        "number": 7638,
        "title": "[Feature Request]:  Expose the function callback name and the function_call for the callback handler via messages",
        "user": {
            "login": "mikeldking",
            "id": 5640648,
            "node_id": "MDQ6VXNlcjU2NDA2NDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5640648?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mikeldking",
            "html_url": "https://github.com/mikeldking",
            "followers_url": "https://api.github.com/users/mikeldking/followers",
            "following_url": "https://api.github.com/users/mikeldking/following{/other_user}",
            "gists_url": "https://api.github.com/users/mikeldking/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mikeldking/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mikeldking/subscriptions",
            "organizations_url": "https://api.github.com/users/mikeldking/orgs",
            "repos_url": "https://api.github.com/users/mikeldking/repos",
            "events_url": "https://api.github.com/users/mikeldking/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mikeldking/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-12T00:07:04Z",
        "updated_at": "2023-09-12T15:53:27Z",
        "closed_at": "2023-09-12T15:53:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\r\n\r\nThe message class is described as \r\n\r\n```python\r\n# ===== Generic Model Input - Chat =====\r\nclass ChatMessage(BaseModel):\r\n    \"\"\"Chat message.\"\"\"\r\n\r\n    role: MessageRole = MessageRole.USER\r\n    content: Optional[str] = \"\"\r\n    additional_kwargs: dict = Field(default_factory=dict)\r\n\r\n    def __str__(self) -> str:\r\n        return f\"{self.role.value}: {self.content}\"\r\n```\r\n\r\nhowever when the message is a function call, there is an additional  `name` property that describes which function was called.\r\n\r\nRight now the callback system receives a list of messages but they are not very useful for data agents:\r\n\r\nBelow is a serialization of the keys that would ideally be filled out in full (excluding the name which only needs to be there for function calls).\r\n\r\n\r\n```json\r\n[\r\n      {\r\n        \"message.content\": \"What is (121 * 3) + 42?\",\r\n        \"message.role\": \"user\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"363\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"405\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"(121 * 3) + 42 is equal to 405.\",\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"What is (121 * 3) + 42?\",\r\n        \"message.role\": \"user\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"363\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"405\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"(121 * 3) + 42 is equal to 405.\",\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"what is 3 * 3?\",\r\n        \"message.role\": \"user\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"9\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"3 * 3 is equal to 9.\",\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"what is 4 * 4?\",\r\n        \"message.role\": \"user\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"16\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"4 * 4 is equal to 16.\",\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"what is 75 * (3 + 4)?\",\r\n        \"message.role\": \"user\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": null,\r\n        \"message.role\": \"assistant\",\r\n        \"message.name\": null\r\n      },\r\n      {\r\n        \"message.content\": \"7\",\r\n        \"message.role\": \"function\",\r\n        \"message.name\": null\r\n      }\r\n    ]\r\n```\r\n\r\n### Reason\r\n\r\nI don't think there should be anything preventing llama_index from supporting this.\r\n\r\n### Value of Feature\r\n\r\nThe ability to troubleshoot function callbacks using traces.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7638/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7638/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7637",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7637/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7637/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7637/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7637",
        "id": 1891441867,
        "node_id": "PR_kwDOIWuq585aEqQw",
        "number": 7637,
        "title": "add simple chat engine to as_chat_engine",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-11T23:55:44Z",
        "updated_at": "2023-09-12T00:45:55Z",
        "closed_at": "2023-09-12T00:45:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7637",
            "html_url": "https://github.com/run-llama/llama_index/pull/7637",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7637.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7637.patch",
            "merged_at": "2023-09-12T00:45:54Z"
        },
        "body": "# Description\r\n\r\nWhile it doesn't make total sense to include this in `as_chat_engine()`, it does make it easier to instantiate the chat engine itself, and lines up with expectations from our docs.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7622\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7637/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7637/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7636",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7636/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7636/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7636/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7636",
        "id": 1891408024,
        "node_id": "PR_kwDOIWuq585aEi9g",
        "number": 7636,
        "title": "SPARQL Graph Store (minimal)",
        "user": {
            "login": "danja",
            "id": 2303,
            "node_id": "MDQ6VXNlcjIzMDM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2303?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danja",
            "html_url": "https://github.com/danja",
            "followers_url": "https://api.github.com/users/danja/followers",
            "following_url": "https://api.github.com/users/danja/following{/other_user}",
            "gists_url": "https://api.github.com/users/danja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danja/subscriptions",
            "organizations_url": "https://api.github.com/users/danja/orgs",
            "repos_url": "https://api.github.com/users/danja/repos",
            "events_url": "https://api.github.com/users/danja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danja/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-11T23:15:22Z",
        "updated_at": "2023-09-15T22:16:41Z",
        "closed_at": "2023-09-14T18:57:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7636",
            "html_url": "https://github.com/run-llama/llama_index/pull/7636",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7636.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7636.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\n(Please be gentle, if I've done this before it was a long time ago)\r\n\r\nA first-pass implementation of (some of) the graph_store/types.py interface, that provides some the same functionality as nebulagraph.py but against a SPARQL store (as sparql.py).\r\n\r\nThe immediate aim was to be able to run the equivalent of Wey Gu's Graph RAG demo -\r\nhttps://www.siwei.io/en/demos/graph-rag/\r\n but rather than using a NebulaGraph store, use a SPARQL store. It does that.\r\n\r\nIt has a couple of glaring inefficiencies (the shape of the queries needs work, and there's no batching of data when uploading to store), but I think works well enough to expose to other eyeballs. I reckon the harder parts are done.\r\n\r\nIt depends on sparqlwrapper (which is available through pip etc). \r\nI don't believe it'll have any impact on anything else in the codebase.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nFor convenience I've set up a wide-open SPARQL store online.\r\n\r\nI got results comparable to Wey's Notebook running it locally with :\r\nhttps://github.com/danja/nlp/blob/main/GraphRAG/src/graph-rag-sparql-minimal.py\r\n\r\nI've also put a version of this in a Jupyter Notebook, in this request. \r\n\r\nMore docs to follow very soon, I have material in rough form, needs an hour or two's copy, paste & tidy.\r\n\r\n# Tests\r\n\r\nThe script/Notebook should be ok for end-to-end. \r\nI've made a start on unit tests, but they are currently very rough, only really worth putting into the repo as placeholders, *if* that seems a good idea.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7636/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7636/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7635",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7635/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7635/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7635/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7635",
        "id": 1891365462,
        "node_id": "PR_kwDOIWuq585aEZr9",
        "number": 7635,
        "title": "Adding Ollama Support",
        "user": {
            "login": "pjerryhu",
            "id": 3605555,
            "node_id": "MDQ6VXNlcjM2MDU1NTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3605555?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pjerryhu",
            "html_url": "https://github.com/pjerryhu",
            "followers_url": "https://api.github.com/users/pjerryhu/followers",
            "following_url": "https://api.github.com/users/pjerryhu/following{/other_user}",
            "gists_url": "https://api.github.com/users/pjerryhu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pjerryhu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pjerryhu/subscriptions",
            "organizations_url": "https://api.github.com/users/pjerryhu/orgs",
            "repos_url": "https://api.github.com/users/pjerryhu/repos",
            "events_url": "https://api.github.com/users/pjerryhu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pjerryhu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-11T22:27:14Z",
        "updated_at": "2023-09-15T15:40:40Z",
        "closed_at": "2023-09-15T15:40:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7635",
            "html_url": "https://github.com/run-llama/llama_index/pull/7635",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7635.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7635.patch",
            "merged_at": "2023-09-15T15:40:40Z"
        },
        "body": "# Description\r\n\r\nFixes [# (issue 7487)](https://github.com/jerryjliu/llama_index/issues/7487)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7635/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7635/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7634",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7634/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7634/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7634/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7634",
        "id": 1890806766,
        "node_id": "PR_kwDOIWuq585aCfv_",
        "number": 7634,
        "title": "[version] bump version to 0.8.24.post1",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-11T15:52:13Z",
        "updated_at": "2023-09-11T16:13:10Z",
        "closed_at": "2023-09-11T16:13:09Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7634",
            "html_url": "https://github.com/run-llama/llama_index/pull/7634",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7634.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7634.patch",
            "merged_at": "2023-09-11T16:13:09Z"
        },
        "body": "need to link the guide in the docs",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7634/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7634/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7633",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7633/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7633/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7633/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7633",
        "id": 1890802642,
        "node_id": "I_kwDOIWuq585ws1vS",
        "number": 7633,
        "title": "[Bug]: DocumentSummaryIndexEmbeddingRetriever not returning similarity scores",
        "user": {
            "login": "kevon217",
            "id": 13077896,
            "node_id": "MDQ6VXNlcjEzMDc3ODk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/13077896?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kevon217",
            "html_url": "https://github.com/kevon217",
            "followers_url": "https://api.github.com/users/kevon217/followers",
            "following_url": "https://api.github.com/users/kevon217/following{/other_user}",
            "gists_url": "https://api.github.com/users/kevon217/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kevon217/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kevon217/subscriptions",
            "organizations_url": "https://api.github.com/users/kevon217/orgs",
            "repos_url": "https://api.github.com/users/kevon217/repos",
            "events_url": "https://api.github.com/users/kevon217/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kevon217/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            },
            {
                "id": 5860091515,
                "node_id": "LA_kwDOIWuq588AAAABXUnmew",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/stale",
                "name": "stale",
                "color": "dadada",
                "default": false,
                "description": "Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-11T15:49:50Z",
        "updated_at": "2023-12-11T16:02:20Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI'm using **DocumentSummaryIndexEmbeddingRetriever** on my document summary index, but the retrieved nodes are not given a score. Is this expected behavior?\n\n### Version\n\n0.8.20\n\n### Steps to Reproduce\n\n```\r\n# service context \r\nnode_parser = SimpleNodeParser.from_defaults(\r\n    include_metadata=False, \r\n)\r\nchatgpt = OpenAI(temperature=self.config.service_context.llm.llm_kwargs.temperature, \r\n                 model=self.config.service_context.llm.llm_kwargs.model_name)\r\nservice_context = ServiceContext.from_defaults(llm=chatgpt, \r\n                                               node_parser=node_parser)\r\n\r\n# response synthesizer \r\nresponse_synthesizer = get_response_synthesizer(response_mode='compact', use_async=True)\r\n\r\n# summary index\r\nCUSTOM_SUMMARY_QUERY = \"Succinctly describe what this study is about.\" \r\nsummary_index = DocumentSummaryIndex.from_documents(\r\n    self.docs,\r\n    include_metadata=False,\r\n    summary_query=CUSTOM_SUMMARY_QUERY,\r\n    response_synthesizer=response_synthesizer,\r\n    service_context=service_context,\r\n    show_progress=True,\r\n)\r\n\r\n# persist index locally\r\nstorage_path = '/test'\r\nsummary_index.storage_context.persist(storage_path)\r\n\r\n# reload index\r\nstorage_context = StorageContext.from_defaults(persist_dir=storage_path)\r\nsummary_index = load_index_from_storage(storage_context)\r\n\r\n# initialize retriever\r\nsummary_retriever = DocumentSummaryIndexEmbeddingRetriever(\r\n                    index=summary_index,\r\n                    similarity_top_k=similarity_top_k\r\n                )\r\n\r\n# retrieve\r\nretrieved_nodes = summary_retriever.retrieve(\"I'm looking for studies on TBI.\")\r\n\r\n```\r\nThe retrieved nodes are relevant, but score information is missing:\r\nretrieved_nodes[0].score --> None\r\nretrieved_nodes[0].get_score() --> 0.0\r\n\r\nNot sure if I am missing a step or misunderstanding the class. Any guidance is much appreciated!\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7633/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7633/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7632",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7632/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7632/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7632/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7632",
        "id": 1890784613,
        "node_id": "PR_kwDOIWuq585aCbBl",
        "number": 7632,
        "title": "[version] bump version to 0.8.24",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-11T15:39:28Z",
        "updated_at": "2023-09-11T15:48:07Z",
        "closed_at": "2023-09-11T15:48:06Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7632",
            "html_url": "https://github.com/run-llama/llama_index/pull/7632",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7632.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7632.patch",
            "merged_at": "2023-09-11T15:48:06Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7632/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7632/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7631",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7631/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7631/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7631/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7631",
        "id": 1890737645,
        "node_id": "PR_kwDOIWuq585aCQ20",
        "number": 7631,
        "title": "update wandb callback for more span types",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-11T15:13:35Z",
        "updated_at": "2023-09-11T15:28:17Z",
        "closed_at": "2023-09-11T15:28:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7631",
            "html_url": "https://github.com/run-llama/llama_index/pull/7631",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7631.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7631.patch",
            "merged_at": "2023-09-11T15:28:16Z"
        },
        "body": "# Description\r\n\r\nBug fix to better handle span types with wandb.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7630\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7631/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7631/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7630",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7630/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7630/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7630/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7630",
        "id": 1890552113,
        "node_id": "I_kwDOIWuq585wr4kx",
        "number": 7630,
        "title": "[Bug]: Failed to log trace tree to W&B: Unknown event type: templating",
        "user": {
            "login": "courtneyjean",
            "id": 40828469,
            "node_id": "MDQ6VXNlcjQwODI4NDY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/40828469?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/courtneyjean",
            "html_url": "https://github.com/courtneyjean",
            "followers_url": "https://api.github.com/users/courtneyjean/followers",
            "following_url": "https://api.github.com/users/courtneyjean/following{/other_user}",
            "gists_url": "https://api.github.com/users/courtneyjean/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/courtneyjean/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/courtneyjean/subscriptions",
            "organizations_url": "https://api.github.com/users/courtneyjean/orgs",
            "repos_url": "https://api.github.com/users/courtneyjean/repos",
            "events_url": "https://api.github.com/users/courtneyjean/events{/privacy}",
            "received_events_url": "https://api.github.com/users/courtneyjean/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-11T13:44:21Z",
        "updated_at": "2023-09-11T15:51:23Z",
        "closed_at": "2023-09-11T15:28:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI was working through the example in this demo: https://gpt-index.readthedocs.io/en/v0.6.36/examples/callbacks/WandbCallbackHandler.html\r\n\r\nWhen I call the following code:\r\n\r\nquery_engine = index.as_query_engine()\r\nresponse = query_engine.query(query_str)\r\n\r\nI get this printout: \r\n**********\r\nTrace: query\r\n    |_query ->  11.801936 seconds\r\n      |_retrieve ->  0.361814 seconds\r\n        |_embedding ->  0.351348 seconds\r\n      |_synthesize ->  11.439857 seconds\r\n        |_templating ->  5.9e-05 seconds\r\n        |_llm ->  11.434557 seconds\r\n**********\r\nFailed to log trace tree to W&B: Unknown event type: templating\n\n### Version\n\n0.8.23.post1\n\n### Steps to Reproduce\n\nimport os\r\nimport openai\r\nimport wandb\r\nimport pandas as pd\r\nfrom llama_index import Document\r\nfrom llama_index.callbacks import CallbackManager, CBEventType\r\nfrom llama_index.callbacks import LlamaDebugHandler, WandbCallbackHandler\r\nfrom llama_index import (GPTVectorStoreIndex,\r\n    ServiceContext, LLMPredictor, StorageContext\r\n)\r\nfrom langchain.chat_models import ChatOpenAI\r\n\r\n# test docs\r\ndf = pd.read_excel(\"/dbfs/test_docs.xlsx\")\r\ndocuments=[]\r\nfor i in range(df.shape[0]):\r\n  doc =  Document(text=df.iloc[i][\"CONTENT\"])\r\n  documents.append(doc)\r\n\r\nwandb.login(key=os.getenv(\"WANDB_API\"))\r\n\r\nllm_predictor = LLMPredictor(llm=ChatOpenAI(model_name='gpt-4', openai_api_key = OPENAI_API_KEY, temperature=0))\r\n\r\nllama_debug = LlamaDebugHandler(print_trace_on_end=True)\r\n\r\n# wandb.init args\r\nrun_args = dict(\r\n    project=\"llamaindex\", dir=\"/tmp/wandb/\") #\r\n\r\nwandb_callback = WandbCallbackHandler(run_args=run_args)\r\n\r\ncallback_manager = CallbackManager([llama_debug, wandb_callback])\r\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager, llm_predictor=llm_predictor)\r\n\r\nindex = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\r\nquery_engine = index.as_query_engine()\r\nresponse = query_engine.query(\"What did the author do growing up?\")\n\n### Relevant Logs/Tracbacks\n\n```shell\n**********\r\nTrace: index_construction\r\n    |_node_parsing ->  0.220429 seconds\r\n      |_chunking ->  0.002109 seconds\r\n      |_chunking ->  0.020112 seconds\r\n      |_chunking ->  0.002749 seconds\r\n      |_chunking ->  0.011723 seconds\r\n      |_chunking ->  0.000921 seconds\r\n      |_chunking ->  0.00255 seconds\r\n      |_chunking ->  0.004203 seconds\r\n      |_chunking ->  0.005499 seconds\r\n      |_chunking ->  0.001444 seconds\r\n      |_chunking ->  0.007912 seconds\r\n      |_chunking ->  0.001569 seconds\r\n      |_chunking ->  0.003608 seconds\r\n      |_chunking ->  0.001139 seconds\r\n      |_chunking ->  0.001225 seconds\r\n      |_chunking ->  0.001568 seconds\r\n      |_chunking ->  0.002994 seconds\r\n      |_chunking ->  0.001136 seconds\r\n      |_chunking ->  0.006493 seconds\r\n      |_chunking ->  0.000934 seconds\r\n      |_chunking ->  0.003699 seconds\r\n      |_chunking ->  0.00535 seconds\r\n      |_chunking ->  0.000774 seconds\r\n      |_chunking ->  0.001132 seconds\r\n      |_chunking ->  0.001153 seconds\r\n      |_chunking ->  0.004142 seconds\r\n      |_chunking ->  0.000558 seconds\r\n      |_chunking ->  0.001583 seconds\r\n      |_chunking ->  0.009302 seconds\r\n      |_chunking ->  0.001553 seconds\r\n      |_chunking ->  0.000813 seconds\r\n      |_chunking ->  0.001526 seconds\r\n      |_chunking ->  0.003128 seconds\r\n      |_chunking ->  0.001125 seconds\r\n      |_chunking ->  0.005968 seconds\r\n      |_chunking ->  0.003741 seconds\r\n      |_chunking ->  0.007644 seconds\r\n      |_chunking ->  0.002747 seconds\r\n      |_chunking ->  0.007198 seconds\r\n      |_chunking ->  0.003727 seconds\r\n      |_chunking ->  0.003807 seconds\r\n      |_chunking ->  0.003035 seconds\r\n      |_chunking ->  0.00364 seconds\r\n      |_chunking ->  0.005579 seconds\r\n      |_chunking ->  0.002973 seconds\r\n      |_chunking ->  0.00501 seconds\r\n      |_chunking ->  0.001135 seconds\r\n      |_chunking ->  0.003503 seconds\r\n      |_chunking ->  0.001278 seconds\r\n      |_chunking ->  0.001328 seconds\r\n      |_chunking ->  0.004167 seconds\r\n      |_chunking ->  0.001473 seconds\r\n      |_chunking ->  0.003016 seconds\r\n      |_chunking ->  0.002388 seconds\r\n      |_chunking ->  0.001503 seconds\r\n      |_chunking ->  0.001229 seconds\r\n      |_chunking ->  0.003638 seconds\r\n      |_chunking ->  0.003668 seconds\r\n      |_chunking ->  0.003397 seconds\r\n    |_embedding ->  0.538768 seconds\r\n    |_embedding ->  0.515932 seconds\r\n    |_embedding ->  1.609985 seconds\r\n    |_embedding ->  0.58475 seconds\r\n    |_embedding ->  0.279321 seconds\r\n    |_embedding ->  0.546799 seconds\r\n    |_embedding ->  0.451112 seconds\r\n    |_embedding ->  0.452841 seconds\r\n    |_embedding ->  0.484817 seconds\r\n    |_embedding ->  0.502272 seconds\r\n**********\r\nwandb: Logged trace tree to W&B.\r\n**********\r\nTrace: query\r\n    |_query ->  2.412136 seconds\r\n      |_retrieve ->  0.285512 seconds\r\n        |_embedding ->  0.272951 seconds\r\n      |_synthesize ->  2.126364 seconds\r\n        |_templating ->  5.9e-05 seconds\r\n        |_llm ->  2.123693 seconds\r\n**********\r\nFailed to log trace tree to W&B: Unknown event type: templating\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7630/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7630/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7629",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7629/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7629/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7629/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7629",
        "id": 1890374249,
        "node_id": "I_kwDOIWuq585wrNJp",
        "number": 7629,
        "title": "[Bug]: ERROR WHEN USING 'chat_history' PARAMETER INSIDE engine.chat(). ERROR : 'dict' object has no attribute 'content'",
        "user": {
            "login": "sayantan-diatoz",
            "id": 138863560,
            "node_id": "U_kgDOCEbjyA",
            "avatar_url": "https://avatars.githubusercontent.com/u/138863560?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sayantan-diatoz",
            "html_url": "https://github.com/sayantan-diatoz",
            "followers_url": "https://api.github.com/users/sayantan-diatoz/followers",
            "following_url": "https://api.github.com/users/sayantan-diatoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sayantan-diatoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sayantan-diatoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sayantan-diatoz/subscriptions",
            "organizations_url": "https://api.github.com/users/sayantan-diatoz/orgs",
            "repos_url": "https://api.github.com/users/sayantan-diatoz/repos",
            "events_url": "https://api.github.com/users/sayantan-diatoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sayantan-diatoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-11T12:12:38Z",
        "updated_at": "2023-09-11T15:16:44Z",
        "closed_at": "2023-09-11T15:16:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nengine=index.as_chat_engine() \r\nquery=\"What You Want To Ask From Engine.\"\r\nconversation=[\r\n        {\r\n            \"role\": \"user\",\r\n            \"content\": \"What is the revenue for India\"\r\n        },\r\n        {\r\n            \"role\": \"assistant\",\r\n            \"content\": \"The total revenue for India is 50000 Rupees.\"\r\n        }       \r\n    ]\r\nresponse = engine.chat(message=query, chat_history=conversation)\r\n\r\nGIVING ERROR AS : 'dict' object has no attribute 'content'.\r\n\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nCreate an 'engine' from 'index.as_chat_engine()'.\r\nquery=\"What You Want To Ask From Engine.\"\r\nSend previous conversation inside 'chat_history'.\r\nLike,\r\nresponse= engine.chat(message=query,chat_history=conversation).\r\nWhere,\r\nconversation=[\r\n        {\r\n            \"role\": \"user\",\r\n            \"content\": \"What is the revenue for India\"\r\n        },\r\n        {\r\n            \"role\": \"assistant\",\r\n            \"content\": \"The total revenue for India is 50000 Rupees.\"\r\n        }       \r\n    ]\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7629/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7629/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7628",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7628/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7628/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7628/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7628",
        "id": 1890178622,
        "node_id": "I_kwDOIWuq585wqdY-",
        "number": 7628,
        "title": "[Question]: Query engine and context",
        "user": {
            "login": "uzumakinaruto19",
            "id": 99479748,
            "node_id": "U_kgDOBe3wxA",
            "avatar_url": "https://avatars.githubusercontent.com/u/99479748?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/uzumakinaruto19",
            "html_url": "https://github.com/uzumakinaruto19",
            "followers_url": "https://api.github.com/users/uzumakinaruto19/followers",
            "following_url": "https://api.github.com/users/uzumakinaruto19/following{/other_user}",
            "gists_url": "https://api.github.com/users/uzumakinaruto19/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/uzumakinaruto19/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/uzumakinaruto19/subscriptions",
            "organizations_url": "https://api.github.com/users/uzumakinaruto19/orgs",
            "repos_url": "https://api.github.com/users/uzumakinaruto19/repos",
            "events_url": "https://api.github.com/users/uzumakinaruto19/events{/privacy}",
            "received_events_url": "https://api.github.com/users/uzumakinaruto19/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-09-11T10:21:41Z",
        "updated_at": "2023-09-25T13:52:22Z",
        "closed_at": "2023-09-22T13:47:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIs there a way I could see what context goes through the query engine when I ask a question ? like what is the metadata\r\n` \r\nindex = GPTVectorStoreIndex.from_documents(documents)\r\nservice_context = ServiceContext.from_defaults(llm=ChatOpenAI(temperature=0, model_name=model_name, streaming=True),chunk_size=1000)`\r\n`query_engine = index.as_query_engine(service_context=service_context, system_prompt=input_prompt, similarity_top_k=3, streaming=True) `\r\n`quest = query_engine.query(input_prompt)\r\n`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7628/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7628/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7627",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7627/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7627/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7627/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7627",
        "id": 1889776513,
        "node_id": "I_kwDOIWuq585wo7OB",
        "number": 7627,
        "title": "[Question]: Want to load all the Data from a MongoDB Database, by using 'SimpleMongoReader' and 'load_data()' method. Currently it is Collection specific as 'collection_name' is a mandatory parameter inside 'load_data()' method. I want the entire Database Data inside the 'document' variable.",
        "user": {
            "login": "sayantan-diatoz",
            "id": 138863560,
            "node_id": "U_kgDOCEbjyA",
            "avatar_url": "https://avatars.githubusercontent.com/u/138863560?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sayantan-diatoz",
            "html_url": "https://github.com/sayantan-diatoz",
            "followers_url": "https://api.github.com/users/sayantan-diatoz/followers",
            "following_url": "https://api.github.com/users/sayantan-diatoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sayantan-diatoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sayantan-diatoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sayantan-diatoz/subscriptions",
            "organizations_url": "https://api.github.com/users/sayantan-diatoz/orgs",
            "repos_url": "https://api.github.com/users/sayantan-diatoz/repos",
            "events_url": "https://api.github.com/users/sayantan-diatoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sayantan-diatoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-11T06:38:42Z",
        "updated_at": "2023-09-11T15:18:59Z",
        "closed_at": "2023-09-11T15:18:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nIs there any way that 'SimpleMongoReader' can read the entire Database instead of a specific Collection?\r\nI am using reader.load_data() method where 'collection_name' is a mandatory field. It is only loading the Data from that specific MongoDB Collection. But I want to include all the Database Data inside my 'document' variable.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7627/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7627/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7626",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7626/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7626/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7626/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7626",
        "id": 1889763006,
        "node_id": "PR_kwDOIWuq585Z-8OO",
        "number": 7626,
        "title": "guide: fine-tuning to memorize knowledge",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-11T06:28:53Z",
        "updated_at": "2023-09-11T15:37:39Z",
        "closed_at": "2023-09-11T15:37:38Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7626",
            "html_url": "https://github.com/run-llama/llama_index/pull/7626",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7626.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7626.patch",
            "merged_at": "2023-09-11T15:37:38Z"
        },
        "body": "created a notebook showing how we can try fine-tuning to memorize knowledge.\r\n\r\nIt's still very WIP, not trying to promise any conclusive results. The model does get better at answering questions from the training set, but not necc the eval set. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7626/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7626/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7625",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7625/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7625/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7625/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7625",
        "id": 1889719334,
        "node_id": "I_kwDOIWuq585wotQm",
        "number": 7625,
        "title": "[Bug]: 'SimpleMongoReader' not working if any value inside any MongoDB Key (for that specific Collection) is in any other format except String.",
        "user": {
            "login": "sayantan-diatoz",
            "id": 138863560,
            "node_id": "U_kgDOCEbjyA",
            "avatar_url": "https://avatars.githubusercontent.com/u/138863560?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sayantan-diatoz",
            "html_url": "https://github.com/sayantan-diatoz",
            "followers_url": "https://api.github.com/users/sayantan-diatoz/followers",
            "following_url": "https://api.github.com/users/sayantan-diatoz/following{/other_user}",
            "gists_url": "https://api.github.com/users/sayantan-diatoz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sayantan-diatoz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sayantan-diatoz/subscriptions",
            "organizations_url": "https://api.github.com/users/sayantan-diatoz/orgs",
            "repos_url": "https://api.github.com/users/sayantan-diatoz/repos",
            "events_url": "https://api.github.com/users/sayantan-diatoz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sayantan-diatoz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            },
            {
                "id": 5860091515,
                "node_id": "LA_kwDOIWuq588AAAABXUnmew",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/stale",
                "name": "stale",
                "color": "dadada",
                "default": false,
                "description": "Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-11T05:55:12Z",
        "updated_at": "2023-12-11T16:02:31Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n'SimpleMongoReader' not working if any value inside any MongoDB Key (for that specific Collection) is in any other format except String.\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nUse 'SimpleMongoReader' with integer value inside a Key in that specific Collection.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7625/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7625/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7624",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7624/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7624/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7624/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7624",
        "id": 1889551466,
        "node_id": "PR_kwDOIWuq585Z-ORa",
        "number": 7624,
        "title": "fix fine-tune embedding nb ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-11T02:57:49Z",
        "updated_at": "2023-09-11T03:19:19Z",
        "closed_at": "2023-09-11T03:19:18Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7624",
            "html_url": "https://github.com/run-llama/llama_index/pull/7624",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7624.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7624.patch",
            "merged_at": "2023-09-11T03:19:18Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7624/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7624/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7623",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7623/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7623/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7623/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7623",
        "id": 1889543053,
        "node_id": "I_kwDOIWuq585woCON",
        "number": 7623,
        "title": "[Bug]: Running the chatbot customization tutorial doesn't load context data",
        "user": {
            "login": "robgon-art",
            "id": 1119357,
            "node_id": "MDQ6VXNlcjExMTkzNTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1119357?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/robgon-art",
            "html_url": "https://github.com/robgon-art",
            "followers_url": "https://api.github.com/users/robgon-art/followers",
            "following_url": "https://api.github.com/users/robgon-art/following{/other_user}",
            "gists_url": "https://api.github.com/users/robgon-art/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/robgon-art/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/robgon-art/subscriptions",
            "organizations_url": "https://api.github.com/users/robgon-art/orgs",
            "repos_url": "https://api.github.com/users/robgon-art/repos",
            "events_url": "https://api.github.com/users/robgon-art/events{/privacy}",
            "received_events_url": "https://api.github.com/users/robgon-art/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-11T02:46:49Z",
        "updated_at": "2023-09-15T04:19:11Z",
        "closed_at": "2023-09-15T04:19:11Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHello, great project! I was able to run the Starter Tutorial just fine on a Google Colab running llama_index v0.8.23.post1 using my OpenAI API token.\r\n\r\nBut when I tried to run the Customization Tutorial called \"I want a chatbot instead of Q&A,\" it didn't seem to load any context from the index, and the response was wrong.\r\n\r\nAm I missing something? Or is there a bug with loading a context using the chat engine?\n\n### Version\n\n0.8.23.post1\n\n### Steps to Reproduce\n\nFirst, here's my code that works using `query_engine.query()`\r\n\r\n```!pip install llama-index\r\n!mkdir data\r\n!wget https://raw.githubusercontent.com/jerryjliu/llama_index/main/examples/paul_graham_essay/data/paul_graham_essay.txt -P data\r\n\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = 'my-openai-key'\r\n\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\nindex = VectorStoreIndex.from_documents(documents)\r\n\r\nimport textwrap\r\nquery_engine = index.as_query_engine()\r\nresponse = query_engine.query(\"What did the author do growing up?\")\r\nprint(textwrap.fill(response.response, width=150, replace_whitespace=False))\r\n\r\n# Output:\r\n# The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401\r\n# computer. They also built a microcomputer kit and started programming on it, writing simple games and a word processor.\r\n```\r\n\r\nThe above worked fine. But this doesn't seem to work using `query_engine.chat()`\r\n\r\n```\r\nquery_engine = index.as_chat_engine()\r\nresponse = query_engine.chat(\"What did the author do growing up?\")\r\nprint(textwrap.fill(response.response, width=150, replace_whitespace=False))\r\nprint()\r\nresponse = query_engine.chat(\"Oh interesting, tell me more.\")\r\nprint(textwrap.fill(response.response, width=150, replace_whitespace=False))\r\n\r\n# Output:\r\n# I'm sorry, but I don't have access to personal information about the author.\r\n# \r\n# I apologize for the confusion. As an AI language model, I don't have real-time access to personal information about individuals unless it has been\r\n# shared with me in the course of our conversation. I can provide general information and answer questions based on my training, but I don't have\r\n# specific details about the author's personal life or experiences. Is there anything else I can help you with?\r\n```\r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nFor reference, here are the versions of packages that were installed from running `!pip install llama-index`\r\n\r\n\r\nCollecting llama-index\r\n  Downloading llama_index-0.8.23.post1-py3-none-any.whl (786 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 786.5/786.5 kB 5.3 MB/s eta 0:00:00\r\nCollecting tiktoken (from llama-index)\r\n  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 9.9 MB/s eta 0:00:00\r\nCollecting dataclasses-json (from llama-index)\r\n  Downloading dataclasses_json-0.6.0-py3-none-any.whl (27 kB)\r\nCollecting langchain>=0.0.262 (from llama-index)\r\n  Downloading langchain-0.0.285-py3-none-any.whl (1.7 MB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 15.6 MB/s eta 0:00:00\r\nRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.20)\r\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\r\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\r\nCollecting openai>=0.26.4 (from llama-index)\r\n  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 76.5/76.5 kB 7.6 MB/s eta 0:00:00\r\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\r\nCollecting urllib3<2 (from llama-index)\r\n  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 143.1/143.1 kB 10.6 MB/s eta 0:00:00\r\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\r\nCollecting typing-inspect>=0.8.0 (from llama-index)\r\n  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\r\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.11.2)\r\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.7)\r\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\r\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (6.0.1)\r\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (3.8.5)\r\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (4.0.3)\r\nCollecting dataclasses-json (from llama-index)\r\n  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\r\nCollecting langsmith<0.1.0,>=0.0.21 (from langchain>=0.0.262->llama-index)\r\n  Downloading langsmith-0.0.35-py3-none-any.whl (37 kB)\r\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (2.8.5)\r\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (1.10.12)\r\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.262->llama-index) (2.31.0)\r\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\r\n  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.4/49.4 kB 5.8 MB/s eta 0:00:00\r\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.66.1)\r\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\r\nCollecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\r\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index) (2.5)\r\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (8.1.7)\r\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (1.3.2)\r\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->llama-index) (2023.6.3)\r\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\r\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (23.1.0)\r\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (3.2.0)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (6.0.4)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (1.9.2)\r\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (1.4.0)\r\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.262->llama-index) (1.3.1)\r\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.1)\r\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\r\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.262->llama-index) (3.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.262->llama-index) (2023.7.22)\r\nInstalling collected packages: urllib3, mypy-extensions, marshmallow, typing-inspect, tiktoken, openai, langsmith, dataclasses-json, langchain, llama-index\r\n  Attempting uninstall: urllib3\r\n    Found existing installation: urllib3 2.0.4\r\n    Uninstalling urllib3-2.0.4:\r\n      Successfully uninstalled urllib3-2.0.4\r\nSuccessfully installed dataclasses-json-0.5.14 langchain-0.0.285 langsmith-0.0.35 llama-index-0.8.23.post1 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.0 tiktoken-0.4.0 typing-inspect-0.9.0 urllib3-1.26.16\r\n```\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7623/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7623/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7622",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7622/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7622/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7622/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7622",
        "id": 1889412072,
        "node_id": "I_kwDOIWuq585wniPo",
        "number": 7622,
        "title": "[Bug]: chat_mode 'simple' gives error",
        "user": {
            "login": "fariazz",
            "id": 1313597,
            "node_id": "MDQ6VXNlcjEzMTM1OTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1313597?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fariazz",
            "html_url": "https://github.com/fariazz",
            "followers_url": "https://api.github.com/users/fariazz/followers",
            "following_url": "https://api.github.com/users/fariazz/following{/other_user}",
            "gists_url": "https://api.github.com/users/fariazz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fariazz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fariazz/subscriptions",
            "organizations_url": "https://api.github.com/users/fariazz/orgs",
            "repos_url": "https://api.github.com/users/fariazz/repos",
            "events_url": "https://api.github.com/users/fariazz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fariazz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-11T00:33:18Z",
        "updated_at": "2023-09-12T00:45:55Z",
        "closed_at": "2023-09-12T00:45:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nIf you create a chat engine with chat_mode set as `'simple'` (mentioned in the documentation [here](https://gpt-index.readthedocs.io/en/stable/core_modules/query_modules/chat_engines/usage_pattern.html#available-chat-modes)), it gives you this error:\r\n\r\n```\r\nFile \"C:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py\", line 405, in as_chat_engine\r\n    raise ValueError(f\"Unknown chat mode: {chat_mode}\")\r\nValueError: Unknown chat mode: simple\r\n```\n\n### Version\n\n0.8.23.post1\n\n### Steps to Reproduce\n\nRun this code (assumes a local folder called \"documents\" with any supported file):\r\n\r\n```\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\n\r\n# load documents\r\ndocuments = SimpleDirectoryReader('documents').load_data()\r\n\r\n# create index\r\nindex = VectorStoreIndex.from_documents(documents)\r\n\r\n# create chatbot\r\nchat_engine = index.as_chat_engine(verbose=True, chat_mode='simple')\r\n\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nFile \"C:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py\", line 405, in as_chat_engine\r\n    raise ValueError(f\"Unknown chat mode: {chat_mode}\")\r\nValueError: Unknown chat mode: simple\r\n```\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7622/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7622/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7621",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7621/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7621/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7621/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7621",
        "id": 1889337296,
        "node_id": "PR_kwDOIWuq585Z9gHF",
        "number": 7621,
        "title": "pass in summary_template for tree_summarize",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-10T21:30:37Z",
        "updated_at": "2023-09-10T21:38:25Z",
        "closed_at": "2023-09-10T21:38:24Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7621",
            "html_url": "https://github.com/run-llama/llama_index/pull/7621",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7621.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7621.patch",
            "merged_at": "2023-09-10T21:38:24Z"
        },
        "body": "# Description\r\n\r\nThis ensures that the `summary_template` is properly passed when doing `RetrieverQueryEngine.from_args(...)`\r\n\r\nFixes #7186\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7621/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7621/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7620",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7620/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7620/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7620/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7620",
        "id": 1889330609,
        "node_id": "I_kwDOIWuq585wnOWx",
        "number": 7620,
        "title": "[Question]: Does SQLTableRetrieverQueryEngine support streaming?",
        "user": {
            "login": "rolandgvc",
            "id": 26813782,
            "node_id": "MDQ6VXNlcjI2ODEzNzgy",
            "avatar_url": "https://avatars.githubusercontent.com/u/26813782?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rolandgvc",
            "html_url": "https://github.com/rolandgvc",
            "followers_url": "https://api.github.com/users/rolandgvc/followers",
            "following_url": "https://api.github.com/users/rolandgvc/following{/other_user}",
            "gists_url": "https://api.github.com/users/rolandgvc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rolandgvc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rolandgvc/subscriptions",
            "organizations_url": "https://api.github.com/users/rolandgvc/orgs",
            "repos_url": "https://api.github.com/users/rolandgvc/repos",
            "events_url": "https://api.github.com/users/rolandgvc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rolandgvc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-10T21:17:14Z",
        "updated_at": "2023-10-24T06:31:25Z",
        "closed_at": "2023-10-24T06:31:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHere is my current code\r\n\r\n```python\r\nllm = ChatOpenAI(temperature=0.1, model=\"gpt-4\", streaming=True)\r\nservice_context = ServiceContext.from_defaults(llm=llm)\r\n\r\nquery_engine = SQLTableRetrieverQueryEngine(\r\n    sql_database, obj_index.as_retriever(similarity_top_k=5), service_context=service_context\r\n)\r\n\r\n```\r\n\r\nhowever, I can't get the `StreamingResponse` output out of `query_engine.query`. Any ideas how I could get the streaming functionality working here?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7620/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7620/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7619",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7619/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7619/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7619/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7619",
        "id": 1889304885,
        "node_id": "I_kwDOIWuq585wnIE1",
        "number": 7619,
        "title": "[Question]:  ValueError: \"HuggingFaceEmbeddings\" object has no field \"callback_manager\"",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 17,
        "created_at": "2023-09-10T19:58:40Z",
        "updated_at": "2023-09-21T20:18:20Z",
        "closed_at": "2023-09-21T20:18:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nfrom langchain.text_splitter import CharacterTextSplitter\r\n\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\nembed_mode = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2'\r\n\r\n\r\nnode_parser = SimpleNodeParser(\r\n  text_splitter=TokenTextSplitter(chunk_size=100, chunk_overlap=100)\r\n)\r\nprompt_helper = PromptHelper(\r\n  context_window=500,\r\n  num_output=256,\r\n  chunk_overlap_ratio=0.1,\r\n  chunk_size_limit=20\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n  llm=llm,  chunk_size=800,embed_model=embed_mode\r\n)\r\n\r\n\r\n\r\nFile [~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\main.py:357](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/ab880/Documents/GitHub/gtp/~/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0/LocalCache/local-packages/Python311/site-packages/pydantic/main.py:357), in pydantic.main.BaseModel.__setattr__()\r\n\r\nValueError: \"HuggingFaceEmbeddings\" object has no field \"callback_manager\"\r\nOutput is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?70d6868f-15af-4032-8692-7072c2ca5557) or open in a [text editor](command:workbench.action.openLargeOutput?70d6868f-15af-4032-8692-7072c2ca5557). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7619/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7619/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7618",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7618/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7618/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7618/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7618",
        "id": 1889304055,
        "node_id": "PR_kwDOIWuq585Z9Zdn",
        "number": 7618,
        "title": "ElasticsearchStore: Add more detailed docs",
        "user": {
            "login": "joemcelroy",
            "id": 49480,
            "node_id": "MDQ6VXNlcjQ5NDgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/49480?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/joemcelroy",
            "html_url": "https://github.com/joemcelroy",
            "followers_url": "https://api.github.com/users/joemcelroy/followers",
            "following_url": "https://api.github.com/users/joemcelroy/following{/other_user}",
            "gists_url": "https://api.github.com/users/joemcelroy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/joemcelroy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/joemcelroy/subscriptions",
            "organizations_url": "https://api.github.com/users/joemcelroy/orgs",
            "repos_url": "https://api.github.com/users/joemcelroy/repos",
            "events_url": "https://api.github.com/users/joemcelroy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/joemcelroy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-10T19:55:42Z",
        "updated_at": "2023-09-10T21:35:09Z",
        "closed_at": "2023-09-10T21:35:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7618",
            "html_url": "https://github.com/run-llama/llama_index/pull/7618",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7618.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7618.patch",
            "merged_at": "2023-09-10T21:35:09Z"
        },
        "body": "Adding more documentation with:\r\n- how to connect from a variety of options (local self-hosted / cloud)\r\n- how to use metadata filters\r\n- the custom filter example with a better cell output\r\n- ElasticsearchStore parameters\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7618/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7618/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7617",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7617/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7617/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7617/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7617",
        "id": 1889163706,
        "node_id": "I_kwDOIWuq585wmlm6",
        "number": 7617,
        "title": "[Question]: ",
        "user": {
            "login": "ddealwis09",
            "id": 115846150,
            "node_id": "U_kgDOBuesBg",
            "avatar_url": "https://avatars.githubusercontent.com/u/115846150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ddealwis09",
            "html_url": "https://github.com/ddealwis09",
            "followers_url": "https://api.github.com/users/ddealwis09/followers",
            "following_url": "https://api.github.com/users/ddealwis09/following{/other_user}",
            "gists_url": "https://api.github.com/users/ddealwis09/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ddealwis09/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ddealwis09/subscriptions",
            "organizations_url": "https://api.github.com/users/ddealwis09/orgs",
            "repos_url": "https://api.github.com/users/ddealwis09/repos",
            "events_url": "https://api.github.com/users/ddealwis09/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ddealwis09/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-10T14:19:23Z",
        "updated_at": "2023-10-24T06:31:23Z",
        "closed_at": "2023-10-24T06:31:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nUsing SimpleDirectoryReader for my new document or nodes, how can I load them into an existing FAISS vector store that I have persisting in ./storage? The index.insert and index.insert_nodes methods are not working. \r\nThe docstore.json and index_store.json are not being updated in the ./storage directory. Thanks!\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7617/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7617/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7616",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7616/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7616/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7616/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7616",
        "id": 1889065794,
        "node_id": "PR_kwDOIWuq585Z8si1",
        "number": 7616,
        "title": "Fix #7547: llama-cpp update in documentation and default model download",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-10T09:16:40Z",
        "updated_at": "2023-09-10T21:13:13Z",
        "closed_at": "2023-09-10T21:13:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7616",
            "html_url": "https://github.com/run-llama/llama_index/pull/7616",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7616.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7616.patch",
            "merged_at": "2023-09-10T21:13:13Z"
        },
        "body": "# Description\r\n\r\nUpdates the [llama-cpp] example in the documentation to give some information about llama-cpp-python versioning and llama.cpp not supporting GGML after v0.1.79. A question was raised in #7547 about this and hopefully this makes it clearer going forward.\r\n\r\nI also made a change to the [embeddings](https://gpt-index.readthedocs.io/en/stable/core_modules/model_modules/embeddings/root.html) root page in the documentation so that the embeddings modules are listed as it is in done [here](https://gpt-index.readthedocs.io/en/stable/core_modules/model_modules/llms/root.html).\r\n\r\nFixes #7547 \r\n\r\n## Type of Change\r\n\r\nDocumentation update.\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7616/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7616/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7615",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7615/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7615/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7615/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7615",
        "id": 1889060432,
        "node_id": "I_kwDOIWuq585wmMZQ",
        "number": 7615,
        "title": "[Question]: ",
        "user": {
            "login": "ddealwis09",
            "id": 115846150,
            "node_id": "U_kgDOBuesBg",
            "avatar_url": "https://avatars.githubusercontent.com/u/115846150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ddealwis09",
            "html_url": "https://github.com/ddealwis09",
            "followers_url": "https://api.github.com/users/ddealwis09/followers",
            "following_url": "https://api.github.com/users/ddealwis09/following{/other_user}",
            "gists_url": "https://api.github.com/users/ddealwis09/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ddealwis09/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ddealwis09/subscriptions",
            "organizations_url": "https://api.github.com/users/ddealwis09/orgs",
            "repos_url": "https://api.github.com/users/ddealwis09/repos",
            "events_url": "https://api.github.com/users/ddealwis09/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ddealwis09/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-10T09:00:32Z",
        "updated_at": "2023-10-24T06:31:22Z",
        "closed_at": "2023-10-24T06:31:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nFor the SimpleDirectoryReader, how do you exclude metadata, using 'exclude' does not appear to work? Thanks!\r\n\r\n``\r\n\r\n    doc_metadata = [\"2023-03-21\", \"Poland Pricing Research\", \"BgM\", \"Sam Smith\"]\r\n    def add_file_metadata(self) -> Dict:\r\n        return {'pubdate': doc_metadata[0], \r\n                'filename': doc_metadata[1], \r\n                'Agency': doc_metadata[2],\r\n                'Coauthor': doc_metadata[3]}\r\n    document = SimpleDirectoryReader(input_files=[temp_file_path], \r\n                                               filename_as_id=True,\r\n                                               file_metadata=add_file_metadata,\r\n                                               exclude=[\"Agency\"] # metadata to make invisible to LLM response\r\n                                               ).load_data()\r\n    query_engine.query(\"Which agency was used?\")\r\n\r\n``\r\n\r\n\r\n\r\n\r\nModel response still includes \"Agency\":\r\n\r\nresponseResponseResponse(response='The agency used for the Poland Pricing Research was **BgM**.', source_nodes=[NodeWithScore(node=TextNode(id_='0a17f4c4-e080-4a27-8d21-9df1eb18d729', embedding=None, metadata={'pubdate': '2023-03-21', 'filename': 'Winston Poland Pricing Research', 'Agency': 'Gfk', 'Coauthor': '...\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7615/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7615/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7614",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7614/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7614/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7614/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7614",
        "id": 1889052294,
        "node_id": "I_kwDOIWuq585wmKaG",
        "number": 7614,
        "title": "[Question]: Embedding before index?",
        "user": {
            "login": "Data-drone",
            "id": 4410493,
            "node_id": "MDQ6VXNlcjQ0MTA0OTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4410493?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Data-drone",
            "html_url": "https://github.com/Data-drone",
            "followers_url": "https://api.github.com/users/Data-drone/followers",
            "following_url": "https://api.github.com/users/Data-drone/following{/other_user}",
            "gists_url": "https://api.github.com/users/Data-drone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Data-drone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Data-drone/subscriptions",
            "organizations_url": "https://api.github.com/users/Data-drone/orgs",
            "repos_url": "https://api.github.com/users/Data-drone/repos",
            "events_url": "https://api.github.com/users/Data-drone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Data-drone/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-10T08:40:36Z",
        "updated_at": "2023-10-24T06:31:20Z",
        "closed_at": "2023-10-24T06:31:20Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nWhat is the process if I want to externally embed a cache of documents before constructing an index on top?\r\n\r\nOr is it recommended to use llama_index structures to do all that and just plug in a VectorDB?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7614/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7614/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7613",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7613/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7613/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7613/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7613",
        "id": 1888935435,
        "node_id": "PR_kwDOIWuq585Z8Toc",
        "number": 7613,
        "title": "Feature async elasticsearch",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-10T02:16:44Z",
        "updated_at": "2023-09-14T20:30:32Z",
        "closed_at": "2023-09-14T19:10:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7613",
            "html_url": "https://github.com/run-llama/llama_index/pull/7613",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7613.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7613.patch",
            "merged_at": "2023-09-14T19:10:09Z"
        },
        "body": "# Description\r\n\r\n**Motivation**: vector-db queries are often blocking. And, so its desirable to add sync support to such queries and other vector-db methods that are also blocking.\r\n\r\n**Summary**\r\n\r\n- Modified `ElasticsearchStore` to consist of both kinds of Elasticsearch clients: `Elasticsearch` and `AsyncElasticsearch` (`es_store.client` and `es_store.async_client`, respectively)\r\n- Implemented `async_add`, `aquery`, and `adelete`\r\n- Modified `test_elasticsearch.py` to follow `test_postgres.py`. In particular, made use of below in all tests so that both `sync` and `async` variants are tested for each of the tests.\r\n```\r\n@pytest.mark.asyncio\r\n@pytest.mark.parametrize(\"use_async\", [True, False])\r\n``` \r\n\r\n- ~~Added `AsyncElasticsearchStore` which is the async version of `ElasticsearchStore` and with the exception of how they are constructed, have the same api \u2014 user just needs to use `await` when using `add` `delete` or `query` with `AsyncElasticsearchStore`.~~\r\n- ~~NOTE: these abstractions are in line with how ElasticSearch handles async and sync versions of `Elasticsearch` (i.e., see [here](https://elasticsearch-py.readthedocs.io/en/v7.12.0/async.html))~~\r\n\r\n\r\nFixes # (issue) - N/A\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n\r\n**Summary**\r\n(Note: installed ElasticSearch locally using docker)\r\n- As noted above, `test_elasticsearch.py` is modified to test both variants `sync` and `async` calls of `es_store` methods for all unit tests. (see (updated) image below for passing of all tests)\r\n- ~~I created an \"async\" version of `test_elasticsearch.py` called `test_elasticsearch_async.py` that uses the new `AsyncElasticsearchStore` object.~~\r\n    - ~~See image below for all passing tests:~~\r\n\r\n<img width=\"1150\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/92402603/02f1ecbb-d236-4345-9332-976393bad625\">\r\n\r\n# Suggested Checklist:\r\n\r\n- [ x ] I have performed a self-review of my own code\r\n- [ x ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ x ] My changes generate no new warnings\r\n- [ x ] I have added tests that prove my fix is effective or that my feature works\r\n- [ x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7613/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7613/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7612",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7612/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7612/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7612/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7612",
        "id": 1888905657,
        "node_id": "PR_kwDOIWuq585Z8N8-",
        "number": 7612,
        "title": "Version bump to v0.8.23.post1",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-09T23:42:46Z",
        "updated_at": "2023-09-09T23:42:59Z",
        "closed_at": "2023-09-09T23:42:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7612",
            "html_url": "https://github.com/run-llama/llama_index/pull/7612",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7612.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7612.patch",
            "merged_at": "2023-09-09T23:42:58Z"
        },
        "body": "Version bump",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7612/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7612/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7611",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7611/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7611/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7611/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7611",
        "id": 1888879997,
        "node_id": "PR_kwDOIWuq585Z8JV8",
        "number": 7611,
        "title": "Fix relationships in hierarchical node parser",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-09T21:33:44Z",
        "updated_at": "2023-09-09T22:22:30Z",
        "closed_at": "2023-09-09T22:22:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7611",
            "html_url": "https://github.com/run-llama/llama_index/pull/7611",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7611.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7611.patch",
            "merged_at": "2023-09-09T22:22:29Z"
        },
        "body": "# Description\r\n\r\nIf the input document is shorter than all hierarchical chunk sizes, there is a strong possibility of merging all the way up the hierarchy.\r\n\r\nHowever, since we create references to parent nodes that are never inserted (i.e. the input documents themselves), this leads to key errors.\r\n\r\nThis PR fixes that.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7611/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7611/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7610",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7610/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7610/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7610/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7610",
        "id": 1888787718,
        "node_id": "I_kwDOIWuq585wlJ0G",
        "number": 7610,
        "title": "[Question]: Understanding the PDFLoader",
        "user": {
            "login": "Data-drone",
            "id": 4410493,
            "node_id": "MDQ6VXNlcjQ0MTA0OTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4410493?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Data-drone",
            "html_url": "https://github.com/Data-drone",
            "followers_url": "https://api.github.com/users/Data-drone/followers",
            "following_url": "https://api.github.com/users/Data-drone/following{/other_user}",
            "gists_url": "https://api.github.com/users/Data-drone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Data-drone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Data-drone/subscriptions",
            "organizations_url": "https://api.github.com/users/Data-drone/orgs",
            "repos_url": "https://api.github.com/users/Data-drone/repos",
            "events_url": "https://api.github.com/users/Data-drone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Data-drone/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-09T15:28:02Z",
        "updated_at": "2023-09-10T07:43:41Z",
        "closed_at": "2023-09-09T17:27:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHow do I find the default settings for `PDFLoader`?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7610/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7610/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7609",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7609/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7609/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7609/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7609",
        "id": 1888784536,
        "node_id": "I_kwDOIWuq585wlJCY",
        "number": 7609,
        "title": "[Question]: How to resolve this error?",
        "user": {
            "login": "qxpf666",
            "id": 166635,
            "node_id": "MDQ6VXNlcjE2NjYzNQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/166635?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/qxpf666",
            "html_url": "https://github.com/qxpf666",
            "followers_url": "https://api.github.com/users/qxpf666/followers",
            "following_url": "https://api.github.com/users/qxpf666/following{/other_user}",
            "gists_url": "https://api.github.com/users/qxpf666/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/qxpf666/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/qxpf666/subscriptions",
            "organizations_url": "https://api.github.com/users/qxpf666/orgs",
            "repos_url": "https://api.github.com/users/qxpf666/repos",
            "events_url": "https://api.github.com/users/qxpf666/events{/privacy}",
            "received_events_url": "https://api.github.com/users/qxpf666/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-09T15:16:18Z",
        "updated_at": "2023-09-10T02:48:23Z",
        "closed_at": "2023-09-10T02:48:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nParsing documents into nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [00:00<00:00, 64.00it/s]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 181/181 [02:13<00:00,  1.36it/s]\r\nInternal Server Error: /api/chat-with-custommodel/\r\nTraceback (most recent call last):\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\django\\core\\handlers\\exception.py\", line 55, in inner\r\n    response = get_response(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\django\\core\\handlers\\base.py\", line 197, in _get_response\r\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\django\\views\\decorators\\csrf.py\", line 56, in wrapper_view\r\n    return view_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\django\\views\\generic\\base.py\", line 104, in view\r\n    return self.dispatch(request, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\rest_framework\\views.py\", line 509, in dispatch\r\n    response = self.handle_exception(exc)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\rest_framework\\views.py\", line 469, in handle_exception\r\n    self.raise_uncaught_exception(exc)\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\rest_framework\\views.py\", line 480, in raise_uncaught_exception\r\n    raise exc\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\rest_framework\\views.py\", line 506, in dispatch\r\n    response = handler(request, *args, **kwargs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\hr_management\\views.py\", line 82, in post\r\n    response = query_engine.query(input_text)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\query_engine\\retriever_query_engine.py\", line 170, in _query\r\n    nodes = self.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\query_engine\\retriever_query_engine.py\", line 118, in retrieve\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\indices\\base_retriever.py\", line 22, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\indices\\vector_store\\retrievers\\retriever.py\", line 87, in _retrieve\r\n    return self._get_nodes_with_embeddings(query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\indices\\vector_store\\retrievers\\retriever.py\", line 164, in _get_nodes_with_embeddings\r\n    query_result = self._vector_store.query(query, **self._kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\vector_stores\\simple.py\", line 168, in query\r\n    top_similarities, top_ids = get_top_k_embeddings(\r\n                                ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\indices\\query\\embedding_utils.py\", line 30, in get_top_k_embeddings\r\n    similarity = similarity_fn(query_embedding_np, emb)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\djangosass\\sass_env\\Lib\\site-packages\\llama_index\\embeddings\\base.py\", line 48, in similarity\r\n    product = np.dot(embedding1, embedding2)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nValueError: shapes (1536,) and (768,) not aligned: 1536 (dim 0) != 768 (dim 0)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7609/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7609/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7608",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7608/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7608/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7608/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7608",
        "id": 1888774424,
        "node_id": "PR_kwDOIWuq585Z71dI",
        "number": 7608,
        "title": "[Documentation]: #7595",
        "user": {
            "login": "Gunnvant",
            "id": 11598512,
            "node_id": "MDQ6VXNlcjExNTk4NTEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11598512?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Gunnvant",
            "html_url": "https://github.com/Gunnvant",
            "followers_url": "https://api.github.com/users/Gunnvant/followers",
            "following_url": "https://api.github.com/users/Gunnvant/following{/other_user}",
            "gists_url": "https://api.github.com/users/Gunnvant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Gunnvant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Gunnvant/subscriptions",
            "organizations_url": "https://api.github.com/users/Gunnvant/orgs",
            "repos_url": "https://api.github.com/users/Gunnvant/repos",
            "events_url": "https://api.github.com/users/Gunnvant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Gunnvant/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-09T14:47:20Z",
        "updated_at": "2023-09-09T21:06:51Z",
        "closed_at": "2023-09-09T21:06:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7608",
            "html_url": "https://github.com/run-llama/llama_index/pull/7608",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7608.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7608.patch",
            "merged_at": "2023-09-09T21:06:51Z"
        },
        "body": "Updated the typo in the docs\r\n\r\n# Description\r\n\r\nThis pertains to the issue `[Documentation]: #7595` raised a while back. Have made changes in notebook example [here](https://github.com/jerryjliu/llama_index/edit/main/docs/examples/customization/llms/AzureOpenAI.ipynb)\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7608/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7608/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7607",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7607/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7607/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7607/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7607",
        "id": 1888748396,
        "node_id": "PR_kwDOIWuq585Z7wNW",
        "number": 7607,
        "title": "Fix #6465 (Got a larger chunk overlap (...) than chunk size (...), should be smaller error)",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-09T13:42:44Z",
        "updated_at": "2023-09-09T23:23:42Z",
        "closed_at": "2023-09-09T23:12:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7607",
            "html_url": "https://github.com/run-llama/llama_index/pull/7607",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7607.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7607.patch",
            "merged_at": "2023-09-09T23:12:34Z"
        },
        "body": "# Description\r\n\r\nLooking to fix an issue (#6465) I had a while ago where I would come to a `Got a larger chunk overlap (...) than chunk size (...), should be smaller` error. This would usually occur when the available chunk size was negative.\r\n\r\nAfter some discussion with @logan-markewich, this seemed to be a problem with the refine template and its in a situtation where the prompt template + query + existing answer is too long.\r\n\r\nThis PR tries to avoid this by checking the available chunk size in `Refine._refine_response_single`, and if this is negative, it will simply just return the response without trying to refine it.\r\n\r\nThis avoids having an error during refining and just returns the existing answer. \r\n\r\nApplying linting changed some other files that I was playing around with during working on this PR.\r\n\r\nFixes #6465 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7607/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7607/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7606",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7606/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7606/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7606/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7606",
        "id": 1888694511,
        "node_id": "PR_kwDOIWuq585Z7la_",
        "number": 7606,
        "title": "feat(setup.py): add nltk to install_requires",
        "user": {
            "login": "ericmjl",
            "id": 2631566,
            "node_id": "MDQ6VXNlcjI2MzE1NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2631566?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ericmjl",
            "html_url": "https://github.com/ericmjl",
            "followers_url": "https://api.github.com/users/ericmjl/followers",
            "following_url": "https://api.github.com/users/ericmjl/following{/other_user}",
            "gists_url": "https://api.github.com/users/ericmjl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ericmjl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ericmjl/subscriptions",
            "organizations_url": "https://api.github.com/users/ericmjl/orgs",
            "repos_url": "https://api.github.com/users/ericmjl/repos",
            "events_url": "https://api.github.com/users/ericmjl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ericmjl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-09T11:07:37Z",
        "updated_at": "2023-09-10T18:04:23Z",
        "closed_at": "2023-09-09T22:00:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7606",
            "html_url": "https://github.com/run-llama/llama_index/pull/7606",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7606.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7606.patch",
            "merged_at": "2023-09-09T22:00:01Z"
        },
        "body": "\n# Description\n\n- The nltk library has been added to the list of required dependencies in setup.py.\n\nFixes #7605\n\n## Type of Change\n\nPlease delete options that are not relevant.\n\n- [x] Bug fix (non-breaking change which fixes an issue)\n\n# How Has This Been Tested?\n\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\n\n- [ ] Added new unit/integration tests\n- [ ] Added new notebook (that tests end-to-end)\n- [x] I stared at the code and made sure it makes sense\n\n(FYI, I appreciate the candor associated with option 3.)\n\n# Suggested Checklist:\n\n- [x] I have performed a self-review of my own code\n- [x] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [x] My changes generate no new warnings\n- [ ] I have added tests that prove my fix is effective or that my feature works\n- [ ] New and existing unit tests pass locally with my changes\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7606/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7606/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7605",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7605/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7605/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7605/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7605",
        "id": 1888693301,
        "node_id": "I_kwDOIWuq585wkyw1",
        "number": 7605,
        "title": "[Bug]: nltk should be a dependency of llama_index",
        "user": {
            "login": "ericmjl",
            "id": 2631566,
            "node_id": "MDQ6VXNlcjI2MzE1NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2631566?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ericmjl",
            "html_url": "https://github.com/ericmjl",
            "followers_url": "https://api.github.com/users/ericmjl/followers",
            "following_url": "https://api.github.com/users/ericmjl/following{/other_user}",
            "gists_url": "https://api.github.com/users/ericmjl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ericmjl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ericmjl/subscriptions",
            "organizations_url": "https://api.github.com/users/ericmjl/orgs",
            "repos_url": "https://api.github.com/users/ericmjl/repos",
            "events_url": "https://api.github.com/users/ericmjl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ericmjl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-09T11:02:53Z",
        "updated_at": "2023-09-09T22:00:02Z",
        "closed_at": "2023-09-09T22:00:02Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI was developing `llamabot`, which relies on `llama_index`, and found (by surprise) that `nltk` was needed (via inspecting an error stack trace):\r\n\r\n```python\r\n\u2502    90 \u2502   \u2502   callback_manager = callback_manager or CallbackManager([])                         \u2502\r\n\u2502 \u2771  91 \u2502   \u2502   chunking_tokenizer_fn = chunking_tokenizer_fn or split_by_sentence_tokenizer()     \u2502\r\n\u2502    92 \u2502   \u2502   tokenizer = tokenizer or globals_helper.tokenizer                                  \u2502\r\n\u2502    93 \u2502   \u2502                                                                                      \u2502\r\n\u2502    94 \u2502   \u2502   self._split_fns = [                                                                \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\r\n\u2502 \u2502                __class__ = <class                                                            \u2502 \u2502\r\n\u2502 \u2502                            'llama_index.text_splitter.sentence_splitter.SentenceSplitter'>   \u2502 \u2502\r\n\u2502 \u2502         callback_manager = <llama_index.callbacks.base.CallbackManager object at             \u2502 \u2502\r\n\u2502 \u2502                            0x17070cf10>                                                      \u2502 \u2502\r\n\u2502 \u2502            chunk_overlap = 20                                                                \u2502 \u2502\r\n\u2502 \u2502               chunk_size = 1024                                                              \u2502 \u2502\r\n\u2502 \u2502    chunking_tokenizer_fn = None                                                              \u2502 \u2502\r\n\u2502 \u2502      paragraph_separator = '\\n\\n\\n'                                                          \u2502 \u2502\r\n\u2502 \u2502 secondary_chunking_regex = '[^,.;\u3002]+[,.;\u3002]?'                                               \u2502 \u2502\r\n\u2502 \u2502                     self = SentenceSplitter()                                                \u2502 \u2502\r\n\u2502 \u2502                separator = ' '                                                               \u2502 \u2502\r\n\u2502 \u2502                tokenizer = None                                                              \u2502 \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/text_splitter/utils.py:34 in    \u2502\r\n\u2502 split_by_sentence_tokenizer                                                                      \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   31                                                                                             \u2502\r\n\u2502   32                                                                                             \u2502\r\n\u2502   33 def split_by_sentence_tokenizer() -> Callable[[str], List[str]]:                            \u2502\r\n\u2502 \u2771 34 \u2502   import nltk                                                                             \u2502\r\n\u2502   35 \u2502   import os                                                                               \u2502\r\n\u2502   36 \u2502   from llama_index.utils import get_cache_dir                                             \u2502\r\n\u2502   37                                                                                             \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nModuleNotFoundError: No module named 'nltk'\r\n```\r\n\r\nCode style aside (I believe it is Pythonic to put imports at the top of the file unless import performance is an issue), `nltk` should be made an explicit dependency of `llama_index`.\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nBased on the stack trace above, to reproduce the error, one needs to:\r\n\r\n1. Install `llama_index` into a Python env that does not have `nltk`.\r\n2. Attempt to execute the function `split_by_sentence_tokenizer` from `llama_index.text_splitter`. It has no arguments, so it should be easily reproducible inside a notebook by simply importing the function and callign on it.\n\n### Relevant Logs/Tracbacks\n\n```shell\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llamabot/cli/zotero.py:84 in chat           \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    81 \u2502                                                                                          \u2502\r\n\u2502    82 \u2502   with progress:                                                                         \u2502\r\n\u2502    83 \u2502   \u2502   task = progress.add_task(\"Embedding Zotero library...\", total=None)                \u2502\r\n\u2502 \u2771  84 \u2502   \u2502   retrieverbot = QueryBot(                                                           \u2502\r\n\u2502    85 \u2502   \u2502   \u2502   retrieverbot_sysprompt(),                                                      \u2502\r\n\u2502    86 \u2502   \u2502   \u2502   doc_paths=list(ZOTERO_JSON_DIR.glob(\"*.json\")),                                \u2502\r\n\u2502    87 \u2502   \u2502   \u2502   stream=True,                                                                   \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e   \u2502\r\n\u2502 \u2502 library = ZoteroLibrary(zot=<pyzotero.zotero.Zotero object at 0x1705c8d90>, json_dir=None) \u2502   \u2502\r\n\u2502 \u2502   query = 'The simplicity of protein sequence-function relationships'                      \u2502   \u2502\r\n\u2502 \u2502    sync = True                                                                             \u2502   \u2502\r\n\u2502 \u2502    task = 0                                                                                \u2502   \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f   \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llamabot/bot/querybot.py:82 in __init__     \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    79 \u2502   \u2502   \u2502   ),                                                                             \u2502\r\n\u2502    80 \u2502   \u2502   )                                                                                  \u2502\r\n\u2502    81 \u2502   \u2502   llm_predictor = LLMPredictor(llm=chat)                                             \u2502\r\n\u2502 \u2771  82 \u2502   \u2502   service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)        \u2502\r\n\u2502    83 \u2502   \u2502                                                                                      \u2502\r\n\u2502    84 \u2502   \u2502   # Initialize index or load it from disk.                                           \u2502\r\n\u2502    85 \u2502   \u2502   if saved_index_path is None:                                                       \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\r\n\u2502 \u2502             chat = ChatOpenAI(                                                               \u2502 \u2502\r\n\u2502 \u2502                    \u2502   cache=None,                                                           \u2502 \u2502\r\n\u2502 \u2502                    \u2502   verbose=True,                                                         \u2502 \u2502\r\n\u2502 \u2502                    \u2502   callbacks=<langchain.callbacks.base.BaseCallbackManager object at     \u2502 \u2502\r\n\u2502 \u2502                    0x17070cbe0>,                                                             \u2502 \u2502\r\n\u2502 \u2502                    \u2502   tags=None,                                                            \u2502 \u2502\r\n\u2502 \u2502                    \u2502   metadata=None,                                                        \u2502 \u2502\r\n\u2502 \u2502                    \u2502   client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, \u2502 \u2502\r\n\u2502 \u2502                    \u2502   model_name='gpt-4-32k',                                               \u2502 \u2502\r\n\u2502 \u2502                    \u2502   temperature=0.0,                                                      \u2502 \u2502\r\n\u2502 \u2502                    \u2502   model_kwargs={},                                                      \u2502 \u2502\r\n\u2502 \u2502                    \u2502   openai_api_key='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', \u2502 \u2502\r\n\u2502 \u2502                    \u2502   openai_api_base='',                                                   \u2502 \u2502\r\n\u2502 \u2502                    \u2502   openai_organization='',                                               \u2502 \u2502\r\n\u2502 \u2502                    \u2502   openai_proxy='',                                                      \u2502 \u2502\r\n\u2502 \u2502                    \u2502   request_timeout=None,                                                 \u2502 \u2502\r\n\u2502 \u2502                    \u2502   max_retries=6,                                                        \u2502 \u2502\r\n\u2502 \u2502                    \u2502   streaming=True,                                                       \u2502 \u2502\r\n\u2502 \u2502                    \u2502   n=1,                                                                  \u2502 \u2502\r\n\u2502 \u2502                    \u2502   max_tokens=None,                                                      \u2502 \u2502\r\n\u2502 \u2502                    \u2502   tiktoken_model_name=None                                              \u2502 \u2502\r\n\u2502 \u2502                    )                                                                         \u2502 \u2502\r\n\u2502 \u2502    chunk_overlap = 0                                                                         \u2502 \u2502\r\n\u2502 \u2502       chunk_size = 2000                                                                      \u2502 \u2502\r\n\u2502 \u2502        doc_paths = [                                                                         \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/BNGBSLPD.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/H9PW285U.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/NLIZI4N4.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/ZN2PQCMK.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/FNSJNXSD.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/8L36HNZH.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/YRKLE83E.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/ZN8MNGP3.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/RJ6BESM8.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502                                                                         \u2502 \u2502\r\n\u2502 \u2502                    PosixPath('/Users/ericmjl/.llamabot/zotero/zotero_index/ZIFP9ZPQ.json'),  \u2502 \u2502\r\n\u2502 \u2502                    \u2502   ... +199                                                              \u2502 \u2502\r\n\u2502 \u2502                    ]                                                                         \u2502 \u2502\r\n\u2502 \u2502    llm_predictor = LLMPredictor(system_prompt=None, query_wrapper_prompt=None)               \u2502 \u2502\r\n\u2502 \u2502       model_name = 'gpt-4-32k'                                                               \u2502 \u2502\r\n\u2502 \u2502 saved_index_path = None                                                                      \u2502 \u2502\r\n\u2502 \u2502             self = <llamabot.bot.querybot.QueryBot object at 0x17070cee0>                    \u2502 \u2502\r\n\u2502 \u2502           stream = True                                                                      \u2502 \u2502\r\n\u2502 \u2502   system_message = 'You are an expert in retrieving information from JSON files.'            \u2502 \u2502\r\n\u2502 \u2502      temperature = 0.0                                                                       \u2502 \u2502\r\n\u2502 \u2502        use_cache = True                                                                      \u2502 \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/indices/service_context.py:158  \u2502\r\n\u2502 in from_defaults                                                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   155 \u2502   \u2502   \u2502   num_output=num_output,                                                         \u2502\r\n\u2502   156 \u2502   \u2502   )                                                                                  \u2502\r\n\u2502   157 \u2502   \u2502                                                                                      \u2502\r\n\u2502 \u2771 158 \u2502   \u2502   node_parser = node_parser or _get_default_node_parser(                             \u2502\r\n\u2502   159 \u2502   \u2502   \u2502   chunk_size=chunk_size,                                                         \u2502\r\n\u2502   160 \u2502   \u2502   \u2502   chunk_overlap=chunk_overlap,                                                   \u2502\r\n\u2502   161 \u2502   \u2502   \u2502   callback_manager=callback_manager,                                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\r\n\u2502 \u2502     callback_manager = <llama_index.callbacks.base.CallbackManager object at 0x17070cf10>    \u2502 \u2502\r\n\u2502 \u2502        chunk_overlap = None                                                                  \u2502 \u2502\r\n\u2502 \u2502           chunk_size = None                                                                  \u2502 \u2502\r\n\u2502 \u2502     chunk_size_limit = None                                                                  \u2502 \u2502\r\n\u2502 \u2502                  cls = <class 'llama_index.indices.service_context.ServiceContext'>          \u2502 \u2502\r\n\u2502 \u2502       context_window = None                                                                  \u2502 \u2502\r\n\u2502 \u2502          embed_model = OpenAIEmbedding(                                                      \u2502 \u2502\r\n\u2502 \u2502                        \u2502   model_name='text-embedding-ada-002',                              \u2502 \u2502\r\n\u2502 \u2502                        \u2502   embed_batch_size=10,                                              \u2502 \u2502\r\n\u2502 \u2502                        \u2502   callback_manager=<llama_index.callbacks.base.CallbackManager      \u2502 \u2502\r\n\u2502 \u2502                        object at 0x17070cf10>,                                               \u2502 \u2502\r\n\u2502 \u2502                        \u2502   deployment_name=None,                                             \u2502 \u2502\r\n\u2502 \u2502                        \u2502   openai_kwargs={}                                                  \u2502 \u2502\r\n\u2502 \u2502                        )                                                                     \u2502 \u2502\r\n\u2502 \u2502         llama_logger = None                                                                  \u2502 \u2502\r\n\u2502 \u2502                  llm = 'default'                                                             \u2502 \u2502\r\n\u2502 \u2502        llm_predictor = LLMPredictor(system_prompt=None, query_wrapper_prompt=None)           \u2502 \u2502\r\n\u2502 \u2502          node_parser = None                                                                  \u2502 \u2502\r\n\u2502 \u2502           num_output = None                                                                  \u2502 \u2502\r\n\u2502 \u2502        prompt_helper = PromptHelper(                                                         \u2502 \u2502\r\n\u2502 \u2502                        \u2502   context_window=32768,                                             \u2502 \u2502\r\n\u2502 \u2502                        \u2502   num_output=256,                                                   \u2502 \u2502\r\n\u2502 \u2502                        \u2502   chunk_overlap_ratio=0.1,                                          \u2502 \u2502\r\n\u2502 \u2502                        \u2502   chunk_size_limit=None,                                            \u2502 \u2502\r\n\u2502 \u2502                        \u2502   separator=' '                                                     \u2502 \u2502\r\n\u2502 \u2502                        )                                                                     \u2502 \u2502\r\n\u2502 \u2502 query_wrapper_prompt = None                                                                  \u2502 \u2502\r\n\u2502 \u2502        system_prompt = None                                                                  \u2502 \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/indices/service_context.py:28   \u2502\r\n\u2502 in _get_default_node_parser                                                                      \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    25 \u2502   callback_manager: Optional[CallbackManager] = None,                                    \u2502\r\n\u2502    26 ) -> NodeParser:                                                                           \u2502\r\n\u2502    27 \u2502   \"\"\"Get default node parser.\"\"\"                                                         \u2502\r\n\u2502 \u2771  28 \u2502   return SimpleNodeParser.from_defaults(                                                 \u2502\r\n\u2502    29 \u2502   \u2502   chunk_size=chunk_size,                                                             \u2502\r\n\u2502    30 \u2502   \u2502   chunk_overlap=chunk_overlap,                                                       \u2502\r\n\u2502    31 \u2502   \u2502   callback_manager=callback_manager,                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e        \u2502\r\n\u2502 \u2502 callback_manager = <llama_index.callbacks.base.CallbackManager object at 0x17070cf10> \u2502        \u2502\r\n\u2502 \u2502    chunk_overlap = None                                                               \u2502        \u2502\r\n\u2502 \u2502       chunk_size = None                                                               \u2502        \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/node_parser/simple.py:56 in     \u2502\r\n\u2502 from_defaults                                                                                    \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    53 \u2502   ) -> \"SimpleNodeParser\":                                                               \u2502\r\n\u2502    54 \u2502   \u2502   callback_manager = callback_manager or CallbackManager([])                         \u2502\r\n\u2502    55 \u2502   \u2502                                                                                      \u2502\r\n\u2502 \u2771  56 \u2502   \u2502   text_splitter = text_splitter or get_default_text_splitter(                        \u2502\r\n\u2502    57 \u2502   \u2502   \u2502   chunk_size=chunk_size,                                                         \u2502\r\n\u2502    58 \u2502   \u2502   \u2502   chunk_overlap=chunk_overlap,                                                   \u2502\r\n\u2502    59 \u2502   \u2502   \u2502   callback_manager=callback_manager,                                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e   \u2502\r\n\u2502 \u2502      callback_manager = <llama_index.callbacks.base.CallbackManager object at 0x17070cf10> \u2502   \u2502\r\n\u2502 \u2502         chunk_overlap = None                                                               \u2502   \u2502\r\n\u2502 \u2502            chunk_size = None                                                               \u2502   \u2502\r\n\u2502 \u2502                   cls = <class 'llama_index.node_parser.simple.SimpleNodeParser'>          \u2502   \u2502\r\n\u2502 \u2502      include_metadata = True                                                               \u2502   \u2502\r\n\u2502 \u2502 include_prev_next_rel = True                                                               \u2502   \u2502\r\n\u2502 \u2502    metadata_extractor = None                                                               \u2502   \u2502\r\n\u2502 \u2502         text_splitter = None                                                               \u2502   \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f   \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/text_splitter/__init__.py:22 in \u2502\r\n\u2502 get_default_text_splitter                                                                        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   19 \u2502   \u2502   chunk_overlap if chunk_overlap is not None else DEFAULT_CHUNK_OVERLAP               \u2502\r\n\u2502   20 \u2502   )                                                                                       \u2502\r\n\u2502   21 \u2502                                                                                           \u2502\r\n\u2502 \u2771 22 \u2502   return SentenceSplitter(                                                                \u2502\r\n\u2502   23 \u2502   \u2502   chunk_size=chunk_size,                                                              \u2502\r\n\u2502   24 \u2502   \u2502   chunk_overlap=chunk_overlap,                                                        \u2502\r\n\u2502   25 \u2502   \u2502   callback_manager=callback_manager,                                                  \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e        \u2502\r\n\u2502 \u2502 callback_manager = <llama_index.callbacks.base.CallbackManager object at 0x17070cf10> \u2502        \u2502\r\n\u2502 \u2502    chunk_overlap = 20                                                                 \u2502        \u2502\r\n\u2502 \u2502       chunk_size = 1024                                                               \u2502        \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/text_splitter/sentence_splitter \u2502\r\n\u2502 .py:91 in __init__                                                                               \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    88 \u2502   \u2502   \u2502   )                                                                              \u2502\r\n\u2502    89 \u2502   \u2502                                                                                      \u2502\r\n\u2502    90 \u2502   \u2502   callback_manager = callback_manager or CallbackManager([])                         \u2502\r\n\u2502 \u2771  91 \u2502   \u2502   chunking_tokenizer_fn = chunking_tokenizer_fn or split_by_sentence_tokenizer()     \u2502\r\n\u2502    92 \u2502   \u2502   tokenizer = tokenizer or globals_helper.tokenizer                                  \u2502\r\n\u2502    93 \u2502   \u2502                                                                                      \u2502\r\n\u2502    94 \u2502   \u2502   self._split_fns = [                                                                \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 locals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\r\n\u2502 \u2502                __class__ = <class                                                            \u2502 \u2502\r\n\u2502 \u2502                            'llama_index.text_splitter.sentence_splitter.SentenceSplitter'>   \u2502 \u2502\r\n\u2502 \u2502         callback_manager = <llama_index.callbacks.base.CallbackManager object at             \u2502 \u2502\r\n\u2502 \u2502                            0x17070cf10>                                                      \u2502 \u2502\r\n\u2502 \u2502            chunk_overlap = 20                                                                \u2502 \u2502\r\n\u2502 \u2502               chunk_size = 1024                                                              \u2502 \u2502\r\n\u2502 \u2502    chunking_tokenizer_fn = None                                                              \u2502 \u2502\r\n\u2502 \u2502      paragraph_separator = '\\n\\n\\n'                                                          \u2502 \u2502\r\n\u2502 \u2502 secondary_chunking_regex = '[^,.;\u3002]+[,.;\u3002]?'                                               \u2502 \u2502\r\n\u2502 \u2502                     self = SentenceSplitter()                                                \u2502 \u2502\r\n\u2502 \u2502                separator = ' '                                                               \u2502 \u2502\r\n\u2502 \u2502                tokenizer = None                                                              \u2502 \u2502\r\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/ericmjl/anaconda/lib/python3.10/site-packages/llama_index/text_splitter/utils.py:34 in    \u2502\r\n\u2502 split_by_sentence_tokenizer                                                                      \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   31                                                                                             \u2502\r\n\u2502   32                                                                                             \u2502\r\n\u2502   33 def split_by_sentence_tokenizer() -> Callable[[str], List[str]]:                            \u2502\r\n\u2502 \u2771 34 \u2502   import nltk                                                                             \u2502\r\n\u2502   35 \u2502   import os                                                                               \u2502\r\n\u2502   36 \u2502   from llama_index.utils import get_cache_dir                                             \u2502\r\n\u2502   37                                                                                             \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nModuleNotFoundError: No module named 'nltk'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7605/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7605/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7604",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7604/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7604/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7604/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7604",
        "id": 1888686471,
        "node_id": "I_kwDOIWuq585wkxGH",
        "number": 7604,
        "title": "[Question]: ",
        "user": {
            "login": "ddealwis09",
            "id": 115846150,
            "node_id": "U_kgDOBuesBg",
            "avatar_url": "https://avatars.githubusercontent.com/u/115846150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ddealwis09",
            "html_url": "https://github.com/ddealwis09",
            "followers_url": "https://api.github.com/users/ddealwis09/followers",
            "following_url": "https://api.github.com/users/ddealwis09/following{/other_user}",
            "gists_url": "https://api.github.com/users/ddealwis09/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ddealwis09/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ddealwis09/subscriptions",
            "organizations_url": "https://api.github.com/users/ddealwis09/orgs",
            "repos_url": "https://api.github.com/users/ddealwis09/repos",
            "events_url": "https://api.github.com/users/ddealwis09/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ddealwis09/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-09T10:38:48Z",
        "updated_at": "2023-09-09T17:27:10Z",
        "closed_at": "2023-09-09T17:27:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI can't seem to figure out how to add additional metadata when using SimpleDirectoryReader. For example, in addition to the filename, I would like to add 'filedate'? Thanks!\r\n\r\nfrom llama_index import SimpleDirectoryReader\r\nfilename_fn = lambda filename: {'file_name': filename}\r\n\r\n# automatically sets the metadata of each document according to filename_fn\r\ndocuments = SimpleDirectoryReader('./data', file_metadata=filename_fn).load_data()",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7604/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7604/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7603",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7603/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7603/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7603/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7603",
        "id": 1888632778,
        "node_id": "PR_kwDOIWuq585Z7ZFk",
        "number": 7603,
        "title": "Fix typo in documentation",
        "user": {
            "login": "issei-m",
            "id": 1135118,
            "node_id": "MDQ6VXNlcjExMzUxMTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1135118?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/issei-m",
            "html_url": "https://github.com/issei-m",
            "followers_url": "https://api.github.com/users/issei-m/followers",
            "following_url": "https://api.github.com/users/issei-m/following{/other_user}",
            "gists_url": "https://api.github.com/users/issei-m/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/issei-m/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/issei-m/subscriptions",
            "organizations_url": "https://api.github.com/users/issei-m/orgs",
            "repos_url": "https://api.github.com/users/issei-m/repos",
            "events_url": "https://api.github.com/users/issei-m/events{/privacy}",
            "received_events_url": "https://api.github.com/users/issei-m/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-09T07:54:52Z",
        "updated_at": "2023-09-10T06:26:59Z",
        "closed_at": "2023-09-09T21:53:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7603",
            "html_url": "https://github.com/run-llama/llama_index/pull/7603",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7603.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7603.patch",
            "merged_at": "2023-09-09T21:53:17Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7603/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7603/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7602",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7602/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7602/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7602/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7602",
        "id": 1888571381,
        "node_id": "PR_kwDOIWuq585Z7Mz7",
        "number": 7602,
        "title": "Update Anyscale integration to use OpenAI client library",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-09T04:28:20Z",
        "updated_at": "2023-09-09T23:38:40Z",
        "closed_at": "2023-09-09T23:38:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7602",
            "html_url": "https://github.com/run-llama/llama_index/pull/7602",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7602.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7602.patch",
            "merged_at": "2023-09-09T23:38:39Z"
        },
        "body": "# Description\r\n\r\n- Update Anyscale integration to use OpenAI client library\r\n- Also better support for passing credentials as LLM contructor args in `OpenAI`, `AzureOpenAI`, and  `Anyscale`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7602/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7602/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7601",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7601/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7601/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7601/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7601",
        "id": 1888281897,
        "node_id": "PR_kwDOIWuq585Z6OLi",
        "number": 7601,
        "title": "update vectara imports",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-08T20:21:52Z",
        "updated_at": "2023-09-08T20:45:39Z",
        "closed_at": "2023-09-08T20:45:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7601",
            "html_url": "https://github.com/run-llama/llama_index/pull/7601",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7601.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7601.patch",
            "merged_at": "2023-09-08T20:45:39Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7601/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7601/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7600",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7600/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7600/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7600/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7600",
        "id": 1888242229,
        "node_id": "PR_kwDOIWuq585Z6FGj",
        "number": 7600,
        "title": "adding litellm integration",
        "user": {
            "login": "krrishdholakia",
            "id": 17561003,
            "node_id": "MDQ6VXNlcjE3NTYxMDAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/17561003?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/krrishdholakia",
            "html_url": "https://github.com/krrishdholakia",
            "followers_url": "https://api.github.com/users/krrishdholakia/followers",
            "following_url": "https://api.github.com/users/krrishdholakia/following{/other_user}",
            "gists_url": "https://api.github.com/users/krrishdholakia/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/krrishdholakia/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/krrishdholakia/subscriptions",
            "organizations_url": "https://api.github.com/users/krrishdholakia/orgs",
            "repos_url": "https://api.github.com/users/krrishdholakia/repos",
            "events_url": "https://api.github.com/users/krrishdholakia/events{/privacy}",
            "received_events_url": "https://api.github.com/users/krrishdholakia/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-09-08T19:58:54Z",
        "updated_at": "2023-09-15T17:08:43Z",
        "closed_at": "2023-09-15T15:53:18Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7600",
            "html_url": "https://github.com/run-llama/llama_index/pull/7600",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7600.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7600.patch",
            "merged_at": "2023-09-15T15:53:18Z"
        },
        "body": "This helps solve issue - https://github.com/jerryjliu/llama_index/issues/7458\r\n\r\nHi @jerryjliu @logan-markewich, \r\n\r\nI'm working on LiteLLM (https://github.com/BerriAI/litellm) and we've had a couple users request us for a Llama Index integration. \r\n\r\nWe simplify making LLM API Calls by providing a drop-in replacement for the openai-python sdk.\r\n\r\nHappy to add docs, additional testing if the initial PR looks good",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7600/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7600/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7599",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7599/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7599/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7599/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7599",
        "id": 1887952954,
        "node_id": "PR_kwDOIWuq585Z5F_n",
        "number": 7599,
        "title": "Update bm25_retriever.ipynb",
        "user": {
            "login": "thoraxe",
            "id": 94413,
            "node_id": "MDQ6VXNlcjk0NDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/94413?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thoraxe",
            "html_url": "https://github.com/thoraxe",
            "followers_url": "https://api.github.com/users/thoraxe/followers",
            "following_url": "https://api.github.com/users/thoraxe/following{/other_user}",
            "gists_url": "https://api.github.com/users/thoraxe/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thoraxe/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thoraxe/subscriptions",
            "organizations_url": "https://api.github.com/users/thoraxe/orgs",
            "repos_url": "https://api.github.com/users/thoraxe/repos",
            "events_url": "https://api.github.com/users/thoraxe/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thoraxe/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-08T16:04:54Z",
        "updated_at": "2023-09-08T16:22:13Z",
        "closed_at": "2023-09-08T16:22:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7599",
            "html_url": "https://github.com/run-llama/llama_index/pull/7599",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7599.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7599.patch",
            "merged_at": "2023-09-08T16:22:12Z"
        },
        "body": "# Description\r\nFixes minor grammatical error\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7599/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7599/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7598",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7598/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7598/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7598/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7598",
        "id": 1887746695,
        "node_id": "I_kwDOIWuq585whLqH",
        "number": 7598,
        "title": "[Question]: How can I utilize JSONQueryEngine with MongoDB documents ?",
        "user": {
            "login": "Exorcismus",
            "id": 5602496,
            "node_id": "MDQ6VXNlcjU2MDI0OTY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5602496?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Exorcismus",
            "html_url": "https://github.com/Exorcismus",
            "followers_url": "https://api.github.com/users/Exorcismus/followers",
            "following_url": "https://api.github.com/users/Exorcismus/following{/other_user}",
            "gists_url": "https://api.github.com/users/Exorcismus/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Exorcismus/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Exorcismus/subscriptions",
            "organizations_url": "https://api.github.com/users/Exorcismus/orgs",
            "repos_url": "https://api.github.com/users/Exorcismus/repos",
            "events_url": "https://api.github.com/users/Exorcismus/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Exorcismus/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-09-08T13:59:16Z",
        "updated_at": "2023-10-24T06:31:18Z",
        "closed_at": "2023-10-24T06:31:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nAm using the below code snippet to read data from a mongoDB\r\n\r\nas my data structure is different from expected, I had to combine multiple values into `text`\r\n\r\n`documents = reader.load_data(\r\n db_name, collection_name, field_names, query_dict)\r\n index = GPTVectorStoreIndex.from_documents(documents)\r\n index.storage_context.persist()\r\n query_engine = index.as_query_engine(\r\nsimilarity_top_k=5, service_context=service_context, response_synthesizer=response_synthesizer, verbose=True)\r\n`\r\n\r\nI can see there is a `JSON Query Engine` but I can't see an easy way to combine both.\r\n\r\nis there a best practice on how to JSONQueryEngine on Mongo documents directly ?\r\n\r\n\r\n \r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7598/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7598/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7597",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7597/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7597/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7597/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7597",
        "id": 1887380271,
        "node_id": "PR_kwDOIWuq585Z3IYL",
        "number": 7597,
        "title": "Fix #7596: make sure context and system prompt is included in prompt for first chat",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-08T10:20:10Z",
        "updated_at": "2023-09-08T17:34:51Z",
        "closed_at": "2023-09-08T17:34:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7597",
            "html_url": "https://github.com/run-llama/llama_index/pull/7597",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7597.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7597.patch",
            "merged_at": "2023-09-08T17:34:51Z"
        },
        "body": "# Description\r\n\r\nMade changes to `messages_to_prompt` since previous behaviour was that the system prompt (which also includes the context if using the \"context\" chat engine) was not included in the prompt if it was the first chat interaction. The reason for this is because previously, there is a for loop over `zip(messages[::2], messages[1::2])`. \r\n\r\nIn the first chat interaction with the engine, `messages` should be a list of two `ChatMessage` objects, the first being a system message, the second being a user message. In the function, if the first message in `messages` was a system message, it would pull that out and `messages = messages[1:]`.\r\n\r\nThis means that we never enter the for loop in the function since `messages[::2]` is a list of length 1 storing the user message, and `messages[1::2]` is an empty list, `[]`. As a result, the system prompt is never included, and we only add the message at the end (with `last_message=messages[-1]`).\r\n\r\nTherefore, the first time we enter a chat using this `messages_to_prompt` function, we would never include the context or system prompt.\r\n\r\nThis PR attempts to solve this.\r\n\r\nFixes #7596 (and potentially #7057).\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7597/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7597/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7596",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7596/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7596/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7596/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7596",
        "id": 1887197231,
        "node_id": "I_kwDOIWuq585wfFgv",
        "number": 7596,
        "title": "[Bug]: chat_engine - context and system prompt is not added to the first chat ",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-08T08:20:56Z",
        "updated_at": "2023-09-08T17:34:52Z",
        "closed_at": "2023-09-08T17:34:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nRelated issue: #7057 \r\n\r\n(Happy to be assigned this, as already been working on a fix to this).\r\n\r\nI've been playing around with the `chat_engine` feature (in particular, this was using the context chat_engine) and I noticed that in the first chat, the engine is not able to answer a question that was easily answered when using the query engine.\r\n\r\nAfter some inspection to what was the prompt going into the LLM, it seemed that during the first chat, the prompt did not include the context obtained. Further, if a system prompt was included, this also does not get included into the first chat.\r\n\r\nIt seems like the issue is in the `messages_to_prompt` function, as we run a loop over `zip(messages[::2], messages[1::2])`. The issue is that if messages only includes one message (a user message), it does not enter a loop, and the system prompt (which includes the context if using the context engine) is not included in the LLM prompt by the end of this function.\r\n\r\nThis also causes an issue with the ReAct chat engine, as the system prompt (which details the output format to the LLM) does not seem to be added to the first prompt either.\r\n\r\n### Version\r\n\r\n0.8.21\r\n\r\n### Steps to Reproduce\r\n\r\nCurrently using `LlamaCPP` as my LLM, using the `.gguf` file taken from https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF:\r\n\r\n```\r\nllm = LlamaCPP(\r\n    model_path=\"llama-2-7b-chat.Q4_K_M.gguf\",\r\n    temperature=0.1,\r\n    max_new_tokens=1024,\r\n    # llama2 has a context window of 4096 tokens,\r\n    # but we set it lower to allow for some wiggle room\r\n    context_window=3900,\r\n    # kwargs to pass to __call__()\r\n    generate_kwargs={},\r\n    # kwargs to pass to __init__()\r\n    # set to at least 1 to use GPU\r\n    model_kwargs={\"n_gpu_layers\": 1},\r\n    # transform inputs into Llama2 format\r\n    messages_to_prompt=messages_to_prompt,\r\n    completion_to_prompt=completion_to_prompt,\r\n    verbose=True,\r\n)\r\n```\r\n\r\nSetting up documents and chat engine:\r\n\r\n```\r\ntext_data = pd.read_csv(\"test.csv\")\r\ntext_list = list(handbook[\"text_data\"].astype(\"str\"))\r\ndocuments = [Document(text=t) for t in text_list]\r\n\r\n service_context = ServiceContext.from_defaults(\r\n    llm_predictor=LLMPredictor(llm=llm),\r\n    embed_model=embed_model,\r\n)\r\n\r\nindex = VectorStoreIndex.from_documents(\r\n    documents, service_context=service_context\r\n)\r\n\r\nsystem_prompt = \"blah blah\"\r\nchat_engine = index.as_chat_engine(\r\n    chat_mode=\"context\",\r\n    system_prompt=system_prompt,\r\n)\r\n\r\nchat_engine.chat(\"who is the director of our team?\")\r\n```\r\n\r\nTo inspect the prompt into the LLM, I simply added a print statement in [`llama_index/llms/llama_cpp.py` after line 177](https://github.com/jerryjliu/llama_index/blob/623024ea2f204b4c8fff9bafa835987ae5bec60a/llama_index/llms/llama_cpp.py#L177).\r\n\r\nBy doing so, you'll see that the context and the system prompt will not be added to the prompt to the LLM. \r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7596/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7596/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7595",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7595/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7595/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7595/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7595",
        "id": 1887051134,
        "node_id": "I_kwDOIWuq585weh1-",
        "number": 7595,
        "title": "[Documentation]: ",
        "user": {
            "login": "moti-malka",
            "id": 27952544,
            "node_id": "MDQ6VXNlcjI3OTUyNTQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/27952544?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/moti-malka",
            "html_url": "https://github.com/moti-malka",
            "followers_url": "https://api.github.com/users/moti-malka/followers",
            "following_url": "https://api.github.com/users/moti-malka/following{/other_user}",
            "gists_url": "https://api.github.com/users/moti-malka/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/moti-malka/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/moti-malka/subscriptions",
            "organizations_url": "https://api.github.com/users/moti-malka/orgs",
            "repos_url": "https://api.github.com/users/moti-malka/repos",
            "events_url": "https://api.github.com/users/moti-malka/events{/privacy}",
            "received_events_url": "https://api.github.com/users/moti-malka/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-08T06:47:39Z",
        "updated_at": "2023-09-10T05:57:27Z",
        "closed_at": "2023-09-10T05:57:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nOn AzureOpenAI docs there is typo on this line:\r\nllm = AzureOpenAI(engine=\"<insert deployment name from azure>\", **mode=\"model** name\")\r\n\r\nneed to replace to this (just need to add 'l' to model arguments):\r\nllm = AzureOpenAI(engine=\"<insert deployment name from azure>\", model=\"model name\")\r\n\r\nhere the link for the docs: https://gpt-index.readthedocs.io/en/latest/examples/customization/llms/AzureOpenAI.html\r\n\r\ncan create new branch and fix that ? \n\n### Documenation Link\n\nhttps://gpt-index.readthedocs.io/en/latest/examples/customization/llms/AzureOpenAI.html",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7595/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7595/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7594",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7594/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7594/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7594/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7594",
        "id": 1886940734,
        "node_id": "I_kwDOIWuq585weG4-",
        "number": 7594,
        "title": "[Question]: Getting error while using Elasticsearch Vector Store",
        "user": {
            "login": "dhruv2512",
            "id": 45820090,
            "node_id": "MDQ6VXNlcjQ1ODIwMDkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/45820090?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dhruv2512",
            "html_url": "https://github.com/dhruv2512",
            "followers_url": "https://api.github.com/users/dhruv2512/followers",
            "following_url": "https://api.github.com/users/dhruv2512/following{/other_user}",
            "gists_url": "https://api.github.com/users/dhruv2512/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dhruv2512/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dhruv2512/subscriptions",
            "organizations_url": "https://api.github.com/users/dhruv2512/orgs",
            "repos_url": "https://api.github.com/users/dhruv2512/repos",
            "events_url": "https://api.github.com/users/dhruv2512/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dhruv2512/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-09-08T05:05:50Z",
        "updated_at": "2023-09-30T03:20:57Z",
        "closed_at": "2023-09-15T04:23:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am trying to use a newly supported ES vector store.\r\n\r\nBut after building the index, I got the below error:\r\n\r\n```\r\n    244 logger.debug(\r\n    245     f\"Creating index {index_name} with mappings {index_settings['mappings']}\"  # noqa: E501\r\n    246 )\r\n--> 247 self.client.indices.create(index=index_name, **index_settings)\r\n\r\nFile ~/.conda/lib/python3.11/site-packages/elasticsearch/client/utils.py:152, in query_params.<locals>._wrapper.<locals>._wrapped(*args, **kwargs)\r\n    150     if p in kwargs:\r\n    151         params[p] = kwargs.pop(p)\r\n--> 152 return func(*args, params=params, headers=headers, **kwargs)\r\n\r\nTypeError: IndicesClient.create() got an unexpected keyword argument 'mappings'\r\n```\r\n\r\nES version: 7.9.1\r\nPython ES client version: 7.9.1",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7594/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7594/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7593",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7593/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7593/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7593/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7593",
        "id": 1886855738,
        "node_id": "I_kwDOIWuq585wdyI6",
        "number": 7593,
        "title": "[Question]: Using DocArrayHnswVectorStore to persist",
        "user": {
            "login": "ricoyudog",
            "id": 73219750,
            "node_id": "MDQ6VXNlcjczMjE5NzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/73219750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ricoyudog",
            "html_url": "https://github.com/ricoyudog",
            "followers_url": "https://api.github.com/users/ricoyudog/followers",
            "following_url": "https://api.github.com/users/ricoyudog/following{/other_user}",
            "gists_url": "https://api.github.com/users/ricoyudog/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ricoyudog/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ricoyudog/subscriptions",
            "organizations_url": "https://api.github.com/users/ricoyudog/orgs",
            "repos_url": "https://api.github.com/users/ricoyudog/repos",
            "events_url": "https://api.github.com/users/ricoyudog/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ricoyudog/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-08T02:57:46Z",
        "updated_at": "2023-10-24T06:31:16Z",
        "closed_at": "2023-10-24T06:31:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi teams, I am tring follow the save local document to save the index which created by \r\n`\r\n\r\n```python\r\nfrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, Document\r\nfrom llama_index.vector_stores import DocArrayHnswVectorStore\r\nvector_store = DocArrayHnswVectorStore(work_dir=)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context,show_progress=True)\r\n\r\nindex.storage_context.persist(persist_dir=)\r\n``` \r\n\r\n, But when I go through the local file, there is no vector_stores file. So it cant not be load by \r\n```python\r\n load_index_from_storage\r\n```\r\n\r\nThe director only have:\r\ndocstore.json\r\ngraph_store.json\r\nindex_store.json\r\n\r\n\r\nMay I have help from you.\r\nThank you very much!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7593/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7593/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7592",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7592/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7592/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7592/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7592",
        "id": 1886793593,
        "node_id": "PR_kwDOIWuq585Z1KDF",
        "number": 7592,
        "title": "Version bump to 0.8.22",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-08T01:21:14Z",
        "updated_at": "2023-09-08T01:21:30Z",
        "closed_at": "2023-09-08T01:21:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7592",
            "html_url": "https://github.com/run-llama/llama_index/pull/7592",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7592.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7592.patch",
            "merged_at": "2023-09-08T01:21:29Z"
        },
        "body": "# Description\r\n\r\nVersion bump to 0.8.22",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7592/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7592/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7591",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7591/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7591/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7591/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7591",
        "id": 1886790959,
        "node_id": "PR_kwDOIWuq585Z1Jfg",
        "number": 7591,
        "title": "Fixed issue with GPTTreeIndex example retrieving answer from root node",
        "user": {
            "login": "shankar24x7",
            "id": 3857913,
            "node_id": "MDQ6VXNlcjM4NTc5MTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3857913?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/shankar24x7",
            "html_url": "https://github.com/shankar24x7",
            "followers_url": "https://api.github.com/users/shankar24x7/followers",
            "following_url": "https://api.github.com/users/shankar24x7/following{/other_user}",
            "gists_url": "https://api.github.com/users/shankar24x7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/shankar24x7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/shankar24x7/subscriptions",
            "organizations_url": "https://api.github.com/users/shankar24x7/orgs",
            "repos_url": "https://api.github.com/users/shankar24x7/repos",
            "events_url": "https://api.github.com/users/shankar24x7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/shankar24x7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-08T01:16:26Z",
        "updated_at": "2023-09-08T03:35:54Z",
        "closed_at": "2023-09-08T03:35:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7591",
            "html_url": "https://github.com/run-llama/llama_index/pull/7591",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7591.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7591.patch",
            "merged_at": "2023-09-08T03:35:53Z"
        },
        "body": "# Description\r\n\r\nThe TestEssay notebook in the paul_graham_essay example had one part broken which caused it to fail. It was a simple fix - the wrong variable was being referenced in one of the statements.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nManually. It is a simple one line change. Notebook was not working without the fix - verified it works properly post fix.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7591/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7591/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7590",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7590/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7590/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7590/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7590",
        "id": 1886775056,
        "node_id": "PR_kwDOIWuq585Z1GJv",
        "number": 7590,
        "title": "fix splitter eating whitespace",
        "user": {
            "login": "yisding",
            "id": 1209314,
            "node_id": "MDQ6VXNlcjEyMDkzMTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1209314?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yisding",
            "html_url": "https://github.com/yisding",
            "followers_url": "https://api.github.com/users/yisding/followers",
            "following_url": "https://api.github.com/users/yisding/following{/other_user}",
            "gists_url": "https://api.github.com/users/yisding/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yisding/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yisding/subscriptions",
            "organizations_url": "https://api.github.com/users/yisding/orgs",
            "repos_url": "https://api.github.com/users/yisding/repos",
            "events_url": "https://api.github.com/users/yisding/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yisding/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-08T00:48:39Z",
        "updated_at": "2023-09-13T02:07:11Z",
        "closed_at": "2023-09-13T02:07:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7590",
            "html_url": "https://github.com/run-llama/llama_index/pull/7590",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7590.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7590.patch",
            "merged_at": "2023-09-13T02:07:10Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] My changes generate no new warnings\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7590/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7590/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7589",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7589/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7589/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7589/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7589",
        "id": 1886673807,
        "node_id": "PR_kwDOIWuq585Z0va-",
        "number": 7589,
        "title": "Add bs4 based HTML tag reader",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-07T23:03:45Z",
        "updated_at": "2023-09-08T00:08:10Z",
        "closed_at": "2023-09-08T00:08:09Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7589",
            "html_url": "https://github.com/run-llama/llama_index/pull/7589",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7589.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7589.patch",
            "merged_at": "2023-09-08T00:08:09Z"
        },
        "body": "# Description\r\n\r\nRead HTML files and extract text from a specific tag with BeautifulSoup.\r\n\r\nBy default, reads the text from the ``<section>`` tag.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7589/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7589/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]