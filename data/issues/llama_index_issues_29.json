[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6481",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6481/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6481/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6481/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6481",
        "id": 1759584520,
        "node_id": "I_kwDOIWuq585o4SEI",
        "number": 6481,
        "title": "[Bug]: GithubRepoReader should fail gracefully",
        "user": {
            "login": "gibraltariq",
            "id": 10490649,
            "node_id": "MDQ6VXNlcjEwNDkwNjQ5",
            "avatar_url": "https://avatars.githubusercontent.com/u/10490649?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gibraltariq",
            "html_url": "https://github.com/gibraltariq",
            "followers_url": "https://api.github.com/users/gibraltariq/followers",
            "following_url": "https://api.github.com/users/gibraltariq/following{/other_user}",
            "gists_url": "https://api.github.com/users/gibraltariq/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gibraltariq/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gibraltariq/subscriptions",
            "organizations_url": "https://api.github.com/users/gibraltariq/orgs",
            "repos_url": "https://api.github.com/users/gibraltariq/repos",
            "events_url": "https://api.github.com/users/gibraltariq/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gibraltariq/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-15T21:39:25Z",
        "updated_at": "2023-09-21T16:02:16Z",
        "closed_at": "2023-09-21T16:02:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nToday using GithubRepoReader, when fetching a particular document in a repo fails, the entire fetch and load of the repo fails. Instead it should fail gracefully and just skip the particular document it could not fetch in the loading tree.\r\n\r\n<img width=\"1309\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/10490649/497ca891-b6ee-4f08-8cc9-0a18a4bc5051\">\r\n\r\nDumping the full error logs below:\r\nHTTP Exception for https://api.github.com/repos/maticnetwork/matic-docs/git/blobs/7d0d709bf50456ffe20cbbf6e3fbfadebb72fb70 - Client error '403 Forbidden' for url 'https://api.github.com/repos/maticnetwork/matic-docs/git/blobs/7d0d709bf50456ffe20cbbf6e3fbfadebb72fb70'\r\nFor more information check: https://httpstatuses.com/403\r\n---------------------------------------------------------------------------\r\nHTTPStatusError                           Traceback (most recent call last)\r\n[<ipython-input-37-7e1224099b88>](https://localhost:8080/#) in <cell line: 1>()\r\n----> 1 documents = reader.load_data(branch=branch)\r\n      2 \r\n      3 for doc in documents:\r\n      4     print(doc.extra_info)\r\n\r\n13 frames\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_repository_reader.py](https://localhost:8080/#) in load_data(self, commit_sha, branch)\r\n    184 \r\n    185         if branch is not None:\r\n--> 186             return self._load_data_from_branch(branch)\r\n    187 \r\n    188         raise ValueError(\"You must specify one of commit or branch.\")\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_repository_reader.py](https://localhost:8080/#) in _load_data_from_branch(self, branch)\r\n    155         print_if_verbose(self._verbose, f\"got {len(blobs_and_paths)} blobs\")\r\n    156 \r\n--> 157         return self._loop.run_until_complete(\r\n    158             self._generate_documents(blobs_and_paths=blobs_and_paths)\r\n    159         )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/nest_asyncio.py](https://localhost:8080/#) in run_until_complete(self, future)\r\n     88                 raise RuntimeError(\r\n     89                     'Event loop stopped before Future completed.')\r\n---> 90             return f.result()\r\n     91 \r\n     92     def _run_once(self):\r\n\r\n[/usr/lib/python3.10/asyncio/futures.py](https://localhost:8080/#) in result(self)\r\n    199         self.__log_traceback = False\r\n    200         if self._exception is not None:\r\n--> 201             raise self._exception.with_traceback(self._exception_tb)\r\n    202         return self._result\r\n    203 \r\n\r\n[/usr/lib/python3.10/asyncio/tasks.py](https://localhost:8080/#) in __step(***failed resolving arguments***)\r\n    232                 result = coro.send(None)\r\n    233             else:\r\n--> 234                 result = coro.throw(exc)\r\n    235         except StopIteration as exc:\r\n    236             if self._must_cancel:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_repository_reader.py](https://localhost:8080/#) in _generate_documents(self, blobs_and_paths)\r\n    270 \r\n    271         documents = []\r\n--> 272         async for blob_data, full_path in buffered_iterator:\r\n    273             print_if_verbose(self._verbose, f\"generating document for {full_path}\")\r\n    274             assert (\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/utils.py](https://localhost:8080/#) in __anext__(self)\r\n     72         \"\"\"\r\n     73         if not self._buffer:\r\n---> 74             await self._fill_buffer()\r\n     75 \r\n     76         if not self._buffer:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/utils.py](https://localhost:8080/#) in _fill_buffer(self)\r\n    146         if self._verbose:\r\n    147             start_t = time.time()\r\n--> 148         results: List[GitBlobResponseModel] = await asyncio.gather(\r\n    149             *[\r\n    150                 self._github_client.get_blob(self._owner, self._repo, blob.sha)\r\n\r\n[/usr/lib/python3.10/asyncio/tasks.py](https://localhost:8080/#) in __wakeup(self, future)\r\n    302     def __wakeup(self, future):\r\n    303         try:\r\n--> 304             future.result()\r\n    305         except BaseException as exc:\r\n    306             # This may also be a cancellation.\r\n\r\n[/usr/lib/python3.10/asyncio/tasks.py](https://localhost:8080/#) in __step(***failed resolving arguments***)\r\n    230                 # We use the `send` method directly, because coroutines\r\n    231                 # don't have `__iter__` and `__next__` methods.\r\n--> 232                 result = coro.send(None)\r\n    233             else:\r\n    234                 result = coro.throw(exc)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_api_client.py](https://localhost:8080/#) in get_blob(self, owner, repo, file_sha)\r\n    334         return GitBlobResponseModel.from_json(\r\n    335             (\r\n--> 336                 await self.request(\r\n    337                     \"getBlob\", \"GET\", owner=owner, repo=repo, file_sha=file_sha\r\n    338                 )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_api_client.py](https://localhost:8080/#) in request(self, endpoint, method, headers, **kwargs)\r\n    262             except httpx.HTTPError as excp:\r\n    263                 print(f\"HTTP Exception for {excp.request.url} - {excp}\")\r\n--> 264                 raise excp\r\n    265             return response\r\n    266 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/readers/github_readers/github_api_client.py](https://localhost:8080/#) in request(self, endpoint, method, headers, **kwargs)\r\n    259                     method, url=self._endpoints[endpoint].format(**kwargs)\r\n    260                 )\r\n--> 261                 response.raise_for_status()\r\n    262             except httpx.HTTPError as excp:\r\n    263                 print(f\"HTTP Exception for {excp.request.url} - {excp}\")\r\n\r\n[/usr/local/lib/python3.10/dist-packages/httpx/_models.py](https://localhost:8080/#) in raise_for_status(self)\r\n    747         error_type = error_types.get(status_class, \"Invalid status code\")\r\n    748         message = message.format(self, error_type=error_type)\r\n--> 749         raise HTTPStatusError(message, request=request, response=self)\r\n    750 \r\n    751     def json(self, **kwargs: typing.Any) -> typing.Any:\r\n\r\nHTTPStatusError: Client error '403 Forbidden' for url 'https://api.github.com/repos/maticnetwork/matic-docs/git/blobs/7d0d709bf50456ffe20cbbf6e3fbfadebb72fb70'\r\nFor more information check: https://httpstatuses.com/403\n\n### Version\n\n0.6.26\n\n### Steps to Reproduce\n\nTo reproduce run the following code (add in a github token):\r\n\r\n```\r\n!pip install llama-index GitPython nest_asyncio httpx\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\n\r\nfrom llama_index import VectorStoreIndex, GithubRepositoryReader\r\nfrom IPython.display import Markdown, display\r\nimport os\r\nos.environ['OPENAI_API_KEY'] = '...'\r\n\r\nos.environ['GITHUB_TOKEN']= '...'\r\ngithub_token = os.environ.get(\"GITHUB_TOKEN\")\r\n\r\nowner = \"maticnetwork\"\r\nrepo = \"matic-docs\"\r\nbranch = \"master\"\r\ncommit_sha = \"c7949cb3651c4ab07e44b26b1f2f95b795dc5e52\"\r\n\r\nreader = GithubRepositoryReader(\r\n    github_token=github_token,\r\n    owner=owner,\r\n    repo=repo,\r\n    use_parser=False,\r\n    verbose=False,\r\n)\r\ndocuments = reader.load_data(branch=branch)\r\n\r\nfor doc in documents:\r\n    print(doc.extra_info)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6481/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6481/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6480",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6480/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6480/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6480/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6480",
        "id": 1759533214,
        "node_id": "PR_kwDOIWuq585TIjdG",
        "number": 6480,
        "title": "[WIP] initial node/document schema",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-15T20:54:10Z",
        "updated_at": "2023-06-22T21:29:43Z",
        "closed_at": "2023-06-22T21:29:43Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6480",
            "html_url": "https://github.com/run-llama/llama_index/pull/6480",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6480.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6480.patch",
            "merged_at": null
        },
        "body": "So I charged ahead with my original design doc, but I'm still not entirely convinced of the value add vs. effort needed. But, who knows lol\r\n\r\n\r\nThoughts and criticism extremely appreciated. I haven't actually used these new objects anywhere yet, but will plow ahead if approved \ud83d\udc4d\ud83c\udffb We could also change course and just refactor our existing objects to support these newer features ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6480/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6480/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6479",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6479/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6479/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6479/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6479",
        "id": 1759447177,
        "node_id": "PR_kwDOIWuq585TIQ9t",
        "number": 6479,
        "title": "SQL Struct store query engine context str resynthesis",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-15T19:44:36Z",
        "updated_at": "2023-06-30T20:42:25Z",
        "closed_at": "2023-06-20T16:54:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6479",
            "html_url": "https://github.com/run-llama/llama_index/pull/6479",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6479.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6479.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nCurrently the context_str must be set during index construction for a sqlstructstore. This means the user has to pass in the query_str to the query_index_for_context function during index construction. Instead this PR allows by default that during query time the context_str is recomputed based on the query_str passed in.\r\n\r\n## Type of Change\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nCopied snowflake sql db notebook from the Airbyte example to use the new syntax\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6479/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6479/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6478",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6478/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6478/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6478/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6478",
        "id": 1759415996,
        "node_id": "I_kwDOIWuq585o3o68",
        "number": 6478,
        "title": "[Bug]:  No module named 'langchain.chat_models' after import llama-index",
        "user": {
            "login": "camilarmoraes",
            "id": 72588121,
            "node_id": "MDQ6VXNlcjcyNTg4MTIx",
            "avatar_url": "https://avatars.githubusercontent.com/u/72588121?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/camilarmoraes",
            "html_url": "https://github.com/camilarmoraes",
            "followers_url": "https://api.github.com/users/camilarmoraes/followers",
            "following_url": "https://api.github.com/users/camilarmoraes/following{/other_user}",
            "gists_url": "https://api.github.com/users/camilarmoraes/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/camilarmoraes/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/camilarmoraes/subscriptions",
            "organizations_url": "https://api.github.com/users/camilarmoraes/orgs",
            "repos_url": "https://api.github.com/users/camilarmoraes/repos",
            "events_url": "https://api.github.com/users/camilarmoraes/events{/privacy}",
            "received_events_url": "https://api.github.com/users/camilarmoraes/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-15T19:22:14Z",
        "updated_at": "2023-06-15T19:40:38Z",
        "closed_at": "2023-06-15T19:40:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nEven not using langchain package diretly; only import  `from llama_index import download_loader` or any other method from llama-index; the console show this error: \r\n``No module named 'langchain.chat_models'; 'langchain' is not a package``\r\n\r\nAnd this is my imports\r\n`import os `\r\n`import pandas as pd`\r\n`from pathlib import Path`\r\n`from llama_index import download_loader`\r\n`from llama_index import GPTVectorStoreIndex, Document, SimpleWebPageReader`\r\n\r\n\n\n### Version\n\n0.6.26\n\n### Steps to Reproduce\n\nOnly install the libs.\n\n### Relevant Logs/Tracbacks\n\n```shell\nTraceback (most recent call last):\r\n  File \"/home/camila/Documentos/Workspace//PDFSEARCH/code/algoritmo_llama.py\", line 12, in <module>\r\n    from llama_index import download_loader\r\n  File \"/home/camila/anaconda3/envs/pdf_search/lib/python3.11/site-packages/llama_index/__init__.py\", line 15, in <module>\r\n    from llama_index.embeddings.langchain import LangchainEmbedding\r\n  File \"/home/camila/anaconda3/envs/pdf_search/lib/python3.11/site-packages/llama_index/embeddings/__init__.py\", line 4, in <module>\r\n    from llama_index.embeddings.langchain import LangchainEmbedding\r\n  File \"/home/camila/anaconda3/envs/pdf_search/lib/python3.11/site-packages/llama_index/embeddings/langchain.py\", line 6, in <module>\r\n    from langchain.embeddings.base import Embeddings as LCEmbeddings\r\n  File \"/home/camila/Documentos/Workspace//PDFSEARCH/code/langchain.py\", line 9, in <module>\r\n    from langchain.chat_models import ChatOpenAI\r\nModuleNotFoundError: No module named 'langchain.chat_models'; 'langchain' is not a package\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6478/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6478/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6477",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6477/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6477/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6477/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6477",
        "id": 1758991269,
        "node_id": "PR_kwDOIWuq585TGvpd",
        "number": 6477,
        "title": "Allow SimpleDirectoryReader to support custom file extensions",
        "user": {
            "login": "tilleul",
            "id": 3061106,
            "node_id": "MDQ6VXNlcjMwNjExMDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3061106?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tilleul",
            "html_url": "https://github.com/tilleul",
            "followers_url": "https://api.github.com/users/tilleul/followers",
            "following_url": "https://api.github.com/users/tilleul/following{/other_user}",
            "gists_url": "https://api.github.com/users/tilleul/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tilleul/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tilleul/subscriptions",
            "organizations_url": "https://api.github.com/users/tilleul/orgs",
            "repos_url": "https://api.github.com/users/tilleul/repos",
            "events_url": "https://api.github.com/users/tilleul/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tilleul/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-15T14:43:58Z",
        "updated_at": "2023-06-15T19:14:58Z",
        "closed_at": "2023-06-15T19:14:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6477",
            "html_url": "https://github.com/run-llama/llama_index/pull/6477",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6477.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6477.patch",
            "merged_at": "2023-06-15T19:14:57Z"
        },
        "body": "# Description\r\n\r\nFor now, SimpleDirectoryReader only supports the default file extensions as mentioned in DEFAULT_FILE_READER_CLS.\r\nBy checking if the file extension is in one of the (optional) file_extractors, we allow the developer to use the classic SimpleDirectoryReader class not only with custom readers but also with other file extensions.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update (**more precisely a clarification**)\r\n\r\n# How Has This Been Tested?\r\nCreate a directory to read and copy in there a markdown file. Rename the extension to whatever you want (for example: \"new_ext_but_really_md\").\r\nThen create a `SimpleDirectoryReader` instance with a `file_extractor` dict with the new extension handled by `MarkdownReader` and call `load_data()`\r\n```\r\ndocuments = SimpleDirectoryReader(doc_folder, file_extractor={\".new_ext_but_really_md\": MarkdownReader() }).load_data()\r\n```\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6477/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6477/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6476",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6476/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6476/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6476/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6476",
        "id": 1758594302,
        "node_id": "PR_kwDOIWuq585TFY_I",
        "number": 6476,
        "title": "Feat qdrant metadata filtering",
        "user": {
            "login": "kacperlukawski",
            "id": 2649301,
            "node_id": "MDQ6VXNlcjI2NDkzMDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2649301?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kacperlukawski",
            "html_url": "https://github.com/kacperlukawski",
            "followers_url": "https://api.github.com/users/kacperlukawski/followers",
            "following_url": "https://api.github.com/users/kacperlukawski/following{/other_user}",
            "gists_url": "https://api.github.com/users/kacperlukawski/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kacperlukawski/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kacperlukawski/subscriptions",
            "organizations_url": "https://api.github.com/users/kacperlukawski/orgs",
            "repos_url": "https://api.github.com/users/kacperlukawski/repos",
            "events_url": "https://api.github.com/users/kacperlukawski/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kacperlukawski/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-06-15T11:12:09Z",
        "updated_at": "2023-06-20T21:03:52Z",
        "closed_at": "2023-06-20T21:03:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6476",
            "html_url": "https://github.com/run-llama/llama_index/pull/6476",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6476.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6476.patch",
            "merged_at": "2023-06-20T21:03:51Z"
        },
        "body": "# Description\r\n\r\nQdrant has built-in filtering capabilities which weren't reflected in Llama Index. This PR introduces that mechanism to the Qdrant vector store. \r\n\r\nIn addition to that, I fixed the `ExactMatchFilter` implementation. It was using `Union[str, int, float]` instead of strict types what was resulting in a wrong type when applying integers or floats (or all were converted to strings). `ExactMatchFilter(key=\"test\", value=1)` was converted to `ExactMatchFilter(key=\"test\", value=\"1\")`.\r\n\r\nFor reference: https://docs.pydantic.dev/latest/usage/types/#strict-types\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nThe unit tests are included. They cover all the supported types.\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6476/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6476/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6475",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6475/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6475/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6475/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6475",
        "id": 1758550752,
        "node_id": "PR_kwDOIWuq585TFPU8",
        "number": 6475,
        "title": "fix delete bug using pinecone vector store",
        "user": {
            "login": "IANTHEREAL",
            "id": 10701973,
            "node_id": "MDQ6VXNlcjEwNzAxOTcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10701973?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IANTHEREAL",
            "html_url": "https://github.com/IANTHEREAL",
            "followers_url": "https://api.github.com/users/IANTHEREAL/followers",
            "following_url": "https://api.github.com/users/IANTHEREAL/following{/other_user}",
            "gists_url": "https://api.github.com/users/IANTHEREAL/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IANTHEREAL/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IANTHEREAL/subscriptions",
            "organizations_url": "https://api.github.com/users/IANTHEREAL/orgs",
            "repos_url": "https://api.github.com/users/IANTHEREAL/repos",
            "events_url": "https://api.github.com/users/IANTHEREAL/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IANTHEREAL/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-15T10:46:04Z",
        "updated_at": "2023-06-15T18:11:09Z",
        "closed_at": "2023-06-15T18:11:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6475",
            "html_url": "https://github.com/run-llama/llama_index/pull/6475",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6475.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6475.patch",
            "merged_at": "2023-06-15T18:11:09Z"
        },
        "body": "# Description\r\n\r\nIf the namespace is set for the pinecone vector store, deleting the corresponding vector from pinecone will not succeed cause by the deleted code does not set the correct namespace\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [] Added new unit/integration tests\r\n- [] Added new notebook (that tests end-to-end)\r\n- [] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6475/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6474",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6474/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6474/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6474/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6474",
        "id": 1758191538,
        "node_id": "PR_kwDOIWuq585TEBhe",
        "number": 6474,
        "title": "add function agent notebook comparison",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-15T07:13:50Z",
        "updated_at": "2023-06-15T15:31:59Z",
        "closed_at": "2023-06-15T15:31:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6474",
            "html_url": "https://github.com/run-llama/llama_index/pull/6474",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6474.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6474.patch",
            "merged_at": "2023-06-15T15:31:58Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6474/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6474/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6473",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6473/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6473/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6473/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6473",
        "id": 1758145199,
        "node_id": "PR_kwDOIWuq585TD3jF",
        "number": 6473,
        "title": "fix openai agent infinite loop",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-15T06:41:18Z",
        "updated_at": "2023-06-15T07:11:24Z",
        "closed_at": "2023-06-15T07:11:23Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6473",
            "html_url": "https://github.com/run-llama/llama_index/pull/6473",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6473.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6473.patch",
            "merged_at": "2023-06-15T07:11:23Z"
        },
        "body": "# Description\r\n\r\nFixes issue where we were using continue instead of breaking from function call\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6473/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6473/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6472",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6472/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6472/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6472/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6472",
        "id": 1757861907,
        "node_id": "PR_kwDOIWuq585TC6yz",
        "number": 6472,
        "title": "[fix document] JSONReader parameters",
        "user": {
            "login": "kangaechu",
            "id": 989985,
            "node_id": "MDQ6VXNlcjk4OTk4NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/989985?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kangaechu",
            "html_url": "https://github.com/kangaechu",
            "followers_url": "https://api.github.com/users/kangaechu/followers",
            "following_url": "https://api.github.com/users/kangaechu/following{/other_user}",
            "gists_url": "https://api.github.com/users/kangaechu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kangaechu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kangaechu/subscriptions",
            "organizations_url": "https://api.github.com/users/kangaechu/orgs",
            "repos_url": "https://api.github.com/users/kangaechu/repos",
            "events_url": "https://api.github.com/users/kangaechu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kangaechu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-15T01:04:51Z",
        "updated_at": "2023-06-15T22:47:11Z",
        "closed_at": "2023-06-15T18:30:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6472",
            "html_url": "https://github.com/run-llama/llama_index/pull/6472",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6472.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6472.patch",
            "merged_at": "2023-06-15T18:30:41Z"
        },
        "body": "# Description\r\n\r\nThe display of the JSONReader parameter documentation is broken due to missing indentation.\r\n\r\nI have added indentation and fixed it so that the parameters are displayed correctly.\r\n\r\nbefore:\r\n<img width=\"764\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/989985/86a16125-1179-4e2a-ad9e-ba9d93089422\">\r\n\r\nafter:\r\n<img width=\"740\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/989985/eea184cb-6b7b-452d-9516-2378f8602295\">\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6472/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6472/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6471",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6471/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6471/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6471/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6471",
        "id": 1757781863,
        "node_id": "I_kwDOIWuq585oxZ9n",
        "number": 6471,
        "title": "[Question]: Must provide an 'engine' or 'deployment_id' parameter error with AzureOpenAi for MultiStepQueryEngine",
        "user": {
            "login": "zyao-coursera",
            "id": 111776069,
            "node_id": "U_kgDOBqmRRQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/111776069?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zyao-coursera",
            "html_url": "https://github.com/zyao-coursera",
            "followers_url": "https://api.github.com/users/zyao-coursera/followers",
            "following_url": "https://api.github.com/users/zyao-coursera/following{/other_user}",
            "gists_url": "https://api.github.com/users/zyao-coursera/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zyao-coursera/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zyao-coursera/subscriptions",
            "organizations_url": "https://api.github.com/users/zyao-coursera/orgs",
            "repos_url": "https://api.github.com/users/zyao-coursera/repos",
            "events_url": "https://api.github.com/users/zyao-coursera/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zyao-coursera/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-14T23:02:26Z",
        "updated_at": "2023-07-05T00:56:39Z",
        "closed_at": "2023-07-05T00:56:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi experts,\r\n\r\nI'm following this instruction https://gpt-index.readthedocs.io/en/latest/examples/query_transformations/SimpleIndexDemo-multistep.html to try the` Multi-Step Query Engine`, but I'm facing this error\r\n```\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/openai.py](https://localhost:8080/#) in get_embedding(text, engine, **kwargs)\r\n    105     text = text.replace(\"\\n\", \" \")\r\n--> 106     return openai.Embedding.create(input=[text], model=engine, **kwargs)[\"data\"][0][\r\n    107         \"embedding\"\r\n\r\n[/usr/local/lib/python3.10/dist-packages/openai/api_resources/embedding.py](https://localhost:8080/#) in create(cls, *args, **kwargs)\r\n     32             try:\r\n---> 33                 response = super().create(*args, **kwargs)\r\n     34 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py](https://localhost:8080/#) in create(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\r\n    148             params,\r\n--> 149         ) = cls.__prepare_create_request(\r\n    150             api_key, api_base, api_type, api_version, organization, **params\r\n\r\n[/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py](https://localhost:8080/#) in __prepare_create_request(cls, api_key, api_base, api_type, api_version, organization, **params)\r\n     82             if deployment_id is None and engine is None:\r\n---> 83                 raise error.InvalidRequestError(\r\n     84                     \"Must provide an 'engine' or 'deployment_id' parameter to create a %s\"\r\n\r\nInvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nRetryError                                Traceback (most recent call last)\r\n[<ipython-input-12-c9cff2e24be6>](https://localhost:8080/#) in <cell line: 3>()\r\n      1 from IPython.display import Markdown, display\r\n      2 \r\n----> 3 response_gpt3 = query_engine.query(\"what's the problems of the house?\")\r\n      4 display(Markdown(f\"<b>{response_gpt3}</b>\"))\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/query/base.py](https://localhost:8080/#) in query(self, str_or_query_bundle)\r\n     21             if isinstance(str_or_query_bundle, str):\r\n     22                 str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 23             response = self._query(str_or_query_bundle)\r\n     24             return response\r\n     25 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/multistep_query_engine.py](https://localhost:8080/#) in _query(self, query_bundle)\r\n     77             CBEventType.QUERY, payload={\"query_str\": query_bundle.query_str}\r\n     78         )\r\n---> 79         nodes, source_nodes, extra_info = self._query_multistep(query_bundle)\r\n     80 \r\n     81         final_response = self._response_synthesizer.synthesize(\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/multistep_query_engine.py](https://localhost:8080/#) in _query_multistep(self, query_bundle)\r\n    155                 break\r\n    156 \r\n--> 157             cur_response = self._query_engine.query(updated_query_bundle)\r\n    158 \r\n    159             # append to response builder\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/query/base.py](https://localhost:8080/#) in query(self, str_or_query_bundle)\r\n     21             if isinstance(str_or_query_bundle, str):\r\n     22                 str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 23             response = self._query(str_or_query_bundle)\r\n     24             return response\r\n     25 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/retriever_query_engine.py](https://localhost:8080/#) in _query(self, query_bundle)\r\n    140 \r\n    141         retrieve_id = self.callback_manager.on_event_start(CBEventType.RETRIEVE)\r\n--> 142         nodes = self._retriever.retrieve(query_bundle)\r\n    143         self.callback_manager.on_event_end(\r\n    144             CBEventType.RETRIEVE, payload={\"nodes\": nodes}, event_id=retrieve_id\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/base_retriever.py](https://localhost:8080/#) in retrieve(self, str_or_query_bundle)\r\n     19         if isinstance(str_or_query_bundle, str):\r\n     20             str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 21         return self._retrieve(str_or_query_bundle)\r\n     22 \r\n     23     @abstractmethod\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/token_counter/token_counter.py](https://localhost:8080/#) in wrapped_llm_predict(_self, *args, **kwargs)\r\n     76         def wrapped_llm_predict(_self: Any, *args: Any, **kwargs: Any) -> Any:\r\n     77             with wrapper_logic(_self):\r\n---> 78                 f_return_val = f(_self, *args, **kwargs)\r\n     79 \r\n     80             return f_return_val\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/vector_store/retrievers/retriever.py](https://localhost:8080/#) in _retrieve(self, query_bundle)\r\n     68             if query_bundle.embedding is None:\r\n     69                 query_bundle.embedding = (\r\n---> 70                     self._service_context.embed_model.get_agg_embedding_from_queries(\r\n     71                         query_bundle.embedding_strs\r\n     72                     )\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/base.py](https://localhost:8080/#) in get_agg_embedding_from_queries(self, queries, agg_fn)\r\n     89     ) -> List[float]:\r\n     90         \"\"\"Get aggregated embedding from multiple queries.\"\"\"\r\n---> 91         query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n     92         agg_fn = agg_fn or mean_agg\r\n     93         return agg_fn(query_embeddings)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/base.py](https://localhost:8080/#) in <listcomp>(.0)\r\n     89     ) -> List[float]:\r\n     90         \"\"\"Get aggregated embedding from multiple queries.\"\"\"\r\n---> 91         query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n     92         agg_fn = agg_fn or mean_agg\r\n     93         return agg_fn(query_embeddings)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/base.py](https://localhost:8080/#) in get_query_embedding(self, query)\r\n     75         \"\"\"Get query embedding.\"\"\"\r\n     76         event_id = self.callback_manager.on_event_start(CBEventType.EMBEDDING)\r\n---> 77         query_embedding = self._get_query_embedding(query)\r\n     78         query_tokens_count = len(self._tokenizer(query))\r\n     79         self._total_tokens_used += query_tokens_count\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/openai.py](https://localhost:8080/#) in _get_query_embedding(self, query)\r\n    233     def _get_query_embedding(self, query: str) -> List[float]:\r\n    234         \"\"\"Get query embedding.\"\"\"\r\n--> 235         return get_embedding(\r\n    236             query,\r\n    237             engine=self.query_engine,\r\n\r\n[/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py](https://localhost:8080/#) in wrapped_f(*args, **kw)\r\n    287         @functools.wraps(f)\r\n    288         def wrapped_f(*args: t.Any, **kw: t.Any) -> t.Any:\r\n--> 289             return self(f, *args, **kw)\r\n    290 \r\n    291         def retry_with(*args: t.Any, **kwargs: t.Any) -> WrappedFn:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py](https://localhost:8080/#) in __call__(self, fn, *args, **kwargs)\r\n    377         retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)\r\n    378         while True:\r\n--> 379             do = self.iter(retry_state=retry_state)\r\n    380             if isinstance(do, DoAttempt):\r\n    381                 try:\r\n\r\n[/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py](https://localhost:8080/#) in iter(self, retry_state)\r\n    324             if self.reraise:\r\n    325                 raise retry_exc.reraise()\r\n--> 326             raise retry_exc from fut.exception()\r\n    327 \r\n    328         if self.wait:\r\n```\r\n\r\nMy code snippets are \r\n```\r\nllm = AzureOpenAI(deployment_name=\"text-davinci-003\", model_kwargs={\r\n    \"api_key\": openai.api_key,\r\n    \"api_base\": openai.api_base,\r\n    \"api_type\": openai.api_type,\r\n})\r\nllm_predictor = LLMPredictor(llm=llm)\r\n\r\nembedding_llm = LangchainEmbedding(\r\n    OpenAIEmbeddings(\r\n        model=\"text-embedding-ada-002\",\r\n        deployment=\"text-embedding-ada-002\",\r\n        openai_api_key= openai.api_key,\r\n        openai_api_base=openai.api_base,\r\n        openai_api_type=openai.api_type,\r\n        openai_api_version=openai.api_version,\r\n    ),\r\n    embed_batch_size=1,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm_predictor=llm_predictor,\r\n    embed_model=embedding_llm,\r\n    prompt_helper=prompt_helper\r\n)\r\nstep_decompose_transform_gpt3 = StepDecomposeQueryTransform(\r\n    llm_predictor, verbose=True\r\n)\r\nindex_summary = \"Used to answer questions about the house\"\r\nquery_engine = index.as_query_engine(\r\n    service_context=service_context\r\n)\r\nquery_engine = MultiStepQueryEngine(\r\n    query_engine=query_engine,\r\n    query_transform=step_decompose_transform_gpt3,\r\n    index_summary=index_summary\r\n)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6471/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6471/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6470",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6470/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6470/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6470/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6470",
        "id": 1757660747,
        "node_id": "PR_kwDOIWuq585TCOeH",
        "number": 6470,
        "title": "chat engine should inherit service context",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-14T21:17:06Z",
        "updated_at": "2023-06-14T21:27:22Z",
        "closed_at": "2023-06-14T21:27:21Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6470",
            "html_url": "https://github.com/run-llama/llama_index/pull/6470",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6470.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6470.patch",
            "merged_at": "2023-06-14T21:27:21Z"
        },
        "body": "# Description\r\n\r\nchat engine should inherit service context\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6470/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6470/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6469",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6469/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6469/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6469/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6469",
        "id": 1757069753,
        "node_id": "PR_kwDOIWuq585TAN59",
        "number": 6469,
        "title": "[version] bump version to 0.6.26",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-14T14:40:54Z",
        "updated_at": "2023-06-14T14:46:30Z",
        "closed_at": "2023-06-14T14:46:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6469",
            "html_url": "https://github.com/run-llama/llama_index/pull/6469",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6469.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6469.patch",
            "merged_at": "2023-06-14T14:46:29Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6469/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6469/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6468",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6468/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6468/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6468/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6468",
        "id": 1756997661,
        "node_id": "I_kwDOIWuq585ouagd",
        "number": 6468,
        "title": "[Bug]: doc_ids parameter isn't used in the weaviate query function",
        "user": {
            "login": "YasmineMh",
            "id": 42073781,
            "node_id": "MDQ6VXNlcjQyMDczNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42073781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YasmineMh",
            "html_url": "https://github.com/YasmineMh",
            "followers_url": "https://api.github.com/users/YasmineMh/followers",
            "following_url": "https://api.github.com/users/YasmineMh/following{/other_user}",
            "gists_url": "https://api.github.com/users/YasmineMh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YasmineMh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YasmineMh/subscriptions",
            "organizations_url": "https://api.github.com/users/YasmineMh/orgs",
            "repos_url": "https://api.github.com/users/YasmineMh/repos",
            "events_url": "https://api.github.com/users/YasmineMh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YasmineMh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-14T14:08:54Z",
        "updated_at": "2023-06-14T17:23:51Z",
        "closed_at": "2023-06-14T17:23:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\ndoc_ids parameter isn't used in the weaviate query function. The parameter is useful to constrain search, like using only specific docs for search, it's mentioned here https://gpt-index.readthedocs.io/en/stable/reference/query/retrievers/vector_store.html\r\n\r\n### Version\r\n\r\n0.6.24\r\n\r\n### Steps to Reproduce\r\n\r\njust using doc_ids parameter in VectorIndexRetriever function with weaviate as a vector store.\r\n\r\n```\r\nretriever = VectorIndexRetriever(\r\n    index=index, \r\n    similarity_top_k=3, \r\n    doc_ids=[\"id1\",\"id2\"]\r\n)\r\n\r\n```\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6468/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6468/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6467",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6467/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6467/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6467/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6467",
        "id": 1756858388,
        "node_id": "PR_kwDOIWuq585S_fhw",
        "number": 6467,
        "title": "fix: weaviate doc_ids filtering",
        "user": {
            "login": "YasmineMh",
            "id": 42073781,
            "node_id": "MDQ6VXNlcjQyMDczNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42073781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YasmineMh",
            "html_url": "https://github.com/YasmineMh",
            "followers_url": "https://api.github.com/users/YasmineMh/followers",
            "following_url": "https://api.github.com/users/YasmineMh/following{/other_user}",
            "gists_url": "https://api.github.com/users/YasmineMh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YasmineMh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YasmineMh/subscriptions",
            "organizations_url": "https://api.github.com/users/YasmineMh/orgs",
            "repos_url": "https://api.github.com/users/YasmineMh/repos",
            "events_url": "https://api.github.com/users/YasmineMh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YasmineMh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-14T13:01:57Z",
        "updated_at": "2023-06-14T17:23:50Z",
        "closed_at": "2023-06-14T17:23:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6467",
            "html_url": "https://github.com/run-llama/llama_index/pull/6467",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6467.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6467.patch",
            "merged_at": "2023-06-14T17:23:49Z"
        },
        "body": "# Description\r\n\r\ndoc_ids parameter isn't used in the weaviate query function. The parameter is useful to constrain search, like using only specific docs for search, it's mentioned here https://gpt-index.readthedocs.io/en/stable/reference/query/retrievers/vector_store.html\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I tested it on an example locally \r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] My changes generate no new warnings\r\n\r\n\r\nclose #6468",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6467/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6467/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6466",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6466/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6466/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6466/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6466",
        "id": 1756857022,
        "node_id": "I_kwDOIWuq585ot4K-",
        "number": 6466,
        "title": "[Bug]: tenacity.RetryError: RetryError[<Future at 0x139f5d7f0 state=finished raised FileNotFoundError>]",
        "user": {
            "login": "abhishek-chainflux",
            "id": 126469669,
            "node_id": "U_kgDOB4nGJQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/126469669?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abhishek-chainflux",
            "html_url": "https://github.com/abhishek-chainflux",
            "followers_url": "https://api.github.com/users/abhishek-chainflux/followers",
            "following_url": "https://api.github.com/users/abhishek-chainflux/following{/other_user}",
            "gists_url": "https://api.github.com/users/abhishek-chainflux/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abhishek-chainflux/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abhishek-chainflux/subscriptions",
            "organizations_url": "https://api.github.com/users/abhishek-chainflux/orgs",
            "repos_url": "https://api.github.com/users/abhishek-chainflux/repos",
            "events_url": "https://api.github.com/users/abhishek-chainflux/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abhishek-chainflux/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-14T13:01:18Z",
        "updated_at": "2023-07-22T02:04:18Z",
        "closed_at": "2023-07-22T02:04:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI'm unable use the **load_index_from_storage** function tried different ways ,can you guys let me know the solution\r\n\r\nNote:- i have used a txt file as data input\r\n\r\nThe code looks like below:-\r\n\r\nfrom llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, PromptHelper,load_index_from_storage,ServiceContext,StorageContext,VectorStoreIndex\r\nfrom langchain import OpenAI \r\nimport os\r\nimport openai\r\nimport os\r\nfrom tenacity import retry, stop_after_attempt, wait_fixed\r\n\r\n@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\r\ndef read_file(path):\r\n    if not os.path.exists(path):\r\n        raise FileNotFoundError(\"File not found\")\r\n    with open('index.json', \"r\") as file:\r\n        return file.read()\r\n\r\n        \r\n# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-\"\r\nopenai.api_key_path =\"sk-\"\r\n\r\n\r\ndef construct_index(directory_path):\r\n    # set maximum input size\r\n    max_input_size = 4096\r\n    # set number of output tokens\r\n    num_outputs = 512\r\n    # set maximum chunk overlap\r\n    max_chunk_overlap = 1\r\n    # set chunk size limit\r\n    chunk_size_limit = 600 \r\n\r\n    # define LLM\r\n    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\r\n    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\r\n \r\n    documents = SimpleDirectoryReader(directory_path).load_data()\r\n    print(\"documents--->\",documents)\r\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\r\n    print(\"service_context---->\",service_context)\r\n    try:\r\n        index = GPTVectorStoreIndex.from_documents(documents=documents,service_context=service_context)\r\n    except  RuntimeError as e:\r\n        print(e)\r\n    print(\"index----->\",index)\r\n    index.storage_context.persist(persist_dir=\"index.json\")\r\n\r\n    return index\r\n\r\ndef ask_ai():\r\n    storage_context=StorageContext.from_defaults(persist_dir='/index.json')\r\n    print('storage_context--->',storage_context)\r\n    index = load_index_from_storage(storage_context=storage_context).as_retriever()\r\n    while True: \r\n        query = input(\"What do you want to ask? \")\r\n        response = index.retrieve(query)\r\n        print(response)\r\n# res=construct_index('data/text.txt')\r\nask_ai()\r\n# \n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\ncreate a data-dir with text.txt file in it\r\n\r\njust run the code \r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nFile \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/embeddings/openai.py\", line 106, in get_embedding\r\n    return openai.Embedding.create(input=[text], model=engine, **kwargs)[\"data\"][0][\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/openai/api_resources/embedding.py\", line 33, in create\r\n    response = super().create(*args, **kwargs)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 149, in create\r\n    ) = cls.__prepare_create_request(\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 106, in __prepare_create_request\r\n    requestor = api_requestor.APIRequestor(\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/openai/api_requestor.py\", line 138, in __init__\r\n    self.api_key = key or util.default_api_key()\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/openai/util.py\", line 178, in default_api_key\r\n    with open(openai.api_key_path, \"rt\") as k:\r\nFileNotFoundError: [Errno 2] No such file or directory: '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'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/jabebot.py\", line 59, in <module>\r\n    ask_ai()\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/jabebot.py\", line 56, in ask_ai\r\n    response = index.retrieve(query)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/indices/base_retriever.py\", line 21, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/token_counter/token_counter.py\", line 78, in wrapped_llm_predict\r\n    f_return_val = f(_self, *args, **kwargs)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 70, in _retrieve\r\n    self._service_context.embed_model.get_agg_embedding_from_queries(\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/embeddings/base.py\", line 91, in get_agg_embedding_from_queries\r\n    query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/embeddings/base.py\", line 91, in <listcomp>\r\n    query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/embeddings/base.py\", line 77, in get_query_embedding\r\n    query_embedding = self._get_query_embedding(query)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/llama_index/embeddings/openai.py\", line 235, in _get_query_embedding\r\n    return get_embedding(\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"/Users/abhisheksreeram/Desktop/carbon_credits/gpt3-jabebot/venv/lib/python3.9/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x139f5d7f0 state=finished raised FileNotFoundError>]\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6466/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6466/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6465",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6465/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6465/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6465/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6465",
        "id": 1756544489,
        "node_id": "I_kwDOIWuq585osr3p",
        "number": 6465,
        "title": "[Bug]: Got a larger chunk overlap (...) than chunk size (...), should be smaller.",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 12,
        "created_at": "2023-06-14T10:16:14Z",
        "updated_at": "2023-09-09T23:12:35Z",
        "closed_at": "2023-09-09T23:12:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThis has happened a few times to other users, e.g. #3390,  #904, #605 but I don't really see a proper solution to this kind of error. It is also strange that it's possible that there are cases where `chunk_size` (which is computed by [`PromptHelper.chunk_size = self._get_available_chunk_size(prompt, num_chunks, padding=padding)`](https://github.com/jerryjliu/llama_index/blob/main/llama_index/indices/prompt_helper.py#L196) is negative. If the available chunk size is negative, the previous addition to the prompt shouldn't have happened, right?\r\n\r\nI feel like in the steps where it's adding more context and passing in the previous answer to the LLM, it should only add it if there's enough space. Why would there ever be a case that the available chunk is negative?\r\n\r\nIs this expected behaviour, or is it a bug? How can I avoid having this error?\r\n\r\n### Version\r\n\r\n0.6.25.post1\r\n\r\n### Steps to Reproduce\r\n\r\nI'm trying to use `falcon-7b` in 4bit (using this [tutorial](https://vilsonrodrigues.medium.com/run-your-private-llm-falcon-7b-instruct-with-less-than-6gb-of-gpu-using-4-bit-quantization-ff1d4ffbabcc)) from `transformers` library as the LLM\r\n\r\nSetting up data and embeddings (I've done this with several documents). Replace `text_list` with list of ''relatively' long strings...\r\n\r\n```\r\ndocuments = [Document(t) for t in text_list]\r\nhfemb = HuggingFaceEmbeddings()\r\nembed_model = LangchainEmbedding(hfemb)\r\n```\r\n\r\nLoading `falcon-7b` in 4bit:\r\n\r\n```\r\nfrom transformers import (\r\n    pipeline,\r\n    AutoModel,\r\n    AutoModelForCausalLM,\r\n    AutoTokenizer,\r\n    BitsAndBytesConfig\r\n)\r\n\r\nquantization_config = BitsAndBytesConfig(\r\n    load_in_4bit=True,\r\n    bnb_4bit_compute_dtype=torch.float16,\r\n    bnb_4bit_quant_type=\"nf4\",\r\n    bnb_4bit_use_double_quant=True,\r\n)\r\n\r\nmodel_name = \"tiiuae/falcon-7b-instruct\"\r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_name,\r\n    device_map='auto',\r\n    quantization_config=quantization_config,\r\n    trust_remote_code=True,\r\n)\r\n```\r\n\r\nTo set up the pipeline:\r\n\r\n```\r\nfalcon_7b = pipeline(\r\n    \"text-generation\",\r\n    model=model,\r\n    tokenizer=tokenizer,\r\n    use_cache=True,\r\n    device_map=\"auto\",\r\n    do_sample=True,\r\n    top_k=10,\r\n    top_p=0.95,\r\n    num_return_sequences=1,\r\n    eos_token_id=tokenizer.eos_token_id,\r\n    pad_token_id=tokenizer.eos_token_id,\r\n)\r\n\r\nclass CustomLLM(LLM):\r\n    model_name: str\r\n    pipeline: transformers.pipelines.text_generation.TextGenerationPipeline\r\n    \r\n    @property\r\n    def _llm_type(self) -> str:\r\n        return \"custom\"\r\n    \r\n    def _call(self, prompt, stop=None):\r\n        generated_text = self.pipeline(prompt)[0][\"generated_text\"]\r\n        return generated_text\r\n    \r\n    @property\r\n    def _identifying_params(self) -> dict:\r\n        \"\"\"Get the identifying parameters.\"\"\"\r\n        return {\"model_name\": self.model_name}\r\n    \r\nllm_predictor_falcon_7b = LLMPredictor(llm=CustomLLM(model_name=model_name, pipeline=falcon_7b))\r\n```\r\n\r\nSetting up query engine:\r\n```\r\n# set number of output tokens\r\nnum_output = 512\r\n# set maximum input size\r\nmax_input_size = 1024\r\n# set maximum chunk overlap\r\nchunk_size_limit = 256\r\nchunk_overlap_ratio = 0.1\r\n\r\nprompt_helper = PromptHelper(\r\n    context_window=max_input_size,\r\n    num_output=num_output,\r\n    chunk_size_limit=chunk_size_limit,\r\n    chunk_overlap_ratio=chunk_overlap_ratio,\r\n)\r\n\r\n service_context = ServiceContext.from_defaults(\r\n    llm_predictor=llm_predictor_falcon_7b,\r\n    embed_model=embed_model,\r\n    prompt_helper=prompt_helper,\r\n)\r\n\r\nindex = GPTVectorStoreIndex.from_documents(\r\n    documents, service_context=service_context\r\n)\r\nquery_engine_falcon_7b = index.as_query_engine()\r\n```\r\n\r\nTrying to query it:\r\n```\r\nresponse = query_engine_falcon_7b.query(\"...\")\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[48], line 1\r\n----> 1 response = query_engine_falcon_7b.query(\"something...?\")\r\n      2 print(response.response)\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/indices/query/base.py:23, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     21 if isinstance(str_or_query_bundle, str):\r\n     22     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 23 response = self._query(str_or_query_bundle)\r\n     24 return response\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/query_engine/retriever_query_engine.py:147, in RetrieverQueryEngine._query(self, query_bundle)\r\n    142 nodes = self._retriever.retrieve(query_bundle)\r\n    143 self.callback_manager.on_event_end(\r\n    144     CBEventType.RETRIEVE, payload={\"nodes\": nodes}, event_id=retrieve_id\r\n    145 )\r\n--> 147 response = self._response_synthesizer.synthesize(\r\n    148     query_bundle=query_bundle,\r\n    149     nodes=nodes,\r\n    150 )\r\n    152 self.callback_manager.on_event_end(\r\n    153     CBEventType.QUERY,\r\n    154     payload={\"response\": response},\r\n    155     event_id=query_id,\r\n    156 )\r\n    157 return response\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/indices/query/response_synthesis.py:178, in ResponseSynthesizer.synthesize(self, query_bundle, nodes, additional_source_nodes)\r\n    176 if self._response_mode != ResponseMode.NO_TEXT:\r\n    177     assert self._response_builder is not None\r\n--> 178     response_str = self._response_builder.get_response(\r\n    179         query_str=query_bundle.query_str,\r\n    180         text_chunks=text_chunks,\r\n    181         **self._response_kwargs,\r\n    182     )\r\n    183 else:\r\n    184     response_str = None\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/indices/response/compact_and_refine.py:50, in CompactAndRefine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n     48 max_prompt = get_biggest_prompt([text_qa_template, refine_template])\r\n     49 new_texts = self._service_context.prompt_helper.repack(max_prompt, text_chunks)\r\n---> 50 response = super().get_response(\r\n     51     query_str=query_str, text_chunks=new_texts, prev_response=prev_response\r\n     52 )\r\n     53 return response\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/token_counter/token_counter.py:78, in llm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict(_self, *args, **kwargs)\r\n     76 def wrapped_llm_predict(_self: Any, *args: Any, **kwargs: Any) -> Any:\r\n     77     with wrapper_logic(_self):\r\n---> 78         f_return_val = f(_self, *args, **kwargs)\r\n     80     return f_return_val\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/indices/response/refine.py:57, in Refine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n     52         response = self._give_response_single(\r\n     53             query_str,\r\n     54             text_chunk,\r\n     55         )\r\n     56     else:\r\n---> 57         response = self._refine_response_single(\r\n     58             prev_response_obj, query_str, text_chunk\r\n     59         )\r\n     60     prev_response_obj = response\r\n     61 if isinstance(response, str):\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/indices/response/refine.py:131, in Refine._refine_response_single(self, response, query_str, text_chunk, **response_kwargs)\r\n    127 # NOTE: partial format refine template with query_str and existing_answer here\r\n    128 refine_template = self._refine_template.partial_format(\r\n    129     query_str=query_str, existing_answer=response\r\n    130 )\r\n--> 131 text_chunks = self._service_context.prompt_helper.repack(\r\n    132     refine_template, text_chunks=[text_chunk]\r\n    133 )\r\n    135 for cur_text_chunk in text_chunks:\r\n    136     if not self._streaming:\r\n\r\nCell In[43], line 233, in PromptHelper.repack(self, prompt, text_chunks, padding)\r\n    224 def repack(\r\n    225     self, prompt: Prompt, text_chunks: Sequence[str], padding: int = DEFAULT_PADDING\r\n    226 ) -> List[str]:\r\n    227     \"\"\"Repack text chunks to fit available context window.\r\n    228 \r\n    229     This will combine text chunks into consolidated chunks\r\n    230     that more fully \"pack\" the prompt template given the max_input_size.\r\n    231 \r\n    232     \"\"\"\r\n--> 233     text_splitter = self.get_text_splitter_given_prompt(prompt, padding=padding)\r\n    234     combined_str = \"\\n\\n\".join([c.strip() for c in text_chunks if c.strip()])\r\n    235     return text_splitter.split_text(combined_str)\r\n\r\nCell In[43], line 205, in PromptHelper.get_text_splitter_given_prompt(self, prompt, num_chunks, padding)\r\n    203 print(f\"chunk_size: {chunk_size}\")\r\n    204 print(f\"chunk_overlap: {chunk_overlap}\")\r\n--> 205 text_splitter = TokenTextSplitter(\r\n    206     separator=self._separator,\r\n    207     chunk_size=chunk_size,\r\n    208     chunk_overlap=chunk_overlap,\r\n    209     tokenizer=self._tokenizer,\r\n    210 )\r\n    211 return text_splitter\r\n\r\nFile /anaconda/envs/reginald/lib/python3.11/site-packages/llama_index/langchain_helpers/text_splitter.py:40, in TokenTextSplitter.__init__(self, separator, chunk_size, chunk_overlap, tokenizer, backup_separators, callback_manager)\r\n     38 \"\"\"Initialize with parameters.\"\"\"\r\n     39 if chunk_overlap > chunk_size:\r\n---> 40     raise ValueError(\r\n     41         f\"Got a larger chunk overlap ({chunk_overlap}) than chunk size \"\r\n     42         f\"({chunk_size}), should be smaller.\"\r\n     43     )\r\n     44 self._separator = separator\r\n     45 self._chunk_size = chunk_size\r\n\r\nValueError: Got a larger chunk overlap (-27) than chunk size (-275), should be smaller.\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6465/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6465/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6464",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6464/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6464/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6464/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6464",
        "id": 1756463486,
        "node_id": "I_kwDOIWuq585osYF-",
        "number": 6464,
        "title": "[Question]: \u3010Discussion\u3011Multiple sources of information retrieval and inquiry for a question",
        "user": {
            "login": "mintisan",
            "id": 9136049,
            "node_id": "MDQ6VXNlcjkxMzYwNDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9136049?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mintisan",
            "html_url": "https://github.com/mintisan",
            "followers_url": "https://api.github.com/users/mintisan/followers",
            "following_url": "https://api.github.com/users/mintisan/following{/other_user}",
            "gists_url": "https://api.github.com/users/mintisan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mintisan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mintisan/subscriptions",
            "organizations_url": "https://api.github.com/users/mintisan/orgs",
            "repos_url": "https://api.github.com/users/mintisan/repos",
            "events_url": "https://api.github.com/users/mintisan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mintisan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-14T09:31:58Z",
        "updated_at": "2023-07-22T02:05:21Z",
        "closed_at": "2023-07-22T02:05:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFor a problem, it may involve [code/log/documentation] multiple information sources.\r\n\r\n I tried putting all of them in a string-splitter-embedding-retrieval, but the result is not good.\r\n\r\nSo I think that the code/log/documentation creates an index_code/index_log/index_doc respectively, and then each index has top_k_3, so that we have three sources of information with nine nodes for the same problem, \r\n\r\nbut **how do we use these three index/nine nodes in LlamaIndex. The information sources are packaged together through the prompt and sent to ChatGPT.**\r\n\r\nMaybe I need a prompt template just like below:\r\n\r\n```\r\n\"\"\"\r\nUser has a question : {query_str}.\r\n\r\nHe has relative {context_str_doc-1-2-3} description.\r\n\r\nAnd relative codes {context_str_code-1-2-3} with logs {context_str_log-1-2-3} print out.\r\n\r\nGive the reason with above information.\r\n\r\n\"\"\"\r\n```\r\n\r\nI read the relevant information in the document/links, but it seems that it can't solve my problem. \r\n\r\nSo, I'm here to ask for thoughts.\r\n\r\nRelated reference links:\r\n\r\n- https://gpt-index.readthedocs.io/en/latest/use_cases/queries.html#routing-over-heterogeneous-data\r\n- https://gpt-index.readthedocs.io/en/latest/use_cases/queries.html#synthesis-over-heterogeneous-data\r\n- https://gpt-index.readthedocs.io/en/latest/use_cases/queries.html#multi-document-queries\r\n- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/RouterQueryEngine.html#define-query-engines-and-set-metadata",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6464/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6464/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6463",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6463/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6463/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6463/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6463",
        "id": 1756248962,
        "node_id": "I_kwDOIWuq585orjuC",
        "number": 6463,
        "title": "[Bug]: `aquery()` does not work asynchronously ",
        "user": {
            "login": "jjmachan",
            "id": 5261489,
            "node_id": "MDQ6VXNlcjUyNjE0ODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5261489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jjmachan",
            "html_url": "https://github.com/jjmachan",
            "followers_url": "https://api.github.com/users/jjmachan/followers",
            "following_url": "https://api.github.com/users/jjmachan/following{/other_user}",
            "gists_url": "https://api.github.com/users/jjmachan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jjmachan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jjmachan/subscriptions",
            "organizations_url": "https://api.github.com/users/jjmachan/orgs",
            "repos_url": "https://api.github.com/users/jjmachan/repos",
            "events_url": "https://api.github.com/users/jjmachan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jjmachan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-14T07:30:43Z",
        "updated_at": "2023-06-26T09:47:04Z",
        "closed_at": "2023-06-26T09:47:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI want to call `aquery()` to get async responses but that is not happening. I've spent some debugging it and mentioned the issue below.\n\n### Version\n\n0.6.24\n\n### Steps to Reproduce\n\n```python\r\nindex = GPTVectorStoreIndex.from_documents(documents=docs, use_async=True)\r\nqe = index.as_query_engine()\r\nqe.async_query(question)\r\n```\r\n\r\nThis will only run sync. This is because all the `ResponseBuilder` objects redirect the `aget_response()` as so\r\n```python\r\n    @llm_token_counter(\"aget_response\")\r\n    async def aget_response(\r\n        self,\r\n        query_str: str,\r\n        text_chunks: Sequence[str],\r\n        prev_response: Optional[str] = None,\r\n        **response_kwargs: Any,\r\n    ) -> RESPONSE_TEXT_TYPE:\r\n        return self.get_response(query_str, text_chunks, prev_response)\r\n```\r\nfilepath: llama_index/indices/response/refine.py\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6463/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6463/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6462",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6462/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6462/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6462/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6462",
        "id": 1756217860,
        "node_id": "PR_kwDOIWuq585S9VMx",
        "number": 6462,
        "title": "Add `OpenAIPydanticProgram` ",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-14T07:10:29Z",
        "updated_at": "2023-06-14T14:37:49Z",
        "closed_at": "2023-06-14T14:37:48Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6462",
            "html_url": "https://github.com/run-llama/llama_index/pull/6462",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6462.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6462.patch",
            "merged_at": "2023-06-14T14:37:48Z"
        },
        "body": "# Description\r\n\r\n* Add `OpenAIPydanticProgram` (analogous to `GuidancePydanticProgram`)\r\n  * This is a very light wrapper on top of new openai API. The main feature it provides is wrapping the conversion between pydantic class to JSON schema, and JSON object to pydantic object.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6462/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6462/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6461",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6461/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6461/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6461/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6461",
        "id": 1756146866,
        "node_id": "PR_kwDOIWuq585S9Frr",
        "number": 6461,
        "title": "Add `OpenAIAgent` and tutorial notebook for \"build your own agent\"",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-14T06:21:48Z",
        "updated_at": "2023-06-14T14:37:36Z",
        "closed_at": "2023-06-14T14:37:35Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6461",
            "html_url": "https://github.com/run-llama/llama_index/pull/6461",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6461.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6461.patch",
            "merged_at": "2023-06-14T14:37:35Z"
        },
        "body": "# Description\r\n\r\n* Add `OpenAIAgent`, a simple agent implementation leveraging new OpenAI tool-use API. \r\n  * It implements the `BaseChatEngine` and `BaseQueryEngine` interface, so could be plugged into other pipelines.\r\n* Add tutorial notebook for \"build your own agent\", showing how easy it is to write an agent, and link from our docs.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6461/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6461/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6460",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6460/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6460/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6460/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6460",
        "id": 1755922470,
        "node_id": "I_kwDOIWuq585oqUAm",
        "number": 6460,
        "title": "[Feature Request]: gpt-3.5-turbo-16k and other new models support",
        "user": {
            "login": "wikylyu",
            "id": 65841899,
            "node_id": "MDQ6VXNlcjY1ODQxODk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/65841899?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wikylyu",
            "html_url": "https://github.com/wikylyu",
            "followers_url": "https://api.github.com/users/wikylyu/followers",
            "following_url": "https://api.github.com/users/wikylyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/wikylyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wikylyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wikylyu/subscriptions",
            "organizations_url": "https://api.github.com/users/wikylyu/orgs",
            "repos_url": "https://api.github.com/users/wikylyu/repos",
            "events_url": "https://api.github.com/users/wikylyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wikylyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-14T02:24:41Z",
        "updated_at": "2023-06-16T17:15:40Z",
        "closed_at": "2023-06-16T17:15:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\r\n\r\n[OpenAI just announced new models](https://openai.com/blog/function-calling-and-other-api-updates). Please support them.\r\n\r\nWith version **0.6.25**, when I pass **gpt-3.5-turbo-16k** to  **ChatOpenAI** like below\r\n\r\n```python\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=ChatOpenAI(\r\n        model='gpt-3.5-turbo-16k',\r\n    ),\r\n)\r\n```\r\n\r\nException raised\r\n```shell\r\nValueError: Unknown model: gpt-3.5-turbo-16k. Please provide a valid OpenAI model name.Known models are: gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-0301, text-ada-001, ada, text-babbage-001, babbage, text-curie-001, curie, davinci, text-davinci-003, text-davinci-002, code-davinci-002, code-davinci-001, code-cushman-002, code-cushman-001\r\n```\r\n\r\n### Reason\r\n\r\n_No response_\r\n\r\n### Value of Feature\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6460/reactions",
            "total_count": 4,
            "+1": 4,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6460/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6459",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6459/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6459/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6459/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6459",
        "id": 1755785301,
        "node_id": "I_kwDOIWuq585opyhV",
        "number": 6459,
        "title": "[Feature Request]: ",
        "user": {
            "login": "0xJepsen",
            "id": 57912727,
            "node_id": "MDQ6VXNlcjU3OTEyNzI3",
            "avatar_url": "https://avatars.githubusercontent.com/u/57912727?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/0xJepsen",
            "html_url": "https://github.com/0xJepsen",
            "followers_url": "https://api.github.com/users/0xJepsen/followers",
            "following_url": "https://api.github.com/users/0xJepsen/following{/other_user}",
            "gists_url": "https://api.github.com/users/0xJepsen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/0xJepsen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/0xJepsen/subscriptions",
            "organizations_url": "https://api.github.com/users/0xJepsen/orgs",
            "repos_url": "https://api.github.com/users/0xJepsen/repos",
            "events_url": "https://api.github.com/users/0xJepsen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/0xJepsen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T23:23:50Z",
        "updated_at": "2023-06-16T17:12:09Z",
        "closed_at": "2023-06-16T17:12:08Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nJust curious if there is rust version of this?\n\n### Reason\n\nRust is fast and memory safe\n\n### Value of Feature\n\nBetter infrastructure",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6459/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6459/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6458",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6458/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6458/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6458/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6458",
        "id": 1755771950,
        "node_id": "I_kwDOIWuq585opvQu",
        "number": 6458,
        "title": "[Bug]: OpenAPI Key doesn't work as environment variable anymore?",
        "user": {
            "login": "jexp",
            "id": 67427,
            "node_id": "MDQ6VXNlcjY3NDI3",
            "avatar_url": "https://avatars.githubusercontent.com/u/67427?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jexp",
            "html_url": "https://github.com/jexp",
            "followers_url": "https://api.github.com/users/jexp/followers",
            "following_url": "https://api.github.com/users/jexp/following{/other_user}",
            "gists_url": "https://api.github.com/users/jexp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jexp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jexp/subscriptions",
            "organizations_url": "https://api.github.com/users/jexp/orgs",
            "repos_url": "https://api.github.com/users/jexp/repos",
            "events_url": "https://api.github.com/users/jexp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jexp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-06-13T23:05:55Z",
        "updated_at": "2023-07-05T00:44:10Z",
        "closed_at": "2023-07-05T00:44:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nNot sure if that's an openai or LlamaIndex integration issue.\r\n\r\nPreviously one could provide the openai key as `OPENAI_API_KEY` but since a week ago my notebook stopped working like that, and raises this error:\r\n\r\n```\r\nAuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n```\r\n\r\nI had to work around the issue with:\r\n\r\n```\r\nimport openai\r\n\r\nload_dotenv(\"openai.env\")\r\nopenai.api_key=os.getenv('OPENAI_API_KEY')\r\n```\r\n\r\nBut that's not ideal.\n\n### Version\n\n0.6.19\n\n### Steps to Reproduce\n\nColab notebook: https://colab.research.google.com/drive/1NUrIoiOh692LaQkBHEmnD-5IuLBpBqGJ#scrollTo=ysVg3VDrUy2Z\n\n### Relevant Logs/Tracbacks\n\n```shell\nAuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6458/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6458/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6456",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6456/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6456/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6456/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6456",
        "id": 1755689957,
        "node_id": "PR_kwDOIWuq585S7iZl",
        "number": 6456,
        "title": "fix citation engine import",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-13T21:49:46Z",
        "updated_at": "2023-06-13T21:56:04Z",
        "closed_at": "2023-06-13T21:56:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6456",
            "html_url": "https://github.com/run-llama/llama_index/pull/6456",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6456.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6456.patch",
            "merged_at": "2023-06-13T21:56:03Z"
        },
        "body": "# Description\r\n\r\n__init__.py got neglected at some point for the citation query engine\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/6454\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6456/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6456/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6455",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6455/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6455/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6455/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6455",
        "id": 1755596433,
        "node_id": "PR_kwDOIWuq585S7OC5",
        "number": 6455,
        "title": "Airbyte SQL example",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-13T20:25:11Z",
        "updated_at": "2023-06-17T02:20:26Z",
        "closed_at": "2023-06-17T02:20:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6455",
            "html_url": "https://github.com/run-llama/llama_index/pull/6455",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6455.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6455.patch",
            "merged_at": "2023-06-17T02:20:25Z"
        },
        "body": "# Description\r\n\r\nWe show an example of a user connecting to a Snowflake SQL DB generated by Airbyte, then we generate a SQL query based on the user's natural language query.\r\n\r\n## Type of Change\r\n\r\nExample notebook\r\n\r\n# How Has This Been Tested?\r\n\r\nNotebook run.\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6455/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6455/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6454",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6454/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6454/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6454/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6454",
        "id": 1755476252,
        "node_id": "I_kwDOIWuq585oonEc",
        "number": 6454,
        "title": "[Bug]: Issue with importing CitationQueryEngine",
        "user": {
            "login": "Sourasky-DHLAB",
            "id": 125898954,
            "node_id": "U_kgDOB4EQyg",
            "avatar_url": "https://avatars.githubusercontent.com/u/125898954?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Sourasky-DHLAB",
            "html_url": "https://github.com/Sourasky-DHLAB",
            "followers_url": "https://api.github.com/users/Sourasky-DHLAB/followers",
            "following_url": "https://api.github.com/users/Sourasky-DHLAB/following{/other_user}",
            "gists_url": "https://api.github.com/users/Sourasky-DHLAB/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Sourasky-DHLAB/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Sourasky-DHLAB/subscriptions",
            "organizations_url": "https://api.github.com/users/Sourasky-DHLAB/orgs",
            "repos_url": "https://api.github.com/users/Sourasky-DHLAB/repos",
            "events_url": "https://api.github.com/users/Sourasky-DHLAB/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Sourasky-DHLAB/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T18:54:05Z",
        "updated_at": "2023-06-13T21:56:04Z",
        "closed_at": "2023-06-13T21:56:04Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen importing the following:\r\nfrom llama_index.query_engine import CitationQueryEngine\r\nThe following error is received:\r\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n\u2502 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553 in run_code        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   3550 \u2502   \u2502   \u2502   \u2502   elif async_ :                                                             \u2502\r\n\u2502   3551 \u2502   \u2502   \u2502   \u2502   \u2502   await eval(code_obj, self.user_global_ns, self.user_ns)               \u2502\r\n\u2502   3552 \u2502   \u2502   \u2502   \u2502   else:                                                                     \u2502\r\n\u2502 \u2771 3553 \u2502   \u2502   \u2502   \u2502   \u2502   exec(code_obj, self.user_global_ns, self.user_ns)                     \u2502\r\n\u2502   3554 \u2502   \u2502   \u2502   finally:                                                                      \u2502\r\n\u2502   3555 \u2502   \u2502   \u2502   \u2502   # Reset our crash handler in place                                        \u2502\r\n\u2502   3556 \u2502   \u2502   \u2502   \u2502   sys.excepthook = old_excepthook                                           \u2502\r\n\u2502 in <cell line: 4>:4                                                                              \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nImportError: cannot import name 'CitationQueryEngine' from 'llama_index.query_engine' \r\n(/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/__init__.py)\n\n### Version\n\n0.6.25.post1\n\n### Steps to Reproduce\n\n!pip install llama_index\r\nfrom llama_index import query_engine\r\nfrom llama_index.query_engine import CitationQueryEngine\n\n### Relevant Logs/Tracbacks\n\n```shell\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n\u2502 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553 in run_code        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   3550 \u2502   \u2502   \u2502   \u2502   elif async_ :                                                             \u2502\r\n\u2502   3551 \u2502   \u2502   \u2502   \u2502   \u2502   await eval(code_obj, self.user_global_ns, self.user_ns)               \u2502\r\n\u2502   3552 \u2502   \u2502   \u2502   \u2502   else:                                                                     \u2502\r\n\u2502 \u2771 3553 \u2502   \u2502   \u2502   \u2502   \u2502   exec(code_obj, self.user_global_ns, self.user_ns)                     \u2502\r\n\u2502   3554 \u2502   \u2502   \u2502   finally:                                                                      \u2502\r\n\u2502   3555 \u2502   \u2502   \u2502   \u2502   # Reset our crash handler in place                                        \u2502\r\n\u2502   3556 \u2502   \u2502   \u2502   \u2502   sys.excepthook = old_excepthook                                           \u2502\r\n\u2502 in <cell line: 3>:3                                                                              \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nImportError: cannot import name 'CitationQueryEngine' from 'llama_index.query_engine' \r\n(/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/__init__.py)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6454/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6454/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6453",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6453/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6453/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6453/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6453",
        "id": 1755398494,
        "node_id": "I_kwDOIWuq585ooUFe",
        "number": 6453,
        "title": "[Bug]: Issue while accessing GPTVectorStoreIndex.from_documents(documents)",
        "user": {
            "login": "bala-ceg",
            "id": 70808619,
            "node_id": "MDQ6VXNlcjcwODA4NjE5",
            "avatar_url": "https://avatars.githubusercontent.com/u/70808619?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bala-ceg",
            "html_url": "https://github.com/bala-ceg",
            "followers_url": "https://api.github.com/users/bala-ceg/followers",
            "following_url": "https://api.github.com/users/bala-ceg/following{/other_user}",
            "gists_url": "https://api.github.com/users/bala-ceg/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bala-ceg/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bala-ceg/subscriptions",
            "organizations_url": "https://api.github.com/users/bala-ceg/orgs",
            "repos_url": "https://api.github.com/users/bala-ceg/repos",
            "events_url": "https://api.github.com/users/bala-ceg/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bala-ceg/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-13T17:57:14Z",
        "updated_at": "2023-06-18T17:15:21Z",
        "closed_at": "2023-06-18T17:15:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nhttps://colab.research.google.com/drive/11UD_FvE-uUl26dhEiAjrXyj0HK73utAQ#scrollTo=YNRPpcI181gk&line=1&uniqifier=1\r\n\r\nI believe Database Reader will have also issues\r\n\r\n\n\n### Version\n\n 0.6.25.post1\n\n### Steps to Reproduce\n\nhttps://colab.research.google.com/drive/11UD_FvE-uUl26dhEiAjrXyj0HK73utAQ?usp=sharing\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6453/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6453/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6452",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6452/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6452/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6452/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6452",
        "id": 1755088230,
        "node_id": "PR_kwDOIWuq585S5eYy",
        "number": 6452,
        "title": "Update: Improved functionality for reading an existing Milvus collection",
        "user": {
            "login": "nawafalageel",
            "id": 67708790,
            "node_id": "MDQ6VXNlcjY3NzA4Nzkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/67708790?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nawafalageel",
            "html_url": "https://github.com/nawafalageel",
            "followers_url": "https://api.github.com/users/nawafalageel/followers",
            "following_url": "https://api.github.com/users/nawafalageel/following{/other_user}",
            "gists_url": "https://api.github.com/users/nawafalageel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nawafalageel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nawafalageel/subscriptions",
            "organizations_url": "https://api.github.com/users/nawafalageel/orgs",
            "repos_url": "https://api.github.com/users/nawafalageel/repos",
            "events_url": "https://api.github.com/users/nawafalageel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nawafalageel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-13T14:56:02Z",
        "updated_at": "2023-07-12T20:13:43Z",
        "closed_at": "2023-07-12T20:13:42Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6452",
            "html_url": "https://github.com/run-llama/llama_index/pull/6452",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6452.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6452.patch",
            "merged_at": "2023-07-12T20:13:42Z"
        },
        "body": "This commit introduces a simple enhancement to the functionality for reading an existing MilvusVectorStore. It allows the reading from a collection created from pymilvus or from VectorStore, ensuring smoother and more reliable access to the data stored in the collection whether using MilvusVectorStore or pymilvus.\r\n\r\n\r\nThe current method of reading an existing collection requires it to be created from MilvusVectorStore provided by LlamaIndex. Consequently, it is forced to have a `consistency_level` of \"Strong\", regardless of whether the user created it from pymilvus and explicitly set the `consistency_level` to \"Strong\". This limitation results in an error message being displayed: \"SchemaNotReadyException: (code=1, message=The parameter consistency_level is inconsistent with that of the existing collection).\"\r\nTo address this issue, the commit allows users to connect to any type of collection without enforcing a `consistency_level` of \"Strong\". Users are no longer required to set the `consistency_level` to \"Strong\" and are spared from encountering the aforementioned error message. This change provides users with the flexibility to choose the appropriate `consistency_level` for their collections, improving the overall usability of the system.\r\n\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] I tested the code with a collection created from pymilvus and from MilvusVectorStore\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6452/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6452/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6451",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6451/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6451/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6451/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6451",
        "id": 1754604296,
        "node_id": "I_kwDOIWuq585olSMI",
        "number": 6451,
        "title": "[Bug]: Index Fetched from local storage always returns NONE ",
        "user": {
            "login": "khushburajani",
            "id": 94789113,
            "node_id": "U_kgDOBaZd-Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/94789113?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/khushburajani",
            "html_url": "https://github.com/khushburajani",
            "followers_url": "https://api.github.com/users/khushburajani/followers",
            "following_url": "https://api.github.com/users/khushburajani/following{/other_user}",
            "gists_url": "https://api.github.com/users/khushburajani/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/khushburajani/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/khushburajani/subscriptions",
            "organizations_url": "https://api.github.com/users/khushburajani/orgs",
            "repos_url": "https://api.github.com/users/khushburajani/repos",
            "events_url": "https://api.github.com/users/khushburajani/events{/privacy}",
            "received_events_url": "https://api.github.com/users/khushburajani/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T10:54:14Z",
        "updated_at": "2023-07-22T02:09:37Z",
        "closed_at": "2023-07-22T02:09:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nFetching of node from documents storage works fine. Currently I have stored index in MongoDb Atlas. Initially when index is created query engine works fine by searching relevant node. On second time when index is passed externally or loaded from storage response returned is always NONE. Can you please help out where this is going wrong ?\r\n\r\n### Version\r\n\r\n0.6.23\r\n\r\n### Steps to Reproduce\r\n\r\n\r\n\r\n\r\nuri = \"mongodb://user:passwrd@cluster0-shard-00.mongodb.net\" //example string\r\n\r\nindex_store = MongoIndexStore.from_uri(uri)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore=MongoDocumentStore.from_uri(uri=uri),\r\n    index_store=index_store)\r\n    \r\nindex = load_index_from_storage(storage_context,index_id='55712fe8-82db-7a21-52a9-c1373f6bff1a')\r\n    or if one index \r\nindex = load_index_from_storage(storage_context')\r\n\r\nvector_retriever = VectorIndexRetriever(index=index, similarity_top_k=1)\r\n\r\n# define response synthesizer\r\nresponse_synthesizer = ResponseSynthesizer.from_args(\r\n    node_postprocessors=[\r\n        SimilarityPostprocessor(similarity_cutoff=0.7)\r\n    ]\r\n)\r\n\r\n# vector query engine\r\nvector_query_engine = RetrieverQueryEngine.from_args(\r\n    retriever=vector_retriever,\r\n    \r\n    # response_mode='compact',\r\n    response_synthesizer=response_synthesizer,\r\n)\r\n\r\nresponse = vector_query_engine.query(\"What is vector?\")\r\n\r\nprint(response.source_nodes)\r\n\r\nprint(response)\r\n\r\n\r\n\r\n\r\n\r\n    \r\n\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n// logs of Index Struct\r\nIndexDict(index_id='f62222fe8-82db-4a21-92a9-czzzzzz', summary=None, nodes_dict={'1111444-1ce2-48a5-84b0-2ec8a596262e': 'a6fdd863-1ce2-48a5-84b0-2ec8a66662e'}, doc_id_dict={}, embeddings_dict={})\r\n\r\n // Logs of nodes\r\n[]\r\n//Response \r\nNone\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6451/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6451/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6450",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6450/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6450/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6450/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6450",
        "id": 1754491908,
        "node_id": "I_kwDOIWuq585ok2wE",
        "number": 6450,
        "title": "[Feature Request]: Make the AI to generate the answer contacting with a specific person",
        "user": {
            "login": "dinhan92",
            "id": 86275789,
            "node_id": "MDQ6VXNlcjg2Mjc1Nzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/86275789?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dinhan92",
            "html_url": "https://github.com/dinhan92",
            "followers_url": "https://api.github.com/users/dinhan92/followers",
            "following_url": "https://api.github.com/users/dinhan92/following{/other_user}",
            "gists_url": "https://api.github.com/users/dinhan92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dinhan92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dinhan92/subscriptions",
            "organizations_url": "https://api.github.com/users/dinhan92/orgs",
            "repos_url": "https://api.github.com/users/dinhan92/repos",
            "events_url": "https://api.github.com/users/dinhan92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dinhan92/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T09:52:14Z",
        "updated_at": "2023-07-22T02:10:37Z",
        "closed_at": "2023-07-22T02:10:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nAs the question, I seem to not be able to find out how to do make the AI to generate the answer that provide a way to contact with a person in case the AI can not answer the question.\n\n### Reason\n\nI think this make the chatbot better, because there are specific questions that the AI can not answer, only a user can answer\n\n### Value of Feature\n\nThis can make the chatbot more comfortable with the user",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6450/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6450/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6449",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6449/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6449/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6449/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6449",
        "id": 1754377859,
        "node_id": "I_kwDOIWuq585oka6D",
        "number": 6449,
        "title": "[Feature Request]: Return native LLM output if context is not found.",
        "user": {
            "login": "reinershir",
            "id": 6177423,
            "node_id": "MDQ6VXNlcjYxNzc0MjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6177423?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/reinershir",
            "html_url": "https://github.com/reinershir",
            "followers_url": "https://api.github.com/users/reinershir/followers",
            "following_url": "https://api.github.com/users/reinershir/following{/other_user}",
            "gists_url": "https://api.github.com/users/reinershir/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/reinershir/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/reinershir/subscriptions",
            "organizations_url": "https://api.github.com/users/reinershir/orgs",
            "repos_url": "https://api.github.com/users/reinershir/repos",
            "events_url": "https://api.github.com/users/reinershir/events{/privacy}",
            "received_events_url": "https://api.github.com/users/reinershir/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T08:55:32Z",
        "updated_at": "2023-07-22T02:11:00Z",
        "closed_at": "2023-07-22T02:11:00Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nFor example, if I want to implement an AI customer service, I hope that when the customer asks a question that does not exist in the document, it will directly return the native answer of GPT-3.5.\r\n\r\n\n\n### Reason\n\nThis is a very common use case\n\n### Value of Feature\n\nThis can achieve AI customer service with faster response speed",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6449/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6449/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6448",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6448/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6448/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6448/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6448",
        "id": 1754317842,
        "node_id": "PR_kwDOIWuq585S20BV",
        "number": 6448,
        "title": "[version] bump version to 0.6.25",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-13T08:22:31Z",
        "updated_at": "2023-06-13T15:24:17Z",
        "closed_at": "2023-06-13T15:24:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6448",
            "html_url": "https://github.com/run-llama/llama_index/pull/6448",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6448.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6448.patch",
            "merged_at": "2023-06-13T15:24:16Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6448/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6448/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6447",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6447/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6447/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6447/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6447",
        "id": 1754269953,
        "node_id": "I_kwDOIWuq585okAkB",
        "number": 6447,
        "title": "[Question]: I want to ask about MongoDb Reader",
        "user": {
            "login": "dinhan92",
            "id": 86275789,
            "node_id": "MDQ6VXNlcjg2Mjc1Nzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/86275789?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dinhan92",
            "html_url": "https://github.com/dinhan92",
            "followers_url": "https://api.github.com/users/dinhan92/followers",
            "following_url": "https://api.github.com/users/dinhan92/following{/other_user}",
            "gists_url": "https://api.github.com/users/dinhan92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dinhan92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dinhan92/subscriptions",
            "organizations_url": "https://api.github.com/users/dinhan92/orgs",
            "repos_url": "https://api.github.com/users/dinhan92/repos",
            "events_url": "https://api.github.com/users/dinhan92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dinhan92/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T07:55:18Z",
        "updated_at": "2023-09-19T16:01:34Z",
        "closed_at": "2023-09-19T16:01:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nCurrently, I see that using SimpleMongoReader, we can only access a collection with specific field names. But my database has a lot of collections with a lot of field names. More, the collections has relationship with each other. How do I use SimpleMongoReader with my database? Or, is there any other method?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6447/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6447/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6446",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6446/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6446/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6446/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6446",
        "id": 1754240991,
        "node_id": "PR_kwDOIWuq585S2jfj",
        "number": 6446,
        "title": "Add MMR",
        "user": {
            "login": "jeremy-brouillet",
            "id": 63084626,
            "node_id": "MDQ6VXNlcjYzMDg0NjI2",
            "avatar_url": "https://avatars.githubusercontent.com/u/63084626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeremy-brouillet",
            "html_url": "https://github.com/jeremy-brouillet",
            "followers_url": "https://api.github.com/users/jeremy-brouillet/followers",
            "following_url": "https://api.github.com/users/jeremy-brouillet/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeremy-brouillet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeremy-brouillet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeremy-brouillet/subscriptions",
            "organizations_url": "https://api.github.com/users/jeremy-brouillet/orgs",
            "repos_url": "https://api.github.com/users/jeremy-brouillet/repos",
            "events_url": "https://api.github.com/users/jeremy-brouillet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeremy-brouillet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-13T07:38:56Z",
        "updated_at": "2023-06-15T23:16:18Z",
        "closed_at": "2023-06-15T07:17:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6446",
            "html_url": "https://github.com/run-llama/llama_index/pull/6446",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6446.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6446.patch",
            "merged_at": "2023-06-15T07:17:58Z"
        },
        "body": "# Description\r\n\r\nThis change adds a maximum marginal relevance option for the SimpleVectorStore. By enabling the mmr query mode, the SimpleVectorStore will change from comparing vectors based purely on similarity to adding a diversity factor based on similarity to previous results. Additionally, a notebook was added with a simple example as well as tests.\r\n\r\nFixes # (issue)\r\n\r\nNo issues.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6446/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6446/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6445",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6445/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6445/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6445/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6445",
        "id": 1754231028,
        "node_id": "I_kwDOIWuq585oj3D0",
        "number": 6445,
        "title": "[Question]: Can you create an index with one LLM and query using another",
        "user": {
            "login": "Samshive",
            "id": 18461798,
            "node_id": "MDQ6VXNlcjE4NDYxNzk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/18461798?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Samshive",
            "html_url": "https://github.com/Samshive",
            "followers_url": "https://api.github.com/users/Samshive/followers",
            "following_url": "https://api.github.com/users/Samshive/following{/other_user}",
            "gists_url": "https://api.github.com/users/Samshive/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Samshive/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Samshive/subscriptions",
            "organizations_url": "https://api.github.com/users/Samshive/orgs",
            "repos_url": "https://api.github.com/users/Samshive/repos",
            "events_url": "https://api.github.com/users/Samshive/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Samshive/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-13T07:32:40Z",
        "updated_at": "2023-07-22T02:11:11Z",
        "closed_at": "2023-07-22T02:11:11Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi \r\n\r\nGreat tool btw, I was wondering if it is possible to create an index with one LLM and query using another. I'm specifically trying to reduce the cost for index creation by using a cheaper model for index creation, but I want the power of the more capable LLMs when responding to queries. \r\n\r\nYour assistance is much appreciated. \r\n\r\nKind regards",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6445/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6445/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6444",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6444/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6444/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6444/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6444",
        "id": 1754175207,
        "node_id": "I_kwDOIWuq585ojpbn",
        "number": 6444,
        "title": "[Feature Request]: Salesforce connector",
        "user": {
            "login": "akshat-khare",
            "id": 25928898,
            "node_id": "MDQ6VXNlcjI1OTI4ODk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/25928898?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/akshat-khare",
            "html_url": "https://github.com/akshat-khare",
            "followers_url": "https://api.github.com/users/akshat-khare/followers",
            "following_url": "https://api.github.com/users/akshat-khare/following{/other_user}",
            "gists_url": "https://api.github.com/users/akshat-khare/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/akshat-khare/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/akshat-khare/subscriptions",
            "organizations_url": "https://api.github.com/users/akshat-khare/orgs",
            "repos_url": "https://api.github.com/users/akshat-khare/repos",
            "events_url": "https://api.github.com/users/akshat-khare/events{/privacy}",
            "received_events_url": "https://api.github.com/users/akshat-khare/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-13T06:56:50Z",
        "updated_at": "2023-09-19T16:08:32Z",
        "closed_at": "2023-09-19T16:08:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nLike airtable we should also be having salesforce connector. It is there in main page of the app but I couldn't find it on hub/documentation/discord\r\n<img width=\"1228\" alt=\"Screenshot 2023-06-13 at 12 26 20 PM\" src=\"https://github.com/jerryjliu/llama_index/assets/25928898/d9921caf-4593-42b9-bf09-38b2702aade1\">\r\n\n\n### Reason\n\nMight be pricey. salesforce is pricey. Also not a lot of general devs might not be using salesforce. \n\n### Value of Feature\n\nSalesforce is the biggest CRM and having a connector will open up a plethora of opportunities.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6444/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6444/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6443",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6443/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6443/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6443/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6443",
        "id": 1754095358,
        "node_id": "PR_kwDOIWuq585S2EGF",
        "number": 6443,
        "title": "extra space in prompt and error message update",
        "user": {
            "login": "yisding",
            "id": 1209314,
            "node_id": "MDQ6VXNlcjEyMDkzMTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1209314?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yisding",
            "html_url": "https://github.com/yisding",
            "followers_url": "https://api.github.com/users/yisding/followers",
            "following_url": "https://api.github.com/users/yisding/following{/other_user}",
            "gists_url": "https://api.github.com/users/yisding/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yisding/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yisding/subscriptions",
            "organizations_url": "https://api.github.com/users/yisding/orgs",
            "repos_url": "https://api.github.com/users/yisding/repos",
            "events_url": "https://api.github.com/users/yisding/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yisding/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-13T05:58:11Z",
        "updated_at": "2023-06-20T07:51:07Z",
        "closed_at": "2023-06-20T07:51:07Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6443",
            "html_url": "https://github.com/run-llama/llama_index/pull/6443",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6443.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6443.patch",
            "merged_at": "2023-06-20T07:51:07Z"
        },
        "body": "# Description\r\n\r\nRemoved extra space in prompt and updated error message.\r\n\r\n## Type of Change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] My changes generate no new warnings\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6443/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6443/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6441",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6441/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6441/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6441/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6441",
        "id": 1753868664,
        "node_id": "I_kwDOIWuq585oiel4",
        "number": 6441,
        "title": "[Feature Request]: Create Elasticsearch VectorStore",
        "user": {
            "login": "jeffvestal",
            "id": 53237856,
            "node_id": "MDQ6VXNlcjUzMjM3ODU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/53237856?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeffvestal",
            "html_url": "https://github.com/jeffvestal",
            "followers_url": "https://api.github.com/users/jeffvestal/followers",
            "following_url": "https://api.github.com/users/jeffvestal/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeffvestal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeffvestal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeffvestal/subscriptions",
            "organizations_url": "https://api.github.com/users/jeffvestal/orgs",
            "repos_url": "https://api.github.com/users/jeffvestal/repos",
            "events_url": "https://api.github.com/users/jeffvestal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeffvestal/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "jeffvestal",
            "id": 53237856,
            "node_id": "MDQ6VXNlcjUzMjM3ODU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/53237856?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jeffvestal",
            "html_url": "https://github.com/jeffvestal",
            "followers_url": "https://api.github.com/users/jeffvestal/followers",
            "following_url": "https://api.github.com/users/jeffvestal/following{/other_user}",
            "gists_url": "https://api.github.com/users/jeffvestal/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jeffvestal/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jeffvestal/subscriptions",
            "organizations_url": "https://api.github.com/users/jeffvestal/orgs",
            "repos_url": "https://api.github.com/users/jeffvestal/repos",
            "events_url": "https://api.github.com/users/jeffvestal/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jeffvestal/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jeffvestal",
                "id": 53237856,
                "node_id": "MDQ6VXNlcjUzMjM3ODU2",
                "avatar_url": "https://avatars.githubusercontent.com/u/53237856?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jeffvestal",
                "html_url": "https://github.com/jeffvestal",
                "followers_url": "https://api.github.com/users/jeffvestal/followers",
                "following_url": "https://api.github.com/users/jeffvestal/following{/other_user}",
                "gists_url": "https://api.github.com/users/jeffvestal/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jeffvestal/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jeffvestal/subscriptions",
                "organizations_url": "https://api.github.com/users/jeffvestal/orgs",
                "repos_url": "https://api.github.com/users/jeffvestal/repos",
                "events_url": "https://api.github.com/users/jeffvestal/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jeffvestal/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-06-13T01:36:08Z",
        "updated_at": "2023-11-07T05:43:52Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nCreate Elasticsearch Vector store\r\n- Create index to store vectors with correct mapping\r\n-- option for exact match and knn dense_vector settings\r\n- delete index\r\n- perform exact match (script score) vector search\r\n- perform approximate kNN vector search\r\n- Generate embeddings from Elasticsearch hosted embedding model\n\n### Reason\n\nElasticsearch supports vector search (exact and kNN) and can be used as a vector database\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6441/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6441/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6440",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6440/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6440/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6440/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6440",
        "id": 1753801423,
        "node_id": "PR_kwDOIWuq585S1E86",
        "number": 6440,
        "title": "add token counting callback",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-13T00:32:30Z",
        "updated_at": "2023-06-15T18:07:22Z",
        "closed_at": "2023-06-15T18:07:21Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6440",
            "html_url": "https://github.com/run-llama/llama_index/pull/6440",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6440.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6440.patch",
            "merged_at": "2023-06-15T18:07:21Z"
        },
        "body": "# Description\r\n\r\nAdd a specific token counting callback. This should replace the llm_predictor and embed_model token counters.\r\n\r\nThe implementation is fairly un-hand-holdy. It's up to the user to decide when to reset token counts, which counts the care about, etc.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# TODO:\r\n\r\n- [x] Update docs\r\n- [x] Decide what to do with old token counting (How to deprecate? This needs to be a loud change, many users depend on token counting.)\r\n- [x] changelog\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6440/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6440/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6439",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6439/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6439/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6439/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6439",
        "id": 1753572004,
        "node_id": "PR_kwDOIWuq585S0SVo",
        "number": 6439,
        "title": "docs: replace comma with colon in dict object",
        "user": {
            "login": "YasmineMh",
            "id": 42073781,
            "node_id": "MDQ6VXNlcjQyMDczNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42073781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YasmineMh",
            "html_url": "https://github.com/YasmineMh",
            "followers_url": "https://api.github.com/users/YasmineMh/followers",
            "following_url": "https://api.github.com/users/YasmineMh/following{/other_user}",
            "gists_url": "https://api.github.com/users/YasmineMh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YasmineMh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YasmineMh/subscriptions",
            "organizations_url": "https://api.github.com/users/YasmineMh/orgs",
            "repos_url": "https://api.github.com/users/YasmineMh/repos",
            "events_url": "https://api.github.com/users/YasmineMh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YasmineMh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-12T20:57:31Z",
        "updated_at": "2023-06-20T07:51:40Z",
        "closed_at": "2023-06-20T07:51:39Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6439",
            "html_url": "https://github.com/run-llama/llama_index/pull/6439",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6439.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6439.patch",
            "merged_at": "2023-06-20T07:51:39Z"
        },
        "body": "# Description\r\n\r\nThe change involves correcting the syntax of the extra_info dictionary in the Document constructor and the subsequent assignment to document.extra_info. The issue fixed is the incorrect syntax of the extra_info dictionary in the old documentation.\r\n\r\nSo mainly, I replaced `,` with `:`\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] No tests needed\r\n\r\n# Suggested Checklist:\r\n- [x] I have made corresponding changes to the documentation\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6439/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6439/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6438",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6438/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6438/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6438/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6438",
        "id": 1753322049,
        "node_id": "I_kwDOIWuq585ogZJB",
        "number": 6438,
        "title": "[Bug]: LLMPredictor using ChatOpenAI / OpenAI requires OpenAI Key in Environment Variables",
        "user": {
            "login": "mac-ema",
            "id": 129894174,
            "node_id": "U_kgDOB74HHg",
            "avatar_url": "https://avatars.githubusercontent.com/u/129894174?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mac-ema",
            "html_url": "https://github.com/mac-ema",
            "followers_url": "https://api.github.com/users/mac-ema/followers",
            "following_url": "https://api.github.com/users/mac-ema/following{/other_user}",
            "gists_url": "https://api.github.com/users/mac-ema/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mac-ema/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mac-ema/subscriptions",
            "organizations_url": "https://api.github.com/users/mac-ema/orgs",
            "repos_url": "https://api.github.com/users/mac-ema/repos",
            "events_url": "https://api.github.com/users/mac-ema/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mac-ema/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-12T18:27:09Z",
        "updated_at": "2023-07-22T02:12:42Z",
        "closed_at": "2023-07-22T02:12:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWe load our environment variables from a remote secret manager into a settings class and call that vs back populating everything into our bash environment. This means openly calling the langchain OpenAI implementation as done [here](https://github.com/jerryjliu/llama_index/blob/main/llama_index/llm_predictor/base.py#L46-L55), we get a Validation Error thrown despite properly loading our key into the LLM object thats passed in.\n\n### Version\n\nv0.6.23\n\n### Steps to Reproduce\n\nRun the following script. I added in the bit to wipe the OpenAI token from the environment to ensure test mirrors our experience.\r\n\r\n```\r\nimport os\r\n\r\nfrom langchain.chat_models import ChatOpenAI\r\nfrom llama_index import LLMPredictor, ServiceContext\r\n\r\n\r\ndef repro(openai_token):\r\n    os.environ[\"OPENAI_API_KEY\"] = \"\"\r\n    llm_predictor = LLMPredictor(\r\n        llm=ChatOpenAI(\r\n            temperature=0.3,\r\n            model_name=\"gpt-3.5-turbo\",\r\n            openai_api_key=openai_token,\r\n        ),\r\n    )\r\n    service_context = ServiceContext.from_defaults(\r\n        llm_predictor=llm_predictor, chunk_size=1600\r\n    )  # this throws an error\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nValidationError: 1 validation error for OpenAI\r\n__root__\r\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)\r\n  File \"starlette/applications.py\", line 122, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  -snip-\r\n  File \"ema_backend/model/utils/indices.py\", line 150, in build_document_query_engine\r\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size=1600)\r\n  File \"llama_index/indices/service_context.py\", line 141, in from_defaults\r\n    llm_metadata=llm_predictor.get_llm_metadata(),\r\n  File \"llama_index/llm_predictor/base.py\", line 177, in get_llm_metadata\r\n    return _get_llm_metadata(self._llm)\r\n  File \"llama_index/llm_predictor/base.py\", line 53, in _get_llm_metadata\r\n    context_window=OpenAI().modelname_to_contextsize(llm.model_name),\r\n  File \"pydantic/main.py\", line 341, in pydantic.main.BaseModel.__init__\r\n    raise validation_error\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6438/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6438/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6437",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6437/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6437/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6437/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6437",
        "id": 1753220354,
        "node_id": "PR_kwDOIWuq585SzE7E",
        "number": 6437,
        "title": "[version] bump version to 0.6.24",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-12T17:27:29Z",
        "updated_at": "2023-06-12T19:42:11Z",
        "closed_at": "2023-06-12T19:42:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6437",
            "html_url": "https://github.com/run-llama/llama_index/pull/6437",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6437.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6437.patch",
            "merged_at": "2023-06-12T19:42:10Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6437/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6437/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6436",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6436/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6436/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6436/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6436",
        "id": 1753132051,
        "node_id": "I_kwDOIWuq585ofqwT",
        "number": 6436,
        "title": "[Bug]: Error using Azure opeani",
        "user": {
            "login": "qypanzer",
            "id": 130947046,
            "node_id": "U_kgDOB84X5g",
            "avatar_url": "https://avatars.githubusercontent.com/u/130947046?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/qypanzer",
            "html_url": "https://github.com/qypanzer",
            "followers_url": "https://api.github.com/users/qypanzer/followers",
            "following_url": "https://api.github.com/users/qypanzer/following{/other_user}",
            "gists_url": "https://api.github.com/users/qypanzer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/qypanzer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/qypanzer/subscriptions",
            "organizations_url": "https://api.github.com/users/qypanzer/orgs",
            "repos_url": "https://api.github.com/users/qypanzer/repos",
            "events_url": "https://api.github.com/users/qypanzer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/qypanzer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-12T16:38:45Z",
        "updated_at": "2023-07-12T17:13:45Z",
        "closed_at": "2023-07-12T17:13:45Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen I use azure openai, index = GPTVectorStoreIndex.from_documents(documents) always returns with \"INFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\"\r\n\r\nI guess it's because the engine parameter for azure openai is not set properly. \r\n\r\nimport logging\r\nimport sys\r\nimport requests\r\nimport openai\r\nimport os\r\n\r\nAPI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\") \r\nRESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_APIBASE\") \r\n\r\nopenai.api_type = \"azure\"\r\nopenai.api_key = API_KEY\r\nopenai.api_base = RESOURCE_ENDPOINT\r\nopenai.api_version = \"2022-12-01\"\r\nopenai.Engine = \"td3\"\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\nfrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\nindex = GPTVectorStoreIndex.from_documents(documents)\n\n### Version\n\n0.6.10.post1\n\n### Steps to Reproduce\n\nimport logging\r\nimport sys\r\nimport requests\r\nimport openai\r\nimport os\r\n\r\nAPI_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\") \r\nRESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_APIBASE\") \r\n\r\nopenai.api_type = \"azure\"\r\nopenai.api_key = API_KEY\r\nopenai.api_base = RESOURCE_ENDPOINT\r\nopenai.api_version = \"2022-12-01\"\r\nopenai.Engine = \"td3\"\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\nfrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\nindex = GPTVectorStoreIndex.from_documents(documents)\n\n### Relevant Logs/Tracbacks\n\n```shell\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nINFO:openai:error_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\nerror_code=OperationNotSupported error_message='The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.' error_param=None error_type=None message='OpenAI API error received' stream_error=False\r\n---------------------------------------------------------------------------\r\nInvalidRequestError                       Traceback (most recent call last)\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:382, in Retrying.__call__(self, fn, *args, **kwargs)\r\n    381 try:\r\n--> 382     result = fn(*args, **kwargs)\r\n    383 except BaseException:  # noqa: B902\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\embeddings\\openai.py:150, in get_embeddings(list_of_text, engine, **kwargs)\r\n    148 list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\r\n--> 150 data = openai.Embedding.create(input=list_of_text, model=engine, **kwargs).data\r\n    151 return [d[\"embedding\"] for d in data]\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\embedding.py:33, in Embedding.create(cls, *args, **kwargs)\r\n     32 try:\r\n---> 33     response = super().create(*args, **kwargs)\r\n     35     # If a user specifies base64, we'll just return the encoded string.\r\n     36     # This is only for the default case.\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155, in EngineAPIResource.create(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\r\n    140 (\r\n    141     deployment_id,\r\n    142     engine,\r\n   (...)\r\n    152     api_key, api_base, api_type, api_version, organization, **params\r\n    153 )\r\n--> 155 response, _, api_key = requestor.request(\r\n    156     \"post\",\r\n    157     url,\r\n    158     params=params,\r\n    159     headers=headers,\r\n    160     stream=stream,\r\n    161     request_id=request_id,\r\n    162     request_timeout=request_timeout,\r\n    163 )\r\n    165 if stream:\r\n    166     # must be an iterator\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:226, in APIRequestor.request(self, method, url, params, headers, files, stream, request_id, request_timeout)\r\n    216 result = self.request_raw(\r\n    217     method.lower(),\r\n    218     url,\r\n   (...)\r\n    224     request_timeout=request_timeout,\r\n    225 )\r\n--> 226 resp, got_stream = self._interpret_response(result, stream)\r\n    227 return resp, got_stream, self.api_key\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:619, in APIRequestor._interpret_response(self, result, stream)\r\n    617 else:\r\n    618     return (\r\n--> 619         self._interpret_response_line(\r\n    620             result.content.decode(\"utf-8\"),\r\n    621             result.status_code,\r\n    622             result.headers,\r\n    623             stream=False,\r\n    624         ),\r\n    625         False,\r\n    626     )\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\openai\\api_requestor.py:682, in APIRequestor._interpret_response_line(self, rbody, rcode, rheaders, stream)\r\n    681 if stream_error or not 200 <= rcode < 300:\r\n--> 682     raise self.handle_error_response(\r\n    683         rbody, rcode, resp.data, rheaders, stream_error=stream_error\r\n    684     )\r\n    685 return resp\r\n\r\nInvalidRequestError: The embeddings operation does not work with the specified model, gpt-35-turbo. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nRetryError                                Traceback (most recent call last)\r\nCell In[12], line 26\r\n     22 from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\r\n     24 documents = SimpleDirectoryReader('data').load_data()\r\n---> 26 index = GPTVectorStoreIndex.from_documents(documents)\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\base.py:93, in BaseGPTIndex.from_documents(cls, documents, storage_context, service_context, **kwargs)\r\n     89     docstore.set_document_hash(doc.get_doc_id(), doc.get_doc_hash())\r\n     91 nodes = service_context.node_parser.get_nodes_from_documents(documents)\r\n---> 93 return cls(\r\n     94     nodes=nodes,\r\n     95     storage_context=storage_context,\r\n     96     service_context=service_context,\r\n     97     **kwargs,\r\n     98 )\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:44, in GPTVectorStoreIndex.__init__(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, **kwargs)\r\n     42 self._use_async = use_async\r\n     43 self._store_nodes_override = store_nodes_override\r\n---> 44 super().__init__(\r\n     45     nodes=nodes,\r\n     46     index_struct=index_struct,\r\n     47     service_context=service_context,\r\n     48     storage_context=storage_context,\r\n     49     **kwargs,\r\n     50 )\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\base.py:65, in BaseGPTIndex.__init__(self, nodes, index_struct, storage_context, service_context, **kwargs)\r\n     63 if index_struct is None:\r\n     64     assert nodes is not None\r\n---> 65     index_struct = self.build_index_from_nodes(nodes)\r\n     66 self._index_struct = index_struct\r\n     67 self._storage_context.index_store.add_index_struct(self._index_struct)\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\token_counter\\token_counter.py:78, in llm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict(_self, *args, **kwargs)\r\n     76 def wrapped_llm_predict(_self: Any, *args: Any, **kwargs: Any) -> Any:\r\n     77     with wrapper_logic(_self):\r\n---> 78         f_return_val = f(_self, *args, **kwargs)\r\n     80     return f_return_val\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:203, in GPTVectorStoreIndex.build_index_from_nodes(self, nodes)\r\n    195 @llm_token_counter(\"build_index_from_nodes\")\r\n    196 def build_index_from_nodes(self, nodes: Sequence[Node]) -> IndexDict:\r\n    197     \"\"\"Build the index from nodes.\r\n    198 \r\n    199     NOTE: Overrides BaseGPTIndex.build_index_from_nodes.\r\n    200         GPTVectorStoreIndex only stores nodes in document store\r\n    201         if vector store does not store text\r\n    202     \"\"\"\r\n--> 203     return self._build_index_from_nodes(nodes)\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:192, in GPTVectorStoreIndex._build_index_from_nodes(self, nodes)\r\n    190     run_async_tasks(tasks)\r\n    191 else:\r\n--> 192     self._add_nodes_to_index(index_struct, nodes)\r\n    193 return index_struct\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:168, in GPTVectorStoreIndex._add_nodes_to_index(self, index_struct, nodes)\r\n    165 if not nodes:\r\n    166     return\r\n--> 168 embedding_results = self._get_node_embedding_results(nodes)\r\n    169 new_ids = self._vector_store.add(embedding_results)\r\n    171 if not self._vector_store.stores_text or self._store_nodes_override:\r\n    172     # NOTE: if the vector store doesn't store text,\r\n    173     # we need to add the nodes to the index struct and document store\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:87, in GPTVectorStoreIndex._get_node_embedding_results(self, nodes)\r\n     81         id_to_embed_map[n.get_doc_id()] = n.embedding\r\n     83 # call embedding model to get embeddings\r\n     84 (\r\n     85     result_ids,\r\n     86     result_embeddings,\r\n---> 87 ) = self._service_context.embed_model.get_queued_text_embeddings()\r\n     88 for new_id, text_embedding in zip(result_ids, result_embeddings):\r\n     89     id_to_embed_map[new_id] = text_embedding\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\embeddings\\base.py:167, in BaseEmbedding.get_queued_text_embeddings(self)\r\n    165 cur_batch_ids = [text_id for text_id, _ in cur_batch]\r\n    166 cur_batch_texts = [text for _, text in cur_batch]\r\n--> 167 embeddings = self._get_text_embeddings(cur_batch_texts)\r\n    168 result_ids.extend(cur_batch_ids)\r\n    169 result_embeddings.extend(embeddings)\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\llama_index\\embeddings\\openai.py:267, in OpenAIEmbedding._get_text_embeddings(self, texts)\r\n    260 def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\r\n    261     \"\"\"Get text embeddings.\r\n    262 \r\n    263     By default, this is a wrapper around _get_text_embedding.\r\n    264     Can be overriden for batch queries.\r\n    265 \r\n    266     \"\"\"\r\n--> 267     return get_embeddings(\r\n    268         texts,\r\n    269         engine=self.text_engine,\r\n    270         deployment_id=self.deployment_name,\r\n    271         **self.openai_kwargs,\r\n    272     )\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:289, in BaseRetrying.wraps.<locals>.wrapped_f(*args, **kw)\r\n    287 @functools.wraps(f)\r\n    288 def wrapped_f(*args: t.Any, **kw: t.Any) -> t.Any:\r\n--> 289     return self(f, *args, **kw)\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:379, in Retrying.__call__(self, fn, *args, **kwargs)\r\n    377 retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)\r\n    378 while True:\r\n--> 379     do = self.iter(retry_state=retry_state)\r\n    380     if isinstance(do, DoAttempt):\r\n    381         try:\r\n\r\nFile ~\\miniconda3\\envs\\py310\\lib\\site-packages\\tenacity\\__init__.py:326, in BaseRetrying.iter(self, retry_state)\r\n    324     if self.reraise:\r\n    325         raise retry_exc.reraise()\r\n--> 326     raise retry_exc from fut.exception()\r\n    328 if self.wait:\r\n    329     sleep = self.wait(retry_state)\r\n\r\nRetryError: RetryError[<Future at 0x21376f0b2e0 state=finished raised InvalidRequestError>]\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6436/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6436/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6435",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6435/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6435/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6435/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6435",
        "id": 1752990648,
        "node_id": "I_kwDOIWuq585ofIO4",
        "number": 6435,
        "title": "[Question]: _validate_is_flat_dict check extra_info fail when using QdrantVectorStore",
        "user": {
            "login": "Myoungs",
            "id": 15648026,
            "node_id": "MDQ6VXNlcjE1NjQ4MDI2",
            "avatar_url": "https://avatars.githubusercontent.com/u/15648026?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Myoungs",
            "html_url": "https://github.com/Myoungs",
            "followers_url": "https://api.github.com/users/Myoungs/followers",
            "following_url": "https://api.github.com/users/Myoungs/following{/other_user}",
            "gists_url": "https://api.github.com/users/Myoungs/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Myoungs/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Myoungs/subscriptions",
            "organizations_url": "https://api.github.com/users/Myoungs/orgs",
            "repos_url": "https://api.github.com/users/Myoungs/repos",
            "events_url": "https://api.github.com/users/Myoungs/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Myoungs/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-12T15:17:31Z",
        "updated_at": "2023-06-25T06:25:10Z",
        "closed_at": "2023-06-25T06:25:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nWhen I build index with QdrantVectorStore, I add filename in extra_info field. The value of extra_info is dict type, which causes the _validate_is_flat_dict to check the value of the key, which will fail, because extra_info is not a string, integer, float or None. **So I wonder if it is possible to add this dict type ?**\r\n\r\nbuild index codes:  \r\n\r\n    file_meta = lambda filename: {\"filename\": filename}\r\n\r\n    loader = SimpleDirectoryReader(\r\n        dir_path, \r\n        recursive=True, \r\n        exclude_hidden=False, \r\n        file_metadata=file_meta,\r\n    )\r\n\r\n    documents =loader.load_data()\r\n\r\n    index = GPTVectorStoreIndex.from_documents(\r\n        documents,\r\n        service_context=service_context,\r\n        storage_context=storage_context,\r\n    )\r\n\r\n\r\nquery index codes:\r\n\r\n    query_engine = index.as_query_engine(\r\n        service_context=service_context,\r\n        similarity_top_k=2,\r\n    )\r\n    response = query_engine.query(query_str)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6435/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6435/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6434",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6434/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6434/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6434/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6434",
        "id": 1752764892,
        "node_id": "I_kwDOIWuq585oeRHc",
        "number": 6434,
        "title": "[Question]: ImportError: cannot import name 'ChatGPTRetrievalPluginIndex' from 'llama_index.indices.vector_store'",
        "user": {
            "login": "DevAhnsh",
            "id": 44568006,
            "node_id": "MDQ6VXNlcjQ0NTY4MDA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/44568006?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DevAhnsh",
            "html_url": "https://github.com/DevAhnsh",
            "followers_url": "https://api.github.com/users/DevAhnsh/followers",
            "following_url": "https://api.github.com/users/DevAhnsh/following{/other_user}",
            "gists_url": "https://api.github.com/users/DevAhnsh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DevAhnsh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DevAhnsh/subscriptions",
            "organizations_url": "https://api.github.com/users/DevAhnsh/orgs",
            "repos_url": "https://api.github.com/users/DevAhnsh/repos",
            "events_url": "https://api.github.com/users/DevAhnsh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DevAhnsh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-12T13:24:42Z",
        "updated_at": "2023-10-24T06:29:07Z",
        "closed_at": "2023-10-24T06:29:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nhttps://gpt-index.readthedocs.io/en/latest/how_to/integrations/chatgpt_plugins.html#chatgpt-retrieval-plugin-index\r\n\r\nI followed the example in the article above and it says that ChatGPTRetrievalPluginIndex is not found.\r\n\r\nHas ChatGPTRetrievalPluginIndex been removed?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6434/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6434/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6433",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6433/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6433/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6433/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6433",
        "id": 1752569163,
        "node_id": "PR_kwDOIWuq585Sw2OJ",
        "number": 6433,
        "title": "Fix schema error of pinecone date type",
        "user": {
            "login": "IANTHEREAL",
            "id": 10701973,
            "node_id": "MDQ6VXNlcjEwNzAxOTcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10701973?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IANTHEREAL",
            "html_url": "https://github.com/IANTHEREAL",
            "followers_url": "https://api.github.com/users/IANTHEREAL/followers",
            "following_url": "https://api.github.com/users/IANTHEREAL/following{/other_user}",
            "gists_url": "https://api.github.com/users/IANTHEREAL/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IANTHEREAL/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IANTHEREAL/subscriptions",
            "organizations_url": "https://api.github.com/users/IANTHEREAL/orgs",
            "repos_url": "https://api.github.com/users/IANTHEREAL/repos",
            "events_url": "https://api.github.com/users/IANTHEREAL/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IANTHEREAL/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-12T11:46:26Z",
        "updated_at": "2023-06-16T02:50:58Z",
        "closed_at": "2023-06-16T02:50:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6433",
            "html_url": "https://github.com/run-llama/llama_index/pull/6433",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6433.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6433.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nThe date type extra_info field would cause a ValueError when retrieving data from Pinecone. The error occurred because the date was not stored as a string, while Llama_index requires values to be one of (str, int, float, None).\r\n\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\nsome steps to reproduce\r\n```\r\ndef text_to_document(texts: List[str], corpus:str, source:str) -> List[LlamaDocument]:  \r\n    \"\"\"Return a Document object from a text string.\"\"\"  \r\n    documents = []  \r\n    for line in texts:  \r\n        metadata = {  \r\n            \"source\": source,  \r\n            \"corpus\": corpus,  \r\n            \"creare_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  \r\n        }  \r\n        document = LlamaDocument(line.strip(), extra_info=metadata)  \r\n        documents.append(document)  \r\n    return documents  \r\n  \r\ndocs = text_to_document([\"test case\"], \"it-corpus\", \"service-record\")  \r\nprint(type(docs[0].extra_info[\"creare_at\"]))  \r\n  \r\nfor doc in docs:  \r\n    nodes = index.service_context.node_parser.get_nodes_from_documents([doc])  \r\n    index.insert_nodes(nodes)  \r\n  \r\nquery_engine = index.as_query_engine()  \r\nprint(query_engine.query(\"test case\"))  \r\n```\r\n\r\nit will output\r\n```\r\n<class 'str'>\r\nTraceback (most recent call last):\r\n.....\r\n  File \"/Users/ianz/Work/miniconda3/envs/autoxx/lib/python3.10/site-packages/llama_index/schema.py\", line 21, in _validate_is_flat_dict\r\n    raise ValueError(\"Value must be one of (str, int, float, None)\")\r\nValueError: Value must be one of (str, int, float, None)\r\n```\r\n\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6433/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6433/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6432",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6432/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6432/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6432/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6432",
        "id": 1752555954,
        "node_id": "I_kwDOIWuq585odeGy",
        "number": 6432,
        "title": "[Bug]: redis vector query error:Property `vector_score` not loaded nor in schema",
        "user": {
            "login": "Garfield-yin",
            "id": 12005405,
            "node_id": "MDQ6VXNlcjEyMDA1NDA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12005405?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Garfield-yin",
            "html_url": "https://github.com/Garfield-yin",
            "followers_url": "https://api.github.com/users/Garfield-yin/followers",
            "following_url": "https://api.github.com/users/Garfield-yin/following{/other_user}",
            "gists_url": "https://api.github.com/users/Garfield-yin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Garfield-yin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Garfield-yin/subscriptions",
            "organizations_url": "https://api.github.com/users/Garfield-yin/orgs",
            "repos_url": "https://api.github.com/users/Garfield-yin/repos",
            "events_url": "https://api.github.com/users/Garfield-yin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Garfield-yin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-12T11:39:23Z",
        "updated_at": "2023-06-12T13:26:15Z",
        "closed_at": "2023-06-12T13:26:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nrom llama_index.vector_stores.types import MetadataFilters, ExactMatchFilter\r\n\r\nindex = VectorStoreIndex.from_vector_store(\r\n    vector_store=vector_store,\r\n    storage_context=storage_context)\r\n\r\nquery_engine = index.as_query_engine(\r\n    similarity_top_k=3,\r\n)\r\n\r\nGot error: redis.exceptions.ResponseError: Property `vector_score` not loaded nor in schema\n\n### Version\n\n0.6.23\n\n### Steps to Reproduce\n\nuse redis vector demo:\r\nhttps://gpt-index.readthedocs.io/en/latest/examples/vector_stores/RedisIndexDemo.html\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6432/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6432/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6431",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6431/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6431/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6431/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6431",
        "id": 1752193990,
        "node_id": "I_kwDOIWuq585ocFvG",
        "number": 6431,
        "title": "[Question]: How to config BeautifulSoupWebReader to get in other page inside a domain?",
        "user": {
            "login": "dinhan92",
            "id": 86275789,
            "node_id": "MDQ6VXNlcjg2Mjc1Nzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/86275789?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dinhan92",
            "html_url": "https://github.com/dinhan92",
            "followers_url": "https://api.github.com/users/dinhan92/followers",
            "following_url": "https://api.github.com/users/dinhan92/following{/other_user}",
            "gists_url": "https://api.github.com/users/dinhan92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dinhan92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dinhan92/subscriptions",
            "organizations_url": "https://api.github.com/users/dinhan92/orgs",
            "repos_url": "https://api.github.com/users/dinhan92/repos",
            "events_url": "https://api.github.com/users/dinhan92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dinhan92/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-12T08:22:13Z",
        "updated_at": "2023-09-18T16:01:22Z",
        "closed_at": "2023-09-18T16:01:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIt seems that BeautifulSoupWebReader or SimpleWebpageReader can only get data from first page, I have tried both but can not get data from the pages indside, for example pagination or the detail post inside a list of url in a page",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6431/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6431/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6430",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6430/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6430/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6430/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6430",
        "id": 1752172447,
        "node_id": "I_kwDOIWuq585ocAef",
        "number": 6430,
        "title": "How to return streaming response to frontend? react or flask [Feature Request]: ",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-12T08:11:13Z",
        "updated_at": "2023-10-14T20:09:19Z",
        "closed_at": "2023-10-14T20:09:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nHow to return streaming response to frontend? react or flask [Feature Request]: \n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6430/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6430/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6429",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6429/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6429/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6429/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6429",
        "id": 1751696638,
        "node_id": "PR_kwDOIWuq585St5At",
        "number": 6429,
        "title": "Update schema.py",
        "user": {
            "login": "omarih33",
            "id": 83776220,
            "node_id": "MDQ6VXNlcjgzNzc2MjIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/83776220?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/omarih33",
            "html_url": "https://github.com/omarih33",
            "followers_url": "https://api.github.com/users/omarih33/followers",
            "following_url": "https://api.github.com/users/omarih33/following{/other_user}",
            "gists_url": "https://api.github.com/users/omarih33/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/omarih33/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/omarih33/subscriptions",
            "organizations_url": "https://api.github.com/users/omarih33/orgs",
            "repos_url": "https://api.github.com/users/omarih33/repos",
            "events_url": "https://api.github.com/users/omarih33/events{/privacy}",
            "received_events_url": "https://api.github.com/users/omarih33/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-12T01:04:20Z",
        "updated_at": "2023-06-14T21:52:47Z",
        "closed_at": "2023-06-14T21:52:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6429",
            "html_url": "https://github.com/run-llama/llama_index/pull/6429",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6429.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6429.patch",
            "merged_at": null
        },
        "body": "Added formatted_source_nodes as a method of Response class\r\n\r\n# Description\r\n\r\nReason for this change is to make it easier to read the source nodes. \r\n\r\n## Type of Change\r\n\r\n- [ x ] New feature (non-breaking change which adds functionality)\r\n- [ x ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nprint(response.formatted_source_nodes())\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6429/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6429/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6428",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6428/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6428/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6428/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6428",
        "id": 1751637138,
        "node_id": "I_kwDOIWuq585oZ9yS",
        "number": 6428,
        "title": "[Bug]: DocumentSummaryIndex not updating properly",
        "user": {
            "login": "jppaolim",
            "id": 73477568,
            "node_id": "MDQ6VXNlcjczNDc3NTY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/73477568?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jppaolim",
            "html_url": "https://github.com/jppaolim",
            "followers_url": "https://api.github.com/users/jppaolim/followers",
            "following_url": "https://api.github.com/users/jppaolim/following{/other_user}",
            "gists_url": "https://api.github.com/users/jppaolim/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jppaolim/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jppaolim/subscriptions",
            "organizations_url": "https://api.github.com/users/jppaolim/orgs",
            "repos_url": "https://api.github.com/users/jppaolim/repos",
            "events_url": "https://api.github.com/users/jppaolim/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jppaolim/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-11T22:49:23Z",
        "updated_at": "2023-06-14T11:10:02Z",
        "closed_at": "2023-06-14T11:10:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nWhen updating a persisting index with new documents in the folder, sometimes it works, sometimes it exists with a doc_id 459843bb-d74e-431c-9e27-a59ec25df9a8 not in index message.  \r\nTo be noted : otherwise it works like a charm :) it's just the update, which is problematic as I don't want to generate the whole database of summary each time !! \r\n\r\n### Version\r\n\r\n0.6.20\r\n\r\n### Steps to Reproduce\r\n\r\nput some file in a DOC_DIRECTORY \r\nBuild the index with something like : \r\n\r\n```python \r\n...\r\n llm_predictor = LLMPredictor(llm=llm)\r\n\r\n service_context = ServiceContext.from_defaults(\r\n        llm_predictor=llm_predictor,\r\n        embed_model=embed_model,\r\n        prompt_helper=PromptHelper(context_window=2048-150,   num_output=MAXTOKEN, chunk_overlap_ratio=0.1),\r\n        chunk_size=CHUNK_SIZE_LLAMAINDEX, \r\n        node_parser=SimpleNodeParser(SentenceSplitter(chunk_size=CHUNK_SIZE_LLAMAINDEX, chunk_overlap=OVERLAP))\r\n)\r\n\r\nMyResponse_synthesizer = ResponseSynthesizer.from_args(\r\n        response_mode=\"tree_summarize\",\r\n        #important locally to not use async \r\n        use_async=False,\r\n        text_qa_template=Prompt(read_str_prompt(PROMPTSUMMARYDOC)),\r\n        refine_template=Prompt(read_str_prompt(PROMPTSUMMARYDOCREFINE)),\r\n        service_context=service_context\r\n)\r\n\r\n documents = SimpleDirectoryReader(DOC_DIRECTORY, filename_as_id=True).load_data()\r\n\r\nstorage_context = StorageContext.from_defaults(persist_dir=\"./storage\") \r\nindex_summary = load_index_from_storage(storage_context, service_context=service_context, response_synthesizer=MyResponse_synthesizer, summary_query=Prompt(read_str_prompt(PROMPTSUMMARYDOC)))   \r\n        \r\n index_summary.refresh_ref_docs(documents,\r\n          update_kwargs={\"delete_kwargs\": {'delete_from_docstore': True}}\r\n      )\r\n\r\n ```\r\n \r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n**********\r\nTrace: index_construction\r\n**********\r\ncurrent doc id: RessourcesDummy/302 Forgetto Mori.md\r\ncurrent doc id: RessourcesDummy/10 Minutes to Deploying a Deep Learning Model on Google Cloud Platform.md\r\ncurrent doc id: RessourcesDummy/A guide to prompting AI (for what it is worth) copy.md\r\ncurrent doc id: RessourcesDummy/20210895 Une m\u00e9thode pour projeter l \u00e9quipe.md\r\ncurrent doc id: RessourcesDummy/20210815 pourquoi le ML n'est pas la solution en NLU.md\r\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Traceback (most recent call last) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\r\n\u2502 /Users/jppm/Coding/MyCode/ObsidianAIQA/qadocllama.py:184 in <module>                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   181                                                                                            \u2502\r\n\u2502   182                                                                                            \u2502\r\n\u2502   183 if __name__ == \"__main__\":                                                                 \u2502\r\n\u2502 \u2771 184 \u2502   main()                                                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /Users/jppm/Coding/MyCode/ObsidianAIQA/qadocllama.py:164 in main                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   161 #    index_summary.refresh_ref_docs(documents,                                             \u2502\r\n\u2502   162 #            update_kwargs={\"delete_kwargs\": {'delete_from_docstore': True}}               \u2502\r\n\u2502   163 #            )                                                                             \u2502\r\n\u2502 \u2771 164 \u2502   \u2502   index_summary.refresh_ref_docs(documents)                                          \u2502\r\n\u2502   165 \u2502   \u2502   index_summary.storage_context.persist(persist_dir=\"./storage\")                     \u2502\r\n\u2502   166                                                                                            \u2502\r\n\u2502   167                                                                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/homebrew/Caskroom/miniforge/base/envs/ObsidianAIQA/lib/python3.10/site-packages/llama_index \u2502\r\n\u2502 /indices/base.py:310 in refresh_ref_docs                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   307 \u2502   \u2502   \u2502   \u2502   \u2502   document.get_doc_id()                                                  \u2502\r\n\u2502   308 \u2502   \u2502   \u2502   \u2502   )                                                                          \u2502\r\n\u2502   309 \u2502   \u2502   \u2502   \u2502   if existing_doc_hash != document.get_doc_hash():                           \u2502\r\n\u2502 \u2771 310 \u2502   \u2502   \u2502   \u2502   \u2502   self.update_ref_doc(                                                   \u2502\r\n\u2502   311 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   document, **update_kwargs.pop(\"update_kwargs\", {})                 \u2502\r\n\u2502   312 \u2502   \u2502   \u2502   \u2502   \u2502   )                                                                      \u2502\r\n\u2502   313 \u2502   \u2502   \u2502   \u2502   \u2502   refreshed_documents[i] = True                                          \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/homebrew/Caskroom/miniforge/base/envs/ObsidianAIQA/lib/python3.10/site-packages/llama_index \u2502\r\n\u2502 /indices/base.py:274 in update_ref_doc                                                           \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   271 \u2502   \u2502                                                                                      \u2502\r\n\u2502   272 \u2502   \u2502   \"\"\"                                                                                \u2502\r\n\u2502   273 \u2502   \u2502   with self._service_context.callback_manager.as_trace(\"update\"):                    \u2502\r\n\u2502 \u2771 274 \u2502   \u2502   \u2502   self.delete_ref_doc(                                                           \u2502\r\n\u2502   275 \u2502   \u2502   \u2502   \u2502   document.get_doc_id(), **update_kwargs.pop(\"delete_kwargs\", {})            \u2502\r\n\u2502   276 \u2502   \u2502   \u2502   )                                                                              \u2502\r\n\u2502   277 \u2502   \u2502   \u2502   self.insert(document, **update_kwargs.pop(\"insert_kwargs\", {}))                \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/homebrew/Caskroom/miniforge/base/envs/ObsidianAIQA/lib/python3.10/site-packages/llama_index \u2502\r\n\u2502 /indices/base.py:236 in delete_ref_doc                                                           \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   233 \u2502   \u2502   \u2502   logger.warning(f\"ref_doc_id {ref_doc_id} not found, nothing deleted.\")         \u2502\r\n\u2502   234 \u2502   \u2502   \u2502   return                                                                         \u2502\r\n\u2502   235 \u2502   \u2502                                                                                      \u2502\r\n\u2502 \u2771 236 \u2502   \u2502   self.delete_nodes(                                                                 \u2502\r\n\u2502   237 \u2502   \u2502   \u2502   ref_doc_info.doc_ids,                                                          \u2502\r\n\u2502   238 \u2502   \u2502   \u2502   delete_from_docstore=delete_from_docstore,                                     \u2502\r\n\u2502   239 \u2502   \u2502   \u2502   **delete_kwargs,                                                               \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/homebrew/Caskroom/miniforge/base/envs/ObsidianAIQA/lib/python3.10/site-packages/llama_index \u2502\r\n\u2502 /indices/base.py:207 in delete_nodes                                                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   204 \u2502   \u2502                                                                                      \u2502\r\n\u2502   205 \u2502   \u2502   \"\"\"                                                                                \u2502\r\n\u2502   206 \u2502   \u2502   for doc_id in doc_ids:                                                             \u2502\r\n\u2502 \u2771 207 \u2502   \u2502   \u2502   self._delete_node(doc_id, **delete_kwargs)                                     \u2502\r\n\u2502   208 \u2502   \u2502   \u2502   if delete_from_docstore:                                                       \u2502\r\n\u2502   209 \u2502   \u2502   \u2502   \u2502   self.docstore.delete_document(doc_id, raise_error=False)                   \u2502\r\n\u2502   210                                                                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/homebrew/Caskroom/miniforge/base/envs/ObsidianAIQA/lib/python3.10/site-packages/llama_index \u2502\r\n\u2502 /indices/document_summary/base.py:162 in _delete_node                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   159 \u2502   def _delete_node(self, doc_id: str, **delete_kwargs: Any) -> None:                     \u2502\r\n\u2502   160 \u2502   \u2502   \"\"\"Delete a node.\"\"\"                                                               \u2502\r\n\u2502   161 \u2502   \u2502   if doc_id not in self._index_struct.doc_id_to_summary_id:                          \u2502\r\n\u2502 \u2771 162 \u2502   \u2502   \u2502   raise ValueError(f\"doc_id {doc_id} not in index\")                              \u2502\r\n\u2502   163 \u2502   \u2502   summary_id = self._index_struct.doc_id_to_summary_id[doc_id]                       \u2502\r\n\u2502   164 \u2502   \u2502                                                                                      \u2502\r\n\u2502   165 \u2502   \u2502   # delete summary node from docstore                                                \u2502\r\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\r\nValueError: doc_id 459843bb-d74e-431c-9e27-a59ec25df9a8 not in index\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6428/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6428/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6427",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6427/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6427/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6427/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6427",
        "id": 1751631134,
        "node_id": "PR_kwDOIWuq585StrcB",
        "number": 6427,
        "title": "docs: Privacy and security",
        "user": {
            "login": "EmanuelCampos",
            "id": 16262455,
            "node_id": "MDQ6VXNlcjE2MjYyNDU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/16262455?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/EmanuelCampos",
            "html_url": "https://github.com/EmanuelCampos",
            "followers_url": "https://api.github.com/users/EmanuelCampos/followers",
            "following_url": "https://api.github.com/users/EmanuelCampos/following{/other_user}",
            "gists_url": "https://api.github.com/users/EmanuelCampos/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/EmanuelCampos/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/EmanuelCampos/subscriptions",
            "organizations_url": "https://api.github.com/users/EmanuelCampos/orgs",
            "repos_url": "https://api.github.com/users/EmanuelCampos/repos",
            "events_url": "https://api.github.com/users/EmanuelCampos/events{/privacy}",
            "received_events_url": "https://api.github.com/users/EmanuelCampos/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-11T22:25:18Z",
        "updated_at": "2023-06-11T23:39:09Z",
        "closed_at": "2023-06-11T23:39:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6427",
            "html_url": "https://github.com/run-llama/llama_index/pull/6427",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6427.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6427.patch",
            "merged_at": "2023-06-11T23:39:09Z"
        },
        "body": "# Description\r\n\r\nThere's a lot of questions usually on Discord about Privacy of data\r\n\r\nFixes # (issue)\r\n\r\n#6169 \r\n\r\n## Type of Change\r\n\r\n- [ ] Documentation update",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6427/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6427/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6422",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6422/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6422/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6422/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6422",
        "id": 1751333356,
        "node_id": "PR_kwDOIWuq585SsuZy",
        "number": 6422,
        "title": "fix guideline eval import",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-11T09:06:06Z",
        "updated_at": "2023-06-11T17:27:47Z",
        "closed_at": "2023-06-11T17:27:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6422",
            "html_url": "https://github.com/run-llama/llama_index/pull/6422",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6422.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6422.patch",
            "merged_at": "2023-06-11T17:27:46Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6422/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6422/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6421",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6421/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6421/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6421/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6421",
        "id": 1751325899,
        "node_id": "PR_kwDOIWuq585Sss2g",
        "number": 6421,
        "title": "Minor update to retry query engine notebook",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-11T08:45:29Z",
        "updated_at": "2023-06-11T08:59:57Z",
        "closed_at": "2023-06-11T08:59:57Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6421",
            "html_url": "https://github.com/run-llama/llama_index/pull/6421",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6421.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6421.patch",
            "merged_at": "2023-06-11T08:59:57Z"
        },
        "body": "# Description\r\n\r\nMinor update to retry query engine notebook\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6421/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6421/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6420",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6420/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6420/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6420/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6420",
        "id": 1751321290,
        "node_id": "PR_kwDOIWuq585Ssr5K",
        "number": 6420,
        "title": "[version] bump version to 0.6.23",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-11T08:32:25Z",
        "updated_at": "2023-06-11T15:38:18Z",
        "closed_at": "2023-06-11T15:38:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6420",
            "html_url": "https://github.com/run-llama/llama_index/pull/6420",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6420.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6420.patch",
            "merged_at": "2023-06-11T15:38:17Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6420/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6420/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6419",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6419/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6419/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6419/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6419",
        "id": 1751316325,
        "node_id": "PR_kwDOIWuq585Ssq2c",
        "number": 6419,
        "title": "add instruct flare query engine ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-11T08:18:47Z",
        "updated_at": "2023-06-13T08:20:24Z",
        "closed_at": "2023-06-13T08:20:24Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6419",
            "html_url": "https://github.com/run-llama/llama_index/pull/6419",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6419.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6419.patch",
            "merged_at": "2023-06-13T08:20:23Z"
        },
        "body": "# Description\r\n\r\nInitial implementation of FLARE, specifically the instruction variant where we use the LLM to generate \"Search\" tags to do a secondary retrieval pass.\r\n\r\nI couldn't quite grok everything in the source repo, but I did implement an initial version that I felt made sense:\r\n- At the beginning, feed in user query and the existing answer.\r\n- Generate a \"lookahead\" sentence that contains \"search\" tags. Parse this lookahead sentence and extract the search tags, and run those against a query engine to extract the answers. Insert into the lookahead template for an actual answer.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6419/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6419/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6418",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6418/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6418/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6418/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6418",
        "id": 1751302011,
        "node_id": "PR_kwDOIWuq585Ssnvf",
        "number": 6418,
        "title": "Fix notebook",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-11T07:49:40Z",
        "updated_at": "2023-06-11T07:51:47Z",
        "closed_at": "2023-06-11T07:51:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6418",
            "html_url": "https://github.com/run-llama/llama_index/pull/6418",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6418.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6418.patch",
            "merged_at": "2023-06-11T07:51:46Z"
        },
        "body": "# Description\r\n\r\nMinor notebook fix \r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/6198\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6418/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6418/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6417",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6417/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6417/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6417/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6417",
        "id": 1751295864,
        "node_id": "I_kwDOIWuq585oYqd4",
        "number": 6417,
        "title": "[Documentation]: Prompt Template documentation for individual types are off",
        "user": {
            "login": "pycui",
            "id": 6148473,
            "node_id": "MDQ6VXNlcjYxNDg0NzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6148473?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pycui",
            "html_url": "https://github.com/pycui",
            "followers_url": "https://api.github.com/users/pycui/followers",
            "following_url": "https://api.github.com/users/pycui/following{/other_user}",
            "gists_url": "https://api.github.com/users/pycui/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pycui/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pycui/subscriptions",
            "organizations_url": "https://api.github.com/users/pycui/orgs",
            "repos_url": "https://api.github.com/users/pycui/repos",
            "events_url": "https://api.github.com/users/pycui/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pycui/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-11T07:29:03Z",
        "updated_at": "2023-06-22T07:06:33Z",
        "closed_at": "2023-06-22T07:06:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nIn https://gpt-index.readthedocs.io/en/stable/reference/prompts.html#llama_index.prompts.prompts.RefinePrompt, the individual prompts' descriptions seem off. For example:\r\n\r\nllama_index.prompts.prompts.QuestionAnswerPrompt\r\n- Keyword extract prompt.\r\n- ...(continue with keyword related info)\r\n\r\nllama_index.prompts.prompts.QueryKeywordExtractPrompt\r\n- Schema extract prompt.\r\n- ...\r\n\r\nSeems like they are shuffled to an incorrect order. \r\n\r\n\n\n### Documenation Link\n\nhttps://gpt-index.readthedocs.io/en/stable/reference/prompts.html#llama_index.prompts.prompts.RefinePrompt",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6417/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6417/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6415",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6415/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6415/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6415/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6415",
        "id": 1751262650,
        "node_id": "I_kwDOIWuq585oYiW6",
        "number": 6415,
        "title": "[Question]: Why are Japanese characters being saved as escaped Unicode?",
        "user": {
            "login": "tmforai60",
            "id": 96938949,
            "node_id": "U_kgDOBccrxQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/96938949?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tmforai60",
            "html_url": "https://github.com/tmforai60",
            "followers_url": "https://api.github.com/users/tmforai60/followers",
            "following_url": "https://api.github.com/users/tmforai60/following{/other_user}",
            "gists_url": "https://api.github.com/users/tmforai60/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tmforai60/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tmforai60/subscriptions",
            "organizations_url": "https://api.github.com/users/tmforai60/orgs",
            "repos_url": "https://api.github.com/users/tmforai60/repos",
            "events_url": "https://api.github.com/users/tmforai60/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tmforai60/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            },
            {
                "id": 5860091515,
                "node_id": "LA_kwDOIWuq588AAAABXUnmew",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/stale",
                "name": "stale",
                "color": "dadada",
                "default": false,
                "description": "Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-11T06:00:11Z",
        "updated_at": "2023-10-24T06:28:59Z",
        "closed_at": "2023-10-24T06:28:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHello,\r\nI create saved a docstore in the way below.\r\nIt has texts written in unicode with escape, not in Japanese character(or UTF-8) which I want.\r\n\r\nHow can I solve the problem?\r\nThank you for your help.\r\n\r\n```\r\nCode:\r\nfrom langchain import text_splitter\r\nfrom llama_index.indices.loading import load_index_from_storage\r\nfrom llama_index import StorageContext\r\nfrom llama_index.storage.docstore import SimpleDocumentStore\r\nfrom llama_index.storage.index_store import SimpleIndexStore\r\nfrom llama_index.vector_stores import SimpleVectorStore\r\n\r\nfrom llama_index import ServiceContext\r\nfrom llama_index.node_parser import SimpleNodeParser\r\nfrom llama_index.embeddings.openai import OpenAIEmbedding\r\nfrom llama_index import LLMPredictor\r\nfrom llama_index.indices.prompt_helper import PromptHelper\r\nfrom llama_index.logger.base import LlamaLogger\r\nfrom llama_index.callbacks.base import CallbackManager\r\n\r\nfrom llama_index import VectorStoreIndex\r\nfrom llama_index import ResponseSynthesizer\r\nfrom llama_index.optimization.optimizer import SentenceEmbeddingOptimizer\r\nfrom llama_index import SimpleDirectoryReader\r\nfrom llama_index.indices.vector_store.retrievers import VectorIndexRetriever\r\nfrom llama_index.vector_stores.types import VectorStoreQueryMode\r\nfrom llama_index.query_engine.retriever_query_engine import RetrieverQueryEngine\r\nfrom llama_index import LLMPredictor\r\n\r\nfrom llama_index import GPTListIndex\r\nfrom llama_index.llm_predictor.chatgpt import ChatOpenAI\r\n\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\n\r\nllm_predictor = ChatGPTLLMPredictor(\r\n    llm=ChatOpenAI(\r\n        temperature=0,\r\n        model_name='gpt-3.5-turbo',\r\n        streaming=True\r\n        )\r\n)\r\n\r\n'''\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore=SimpleDocumentStore(),\r\n    vector_store=SimpleVectorStore(),\r\n    index_store=SimpleIndexStore()\r\n)\r\n\r\nfrom llama_index.langchain_helpers.text_splitter import TokenTextSplitter\r\nfrom llama_index.constants import DEFAULT_CHUNK_OVERLAP, DEFAULT_CHUNK_SIZE\r\nimport tiktoken\r\n\r\ntext_splitter = TokenTextSplitter(separator=\" \", chunk_size=DEFAULT_CHUNK_SIZE\r\n    , chunk_overlap=DEFAULT_CHUNK_OVERLAP\r\n    , tokenizer=tiktoken.get_encoding(\"cl100k_base\").encode)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    node_parser=SimpleNodeParser(text_splitter=text_splitter),\r\n    embed_model=OpenAIEmbedding(),\r\n    llm_predictor=llm_predictor,\r\n    prompt_helper=PromptHelper.from_llm_metadata(llm_predictor.get_llm_metadata()),\r\n    llama_logger=LlamaLogger(),\r\n    callback_manager=CallbackManager([])\r\n)\r\n\r\nindex.set_index_id(\"test\")\r\nindex.storage_context.persist(\"./storage\")\r\n```\r\n\r\ndocstore\r\n{\"docstore/metadata\":...},` \"docstore/data\": {\"...\": {\"__data__\": {\"text\": \"\\u6c11\\u4e8b\\u88c1\\u5224\\u306b\\u304a\\u3044\\u3066...\", \"doc_id\": ...\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6415/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6415/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6414",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6414/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6414/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6414/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6414",
        "id": 1751255505,
        "node_id": "I_kwDOIWuq585oYgnR",
        "number": 6414,
        "title": "[Bug]: API key not assigned even if the key environment variable is set!!",
        "user": {
            "login": "nick26",
            "id": 425538,
            "node_id": "MDQ6VXNlcjQyNTUzOA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/425538?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nick26",
            "html_url": "https://github.com/nick26",
            "followers_url": "https://api.github.com/users/nick26/followers",
            "following_url": "https://api.github.com/users/nick26/following{/other_user}",
            "gists_url": "https://api.github.com/users/nick26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nick26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nick26/subscriptions",
            "organizations_url": "https://api.github.com/users/nick26/orgs",
            "repos_url": "https://api.github.com/users/nick26/repos",
            "events_url": "https://api.github.com/users/nick26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nick26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-11T05:29:55Z",
        "updated_at": "2023-06-11T07:34:41Z",
        "closed_at": "2023-06-11T07:34:41Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nRunning on google colab:\r\nAuthentication Error\r\n\r\nI have set openai_api_key in environment variable as well as tried to pass it in the call but I still get this error.\r\nDo not understand what I am doing wrong, all of my programs are failing at this point\r\n\r\n\r\n\n\n### Version\n\nlastest\n\n### Steps to Reproduce\n\n\r\nimport os\r\nos.environ [\"OPENAI_API_KEY\"]='a valid key'\r\nos.environ.get('OPENAI_API_KEY')\r\n\r\nfrom llama_index import GPTVectorStoreIndex, StorageContext, ServiceContext\r\nfrom llama_index.embeddings.openai import OpenAIEmbedding\r\n\r\n# setup our storage (vector db)\r\nstorage_context = StorageContext.from_defaults(\r\n    vector_store=vector_store\r\n)\r\n# setup the index/query process, ie the embedding model (and completion if used)\r\nembed_model = OpenAIEmbedding(model='text-embedding-ada-002', embed_batch_size=100)\r\nservice_context = ServiceContext.from_defaults(embed_model=embed_model)\r\n\r\n\r\n# fails at this point\r\nindex = GPTVectorStoreIndex.from_documents(\r\n    docs, storage_context=storage_context,\r\n    service_context=service_context\r\n)\n\n### Relevant Logs/Tracbacks\n\n```shell\nAuthenticationError                       Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py](https://localhost:8080/#) in __call__(self, fn, *args, **kwargs)\r\n    381                 try:\r\n--> 382                     result = fn(*args, **kwargs)\r\n    383                 except BaseException:  # noqa: B902\r\n\r\n19 frames\r\nAuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nRetryError                                Traceback (most recent call last)\r\n[/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py](https://localhost:8080/#) in iter(self, retry_state)\r\n    324             if self.reraise:\r\n    325                 raise retry_exc.reraise()\r\n--> 326             raise retry_exc from fut.exception()\r\n    327 \r\n    328         if self.wait:\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6414/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6414/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6409",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6409/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6409/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6409/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6409",
        "id": 1751042746,
        "node_id": "PR_kwDOIWuq585SryKJ",
        "number": 6409,
        "title": "Add ChangeLog to the docs",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-10T17:03:43Z",
        "updated_at": "2023-08-28T17:11:11Z",
        "closed_at": "2023-06-10T19:46:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6409",
            "html_url": "https://github.com/run-llama/llama_index/pull/6409",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6409.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6409.patch",
            "merged_at": "2023-06-10T19:46:11Z"
        },
        "body": "# Description\r\n\r\nDisplay the ChangeLog in the docs\r\n\r\n## Type of Change\r\n\r\n- [x] This change requires a documentation update\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have made corresponding changes to the documentation",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6409/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6409/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6408",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6408/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6408/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6408/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6408",
        "id": 1751026796,
        "node_id": "PR_kwDOIWuq585SrvBK",
        "number": 6408,
        "title": "Remove hardcoded chunk size for citation query engine",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-10T16:12:17Z",
        "updated_at": "2023-08-28T17:10:41Z",
        "closed_at": "2023-06-10T16:23:44Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6408",
            "html_url": "https://github.com/run-llama/llama_index/pull/6408",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6408.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6408.patch",
            "merged_at": "2023-06-10T16:23:44Z"
        },
        "body": "# Description\r\n\r\nCitation query engine had the chunk size hardcoded\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6408/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6408/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6407",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6407/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6407/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6407/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6407",
        "id": 1751018173,
        "node_id": "I_kwDOIWuq585oXmq9",
        "number": 6407,
        "title": "[Bug]:  cannot import name 'Protocol' from 'typing'",
        "user": {
            "login": "lacls",
            "id": 42736388,
            "node_id": "MDQ6VXNlcjQyNzM2Mzg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/42736388?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lacls",
            "html_url": "https://github.com/lacls",
            "followers_url": "https://api.github.com/users/lacls/followers",
            "following_url": "https://api.github.com/users/lacls/following{/other_user}",
            "gists_url": "https://api.github.com/users/lacls/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lacls/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lacls/subscriptions",
            "organizations_url": "https://api.github.com/users/lacls/orgs",
            "repos_url": "https://api.github.com/users/lacls/repos",
            "events_url": "https://api.github.com/users/lacls/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lacls/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-10T15:46:03Z",
        "updated_at": "2023-06-11T07:53:55Z",
        "closed_at": "2023-06-11T07:53:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAfter installing by the follwing command: \"pip install llama-index\" \r\n\r\nI got an error of cannot import name 'Protocol' from 'typing'\r\n\r\n<img width=\"769\" alt=\"Screen Shot 2023-06-10 at 22 44 35\" src=\"https://github.com/jerryjliu/llama_index/assets/42736388/214820a2-ec38-4ce6-ba09-5a8950830e9d\">\r\n\r\nMany thanks for your reading and support.\n\n### Version\n\n0.5.9\n\n### Steps to Reproduce\n\nError after running an install command \n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6407/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6407/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6406",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6406/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6406/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6406/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6406",
        "id": 1751008705,
        "node_id": "PR_kwDOIWuq585Srra7",
        "number": 6406,
        "title": "Mongo demo improvements",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-10T15:20:11Z",
        "updated_at": "2023-06-10T18:19:23Z",
        "closed_at": "2023-06-10T18:19:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6406",
            "html_url": "https://github.com/run-llama/llama_index/pull/6406",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6406.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6406.patch",
            "merged_at": "2023-06-10T18:19:22Z"
        },
        "body": "Moved MongoDB vector store notebook to the right directory.\r\n\r\nAdded links to notebooks to docs.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6406/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6406/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6404",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6404/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6404/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6404/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6404",
        "id": 1750926142,
        "node_id": "I_kwDOIWuq585oXQM-",
        "number": 6404,
        "title": "[Bug]: cannot import name 'SQLStructStoreIndex' from 'llama_index' ",
        "user": {
            "login": "GregXD",
            "id": 133116162,
            "node_id": "U_kgDOB-8xAg",
            "avatar_url": "https://avatars.githubusercontent.com/u/133116162?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GregXD",
            "html_url": "https://github.com/GregXD",
            "followers_url": "https://api.github.com/users/GregXD/followers",
            "following_url": "https://api.github.com/users/GregXD/following{/other_user}",
            "gists_url": "https://api.github.com/users/GregXD/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GregXD/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GregXD/subscriptions",
            "organizations_url": "https://api.github.com/users/GregXD/orgs",
            "repos_url": "https://api.github.com/users/GregXD/repos",
            "events_url": "https://api.github.com/users/GregXD/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GregXD/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-10T11:17:02Z",
        "updated_at": "2023-07-22T02:15:08Z",
        "closed_at": "2023-07-22T02:15:08Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\nI'm getting this error when trying to build an index on top of structured data (sqlite)\r\n\r\n    from llama_index import SQLStructStoreIndex\r\n    ImportError: cannot import name 'SQLStructStoreIndex' from 'llama_index' \r\n\r\nI'm using the latest version of Llama-Index. Trying to build an index on top of structured data. The other Llama imports are working fine.\r\n\r\nIs this method deprecated? I'm following these docs: https://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/SQLIndexDemo-Context.html#build-index-with-context\r\n\r\n### Version\r\n\r\n0.6.22\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index import SQLStructStoreIndex\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nCell In[26], line 1\r\n----> 1 from llama_index import SQLStructStoreIndex\r\n\r\nImportError: cannot import name 'SQLStructStoreIndex' from 'llama_index'\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6404/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6404/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6402",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6402/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6402/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6402/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6402",
        "id": 1750919275,
        "node_id": "I_kwDOIWuq585oXOhr",
        "number": 6402,
        "title": "[Question]: Why the summary of a Chinese document may be in English, and when it's in Chinese, its lenth is only 220",
        "user": {
            "login": "qypanzer",
            "id": 130947046,
            "node_id": "U_kgDOB84X5g",
            "avatar_url": "https://avatars.githubusercontent.com/u/130947046?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/qypanzer",
            "html_url": "https://github.com/qypanzer",
            "followers_url": "https://api.github.com/users/qypanzer/followers",
            "following_url": "https://api.github.com/users/qypanzer/following{/other_user}",
            "gists_url": "https://api.github.com/users/qypanzer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/qypanzer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/qypanzer/subscriptions",
            "organizations_url": "https://api.github.com/users/qypanzer/orgs",
            "repos_url": "https://api.github.com/users/qypanzer/repos",
            "events_url": "https://api.github.com/users/qypanzer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/qypanzer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-10T10:52:10Z",
        "updated_at": "2023-09-16T16:17:34Z",
        "closed_at": "2023-09-16T16:17:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nIt's strange that when I uses \r\n\r\ndoc_summary_index = GPTDocumentSummaryIndex.from_documents(\r\n    city_docs, \r\n    service_context=service_context,\r\n    response_synthesizer=response_synthesizer,\r\n    summary_query=summary_query\r\n)\r\n\r\nThe summary output is in English... \r\n\r\n<llama_index.indices.query.response_synthesis.ResponseSynthesizer object at 0x000001CED4A436A0>\r\ncurrent doc id: 7700da5d-460b-4ac8-902f-8f68a0934606\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 940 tokens\r\n> [get_response] Total LLM token usage: 940 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\r\n> [get_response] Total embedding token usage: 0 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 940 tokens\r\n> [get_response] Total LLM token usage: 940 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\r\n> [get_response] Total embedding token usage: 0 tokens\r\nINFO:llama_index.indices.document_summary.base:> Generated summary for doc 7700da5d-460b-4ac8-902f-8f68a0934606: - DeepGlint is a company that uses AI to make computers understand the world and benefit humanity.\r\n- The company has a visual computing platform called DeepGlint Zhuyuan.\r\n- The platform has a cloud-edge architecture that maximizes visual computing efficiency.\r\n- The platform has high-performance, cost-effective edge computing products and intelligent camera products.\r\n- The platform has a full-target core technology that can be used in various application scenarios.\r\n- The platform has a series of products, including Haomu behavior analyzer and Huimu camera, that can be used in various application scenarios.\r\n- The platform has accurate big data collection and recognition capabilities that can be used in various application scenarios.\r\n- The platform can be used in various application scenarios, such as urban management, smart finance, and commercial retail.\r\n- The document can answer questions such as: What is DeepGlint? What is DeepGlint Zhuyuan? What is the architecture of DeepGlint Zhuyuan? What are the products of DeepGlint Zhuyuan? What are the capabilities of DeepGlint Zhuyuan? What are the application scenarios of DeepGlint Zhuyuan?<|im_end|>\r\n> Generated summary for doc 7700da5d-460b-4ac8-902f-8f68a0934606: - DeepGlint is a company that uses AI to make computers understand the world and benefit humanity.\r\n- The company has a visual computing platform called DeepGlint Zhuyuan.\r\n- The platform has a cloud-edge architecture that maximizes visual computing efficiency.\r\n- The platform has high-performance, cost-effective edge computing products and intelligent camera products.\r\n- The platform has a full-target core technology that can be used in various application scenarios.\r\n- The platform has a series of products, including Haomu behavior analyzer and Huimu camera, that can be used in various application scenarios.\r\n- The platform has accurate big data collection and recognition capabilities that can be used in various application scenarios.\r\n- The platform can be used in various application scenarios, such as urban management, smart finance, and commercial retail.\r\n- The document can answer questions such as: What is DeepGlint? What is DeepGlint Zhuyuan? What is the architecture of DeepGlint Zhuyuan? What are the products of DeepGlint Zhuyuan? What are the capabilities of DeepGlint Zhuyuan? What are the application scenarios of DeepGlint Zhuyuan?<|im_end|>\r\ncurrent doc id: c8282478-76e4-4eee-9015-781108e5e2e4\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1367 tokens\r\n> [get_response] Total LLM token usage: 1367 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\r\n> [get_response] Total embedding token usage: 0 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1367 tokens\r\n> [get_response] Total LLM token usage: 1367 tokens\r\nINFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\r\n> [get_response] Total embedding token usage: 0 tokens\r\nINFO:llama_index.indices.document_summary.base:> Generated summary for doc c8282478-76e4-4eee-9015-781108e5e2e4: - The document is about DeepGlint, a company that uses computer vision and AI to help people. \r\n- The company has several products, including a behavior analysis device, a camera with AI software, and a facial recognition device. \r\n- The company also has several edge computing devices, including one for traffic analysis and one for city management. \r\n- The company has several industry-specific solutions, including ones for sports and health, retail, and finance. \r\n\r\nThis document can answer questions about DeepGlint's products and services, as well as the company's mission and goals. It can also provide information about the company's industry-specific solutions and edge computing devices.<|im_end|>\r\n> Generated summary for doc c8282478-76e4-4eee-9015-781108e5e2e4: - The document is about DeepGlint, a company that uses computer vision and AI to help people. \r\n- The company has several products, including a behavior analysis device, a camera with AI software, and a facial recognition device. \r\n- The company also has several edge computing devices, including one for traffic analysis and one for city management. \r\n- The company has several industry-specific solutions, including ones for sports and health, retail, and finance. \r\n\r\nThis document can answer questions about DeepGlint's products and services, as well as the company's mission and goals. It can also provide information about the company's industry-specific solutions and edge computing devices.<|im_end|>\r\nINFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\r\n> [build_index_from_nodes] Total LLM token usage: 0 tokens\r\nINFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\r\n> [build_index_from_nodes] Total embedding token usage: 0 tokens\r\n\r\n\r\nBut when I uses query, sometimes the answer comes back to Chinese. But it was cut...\r\n\r\nquery_engine = doc_summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True)\r\nresponse = query_engine.query(\"What are the products?\")\r\nprint(response)\r\n\r\n\r\n['\u7693\u76ee\u884c\u4e3a\u5206\u6790\u4eea', '\u6df1\u77b3\u6167\u76ee\u6444\u50cf\u673a', '\u4eba\u8138\u8bc6\u522b\u8bbe\u5907', '\u53cc\u5149\u6e29\u6d4b\u667a', '\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907', '\u8f66\u8def\u534f\u540c\u8fb9\u7f18\u611f\u77e5\u8bbe\u5907', '5G \u667a\u80fd\u7f51\u8054\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907']\r\n\r\nContext information is below. \r\n---------------------\r\npage_label: 1\r\nfile_name: glst.pdf\r\n\r\n2023/6/10 18:38 \u683c\u7075\u6df1\u77b3 |DeepGlint \u8ba9\u8ba1\u7b97\u673a\u770b\u61c2\u4e16\u754c\uff0c\u8ba9 AI \u9020\u798f\u4eba\u7c7b\r\nhttps://deepglint.com/visualcomputing 1/2\u6df1\u77b3\u667a\u6e90\u89c6\u89c9\u8ba1\u7b97\u5e73\u53f0\r\n\u7cfb\u7edf\u4ecb\u7ecd\r\n\u4e91\u8fb9\u7aef\u534f\u540c  \u6700\u5927\u4f7f\u80fd\u89c6\u89c9\u8ba1\u7b97\u6548\u7387\r\n\u8fb9\u7f18\r\n\u9ad8\u6027\u4ef7\u6bd4\u8fb9\u7f18\u8ba1\u7b97\u4ea7\u54c1\r\n\u667a\u80fd\u76f8\u673a\u4ea7\u54c1\r\n\u57fa\u4e8e\u6df1\u77b3\u5168\u76ee\u6807\u6838\u5fc3\u6280\u672f\uff0c\u8d4b\r\n\r\nSometimes the query answer is in English:\r\n\r\nquery_engine = doc_summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True)\r\nresponse = query_engine.query(\"Which one is the most important product?\")\r\n\r\n\r\nAnswer: DeepGlint's most important product is the DeepGlint Vision Computing Platform.<|im_end|>\r\n\r\nWhy?\r\n\r\nBesides, if I use query with Chinese, the summary can be Chinese, but its length is always around 220 Chinese characters, and sometimes it is not complete.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6402/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6402/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6398",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6398/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6398/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6398/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6398",
        "id": 1750877994,
        "node_id": "I_kwDOIWuq585oXEcq",
        "number": 6398,
        "title": "[Question]: exceeded call rate limit of azure openai using DocumentSummaryIndex",
        "user": {
            "login": "qypanzer",
            "id": 130947046,
            "node_id": "U_kgDOB84X5g",
            "avatar_url": "https://avatars.githubusercontent.com/u/130947046?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/qypanzer",
            "html_url": "https://github.com/qypanzer",
            "followers_url": "https://api.github.com/users/qypanzer/followers",
            "following_url": "https://api.github.com/users/qypanzer/following{/other_user}",
            "gists_url": "https://api.github.com/users/qypanzer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/qypanzer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/qypanzer/subscriptions",
            "organizations_url": "https://api.github.com/users/qypanzer/orgs",
            "repos_url": "https://api.github.com/users/qypanzer/repos",
            "events_url": "https://api.github.com/users/qypanzer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/qypanzer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-10T08:52:40Z",
        "updated_at": "2023-09-16T16:17:39Z",
        "closed_at": "2023-09-16T16:17:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI uses DocumentSummaryIndex with Azure openai api, and I got the errors.\r\n\r\nBackground: I'm following the instructions and the codes of: \r\nhttps://gpt-index.readthedocs.io/en/latest/examples/index_structs/doc_summary/DocSummary.html\r\n\r\nAfter running: \r\n\r\n    response_synthesizer = ResponseSynthesizer.from_args(response_mode=\"tree_summarize\", use_async=True)\r\n    doc_summary_index = DocumentSummaryIndex.from_documents(\r\n        city_docs, \r\n        service_context=service_context,\r\n        response_synthesizer=response_synthesizer\r\n    )\r\n\r\nI've got:\r\n\r\n`<llama_index.indices.query.response_synthesis.ResponseSynthesizer object at 0x000001CC1D03CDF0>\r\ncurrent doc id: Toronto\r\nINFO:llama_index.indices.common_tree.base:> Building index from nodes: 7 chunks\r\n> Building index from nodes: 7 chunks\r\n> Building index from nodes: 7 chunks\r\n> Building index from nodes: 7 chunks\r\nWARNING:langchain.llms.openai:Retrying langchain.llms.openai.acompletion_with_retry.locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\r\nRetrying langchain.llms.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI.\r\n`\r\n\r\nI think the reason is that \"DocumentSummaryIndex.from_documents\" just cuts the document into small pieces and initiates several call of OPENAI api. \r\n\r\nHow to solve this? Thans!\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6398/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6398/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6397",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6397/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6397/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6397/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6397",
        "id": 1750875117,
        "node_id": "PR_kwDOIWuq585SrQq9",
        "number": 6397,
        "title": "[version] bump version to 0.6.22",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-10T08:42:29Z",
        "updated_at": "2023-06-10T15:55:54Z",
        "closed_at": "2023-06-10T15:55:53Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6397",
            "html_url": "https://github.com/run-llama/llama_index/pull/6397",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6397.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6397.patch",
            "merged_at": "2023-06-10T15:55:53Z"
        },
        "body": "bump version to 0.6.22 \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6397/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6397/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6393",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6393/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6393/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6393/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6393",
        "id": 1750840837,
        "node_id": "PR_kwDOIWuq585SrJrj",
        "number": 6393,
        "title": "Better support for vector store with existing data (e.g. allow configurable text key) for Pinecone and Weaviate. ",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-10T07:06:42Z",
        "updated_at": "2023-06-11T23:37:53Z",
        "closed_at": "2023-06-11T23:37:52Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6393",
            "html_url": "https://github.com/run-llama/llama_index/pull/6393",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6393.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6393.patch",
            "merged_at": "2023-06-11T23:37:52Z"
        },
        "body": "# Summary \r\n\r\nMake it easier for users with existing vector store (with data already loaded in) to use llama index to query it.\r\n\r\n# Details\r\nThere are two main aspects to this change\r\n1. expose the right configurations so users can tell us e.g. what the text key is, what the index name is, of their existing vector store index\r\n2. when we load data as Nodes, make sure when additional metadata fields aren't present, we can still properly load the Node)\r\n\r\n# Todos\r\n\r\n- [x] Pinecone\r\n  - [x] Implementation\r\n  - [x] Testing \r\n- [x] Weaviate\r\n  - [x] Implementation\r\n  - [x] Testing \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6393/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6393/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6386",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6386/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6386/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6386/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6386",
        "id": 1750758687,
        "node_id": "I_kwDOIWuq585oWnUf",
        "number": 6386,
        "title": "My question is in Vietnamese, why is the answer in English? Is that because of gpt-3.5-turbo limited?",
        "user": {
            "login": "dinhan92",
            "id": 86275789,
            "node_id": "MDQ6VXNlcjg2Mjc1Nzg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/86275789?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dinhan92",
            "html_url": "https://github.com/dinhan92",
            "followers_url": "https://api.github.com/users/dinhan92/followers",
            "following_url": "https://api.github.com/users/dinhan92/following{/other_user}",
            "gists_url": "https://api.github.com/users/dinhan92/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dinhan92/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dinhan92/subscriptions",
            "organizations_url": "https://api.github.com/users/dinhan92/orgs",
            "repos_url": "https://api.github.com/users/dinhan92/repos",
            "events_url": "https://api.github.com/users/dinhan92/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dinhan92/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-10T03:06:26Z",
        "updated_at": "2023-06-13T03:58:13Z",
        "closed_at": "2023-06-12T08:43:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\n![image](https://github.com/jerryjliu/llama_index/assets/86275789/a00aa50b-38ca-477b-9285-bf26b0d40b65)\r\n\r\nI already set Vietnamese in the prepend messages:\r\nmax_input_size = 4096\r\nnum_outputs = 512\r\nmax_chunk_overlap = 0.2\r\nchunk_size_limit = 1000\r\n\r\nprompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\r\nprepend_messages = [\r\n    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that use the same language as the input question and use Vietnamese as your base language\")\r\n]\r\nllm_predictor = ChatGPTLLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0301\", openai_api_key=\"API Key\", streaming=True), prepend_messages = prepend_messages)\r\n\r\nand use VectorStoreIndex:\r\n index = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\n\r\nThis appears when I upgade to 0.6.20",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6386/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6386/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6384",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6384/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6384/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6384/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6384",
        "id": 1750741955,
        "node_id": "I_kwDOIWuq585oWjPD",
        "number": 6384,
        "title": "[Question]: Want to ask how to support the streaming of multi-document question",
        "user": {
            "login": "MonsterZwj",
            "id": 90378340,
            "node_id": "MDQ6VXNlcjkwMzc4MzQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/90378340?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MonsterZwj",
            "html_url": "https://github.com/MonsterZwj",
            "followers_url": "https://api.github.com/users/MonsterZwj/followers",
            "following_url": "https://api.github.com/users/MonsterZwj/following{/other_user}",
            "gists_url": "https://api.github.com/users/MonsterZwj/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MonsterZwj/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MonsterZwj/subscriptions",
            "organizations_url": "https://api.github.com/users/MonsterZwj/orgs",
            "repos_url": "https://api.github.com/users/MonsterZwj/repos",
            "events_url": "https://api.github.com/users/MonsterZwj/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MonsterZwj/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-10T02:09:46Z",
        "updated_at": "2023-06-13T08:50:00Z",
        "closed_at": "2023-06-10T02:30:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI want to implement multi-document streaming answers, I use SubQuestionQueryEngine, I found a built-in parameter of this method response_synthesizer, set ResponseSynthesizer.from_args(streaming=True\uff09It seems to work, but it still reports ValueError: LLM must support streaming and set streaming=True. I tried to use service_context to solve this problem, but it didn't work",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6384/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6384/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6383",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6383/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6383/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6383/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6383",
        "id": 1750491882,
        "node_id": "PR_kwDOIWuq585Sp9lY",
        "number": 6383,
        "title": "docs: extra_info doc improvement",
        "user": {
            "login": "EmanuelCampos",
            "id": 16262455,
            "node_id": "MDQ6VXNlcjE2MjYyNDU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/16262455?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/EmanuelCampos",
            "html_url": "https://github.com/EmanuelCampos",
            "followers_url": "https://api.github.com/users/EmanuelCampos/followers",
            "following_url": "https://api.github.com/users/EmanuelCampos/following{/other_user}",
            "gists_url": "https://api.github.com/users/EmanuelCampos/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/EmanuelCampos/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/EmanuelCampos/subscriptions",
            "organizations_url": "https://api.github.com/users/EmanuelCampos/orgs",
            "repos_url": "https://api.github.com/users/EmanuelCampos/repos",
            "events_url": "https://api.github.com/users/EmanuelCampos/events{/privacy}",
            "received_events_url": "https://api.github.com/users/EmanuelCampos/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-09T21:03:47Z",
        "updated_at": "2023-06-09T21:09:37Z",
        "closed_at": "2023-06-09T21:09:37Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6383",
            "html_url": "https://github.com/run-llama/llama_index/pull/6383",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6383.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6383.patch",
            "merged_at": "2023-06-09T21:09:37Z"
        },
        "body": "# Description\r\n\r\nThere are a lot of questions about what can be done with the `extra_info` field.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Documentation Improvement\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6383/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6383/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6381",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6381/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6381/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6381/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6381",
        "id": 1750340856,
        "node_id": "PR_kwDOIWuq585SpcXr",
        "number": 6381,
        "title": "Cleanup RetryQuery notebook",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T18:38:27Z",
        "updated_at": "2023-06-11T08:28:08Z",
        "closed_at": "2023-06-11T08:28:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6381",
            "html_url": "https://github.com/run-llama/llama_index/pull/6381",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6381.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6381.patch",
            "merged_at": "2023-06-11T08:28:08Z"
        },
        "body": "# Description\r\nRefactored the Retry Query notebook to make the different implementation variations clearer.\r\n\r\n## Type of Change\r\n\r\nNotebook update\r\n\r\n# How Has This Been Tested?\r\n\r\nNotebook run\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6381/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6381/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6380",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6380/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6380/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6380/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6380",
        "id": 1750324083,
        "node_id": "PR_kwDOIWuq585SpYr9",
        "number": 6380,
        "title": "Fix link for retry related query engines",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T18:26:22Z",
        "updated_at": "2023-06-09T18:40:17Z",
        "closed_at": "2023-06-09T18:40:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6380",
            "html_url": "https://github.com/run-llama/llama_index/pull/6380",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6380.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6380.patch",
            "merged_at": "2023-06-09T18:40:17Z"
        },
        "body": "# Description\r\n\r\nFix link for retry related query engines\r\n\r\n## Type of Change\r\n\r\n- [ ] Documentation update \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6380/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6380/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6379",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6379/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6379/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6379/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6379",
        "id": 1750228175,
        "node_id": "PR_kwDOIWuq585SpDos",
        "number": 6379,
        "title": "MongoDB Atlas vector store",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-09T17:02:50Z",
        "updated_at": "2023-06-10T08:38:48Z",
        "closed_at": "2023-06-09T18:18:42Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6379",
            "html_url": "https://github.com/run-llama/llama_index/pull/6379",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6379.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6379.patch",
            "merged_at": "2023-06-09T18:18:42Z"
        },
        "body": "# Description\r\n\r\nWe want to collaborate with MongoDB Atlas Search to show how we can implement the Atlas\r\n\r\n\r\n## Type of Change\r\n- New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- Added to MongoDB nb an atlas search example.\r\n\r\n# Suggested Checklist:\r\n\r\n- I have performed a self-review of my own code\r\n- I have commented my code, particularly in hard-to-understand areas\r\n- I have made corresponding changes to the documentation\r\n- My changes generate no new warnings\r\n- I have added tests that prove my fix is effective or that my feature works\r\n- New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6379/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6379/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6372",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6372/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6372/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6372/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6372",
        "id": 1750099496,
        "node_id": "PR_kwDOIWuq585SonTx",
        "number": 6372,
        "title": "fix colors error",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T15:26:08Z",
        "updated_at": "2023-08-28T17:09:49Z",
        "closed_at": "2023-06-09T15:35:18Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6372",
            "html_url": "https://github.com/run-llama/llama_index/pull/6372",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6372.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6372.patch",
            "merged_at": "2023-06-09T15:35:18Z"
        },
        "body": "# Description\r\n\r\nverbose=False causes error in sub-question query engine because colors is not initialized\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6372/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6372/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6316",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6316/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6316/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6316/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6316",
        "id": 1749828793,
        "node_id": "I_kwDOIWuq585oTES5",
        "number": 6316,
        "title": "[Feature Request]: CustomLLM should be able to handle streaming",
        "user": {
            "login": "Thytu",
            "id": 43698357,
            "node_id": "MDQ6VXNlcjQzNjk4MzU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/43698357?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Thytu",
            "html_url": "https://github.com/Thytu",
            "followers_url": "https://api.github.com/users/Thytu/followers",
            "following_url": "https://api.github.com/users/Thytu/following{/other_user}",
            "gists_url": "https://api.github.com/users/Thytu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Thytu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Thytu/subscriptions",
            "organizations_url": "https://api.github.com/users/Thytu/orgs",
            "repos_url": "https://api.github.com/users/Thytu/repos",
            "events_url": "https://api.github.com/users/Thytu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Thytu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-09T12:49:51Z",
        "updated_at": "2023-07-22T02:16:56Z",
        "closed_at": "2023-07-22T02:16:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nsimilar to https://github.com/jerryjliu/llama_index/issues/3142 but for [custom LLM](https://github.com/jerryjliu/llama_index/blob/main/docs/how_to/customization/custom_llms.md#example-using-a-custom-llm-model---advanced).\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6316/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6316/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6278",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6278/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6278/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6278/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6278",
        "id": 1749598115,
        "node_id": "I_kwDOIWuq585oSL-j",
        "number": 6278,
        "title": "[Question]: why fetch the nodes is return None by ResponseMode.NO_TEXT",
        "user": {
            "login": "youbai1995",
            "id": 36870654,
            "node_id": "MDQ6VXNlcjM2ODcwNjU0",
            "avatar_url": "https://avatars.githubusercontent.com/u/36870654?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/youbai1995",
            "html_url": "https://github.com/youbai1995",
            "followers_url": "https://api.github.com/users/youbai1995/followers",
            "following_url": "https://api.github.com/users/youbai1995/following{/other_user}",
            "gists_url": "https://api.github.com/users/youbai1995/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/youbai1995/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/youbai1995/subscriptions",
            "organizations_url": "https://api.github.com/users/youbai1995/orgs",
            "repos_url": "https://api.github.com/users/youbai1995/repos",
            "events_url": "https://api.github.com/users/youbai1995/events{/privacy}",
            "received_events_url": "https://api.github.com/users/youbai1995/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-09T10:13:59Z",
        "updated_at": "2023-06-12T04:21:12Z",
        "closed_at": "2023-06-12T04:21:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nWhy does llama return None when response_mode is no_text?\r\n`       service_context = create_service_context()\r\n        index = self.embedding.load_index_simple(game_id, service_context)\r\n        retriever = index.as_retriever(similarity_top_k=15)\r\n        engine = RetrieverQueryEngine.from_args(retriever, service_context,\r\n                                                response_mode=ResponseMode.NO_TEXT)\r\n`\r\ni saw the nodes was print, but it not return",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6278/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6278/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6271",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6271/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6271/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6271/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6271",
        "id": 1749501896,
        "node_id": "I_kwDOIWuq585oR0fI",
        "number": 6271,
        "title": "[Question]:  How I save to disk an index?",
        "user": {
            "login": "Dave86ch",
            "id": 87725170,
            "node_id": "MDQ6VXNlcjg3NzI1MTcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/87725170?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Dave86ch",
            "html_url": "https://github.com/Dave86ch",
            "followers_url": "https://api.github.com/users/Dave86ch/followers",
            "following_url": "https://api.github.com/users/Dave86ch/following{/other_user}",
            "gists_url": "https://api.github.com/users/Dave86ch/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Dave86ch/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Dave86ch/subscriptions",
            "organizations_url": "https://api.github.com/users/Dave86ch/orgs",
            "repos_url": "https://api.github.com/users/Dave86ch/repos",
            "events_url": "https://api.github.com/users/Dave86ch/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Dave86ch/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-09T09:22:31Z",
        "updated_at": "2023-06-11T07:31:00Z",
        "closed_at": "2023-06-11T07:31:00Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI used to use GPTTreeIndex.save_to_disk('/index.json') and GPTTreeIndex.load_from_disk('/index.json'), but they appear to be deprecated now. What is the updated alternative for saving an index to disk and loading it back? \r\n\r\nThank you",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6271/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6271/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6266",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6266/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6266/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6266/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6266",
        "id": 1749381215,
        "node_id": "I_kwDOIWuq585oRXBf",
        "number": 6266,
        "title": "[Bug]: #2129 was closed as resolved but I am still having the same error even with a completely new install and container environment, and others are reporting the same error on discord",
        "user": {
            "login": "afewell",
            "id": 17549071,
            "node_id": "MDQ6VXNlcjE3NTQ5MDcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/17549071?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/afewell",
            "html_url": "https://github.com/afewell",
            "followers_url": "https://api.github.com/users/afewell/followers",
            "following_url": "https://api.github.com/users/afewell/following{/other_user}",
            "gists_url": "https://api.github.com/users/afewell/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/afewell/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/afewell/subscriptions",
            "organizations_url": "https://api.github.com/users/afewell/orgs",
            "repos_url": "https://api.github.com/users/afewell/repos",
            "events_url": "https://api.github.com/users/afewell/events{/privacy}",
            "received_events_url": "https://api.github.com/users/afewell/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-09T08:14:25Z",
        "updated_at": "2023-07-22T02:17:35Z",
        "closed_at": "2023-07-22T02:17:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\nAzure OpenAI API's not working via Llama-index.\r\n\r\nopenai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\nThe scenario is exactly the same as described in #2129 \r\n\r\n### Version\r\n\r\n0.6.21.post1\r\n\r\n### Steps to Reproduce\r\n\r\ntry the azure notebook, it results in this error. \r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nFile \"/workspaces/clean-tanzubot-june-7-2023/demos/demo_scripts/venv/lib/python3.10/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"/workspaces/clean-tanzubot-june-7-2023/demos/demo_scripts/venv/lib/python3.10/site-packages/llama_index/embeddings/openai.py\", line 106, in get_embedding\r\n    return openai.Embedding.create(input=[text], model=engine, **kwargs)[\"data\"][0][\r\n  File \"/workspaces/clean-tanzubot-june-7-2023/demos/demo_scripts/venv/lib/python3.10/site-packages/openai/api_resources/embedding.py\", line 33, in create\r\n    response = super().create(*args, **kwargs)\r\n  File \"/workspaces/clean-tanzubot-june-7-2023/demos/demo_scripts/venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 149, in create\r\n    ) = cls.__prepare_create_request(\r\n  File \"/workspaces/clean-tanzubot-june-7-2023/demos/demo_scripts/venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 83, in __prepare_create_request\r\n    raise error.InvalidRequestError(\r\nopenai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6266/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6266/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6265",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6265/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6265/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6265/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6265",
        "id": 1749371191,
        "node_id": "PR_kwDOIWuq585SmHPW",
        "number": 6265,
        "title": "add sql join query engine ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T08:09:08Z",
        "updated_at": "2023-06-10T08:41:30Z",
        "closed_at": "2023-06-10T08:41:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6265",
            "html_url": "https://github.com/run-llama/llama_index/pull/6265",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6265.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6265.patch",
            "merged_at": "2023-06-10T08:41:29Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nThis generalizes SQLAutoVectorQueryEngine to let the second tool be any query engine, not just a vector store (no reason for it to be). \r\n\r\nWill deprecate SQLAutoVectorQueryEngine probably. \r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6265/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6265/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6251",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6251/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6251/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6251/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6251",
        "id": 1749217011,
        "node_id": "PR_kwDOIWuq585SllS5",
        "number": 6251,
        "title": "Hermes sean",
        "user": {
            "login": "cloud37wind",
            "id": 10485715,
            "node_id": "MDQ6VXNlcjEwNDg1NzE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10485715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cloud37wind",
            "html_url": "https://github.com/cloud37wind",
            "followers_url": "https://api.github.com/users/cloud37wind/followers",
            "following_url": "https://api.github.com/users/cloud37wind/following{/other_user}",
            "gists_url": "https://api.github.com/users/cloud37wind/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cloud37wind/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cloud37wind/subscriptions",
            "organizations_url": "https://api.github.com/users/cloud37wind/orgs",
            "repos_url": "https://api.github.com/users/cloud37wind/repos",
            "events_url": "https://api.github.com/users/cloud37wind/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cloud37wind/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T06:29:21Z",
        "updated_at": "2023-06-09T06:31:53Z",
        "closed_at": "2023-06-09T06:31:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6251",
            "html_url": "https://github.com/run-llama/llama_index/pull/6251",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6251.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6251.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6251/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6251/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6250",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6250/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6250/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6250/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6250",
        "id": 1749195621,
        "node_id": "I_kwDOIWuq585oQptl",
        "number": 6250,
        "title": "[Feature Request]: Delete not yet implemented for Faiss index.",
        "user": {
            "login": "LF112",
            "id": 35809783,
            "node_id": "MDQ6VXNlcjM1ODA5Nzgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/35809783?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LF112",
            "html_url": "https://github.com/LF112",
            "followers_url": "https://api.github.com/users/LF112/followers",
            "following_url": "https://api.github.com/users/LF112/following{/other_user}",
            "gists_url": "https://api.github.com/users/LF112/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LF112/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LF112/subscriptions",
            "organizations_url": "https://api.github.com/users/LF112/orgs",
            "repos_url": "https://api.github.com/users/LF112/repos",
            "events_url": "https://api.github.com/users/LF112/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LF112/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-09T06:13:46Z",
        "updated_at": "2023-11-28T16:03:28Z",
        "closed_at": "2023-11-28T16:03:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nWhen I use the delete_ref_doc index node deletion method provided by GPTVectorStoreIndex, I get an error: \"Delete not yet implemented for Faiss index.\" \r\n\r\nWhen will the function to delete a node from FAISS be implemented?\r\nIs there an alternative way to delete FAISS nodes?\r\n\r\nhttps://github.com/jerryjliu/llama_index/blob/main/llama_index/vector_stores/faiss.py#L142\n\n### Reason\n\nLlama Index does not currently have a function to delete nodes from FAISS.\n\n### Value of Feature\n\nThe delete function is a key part of the process.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6250/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6250/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6248",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6248/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6248/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6248/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6248",
        "id": 1749119102,
        "node_id": "PR_kwDOIWuq585SlP7B",
        "number": 6248,
        "title": "add try...except... for mbox reader",
        "user": {
            "login": "jerryleooo",
            "id": 3231765,
            "node_id": "MDQ6VXNlcjMyMzE3NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3231765?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryleooo",
            "html_url": "https://github.com/jerryleooo",
            "followers_url": "https://api.github.com/users/jerryleooo/followers",
            "following_url": "https://api.github.com/users/jerryleooo/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryleooo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryleooo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryleooo/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryleooo/orgs",
            "repos_url": "https://api.github.com/users/jerryleooo/repos",
            "events_url": "https://api.github.com/users/jerryleooo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryleooo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-09T04:46:59Z",
        "updated_at": "2023-06-20T19:11:45Z",
        "closed_at": "2023-06-20T19:11:45Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6248",
            "html_url": "https://github.com/run-llama/llama_index/pull/6248",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6248.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6248.patch",
            "merged_at": "2023-06-20T19:11:45Z"
        },
        "body": "# Description\r\n\r\nIn my mbox file exported from Gmail, there is a bad date format that can not be handled by Python's email toolkit. And this makes the whole mbox parsing fail.\r\n\r\nWe may need a simple `try...except...` outside each message handling to avoid a single parsing failure failing the whole mbox parsing.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/6247\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6248/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6248/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6247",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6247/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6247/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6247/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6247",
        "id": 1749118290,
        "node_id": "I_kwDOIWuq585oQW1S",
        "number": 6247,
        "title": "[Bug]: Bad email format affect the whole mbox file parsing",
        "user": {
            "login": "jerryleooo",
            "id": 3231765,
            "node_id": "MDQ6VXNlcjMyMzE3NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3231765?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryleooo",
            "html_url": "https://github.com/jerryleooo",
            "followers_url": "https://api.github.com/users/jerryleooo/followers",
            "following_url": "https://api.github.com/users/jerryleooo/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryleooo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryleooo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryleooo/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryleooo/orgs",
            "repos_url": "https://api.github.com/users/jerryleooo/repos",
            "events_url": "https://api.github.com/users/jerryleooo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryleooo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-09T04:46:03Z",
        "updated_at": "2023-06-20T19:11:47Z",
        "closed_at": "2023-06-20T19:11:47Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nIn my mbox file exported from Gmail, there is a bad date format that can not be handled by Python's email toolkit. And this makes the whole mbox parsing fail.\r\n\r\nWe may need a simple `try...except...` outside each message handling to avoid a single parsing failure failing the whole mbox parsing.\n\n### Version\n\n0.6.21.post1\n\n### Steps to Reproduce\n\nJust mock a mbox with following date:\r\n\r\n```\r\n06-MAY-2022 14:55:49\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nTraceback (most recent call last):\r\n  File \"/Users/leo/dev/side-projects/spam-miner/src/llama_index_demo.py\", line 16, in <module>\r\n    documents = loader.load_data('/tmp/mbox/')\r\n  File \"/Users/leo/dev/side-projects/spam-miner/env/lib/python3.8/site-packages/llama_index/readers/mbox.py\", line 33, in load_data\r\n    file_docs = MboxFileReader(**load_kwargs).load_data(Path(filepath))\r\n  File \"/Users/leo/dev/side-projects/spam-miner/env/lib/python3.8/site-packages/llama_index/readers/file/mbox_reader.py\", line 86, in load_data\r\n    _date=msg[\"date\"],\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/message.py\", line 391, in __getitem__\r\n    return self.get(name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/message.py\", line 471, in get\r\n    return self.policy.header_fetch_parse(k, v)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/policy.py\", line 163, in header_fetch_parse\r\n    return self.header_factory(name, value)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/headerregistry.py\", line 607, in __call__\r\n    return self[name](name, value)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/headerregistry.py\", line 202, in __new__\r\n    cls.parse(value, kwds)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/headerregistry.py\", line 311, in parse\r\n    value = utils.parsedate_to_datetime(value)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/email/utils.py\", line 198, in parsedate_to_datetime\r\n    *dtuple, tz = _parsedate_tz(data)\r\nTypeError: cannot unpack non-iterable NoneType object\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6247/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6247/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6246",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6246/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6246/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6246/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6246",
        "id": 1749081068,
        "node_id": "PR_kwDOIWuq585SlHq_",
        "number": 6246,
        "title": "Initial guidance integration",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-09T04:00:26Z",
        "updated_at": "2023-06-12T01:20:05Z",
        "closed_at": "2023-06-12T01:20:04Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6246",
            "html_url": "https://github.com/run-llama/llama_index/pull/6246",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6246.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6246.patch",
            "merged_at": "2023-06-12T01:20:03Z"
        },
        "body": "# Description\r\n\r\nThis PR adds initial [guidance](https://github.com/microsoft/guidance) integration. \r\n\r\nTwo main additions:\r\n1. `GuidancePydanticProgram`, which is a generic guidance-based  \"program\" that can be configured to output arbitrary Pydantic objects. \r\n> Note: the naming is terrible, please help. This also sublasses the `BasePydanticProgram` which is meant to capture any LLM-based function that outputs a pydantic object.\r\n\r\n> The reason we did not subclass from `Prompt` and `LLMPredictor` is because a guidance prompt template can only work with guidance llm (i.e. there's strong coupling). Exposing them as individual parts could be confusing since they are not interoperable with existing LLMs and prompts.\r\n2. `GuidanceQuestionGenerator`, which makes use of `GuidancePydanticProgram` to implement a sub question generator, and can be plugged into `SubQuestionQueryEngine`\r\n\r\nAdded associated unit-tests and notebooks\r\nAdded doc under integration\r\n\r\n## Dirty laundry\r\nThe way we parse the structured output from guidance is not great, mostly due to its relatively poor support for nested objects. This will improve as Scott lands changes on his side.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n\r\n# Todos\r\n- [ ] Make notebooks more comprehensive, and perhaps show working with open source models.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6246/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6246/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6239",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6239/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6239/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6239/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6239",
        "id": 1748735943,
        "node_id": "PR_kwDOIWuq585SkFym",
        "number": 6239,
        "title": "[wip] Citation Query Engine",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-06-08T22:30:40Z",
        "updated_at": "2023-08-28T17:11:27Z",
        "closed_at": "2023-06-09T22:52:06Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6239",
            "html_url": "https://github.com/run-llama/llama_index/pull/6239",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6239.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6239.patch",
            "merged_at": "2023-06-09T22:52:06Z"
        },
        "body": "# Description\r\n\r\nThis PR is an attempt to get the LLM to declare which piece of text(s) it's answer came from.\r\n\r\nTo do this, I\r\n1. Introduce a `CitationQueryEngine` class\r\n2. Reformat retrieved nodes to be smaller and include a source number header\r\n3. Custom prompt to get the LLM to cite sources\r\n4. Return response + new nodes as source nodes\r\n\r\nSee the example notebook for current usage. It is no longer too janky\r\n\r\n# TODO:\r\n\r\n- [x] make the prompt better (including better support for gpt-3.5, rip)\r\n- [x] make the engine easier to instantiate\r\n- [x] let users customize the source chunk size\r\n- [x] update docs\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6239/reactions",
            "total_count": 5,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 5,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6239/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6230",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6230/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6230/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6230/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6230",
        "id": 1748283512,
        "node_id": "PR_kwDOIWuq585SinIF",
        "number": 6230,
        "title": "[Bugfix for issue #6228] QdrantVectorStore query method assigns a value of None to extra_info key while instanting Node causes validation problems",
        "user": {
            "login": "kaizenx",
            "id": 1196872,
            "node_id": "MDQ6VXNlcjExOTY4NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1196872?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kaizenx",
            "html_url": "https://github.com/kaizenx",
            "followers_url": "https://api.github.com/users/kaizenx/followers",
            "following_url": "https://api.github.com/users/kaizenx/following{/other_user}",
            "gists_url": "https://api.github.com/users/kaizenx/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kaizenx/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kaizenx/subscriptions",
            "organizations_url": "https://api.github.com/users/kaizenx/orgs",
            "repos_url": "https://api.github.com/users/kaizenx/repos",
            "events_url": "https://api.github.com/users/kaizenx/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kaizenx/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-08T16:24:38Z",
        "updated_at": "2023-06-09T03:57:35Z",
        "closed_at": "2023-06-09T03:57:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6230",
            "html_url": "https://github.com/run-llama/llama_index/pull/6230",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6230.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6230.patch",
            "merged_at": "2023-06-09T03:57:35Z"
        },
        "body": "# Description\r\n\r\nThis issue is caused by using QdrantVectorStore as your vector store, as the problem occurs in the query method for QdrantVectorStore. \r\n\r\nQdrantVectorStore query method assigns a dictionary to the extra info key when instantiating Node. \r\nDown the line of the call chain Node -> super().__post_init__() -> _validate_is_flat_dict, the extra_info key that has a default value of None causes the _validate_is_flat_dict to check the value of the key, which will fail, because None is not a string, integer or float. \r\n\r\nI added a if val is not None: check in the _validate_is_flat_dict function in schema.py. \r\n\r\nFeels like the \"smallest\" fix I can make without making more impact, like for example modifying metadata_dict_to_node or something else more drastic\r\n\r\nFixes # (6228)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n- [X] Reran my own code that tests end-to-end\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n\r\n*Note the requirements.txt did not include faiss and vellum-ai, I installed them separately.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6230/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6230/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6229",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6229/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6229/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6229/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6229",
        "id": 1748231339,
        "node_id": "I_kwDOIWuq585oM-Sr",
        "number": 6229,
        "title": "[Question]: Understanding token usage when generating indexes",
        "user": {
            "login": "sousanunes",
            "id": 5367028,
            "node_id": "MDQ6VXNlcjUzNjcwMjg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5367028?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sousanunes",
            "html_url": "https://github.com/sousanunes",
            "followers_url": "https://api.github.com/users/sousanunes/followers",
            "following_url": "https://api.github.com/users/sousanunes/following{/other_user}",
            "gists_url": "https://api.github.com/users/sousanunes/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sousanunes/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sousanunes/subscriptions",
            "organizations_url": "https://api.github.com/users/sousanunes/orgs",
            "repos_url": "https://api.github.com/users/sousanunes/repos",
            "events_url": "https://api.github.com/users/sousanunes/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sousanunes/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-06-08T16:05:33Z",
        "updated_at": "2023-07-22T02:18:53Z",
        "closed_at": "2023-07-22T02:18:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi there!\r\n\r\nI'm generating a vector index for several documents, totaling 41568 words. Considering an average of 1.3 tokens per word, the default llama_index chunk size of 1024 tokens, and the default overlap of 200 tokens, I get the following estimates (rounded):\r\n\r\nNo. input tokens = 1.3 * No. input words = 1.3 * 41568 = 54038 tokens\r\nNo. chunks = No. input tokens / (1024 - 200) = 54038 / 824 = 65.6 chunks\r\nNo. tokens to embed = chunk size * no. chunks = 1024 * 65.6 = 67155 tokens\r\n\r\nHowever, the llama_index token counter tells me I've used 134046 tokens, which is almost exactly the double of my 67155 estimate.\r\n\r\nWhat I am missing here? Do we generate embeddings twice in llama_index, or is my estimate way off?\r\n\r\nI tried looking into llm_predictor.last_token_usage but it doesn't make sense.\r\n\r\nAny tips greatly appreciated :)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6229/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6229/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6228",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6228/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6228/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6228/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6228",
        "id": 1748218816,
        "node_id": "I_kwDOIWuq585oM7PA",
        "number": 6228,
        "title": "[Bug]: QdrantVectorStore query method assigns a value of None to extra_info which causes problems down the line",
        "user": {
            "login": "kaizenx",
            "id": 1196872,
            "node_id": "MDQ6VXNlcjExOTY4NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1196872?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kaizenx",
            "html_url": "https://github.com/kaizenx",
            "followers_url": "https://api.github.com/users/kaizenx/followers",
            "following_url": "https://api.github.com/users/kaizenx/following{/other_user}",
            "gists_url": "https://api.github.com/users/kaizenx/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kaizenx/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kaizenx/subscriptions",
            "organizations_url": "https://api.github.com/users/kaizenx/orgs",
            "repos_url": "https://api.github.com/users/kaizenx/repos",
            "events_url": "https://api.github.com/users/kaizenx/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kaizenx/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "kaizenx",
            "id": 1196872,
            "node_id": "MDQ6VXNlcjExOTY4NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1196872?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kaizenx",
            "html_url": "https://github.com/kaizenx",
            "followers_url": "https://api.github.com/users/kaizenx/followers",
            "following_url": "https://api.github.com/users/kaizenx/following{/other_user}",
            "gists_url": "https://api.github.com/users/kaizenx/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kaizenx/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kaizenx/subscriptions",
            "organizations_url": "https://api.github.com/users/kaizenx/orgs",
            "repos_url": "https://api.github.com/users/kaizenx/repos",
            "events_url": "https://api.github.com/users/kaizenx/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kaizenx/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "kaizenx",
                "id": 1196872,
                "node_id": "MDQ6VXNlcjExOTY4NzI=",
                "avatar_url": "https://avatars.githubusercontent.com/u/1196872?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/kaizenx",
                "html_url": "https://github.com/kaizenx",
                "followers_url": "https://api.github.com/users/kaizenx/followers",
                "following_url": "https://api.github.com/users/kaizenx/following{/other_user}",
                "gists_url": "https://api.github.com/users/kaizenx/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/kaizenx/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/kaizenx/subscriptions",
                "organizations_url": "https://api.github.com/users/kaizenx/orgs",
                "repos_url": "https://api.github.com/users/kaizenx/repos",
                "events_url": "https://api.github.com/users/kaizenx/events{/privacy}",
                "received_events_url": "https://api.github.com/users/kaizenx/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-08T16:00:22Z",
        "updated_at": "2023-06-11T07:53:15Z",
        "closed_at": "2023-06-11T07:53:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nQdrantVectorStore query method assigns a value of None to extra info, which causes the _validate_is_flat_dict to check the value of the key, which will fail, because None is not a string, integer or float. \r\n_validate_is_flat_dict is called because the __post_init__ for Node is checking for nullity by checking is not None, which is probably not the best way of doing it. \n\n### Version\n\n0.6.20\n\n### Steps to Reproduce\n\nYou can reproduce this bug by running the code below\r\n\r\n`\r\nquery = \"Say Hi\"\r\n\r\nclient = QdrantClient(host=os.environ['QHOST'], port=int(os.environ['QPORT']))\r\ncollection_name = os.environ['QCOLLECTION_NAME']\r\n\r\nmax_input_size = 1024\r\nnum_output = 256\r\nchunk_size_limit = 1024\r\nchunk_overlap_ratio = 0.5\r\n\r\nvector_store = QdrantVectorStore(client=client, collection_name=collection_name)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\n# for help debugging\r\nllama_debug = LlamaDebugHandler(print_trace_on_end=True)\r\ncallback_manager = CallbackManager([llama_debug])\r\n\r\nllm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=chunk_size_limit))\r\nprompt_helper = PromptHelper(max_input_size=max_input_size, num_output=num_output, chunk_overlap_ratio=chunk_overlap_ratio)\r\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager, llm_predictor=llm_predictor)\r\nindex = GPTVectorStoreIndex([], storage_context=storage_context, service_context=service_context)\r\nquery_engine = index.as_query_engine()\r\nresults = query_engine.query(query)\r\n`\n\n### Relevant Logs/Tracbacks\n\n```shell\n**********\r\nTrace: index_construction\r\n**********\r\nTraceback (most recent call last):\r\n  File \"/Users/kaizenx/workspace/ph-server/src/test2.py\", line 67, in <module>\r\n    results = query_engine.query(query)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 140, in _query\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/indices/base_retriever.py\", line 21, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/token_counter/token_counter.py\", line 78, in wrapped_llm_predict\r\n    f_return_val = f(_self, *args, **kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 83, in _retrieve\r\n    query_result = self._vector_store.query(query, **self._kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/vector_stores/qdrant.py\", line 198, in query\r\n    node = Node(\r\n           ^^^^^\r\n  File \"<string>\", line 10, in __init__\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/data_structs/node.py\", line 63, in __post_init__\r\n    super().__post_init__()\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/schema.py\", line 58, in __post_init__\r\n    _validate_is_flat_dict(self.extra_info)\r\n  File \"/Users/kaizenx/workspace/ph-server/src/lib/python3.11/site-packages/llama_index/schema.py\", line 21, in _validate_is_flat_dict\r\n    raise ValueError(\"Value must be one of (str, int, float)\")\r\nValueError: Value must be one of (str, int, float)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6228/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6228/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6222",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6222/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6222/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6222/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6222",
        "id": 1748018105,
        "node_id": "I_kwDOIWuq585oMKO5",
        "number": 6222,
        "title": "[Question]: How can the extra_info metadata be used for query responses?",
        "user": {
            "login": "YasmineMh",
            "id": 42073781,
            "node_id": "MDQ6VXNlcjQyMDczNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42073781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YasmineMh",
            "html_url": "https://github.com/YasmineMh",
            "followers_url": "https://api.github.com/users/YasmineMh/followers",
            "following_url": "https://api.github.com/users/YasmineMh/following{/other_user}",
            "gists_url": "https://api.github.com/users/YasmineMh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YasmineMh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YasmineMh/subscriptions",
            "organizations_url": "https://api.github.com/users/YasmineMh/orgs",
            "repos_url": "https://api.github.com/users/YasmineMh/repos",
            "events_url": "https://api.github.com/users/YasmineMh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YasmineMh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-06-08T14:28:21Z",
        "updated_at": "2023-06-13T14:39:00Z",
        "closed_at": "2023-06-13T14:39:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHey, do we need to explicitly add a parameter or something during retrieval or querying to use the extra_info metadata?\r\n\r\nFor example, if I have the metadata `filename`, and the query is:\r\n\r\n`What is the topic of the <filename> document ?`\r\n\r\nis the retrieval going to use metadata to return nodes / reply to the question?\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6222/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6222/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6219",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6219/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6219/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6219/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6219",
        "id": 1747935743,
        "node_id": "I_kwDOIWuq585oL2H_",
        "number": 6219,
        "title": "[Question]: Does GPTVectorStoreIndex serve as the sole vector index for storing the data into a DB?",
        "user": {
            "login": "YasmineMh",
            "id": 42073781,
            "node_id": "MDQ6VXNlcjQyMDczNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/42073781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/YasmineMh",
            "html_url": "https://github.com/YasmineMh",
            "followers_url": "https://api.github.com/users/YasmineMh/followers",
            "following_url": "https://api.github.com/users/YasmineMh/following{/other_user}",
            "gists_url": "https://api.github.com/users/YasmineMh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/YasmineMh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/YasmineMh/subscriptions",
            "organizations_url": "https://api.github.com/users/YasmineMh/orgs",
            "repos_url": "https://api.github.com/users/YasmineMh/repos",
            "events_url": "https://api.github.com/users/YasmineMh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/YasmineMh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-06-08T13:49:18Z",
        "updated_at": "2023-06-11T07:33:36Z",
        "closed_at": "2023-06-11T07:33:36Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHey, I attempted to index documents using GPTTreeIndex and save them into Weaviate using the following code:\r\n\r\n```\r\nvector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=class_prefix)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = GPTTreeIndex.from_documents(doc, storage_context=storage_context)\r\n```\r\n\r\nHowever, the data was not saved. Nevertheless, when I tested it with GPTVectorStoreIndex, the data was successfully saved:\r\n\r\n```\r\nvector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=class_prefix)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = GPTVectorStoreIndex.from_documents(doc, storage_context=storage_context)\r\n```\r\n\r\nAny insights on that?\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6219/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6219/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6206",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6206/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6206/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6206/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6206",
        "id": 1747736455,
        "node_id": "PR_kwDOIWuq585Sgv0R",
        "number": 6206,
        "title": "fix: TransformQueryEngine is imported from wrong file on the docs",
        "user": {
            "login": "Ja-sonYun",
            "id": 46551097,
            "node_id": "MDQ6VXNlcjQ2NTUxMDk3",
            "avatar_url": "https://avatars.githubusercontent.com/u/46551097?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ja-sonYun",
            "html_url": "https://github.com/Ja-sonYun",
            "followers_url": "https://api.github.com/users/Ja-sonYun/followers",
            "following_url": "https://api.github.com/users/Ja-sonYun/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ja-sonYun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ja-sonYun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ja-sonYun/subscriptions",
            "organizations_url": "https://api.github.com/users/Ja-sonYun/orgs",
            "repos_url": "https://api.github.com/users/Ja-sonYun/repos",
            "events_url": "https://api.github.com/users/Ja-sonYun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ja-sonYun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-08T11:51:47Z",
        "updated_at": "2023-06-08T17:29:50Z",
        "closed_at": "2023-06-08T17:29:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6206",
            "html_url": "https://github.com/run-llama/llama_index/pull/6206",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6206.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6206.patch",
            "merged_at": "2023-06-08T17:29:49Z"
        },
        "body": "# Description\r\n\r\nhttps://gpt-index.readthedocs.io/en/latest/how_to/query_engine/advanced/query_transformations.html#hyde-hypothetical-document-embeddings\r\n`TransformQueryEngine` is imported from wrong file on the document. Seems like [notebook example](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/query_transformations/HyDEQueryTransformDemo.ipynb) is importing from correct file.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6206/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6206/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6203",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6203/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6203/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6203/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6203",
        "id": 1747399721,
        "node_id": "I_kwDOIWuq585oJzQp",
        "number": 6203,
        "title": "[Bug]: not able to run PandasExcelReader ",
        "user": {
            "login": "eyalsofer",
            "id": 120107188,
            "node_id": "U_kgDOByiwtA",
            "avatar_url": "https://avatars.githubusercontent.com/u/120107188?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eyalsofer",
            "html_url": "https://github.com/eyalsofer",
            "followers_url": "https://api.github.com/users/eyalsofer/followers",
            "following_url": "https://api.github.com/users/eyalsofer/following{/other_user}",
            "gists_url": "https://api.github.com/users/eyalsofer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eyalsofer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eyalsofer/subscriptions",
            "organizations_url": "https://api.github.com/users/eyalsofer/orgs",
            "repos_url": "https://api.github.com/users/eyalsofer/repos",
            "events_url": "https://api.github.com/users/eyalsofer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eyalsofer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-06-08T08:48:00Z",
        "updated_at": "2023-07-17T22:36:19Z",
        "closed_at": "2023-07-17T22:36:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nwhen running the excat same code of the ofiicial example of PandasExcelReader at llama-hub page, i get the following err:\r\nTypeError: PandasExcelReader.load_data() got an unexpected keyword argument 'pandas_config'\r\nwhen removing pandas_config parameter, i get the following err:\r\nAttributeError: 'PandasExcelReader' object has no attribute '_row_joiner'\n\n### Version\n\nV0.6.21.post1\n\n### Steps to Reproduce\n\njust try the official example code of PandasExcelReader\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6203/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6203/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6200",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6200/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6200/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6200/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6200",
        "id": 1747204454,
        "node_id": "I_kwDOIWuq585oJDlm",
        "number": 6200,
        "title": "[Bug]: Elasticsearch loader ValueError: Effective chunk size is non positive after considering extra_info",
        "user": {
            "login": "abhinavmishra590",
            "id": 5388037,
            "node_id": "MDQ6VXNlcjUzODgwMzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5388037?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abhinavmishra590",
            "html_url": "https://github.com/abhinavmishra590",
            "followers_url": "https://api.github.com/users/abhinavmishra590/followers",
            "following_url": "https://api.github.com/users/abhinavmishra590/following{/other_user}",
            "gists_url": "https://api.github.com/users/abhinavmishra590/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abhinavmishra590/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abhinavmishra590/subscriptions",
            "organizations_url": "https://api.github.com/users/abhinavmishra590/orgs",
            "repos_url": "https://api.github.com/users/abhinavmishra590/repos",
            "events_url": "https://api.github.com/users/abhinavmishra590/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abhinavmishra590/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-08T06:55:05Z",
        "updated_at": "2023-09-14T16:12:17Z",
        "closed_at": "2023-09-14T16:12:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI created a Opensearch index and now I want to reload that index and serve query. But it is throwing error. My code is:\r\n```\r\n\r\n   endpoint = getenv(\"OPENSEARCH_ENDPOINT\", \"http://localhost:9200\")\r\n    # index to demonstrate the VectorStore impl\r\n    idx = getenv(\"OPENSEARCH_INDEX\", \"demo\")\r\n    # OpensearchVectorClient stores text in this field by default\r\n    text_field = \"content\"\r\n    # OpensearchVectorClient stores embeddings in this field by default\r\n    embedding_field = \"embedding\"\r\n\r\n\r\n    reader = ElasticsearchReader(\r\n        \"http://localhost:9200\",\r\n        idx,\r\n    )\r\n\r\n    # search index using standard elasticsearch query DSL\r\n    # docs = reader.load_data(text_field, {\"query\": {\"match\": {text_field: question}}})\r\n    docs = reader.load_data(text_field)\r\n   client = OpensearchVectorClient(endpoint, idx, 1536, embedding_field=embedding_field, text_field=text_field)\r\n    # initialize vector store\r\n    vector_store = OpensearchVectorStore(client)\r\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n    index = GPTVectorStoreIndex.from_documents(documents=docs,storage_context=storage_context)\r\n    query_engine = index.as_query_engine()\r\n    res = query_engine.query(question)\r\n\r\n```\r\nI get error at `GPTVectorStoreIndex.from_documents()` as `ValueError: Effective chunk size is non positive after considering extra_info`\r\n\r\n### Version\r\n\r\n0.6.19\r\n\r\n### Steps to Reproduce\r\n\r\n1. Index data into Opensearch\r\n2. Reload the index from Opensearch \r\n3. serve query to get answer\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6200/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6200/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6199",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6199/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6199/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6199/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6199",
        "id": 1747184628,
        "node_id": "I_kwDOIWuq585oI-v0",
        "number": 6199,
        "title": "[Question]:  How do we incorporate service context while loading an index from storage.",
        "user": {
            "login": "nithinjp1997",
            "id": 61446944,
            "node_id": "MDQ6VXNlcjYxNDQ2OTQ0",
            "avatar_url": "https://avatars.githubusercontent.com/u/61446944?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nithinjp1997",
            "html_url": "https://github.com/nithinjp1997",
            "followers_url": "https://api.github.com/users/nithinjp1997/followers",
            "following_url": "https://api.github.com/users/nithinjp1997/following{/other_user}",
            "gists_url": "https://api.github.com/users/nithinjp1997/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nithinjp1997/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nithinjp1997/subscriptions",
            "organizations_url": "https://api.github.com/users/nithinjp1997/orgs",
            "repos_url": "https://api.github.com/users/nithinjp1997/repos",
            "events_url": "https://api.github.com/users/nithinjp1997/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nithinjp1997/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-06-08T06:39:26Z",
        "updated_at": "2023-06-20T13:33:03Z",
        "closed_at": "2023-06-20T13:33:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI tried providing the service context in the load index from storage function as kwargs dictionary and simply as a arguement (i.e service_context = service_context ,where i have a function which creates the service context and it is stored in a variable named service_context ). The issue I faced was that I am using the gpt-3.5-turbo as the llm_predictor in the service context but when I make an API call i.e query using llama-index the openAI usage is showing text-davinci . I have passed the gpt-3.5-turbo model using the ChatOpenAI wrapper so this should not happen . Please help me. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6199/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6199/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6198",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6198/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6198/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6198/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6198",
        "id": 1747088209,
        "node_id": "I_kwDOIWuq585oInNR",
        "number": 6198,
        "title": "OpenSearch Indexing doesn't create any data in index. Empty index exisits[Bug]: ",
        "user": {
            "login": "abhinavmishra590",
            "id": 5388037,
            "node_id": "MDQ6VXNlcjUzODgwMzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5388037?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abhinavmishra590",
            "html_url": "https://github.com/abhinavmishra590",
            "followers_url": "https://api.github.com/users/abhinavmishra590/followers",
            "following_url": "https://api.github.com/users/abhinavmishra590/following{/other_user}",
            "gists_url": "https://api.github.com/users/abhinavmishra590/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abhinavmishra590/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abhinavmishra590/subscriptions",
            "organizations_url": "https://api.github.com/users/abhinavmishra590/orgs",
            "repos_url": "https://api.github.com/users/abhinavmishra590/repos",
            "events_url": "https://api.github.com/users/abhinavmishra590/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abhinavmishra590/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-08T05:05:19Z",
        "updated_at": "2023-06-11T07:51:47Z",
        "closed_at": "2023-06-11T07:51:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am building an app to use Opensearch as vecotr store with Llamaindex using [this](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/OpensearchDemo.html) example. Here is the code I have\r\n\r\n   ```\r\nendpoint = getenv(\"OPENSEARCH_ENDPOINT\", \"http://localhost:9200\")\r\n    idx = getenv(\"OPENSEARCH_INDEX\", \"gpt-index-demo\")\r\n    \r\n    UnstructuredReader = download_loader(\"UnstructuredReader\")\r\n\r\n    loader = UnstructuredReader()\r\n    documents = loader.load_data(file=Path(file_name))\r\n\r\n    # OpensearchVectorClient stores text in this field by default\r\n    text_field = \"content\"\r\n    # OpensearchVectorClient stores embeddings in this field by default\r\n    embedding_field = \"embedding\"\r\n    # OpensearchVectorClient encapsulates logic for a\r\n    # single opensearch index with vector search enabled\r\n    client = OpensearchVectorClient(endpoint, idx, 1536, embedding_field=embedding_field, text_field=text_field)\r\n    # initialize vector store\r\n    vector_store = OpensearchVectorStore(client)\r\n    # initialize an index using our sample data and the client we just created\r\n    index = GPTVectorStoreIndex.from_documents(documents=documents)\r\n```\r\n\r\nThe confusion I am having is that when we create `OpensearchVectorClient`, we are not passing any `documents` and then when we initialize index, we do not pass `vector_store`, nor is there a eligible field to pass this by looking at the definition of `GPTVectorStoreIndex.from_documents()`. So, how does the document gets to `Opensearch` index?\r\n\n\n### Version\n\n0.6.19\n\n### Steps to Reproduce\n\n1. Used the code above but index in Opensearch is empty\r\n2. Code seems to be using default vector store\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6198/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6198/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6197",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6197/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6197/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6197/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/6197",
        "id": 1747074815,
        "node_id": "PR_kwDOIWuq585SegHi",
        "number": 6197,
        "title": "fix agent links",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-06-08T04:48:42Z",
        "updated_at": "2023-06-08T05:15:15Z",
        "closed_at": "2023-06-08T05:15:14Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/6197",
            "html_url": "https://github.com/run-llama/llama_index/pull/6197",
            "diff_url": "https://github.com/run-llama/llama_index/pull/6197.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/6197.patch",
            "merged_at": "2023-06-08T05:15:14Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nThis PR fixes links in the agent docs \r\n\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6197/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6197/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/6195",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/6195/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/6195/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/6195/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/6195",
        "id": 1746960540,
        "node_id": "I_kwDOIWuq585oIICc",
        "number": 6195,
        "title": "[Bug]: StreamingResponse class constructor not accepting keyword arguments",
        "user": {
            "login": "mike-j-brooks",
            "id": 60273459,
            "node_id": "MDQ6VXNlcjYwMjczNDU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/60273459?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mike-j-brooks",
            "html_url": "https://github.com/mike-j-brooks",
            "followers_url": "https://api.github.com/users/mike-j-brooks/followers",
            "following_url": "https://api.github.com/users/mike-j-brooks/following{/other_user}",
            "gists_url": "https://api.github.com/users/mike-j-brooks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mike-j-brooks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mike-j-brooks/subscriptions",
            "organizations_url": "https://api.github.com/users/mike-j-brooks/orgs",
            "repos_url": "https://api.github.com/users/mike-j-brooks/repos",
            "events_url": "https://api.github.com/users/mike-j-brooks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mike-j-brooks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-06-08T02:14:48Z",
        "updated_at": "2023-06-08T02:39:18Z",
        "closed_at": "2023-06-08T02:39:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nFor context, I'm using python 3.8 in a fastapi endpoint that streams to a react frontend. \r\n\r\nInstantiating the StreamingResponse class object works fine if you only pass in a response_gen object as a positional argument, as shown in your documentation examples. \r\n\r\nPython throws a TypeError if you pass the argument as keyword argument as follows: \r\n\r\n```\r\nstreaming_response = StreamingResponse(\r\n        response_gen=query_engine.query(user_input).response_gen,\r\n        extra_info={\"source_url\": source_url}\r\n        )\r\n```\r\n\r\nError message: \r\n```\r\nstreaming_response = StreamingResponse(\r\nTypeError: __init__() got an unexpected keyword argument 'response_gen'\r\n```\r\nThis also occurs for extra_info, if you pass response_gen as positional, and extra_info as keyword argument as follows:\r\n```\r\nstreaming_response = StreamingResponse(\r\n        query_engine.query(user_input).response_gen,\r\n        extra_info={\"source_url\": source_url}\r\n        )\r\n```\r\nError message: \r\n```\r\nTypeError: __init__() got an unexpected keyword argument 'extra_info'\r\n```\r\n\r\nI can't find a syntax related cause for this. The @dataclass decorator provides an automatically generated __init__() method, but it seems to not like keyword arguments. According to python docs, keyword args should be fine for dataclass constructors. \r\n\r\nI've also tried just passing everything as a positional argument, but there's a separate issue where source_nodes won't take a list of nodes, as the documentation would suggest. So I need to pass extra_info as a keyword argument. \r\n\r\n\r\n\n\n### Version\n\n0.6.20\n\n### Steps to Reproduce\n\nThis setup assumes an index has already been built and stored in a directory.\r\nThis is part of a fastapi endpoint, but this script-style setup should explain what I'm doing sufficiently. \r\n\r\n### setup LLM\r\nllm_predictor = LLMPredictor(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", streaming=True))\r\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\r\n\r\n### rebuild storage context\r\nstorage_context = StorageContext.from_defaults(persist_dir=\"/some/data/directory\")\r\n\r\n### load index\r\nindex = load_index_from_storage(storage_context, service_context=service_context)\r\n\r\n### query the index\r\nquery_engine = index.as_query_engine(\r\n    streaming=True,\r\n    similarity_top_k=1\r\n)\r\n\r\n### use user input to retrieve nodes \r\nretriever = index.as_retriever()\r\nnodes = retriever.retrieve(user_input)\r\n\r\n### create the response streaming object\r\n### I'm using a custom method (not shown here) to get the source_url \r\nstreaming_response = StreamingResponse(\r\n        response_gen=query_engine.query(user_input).response_gen,\r\n        extra_info={\"source_url\": source_url}\r\n        )\r\n\r\n### pass the response stream to frontend GUI\r\nreturn streaming_response\n\n### Relevant Logs/Tracbacks\n\n```shell\nERROR:    Exception in ASGI application\r\nTraceback (most recent call last):\r\n  File \"pve1/lib/python3.8/site-packages/uvicorn/protocols/http/h11_impl.py\", line 428, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n  File \"pve1/lib/python3.8/site-packages/uvicorn/middleware/proxy_headers.py\", line 78, in __call__\r\n    return await self.app(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/fastapi/applications.py\", line 276, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/applications.py\", line 122, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/errors.py\", line 184, in __call__\r\n    raise exc\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/errors.py\", line 162, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/cors.py\", line 92, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/cors.py\", line 147, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/exceptions.py\", line 79, in __call__\r\n    raise exc\r\n  File \"pve1/lib/python3.8/site-packages/starlette/middleware/exceptions.py\", line 68, in __call__\r\n    await self.app(scope, receive, sender)\r\n  File \"pve1/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\", line 21, in __call__\r\n    raise e\r\n  File \"pve1/lib/python3.8/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\r\n    await self.app(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/routing.py\", line 718, in __call__\r\n    await route.handle(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/routing.py\", line 276, in handle\r\n    await self.app(scope, receive, send)\r\n  File \"pve1/lib/python3.8/site-packages/starlette/routing.py\", line 66, in app\r\n    response = await func(request)\r\n  File \"pve1/lib/python3.8/site-packages/fastapi/routing.py\", line 237, in app\r\n    raw_response = await run_endpoint_function(\r\n  File \"pve1/lib/python3.8/site-packages/fastapi/routing.py\", line 163, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n  File \"/my/chatbot/app/backend/main.py\", line 298, in sse_endpoint\r\n    streaming_response = StreamingResponse(\r\nTypeError: __init__() got an unexpected keyword argument 'response_gen'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/6195/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/6195/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    }
]