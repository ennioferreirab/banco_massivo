[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9534",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9534/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9534/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9534/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9534",
        "id": 2042627189,
        "node_id": "PR_kwDOIWuq585iDWB3",
        "number": 9534,
        "title": "Fleshing out \"Understanding evaluation\" section a bit",
        "user": {
            "login": "seldo",
            "id": 185893,
            "node_id": "MDQ6VXNlcjE4NTg5Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/185893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seldo",
            "html_url": "https://github.com/seldo",
            "followers_url": "https://api.github.com/users/seldo/followers",
            "following_url": "https://api.github.com/users/seldo/following{/other_user}",
            "gists_url": "https://api.github.com/users/seldo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seldo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seldo/subscriptions",
            "organizations_url": "https://api.github.com/users/seldo/orgs",
            "repos_url": "https://api.github.com/users/seldo/repos",
            "events_url": "https://api.github.com/users/seldo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seldo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T22:56:10Z",
        "updated_at": "2023-12-14T22:56:14Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9534",
            "html_url": "https://github.com/run-llama/llama_index/pull/9534",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9534.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9534.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9534/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9534/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9533",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9533/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9533/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9533/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9533",
        "id": 2042591706,
        "node_id": "PR_kwDOIWuq585iDOOe",
        "number": 9533,
        "title": "Improving \"agents\" section of Putting It All Together",
        "user": {
            "login": "seldo",
            "id": 185893,
            "node_id": "MDQ6VXNlcjE4NTg5Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/185893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seldo",
            "html_url": "https://github.com/seldo",
            "followers_url": "https://api.github.com/users/seldo/followers",
            "following_url": "https://api.github.com/users/seldo/following{/other_user}",
            "gists_url": "https://api.github.com/users/seldo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seldo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seldo/subscriptions",
            "organizations_url": "https://api.github.com/users/seldo/orgs",
            "repos_url": "https://api.github.com/users/seldo/repos",
            "events_url": "https://api.github.com/users/seldo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seldo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T22:20:57Z",
        "updated_at": "2023-12-14T22:25:57Z",
        "closed_at": "2023-12-14T22:25:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9533",
            "html_url": "https://github.com/run-llama/llama_index/pull/9533",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9533.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9533.patch",
            "merged_at": "2023-12-14T22:25:56Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9533/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9533/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9532",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9532/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9532/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9532/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9532",
        "id": 2042507137,
        "node_id": "I_kwDOIWuq5855vi-B",
        "number": 9532,
        "title": "[Question]: How to use HuggingFaceTextGenInference without wrapping with LLMPredictor",
        "user": {
            "login": "gameveloster",
            "id": 103383490,
            "node_id": "U_kgDOBimBwg",
            "avatar_url": "https://avatars.githubusercontent.com/u/103383490?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gameveloster",
            "html_url": "https://github.com/gameveloster",
            "followers_url": "https://api.github.com/users/gameveloster/followers",
            "following_url": "https://api.github.com/users/gameveloster/following{/other_user}",
            "gists_url": "https://api.github.com/users/gameveloster/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gameveloster/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gameveloster/subscriptions",
            "organizations_url": "https://api.github.com/users/gameveloster/orgs",
            "repos_url": "https://api.github.com/users/gameveloster/repos",
            "events_url": "https://api.github.com/users/gameveloster/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gameveloster/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-14T21:09:19Z",
        "updated_at": "2023-12-14T22:07:04Z",
        "closed_at": "2023-12-14T21:39:11Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am trying to use a model hosted on a TGI server and `query_wrapper_prompt` provides a convenient way to format the prompts based on the model being served by TGI.\r\n\r\nWrapping `HuggingFaceTextGenInference` with `LLMPredictor` appears to work, but there are warning messages stating `LLMPredictor is deprecated, please use LLM instead.`\r\n\r\n```py\r\nfrom langchain.llms import HuggingFaceTextGenInference\r\nfrom llama_index import LLMPredictor, PromptTemplate\r\n\r\nllm = HuggingFaceTextGenInference(inference_server_url=\"http://localhost:1234\")\r\nquery_wrapper_prompt = PromptTemplate(\"[INST]{query_str}[/INST]\")\r\nllm_predictor = LLMPredictor(llm=llm, query_wrapper_prompt=query_wrapper_prompt)\r\n```\r\n\r\nWhat is the new method of using `HuggingFaceTextGenInference` with `query_wrapper_prompt`?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9532/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9532/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9531",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9531/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9531/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9531/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9531",
        "id": 2042356548,
        "node_id": "PR_kwDOIWuq585iCZsz",
        "number": 9531,
        "title": "[WIP] `LabelledEvaluationDataset`",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T19:41:24Z",
        "updated_at": "2023-12-14T19:41:24Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9531",
            "html_url": "https://github.com/run-llama/llama_index/pull/9531",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9531.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9531.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\n- used for evaluating/benchmarking an LLM evaluator\r\n- similar to `LabelledRagDataset`, this new one contains of examples that need to be predicted on. Examples include references (i.e., ground truth values). In the context of evaluating an evaluator, prediction means providing an evaluation, and reference is a gold-standard evaluation like those coming from a human, or gpt-4.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9531/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9531/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9530",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9530/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9530/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9530/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9530",
        "id": 2042195142,
        "node_id": "PR_kwDOIWuq585iB2Xp",
        "number": 9530,
        "title": "Add hybrid search to neo4j vector store",
        "user": {
            "login": "tomasonjo",
            "id": 19948365,
            "node_id": "MDQ6VXNlcjE5OTQ4MzY1",
            "avatar_url": "https://avatars.githubusercontent.com/u/19948365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tomasonjo",
            "html_url": "https://github.com/tomasonjo",
            "followers_url": "https://api.github.com/users/tomasonjo/followers",
            "following_url": "https://api.github.com/users/tomasonjo/following{/other_user}",
            "gists_url": "https://api.github.com/users/tomasonjo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tomasonjo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tomasonjo/subscriptions",
            "organizations_url": "https://api.github.com/users/tomasonjo/orgs",
            "repos_url": "https://api.github.com/users/tomasonjo/repos",
            "events_url": "https://api.github.com/users/tomasonjo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tomasonjo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T17:53:13Z",
        "updated_at": "2023-12-14T22:11:09Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9530",
            "html_url": "https://github.com/run-llama/llama_index/pull/9530",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9530.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9530.patch",
            "merged_at": null
        },
        "body": "Add Hybrid Search to Neo4j vector store",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9530/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9530/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9529",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9529/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9529/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9529/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9529",
        "id": 2042068818,
        "node_id": "PR_kwDOIWuq585iBag1",
        "number": 9529,
        "title": "fix/Reintroduce `WHERE` filter to the Sparse Query for PgVectorStore",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-14T16:42:05Z",
        "updated_at": "2023-12-14T22:08:49Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9529",
            "html_url": "https://github.com/run-llama/llama_index/pull/9529",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9529.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9529.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nReintroduce `WHERE` filter to the Sparse query for PgVector (reverting #9400)\r\n\r\nThe considerations are:\r\n- The `ts_rank` function works by ranking all rows, by not filtering the result we will essentially rank all rows in the table most of which will probably have a ranking of 0. So that's expensive and unnecessary.\r\n- The `ts_query` variable we put on the `SELECT` clause will only compiled to `plainto_tsquery($1, $2::VARCHAR)`, which does not do anything other than convert the query to `tsquery` type. So we still need to put the `WHERE` clause to actually filter the result.\r\n\r\nPerformance comparison (you can see the execution time is almost 2x faster):\r\n\r\n**Without `WHERE` clause:**\r\n```\r\nQUERY PLAN                                                                                                                                                    |\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------+\r\nLimit  (cost=61005.45..61017.12 rows=100 width=1191) (actual time=627.584..629.058 rows=100 loops=1)                                                          |\r\n  ->  Gather Merge  (cost=61005.45..88736.49 rows=237678 width=1191) (actual time=627.582..629.048 rows=100 loops=1)                                          |\r\n        Workers Planned: 2                                                                                                                                    |\r\n        Workers Launched: 2                                                                                                                                   |\r\n        ->  Sort  (cost=60005.43..60302.53 rows=118839 width=1191) (actual time=624.766..624.770 rows=64 loops=3)                                             |\r\n              Sort Key: (ts_rank(text_search_tsv, '''china'''::tsquery)) DESC                                                                                 |\r\n              Sort Method: top-N heapsort  Memory: 252kB                                                                                                      |\r\n              Worker 0:  Sort Method: top-N heapsort  Memory: 244kB                                                                                           |\r\n              Worker 1:  Sort Method: top-N heapsort  Memory: 270kB                                                                                           |\r\n              ->  Parallel Seq Scan on my_table                   (cost=0.00..55463.49 rows=118839 width=1191) (actual time=0.072..578.646 rows=95071 loops=3)|\r\nPlanning Time: 0.094 ms                                                                                                                                       |\r\nExecution Time: 629.090 ms                                                                                                                                    |\r\n```\r\n\r\n**With `WHERE` clause:**\r\n```\r\nQUERY PLAN                                                                                                                                               |\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------+\r\nLimit  (cost=55709.26..55709.51 rows=100 width=1191) (actual time=306.273..306.289 rows=100 loops=1)                                                     |\r\n  ->  Sort  (cost=55709.26..55803.64 rows=37753 width=1191) (actual time=306.272..306.278 rows=100 loops=1)                                              |\r\n        Sort Key: (ts_rank(text_search_tsv, '''china'''::tsquery)) DESC                                                                                  |\r\n        Sort Method: top-N heapsort  Memory: 334kB                                                                                                       |\r\n        ->  Bitmap Heap Scan on my_table  (cost=2220.58..54266.37 rows=37753 width=1191) (actual time=9.637..287.518 rows=36933 loops=1)                 |\r\n              Recheck Cond: (text_search_tsv @@ '''china'''::tsquery)                                                                                    |\r\n              Heap Blocks: exact=21136                                                                                                                   |\r\n              ->  Bitmap Index Scan on text_search_tsv_idx  (cost=0.00..2211.15 rows=37753 width=0) (actual time=6.226..6.226 rows=40473 loops=1)        |\r\n                    Index Cond: (text_search_tsv @@ '''china'''::tsquery)                                                                                |\r\nPlanning Time: 0.134 ms                                                                                                                                  |\r\nExecution Time: 306.325 ms                                                                                                                               |\r\n```\r\n\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9529/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9529/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9528",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9528/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9528/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9528/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9528",
        "id": 2042038037,
        "node_id": "PR_kwDOIWuq585iBTtJ",
        "number": 9528,
        "title": "Integrations: Gradient[Embeddings,LLM] - sdk-upgrade",
        "user": {
            "login": "michaelfeil",
            "id": 63565275,
            "node_id": "MDQ6VXNlcjYzNTY1Mjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/63565275?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/michaelfeil",
            "html_url": "https://github.com/michaelfeil",
            "followers_url": "https://api.github.com/users/michaelfeil/followers",
            "following_url": "https://api.github.com/users/michaelfeil/following{/other_user}",
            "gists_url": "https://api.github.com/users/michaelfeil/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/michaelfeil/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/michaelfeil/subscriptions",
            "organizations_url": "https://api.github.com/users/michaelfeil/orgs",
            "repos_url": "https://api.github.com/users/michaelfeil/repos",
            "events_url": "https://api.github.com/users/michaelfeil/events{/privacy}",
            "received_events_url": "https://api.github.com/users/michaelfeil/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T16:24:07Z",
        "updated_at": "2023-12-14T20:49:59Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9528",
            "html_url": "https://github.com/run-llama/llama_index/pull/9528",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9528.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9528.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Potential breaking change for `GradientEmbeddings`: New miniumum version of `pip install \"gradientai>=1.4.0\"` is required. As `gradientai` is not linked with a specific version in `pyproject.toml` this would lead to a breaking change, if the miniumum version is not  `pip install \"gradientai>=1.4.0\"`. Note: It would be awesome if that could be managed, aka `pip install llama-index[gradient]`. @mhaligowski \r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests - for the async\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [not relevant] I have made corresponding changes to the documentation\r\n- [not relevant] I have added Google Colab support for the newly added notebooks.\r\n- [raises importerror / warning ] My changes generate no new warnings \r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9528/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9528/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9527",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9527/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9527/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9527/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9527",
        "id": 2041965161,
        "node_id": "I_kwDOIWuq5855tepp",
        "number": 9527,
        "title": "[Question]: How hit rate and MRR are calculated in Retrieval Evaluation?",
        "user": {
            "login": "terilias",
            "id": 37142366,
            "node_id": "MDQ6VXNlcjM3MTQyMzY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/37142366?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/terilias",
            "html_url": "https://github.com/terilias",
            "followers_url": "https://api.github.com/users/terilias/followers",
            "following_url": "https://api.github.com/users/terilias/following{/other_user}",
            "gists_url": "https://api.github.com/users/terilias/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/terilias/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/terilias/subscriptions",
            "organizations_url": "https://api.github.com/users/terilias/orgs",
            "repos_url": "https://api.github.com/users/terilias/repos",
            "events_url": "https://api.github.com/users/terilias/events{/privacy}",
            "received_events_url": "https://api.github.com/users/terilias/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-14T15:43:13Z",
        "updated_at": "2023-12-14T15:57:52Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nHello,\r\nI recently started to study the evaluation methods that LlamaIndex offers.\r\nI read the following articles and resources:\r\n\r\n- https://docs.llamaindex.ai/en/stable/module_guides/evaluating/root.html\r\n- https://cookbook.openai.com/examples/evaluation/evaluate_rag_with_llamaindex\r\n- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5\r\n\r\n Thanks for publishing this work!\r\nI have some questions regarding the hit rate and the MRR calculations. I know that we call the function on a dataset that has been generated with generate_question_context_pairs(). We expect to create some questions for each node.\r\n\r\n1. I understand that we have a hit, if at least one of the retrieved nodes are relevant with the query.  What does this means? \r\n Does it mean that at least one of the retrieved nodes must be the node for which the specific question has been generated?\r\n2. How to change the embeddings model in the RetrieverEvaluator? I want it to use the same embedding model that I used for the indexing (hugging face embeddings). I tried to specify the embed_model but is uses the OpenAI embeddings. \r\n3. Does the MRR calculation use similarity calculation? Does it check if at the first rank we have the node for which the specific question has been generated?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9527/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9527/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9526",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9526/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9526/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9526/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9526",
        "id": 2041957351,
        "node_id": "PR_kwDOIWuq585iBCG5",
        "number": 9526,
        "title": "fix: improve PgVectorStore Retrieval by not fetching unnecessary columns",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T15:38:53Z",
        "updated_at": "2023-12-14T17:53:19Z",
        "closed_at": "2023-12-14T17:53:19Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9526",
            "html_url": "https://github.com/run-llama/llama_index/pull/9526",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9526.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9526.patch",
            "merged_at": "2023-12-14T17:53:19Z"
        },
        "body": "# Description\r\n\r\nPreviously, since our query doesn't specify the specified column to fetch, SqlAlchemy will fetch all columns, including the `embedding` and `tsv` columns which are pretty huge and weren't used at all.\r\n\r\nThis improvement should improve the retrieval performance, also reduce network transfer cost at scale.\r\n\r\n**Before**\r\n```sql\r\nSELECT\r\n    id,\r\n    text,\r\n    metadata_,\r\n    node_id,\r\n    embedding,\r\n    text_search_tsv,\r\n    embedding <=> $1 AS anon_1\r\nFROM public.data_the_economist_hybrid\r\nORDER BY embedding <=> $2\r\nLIMIT $3::INTEGER\r\n```\r\n\r\n**After**\r\n```sql\r\nSELECT\r\n    id,\r\n    node_id,\r\n    text,\r\n    metadata_,\r\n    embedding <=> $1 AS distance\r\nFROM public.data_the_economist_hybrid\r\nORDER BY distance asc\r\nLIMIT $2::INTEGER\r\n```\r\n\r\n**Used columns**\r\n```python\r\nreturn [\r\n    DBEmbeddingRow(\r\n        node_id=item.node_id,\r\n        text=item.text,\r\n        metadata=item.metadata_,\r\n        similarity=(1 - item.distance) if item.distance is not None else 0,\r\n    )\r\n    for item in res.all()\r\n]\r\n```\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9526/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9526/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9525",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9525/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9525/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9525/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9525",
        "id": 2041921810,
        "node_id": "I_kwDOIWuq5855tUES",
        "number": 9525,
        "title": "[Bug]: Indexing a large number of Documents resulted in ValueError with ChromaDB",
        "user": {
            "login": "hieuv",
            "id": 18454688,
            "node_id": "MDQ6VXNlcjE4NDU0Njg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/18454688?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hieuv",
            "html_url": "https://github.com/hieuv",
            "followers_url": "https://api.github.com/users/hieuv/followers",
            "following_url": "https://api.github.com/users/hieuv/following{/other_user}",
            "gists_url": "https://api.github.com/users/hieuv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hieuv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hieuv/subscriptions",
            "organizations_url": "https://api.github.com/users/hieuv/orgs",
            "repos_url": "https://api.github.com/users/hieuv/repos",
            "events_url": "https://api.github.com/users/hieuv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hieuv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-14T15:19:54Z",
        "updated_at": "2023-12-14T18:09:20Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nIndexing a large number of Documents resulted in ValueError with ChromaDB.\r\nIn my case, I had 34k files, loaded into 191k+ Documents, and parsed into 229k Nodes.\r\n\r\nI found #7648, and https://github.com/chroma-core/chroma/issues/1049. \r\nFrom the log, it seems that LlamaIndex correctly run in batch of 41665 as the fixed for #7648 intended. However, chromadb complains that the maximum batch size is 5461.\r\nLog available below.\r\n\r\nUsing LlamaIndex 0.9.15 and ChromaDB 0.4.19\r\n\r\n### Version\r\n\r\n0.9.15\r\n\r\n### Steps to Reproduce\r\n\r\nRun this code against a large set of document. I suspect >5500 will do.\r\n\r\n```python\r\n# initialize client, setting path to save data\r\ndb = chromadb.PersistentClient(path=\"./chroma_db\")\r\n\r\n# create collection\r\nchroma_collection = db.get_or_create_collection(\"collection_name\")\r\n\r\n# assign chroma as the vector_store to the context\r\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\nindex = VectorStoreIndex.from_documents(\r\n    documents,\r\n    show_progress=True,\r\n    storage_context=storage_context,\r\n)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```text\r\n[REDACTED project folder]\\venv\\Scripts\\python.exe [REDACTED project folder]\\main.py\r\n2023-12-14 13:46:57,044 I main.py L62: <module>(): Loading starts\r\n2023-12-14 13:46:58,055 I [REDACTED custom loader module].py L74: _add_files(): Total files added: 34155\r\nLoading files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 34155/34155 [02:20<00:00, 243.86file/s]\r\n2023-12-14 13:49:18,132 I main.py L71: <module>(): Loading ends\r\n2023-12-14 13:49:18,132 I main.py L72: <module>(): Indexing starts\r\nParsing nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 191025/191025 [02:54<00:00, 1094.34it/s]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 229210/229210 [1:09:27<00:00, 54.99it/s]\r\nTraceback (most recent call last):\r\n  File \"[REDACTED project folder]\\main.py\", line 84, in <module>\r\n    index = VectorStoreIndex.from_documents(\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\base.py\", line 106, in from_documents\r\n    return cls(\r\n           ^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 49, in __init__\r\n    super().__init__(\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\base.py\", line 71, in __init__\r\n    index_struct = self.build_index_from_nodes(nodes)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 255, in build_index_from_nodes\r\n    return self._build_index_from_nodes(nodes, **insert_kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 236, in _build_index_from_nodes\r\n    self._add_nodes_to_index(\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 190, in _add_nodes_to_index\r\n    new_ids = self._vector_store.add(nodes, **insert_kwargs)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\llama_index\\vector_stores\\chroma.py\", line 243, in add\r\n    self._collection.add(\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py\", line 168, in add\r\n    self._client._add(ids, self.id, embeddings, metadatas, documents, uris)\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py\", line 127, in wrapper\r\n    return f(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\chromadb\\api\\segment.py\", line 344, in _add\r\n    validate_batch(\r\n  File \"[REDACTED project folder]\\venv\\Lib\\site-packages\\chromadb\\api\\types.py\", line 505, in validate_batch\r\n    raise ValueError(\r\nValueError: Batch size 41665 exceeds maximum batch size 5461\r\n\r\nProcess finished with exit code 1\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9525/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9525/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9524",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9524/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9524/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9524/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9524",
        "id": 2041759969,
        "node_id": "I_kwDOIWuq5855ssjh",
        "number": 9524,
        "title": "[Question]: Using Open AI for completion",
        "user": {
            "login": "snassimr",
            "id": 6830626,
            "node_id": "MDQ6VXNlcjY4MzA2MjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6830626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snassimr",
            "html_url": "https://github.com/snassimr",
            "followers_url": "https://api.github.com/users/snassimr/followers",
            "following_url": "https://api.github.com/users/snassimr/following{/other_user}",
            "gists_url": "https://api.github.com/users/snassimr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snassimr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snassimr/subscriptions",
            "organizations_url": "https://api.github.com/users/snassimr/orgs",
            "repos_url": "https://api.github.com/users/snassimr/repos",
            "events_url": "https://api.github.com/users/snassimr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snassimr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-14T13:58:38Z",
        "updated_at": "2023-12-14T15:17:22Z",
        "closed_at": "2023-12-14T15:17:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi , \r\n\r\nI have two questions \ud83d\udc4d \r\n\r\n1. How to set some waiting time to avoid rate limit for OpenAI . I saw using of sleep command . Any built-in setting in llama_index.\r\n2. How to get count of tokens returned with complete command\r\n\r\nHere the code I use : \r\n\r\n```\r\nllm = OpenAI(model = 'gpt-4', temperature = 0.1)\r\ngen_text = llm.complete(prompt).text\r\n```\r\n\r\nThanks,\r\nNissim",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9524/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9524/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9523",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9523/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9523/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9523/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9523",
        "id": 2041585102,
        "node_id": "I_kwDOIWuq5855sB3O",
        "number": 9523,
        "title": "[Bug]: Text2SQL generates right SQL but provides wrong answer.",
        "user": {
            "login": "danielstankw",
            "id": 72759092,
            "node_id": "MDQ6VXNlcjcyNzU5MDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/72759092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielstankw",
            "html_url": "https://github.com/danielstankw",
            "followers_url": "https://api.github.com/users/danielstankw/followers",
            "following_url": "https://api.github.com/users/danielstankw/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielstankw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielstankw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielstankw/subscriptions",
            "organizations_url": "https://api.github.com/users/danielstankw/orgs",
            "repos_url": "https://api.github.com/users/danielstankw/repos",
            "events_url": "https://api.github.com/users/danielstankw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielstankw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T12:19:40Z",
        "updated_at": "2023-12-14T12:29:53Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen using an LLM I obtain correct SQL query for my question.\r\n\r\n\r\n```\r\nquery_str = \"What is the total amount for segment called : 'Pharma' for the first, second and third quarter of 2022? \"\r\nresponse = query_engine.query(query_str)\r\n```\r\nThe response I get is:\r\n```\r\n2023-12-14 12:08:02,393 INFO sqlalchemy.engine.Engine BEGIN (implicit)\r\n2023-12-14 12:08:02,394 INFO sqlalchemy.engine.Engine SELECT SUM(Amount) FROM finance WHERE Segment = 'Pharma' AND Year = 2022 AND Quarter IN ('Q1', 'Q2', 'Q3'); \r\n### Answer: 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\r\n```\r\n\r\nIf I take this query and run it using `sql_database.run_sql(sql_query)` I do obtained a correct answer.\r\n```\r\n2023-12-14 12:08:54,797 INFO sqlalchemy.engine.Engine BEGIN (implicit)\r\n2023-12-14 12:08:54,798 INFO sqlalchemy.engine.Engine SELECT SUM(Amount) FROM finance WHERE Segment = 'Pharma' AND Year = 2022 AND Quarter IN ('Q1', 'Q2', 'Q3');\r\n2023-12-14 12:08:54,799 INFO sqlalchemy.engine.Engine [generated in 0.00039s] ()\r\n2023-12-14 12:08:54,900 INFO sqlalchemy.engine.Engine COMMIT\r\n('[(1980417814.2799988,)]',\r\n {'result': [(1980417814.2799988,)], 'col_keys': ['SUM(Amount)']})\r\n```\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nNone\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9523/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9523/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9522",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9522/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9522/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9522/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9522",
        "id": 2041347140,
        "node_id": "I_kwDOIWuq5855rHxE",
        "number": 9522,
        "title": "[Bug]: sqalchemy warning in postgres vectorstore hybrid search",
        "user": {
            "login": "stdweird",
            "id": 1517606,
            "node_id": "MDQ6VXNlcjE1MTc2MDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1517606?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stdweird",
            "html_url": "https://github.com/stdweird",
            "followers_url": "https://api.github.com/users/stdweird/followers",
            "following_url": "https://api.github.com/users/stdweird/following{/other_user}",
            "gists_url": "https://api.github.com/users/stdweird/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stdweird/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stdweird/subscriptions",
            "organizations_url": "https://api.github.com/users/stdweird/orgs",
            "repos_url": "https://api.github.com/users/stdweird/repos",
            "events_url": "https://api.github.com/users/stdweird/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stdweird/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T09:58:44Z",
        "updated_at": "2023-12-14T10:04:35Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nFollowing warning pops up when using hybrid search with postgres vector\r\n```\r\n.../llama_index/vector_stores/postgres.py:510: SAWarning: UserDefinedType REGCONFIG() will not produce a cache key becaus\r\ne the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLA\r\nlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this warning at\r\n: https://sqlalche.me/e/20/cprf)                                                                                                                                        \r\n  res = session.execute(stmt)                     \r\n```\r\n\r\nThis also is present in lantern vector_store (it's in the notebook) and has similar code as postgres vectorstore\n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\nSetup a hybrid postgres vecotr store and run a query\n\n### Relevant Logs/Tracbacks\n\n```shell\nSee https://docs.sqlalchemy.org/en/20/errors.html#assertion-attributes-for-caching for an explanation (that i don't fully understand, so i can't propose a fix)\r\n\r\nthe `_build_sparse_query` in `vector_stores/postgres.py` has a subclassed `UserDefinedType` that is mentioned in the 2nd item in the url above. \r\n\r\nthe line referenced in the warning is the execution of the statement.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9522/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9522/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9520",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9520/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9520/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9520/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9520",
        "id": 2041227753,
        "node_id": "I_kwDOIWuq5855qqnp",
        "number": 9520,
        "title": "[Bug]: *** RuntimeError: Timeout context manager should be used inside a task",
        "user": {
            "login": "huangjiaheng",
            "id": 18376413,
            "node_id": "MDQ6VXNlcjE4Mzc2NDEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/18376413?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/huangjiaheng",
            "html_url": "https://github.com/huangjiaheng",
            "followers_url": "https://api.github.com/users/huangjiaheng/followers",
            "following_url": "https://api.github.com/users/huangjiaheng/following{/other_user}",
            "gists_url": "https://api.github.com/users/huangjiaheng/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/huangjiaheng/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/huangjiaheng/subscriptions",
            "organizations_url": "https://api.github.com/users/huangjiaheng/orgs",
            "repos_url": "https://api.github.com/users/huangjiaheng/repos",
            "events_url": "https://api.github.com/users/huangjiaheng/events{/privacy}",
            "received_events_url": "https://api.github.com/users/huangjiaheng/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T08:49:46Z",
        "updated_at": "2023-12-14T09:01:43Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n*** RuntimeError: Timeout context manager should be used inside a task\n\n### Version\n\nllama_index==0.8.63.post2\n\n### Steps to Reproduce\n\nstep1. use elasticsearch vector store\r\nstep2. start a server\r\nstep3. client request, engine generate reply\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9520/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9520/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9519",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9519/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9519/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9519/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9519",
        "id": 2041047958,
        "node_id": "I_kwDOIWuq5855p-uW",
        "number": 9519,
        "title": "[Bug]: Metadata Filter won't work properly on HNSW PgVectorStore due to PgVector limitation",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T07:05:11Z",
        "updated_at": "2023-12-14T07:34:14Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThere is an open issue on PgVector Repo which causes indexed embedding (HNSW) won't work properly when combined with a filter.\r\n* https://github.com/pgvector/pgvector/issues/259\r\n \r\nThe query in question is similar to the one used by the PgVectorStore retriever.\r\n```\r\nSELECT id, text\r\nFROM document\r\nWHERE category = $1\r\nORDER BY embedding <-> $2\r\nLIMIT 10;\r\n```\r\n\r\nPS: This problem only occurs when you index your PgVector table (with HNSW). The standard table or IFFlat indexed table won't face this issue, but you will hit a performance issue once you have a lot of data.\r\n\r\n### Version\r\n\r\nlatest\r\n\r\n### Steps to Reproduce\r\n\r\nQuery your PgVectorStore with and without metadata filtering, and you will notice something weird happening.\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9519/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9519/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9518",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9518/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9518/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9518/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9518",
        "id": 2040987218,
        "node_id": "I_kwDOIWuq5855pv5S",
        "number": 9518,
        "title": "[Bug]: Unable to connect milvus with latest llama-index package 0.9.15",
        "user": {
            "login": "codesridhar",
            "id": 138313203,
            "node_id": "U_kgDOCD598w",
            "avatar_url": "https://avatars.githubusercontent.com/u/138313203?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/codesridhar",
            "html_url": "https://github.com/codesridhar",
            "followers_url": "https://api.github.com/users/codesridhar/followers",
            "following_url": "https://api.github.com/users/codesridhar/following{/other_user}",
            "gists_url": "https://api.github.com/users/codesridhar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/codesridhar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/codesridhar/subscriptions",
            "organizations_url": "https://api.github.com/users/codesridhar/orgs",
            "repos_url": "https://api.github.com/users/codesridhar/repos",
            "events_url": "https://api.github.com/users/codesridhar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/codesridhar/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T06:14:15Z",
        "updated_at": "2023-12-14T06:21:29Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHello Everyone,\r\n\r\nWe are unable to connect Milvus with the latest version of llama-index, resulting in the error message: \"Node content not found in metadata dict.\"\r\nCurrent Environment:\r\n\r\nopenai==0.28.1\r\nllama-index==0.8.17\r\n\r\nAttempt to connect Milvus with the latest version of llama-index using the provided code snippet.\r\nObserve the \"Node content not found in metadata dict\" error.\r\n\r\nThe connection to Milvus works as expected with the current versions of openai (0.28.1) and llama-index (0.8.17).\r\nAfter upgrading to the latest version of llama-index, we face the mentioned issue.\r\n\r\nMILVUS_DB_URL = f\"http://{MILVUS_DB_HOST}:{MILVUS_DB_PORT}\"\r\n\r\nvector_store = MilvusVectorStore(\r\n    collection_name=milvus_collection_name,\r\n    uri=MILVUS_DB_URL\r\n    # host=MILVUS_DB_HOST,\r\n    # port=MILVUS_DB_PORT,\r\n)\r\n\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\nindex = VectorStoreIndex.from_documents(\r\n    documents=[],\r\n    storage_context=storage_context,\r\n    service_context=service_context,\r\n)\r\n\r\n**Error:** <MilvusException: (code=2, message=Fail connecting to server on 1xx.1xx.2xx.3xx:19530. Timeout)>\r\n\r\n\r\nAlternative Code Attempt:\r\n\r\nvector_store = MilvusVectorStore(\r\n    collection_name=milvus_collection_name,\r\n    host=MILVUS_DB_HOST,\r\n    port=MILVUS_DB_PORT,\r\n)\r\n\r\n**Error:** Node content not found in metadata dict\" error.\r\n\r\nPlease investigate this issue at priority and help us to proceed further.\r\n\r\nThanks,\r\nSridhar\n\n### Version\n\nllama-index 0.9.15\n\n### Steps to Reproduce\n\nJust to execute the program\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9518/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9518/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9517",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9517/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9517/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9517/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9517",
        "id": 2040923149,
        "node_id": "PR_kwDOIWuq585h9hUU",
        "number": 9517,
        "title": "Fixed Docs Spelling Mistakes",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-14T05:17:26Z",
        "updated_at": "2023-12-14T18:17:48Z",
        "closed_at": "2023-12-14T18:17:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9517",
            "html_url": "https://github.com/run-llama/llama_index/pull/9517",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9517.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9517.patch",
            "merged_at": "2023-12-14T18:17:38Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9517/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9517/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9516",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9516/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9516/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9516/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9516",
        "id": 2040913471,
        "node_id": "PR_kwDOIWuq585h9fMo",
        "number": 9516,
        "title": "FIxed DOcs grmmatical issues",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T05:08:21Z",
        "updated_at": "2023-12-14T05:14:32Z",
        "closed_at": "2023-12-14T05:14:31Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9516",
            "html_url": "https://github.com/run-llama/llama_index/pull/9516",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9516.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9516.patch",
            "merged_at": "2023-12-14T05:14:31Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9516/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9516/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9515",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9515/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9515/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9515/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9515",
        "id": 2040906845,
        "node_id": "PR_kwDOIWuq585h9d6L",
        "number": 9515,
        "title": "Fixing Docs",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T05:01:10Z",
        "updated_at": "2023-12-14T05:05:00Z",
        "closed_at": "2023-12-14T05:05:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9515",
            "html_url": "https://github.com/run-llama/llama_index/pull/9515",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9515.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9515.patch",
            "merged_at": "2023-12-14T05:05:00Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9515/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9515/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9514",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9514/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9514/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9514/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9514",
        "id": 2040901566,
        "node_id": "PR_kwDOIWuq585h9cyA",
        "number": 9514,
        "title": "FIxing Grammatical issues in docs",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T04:54:37Z",
        "updated_at": "2023-12-14T04:58:18Z",
        "closed_at": "2023-12-14T04:58:18Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9514",
            "html_url": "https://github.com/run-llama/llama_index/pull/9514",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9514.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9514.patch",
            "merged_at": "2023-12-14T04:58:18Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9514/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9514/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9513",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9513/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9513/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9513/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9513",
        "id": 2040869139,
        "node_id": "PR_kwDOIWuq585h9V8l",
        "number": 9513,
        "title": "Updating Spelling Mistakes",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T04:12:06Z",
        "updated_at": "2023-12-14T04:34:12Z",
        "closed_at": "2023-12-14T04:34:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9513",
            "html_url": "https://github.com/run-llama/llama_index/pull/9513",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9513.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9513.patch",
            "merged_at": "2023-12-14T04:34:12Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9513/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9513/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9512",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9512/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9512/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9512/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9512",
        "id": 2040868716,
        "node_id": "PR_kwDOIWuq585h9V3S",
        "number": 9512,
        "title": "Updated basic_strategies.md file",
        "user": {
            "login": "SaranshSharmaShorthillsAI",
            "id": 142397365,
            "node_id": "U_kgDOCHzPtQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/142397365?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SaranshSharmaShorthillsAI",
            "html_url": "https://github.com/SaranshSharmaShorthillsAI",
            "followers_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/followers",
            "following_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/repos",
            "events_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SaranshSharmaShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T04:11:32Z",
        "updated_at": "2023-12-14T04:17:07Z",
        "closed_at": "2023-12-14T04:17:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9512",
            "html_url": "https://github.com/run-llama/llama_index/pull/9512",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9512.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9512.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9512/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9512/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9511",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9511/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9511/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9511/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9511",
        "id": 2040674864,
        "node_id": "PR_kwDOIWuq585h8tnI",
        "number": 9511,
        "title": "Expanding use-cases docs",
        "user": {
            "login": "seldo",
            "id": 185893,
            "node_id": "MDQ6VXNlcjE4NTg5Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/185893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seldo",
            "html_url": "https://github.com/seldo",
            "followers_url": "https://api.github.com/users/seldo/followers",
            "following_url": "https://api.github.com/users/seldo/following{/other_user}",
            "gists_url": "https://api.github.com/users/seldo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seldo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seldo/subscriptions",
            "organizations_url": "https://api.github.com/users/seldo/orgs",
            "repos_url": "https://api.github.com/users/seldo/repos",
            "events_url": "https://api.github.com/users/seldo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seldo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-14T00:37:23Z",
        "updated_at": "2023-12-14T00:43:39Z",
        "closed_at": "2023-12-14T00:43:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9511",
            "html_url": "https://github.com/run-llama/llama_index/pull/9511",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9511.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9511.patch",
            "merged_at": "2023-12-14T00:43:38Z"
        },
        "body": "* Adding examples to Q&A section\r\n* Add examples to chatbots section",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9511/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9511/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9510",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9510/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9510/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9510/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9510",
        "id": 2040671130,
        "node_id": "I_kwDOIWuq5855oiua",
        "number": 9510,
        "title": "[Question]: SQLAutoVectorQueryEngine ValueError: Invalid result.ind: -2",
        "user": {
            "login": "redswimmer",
            "id": 38088099,
            "node_id": "MDQ6VXNlcjM4MDg4MDk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/38088099?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/redswimmer",
            "html_url": "https://github.com/redswimmer",
            "followers_url": "https://api.github.com/users/redswimmer/followers",
            "following_url": "https://api.github.com/users/redswimmer/following{/other_user}",
            "gists_url": "https://api.github.com/users/redswimmer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/redswimmer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/redswimmer/subscriptions",
            "organizations_url": "https://api.github.com/users/redswimmer/orgs",
            "repos_url": "https://api.github.com/users/redswimmer/repos",
            "events_url": "https://api.github.com/users/redswimmer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/redswimmer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-14T00:32:02Z",
        "updated_at": "2023-12-14T17:40:41Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFor some SQLAutoVectorQueryEngine queries I get the following error when calling `query_engine.query()`.  For example \"Tell me about the author\".  I'm using service_context to select gpt-4.  I've noticed if don't specify the service_context the error seems to go away.\r\n\r\n`chunk_size = 1024`\r\n`llm = OpenAI(temperature=1, model=\"gpt-4\", streaming=True)`\r\n`service_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)`\r\n\r\n`query_engine = SQLAutoVectorQueryEngine(`\r\n`    sql_tool, vector_tool, service_context=service_context`\r\n`)`\r\n\r\n**ERROR BELOW**\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[101], [line 1](vscode-notebook-cell:?execution_count=101&line=1)\r\n----> [1](vscode-notebook-cell:?execution_count=101&line=1) response = query_engine.query(\r\n      [2](vscode-notebook-cell:?execution_count=101&line=2)     \"Tell me about the author.\"\r\n      [3](vscode-notebook-cell:?execution_count=101&line=3) )\r\n\r\nFile [c:\\Python312\\Lib\\site-packages\\llama_index\\core\\base_query_engine.py:30](file:///C:/Python312/Lib/site-packages/llama_index/core/base_query_engine.py:30), in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     [28](file:///C:/Python312/Lib/site-packages/llama_index/core/base_query_engine.py:28) if isinstance(str_or_query_bundle, str):\r\n     [29](file:///C:/Python312/Lib/site-packages/llama_index/core/base_query_engine.py:29)     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> [30](file:///C:/Python312/Lib/site-packages/llama_index/core/base_query_engine.py:30) return self._query(str_or_query_bundle)\r\n\r\nFile [c:\\Python312\\Lib\\site-packages\\llama_index\\query_engine\\sql_join_query_engine.py:328](file:///C:/Python312/Lib/site-packages/llama_index/query_engine/sql_join_query_engine.py:328), in SQLJoinQueryEngine._query(self, query_bundle)\r\n    [326](file:///C:/Python312/Lib/site-packages/llama_index/query_engine/sql_join_query_engine.py:326)     return response\r\n    [327](file:///C:/Python312/Lib/site-packages/llama_index/query_engine/sql_join_query_engine.py:327) else:\r\n--> [328](file:///C:/Python312/Lib/site-packages/llama_index/query_engine/sql_join_query_engine.py:328)     raise ValueError(f\"Invalid result.ind: {result.ind}\")\r\n\r\nValueError: Invalid result.ind: -2\r\n\r\n**DEBUG CAPTURE BELOW**\r\n\r\nDEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.USER: 'user'>, 'content': \"Some choices are given below. It is provided in a numbered list (1 to 2), where each item in the list corresponds to a summary.\\n---------------------\\n(1) Useful for translating a natural language query into a SQL query over a table containing the schedule of surgical procedures.\\n\\n(2) Useful for answering semantic questions about how to perform common surgical procedures.\\n---------------------\\nUsing only the choices above and not prior knowledge, generate the selection object and reason that is most relevant to the question: 'Tell me about the author.'\\n\"}], 'model': 'gpt-4', 'stream': False, 'temperature': 0.9, 'tool_choice': {'type': 'function', 'function': {'name': 'SingleSelection'}}, 'tools': [{'type': 'function', 'function': {'name': 'SingleSelection', 'description': 'A single selection of a choice.', 'parameters': {'title': 'SingleSelection', 'description': 'A single selection of a choice.', 'type': 'object', 'properties': {'index': {'title': 'Index', 'type': 'integer'}, 'reason': {'title': 'Reason', 'type': 'string'}}, 'required': ['index', 'reason']}}}]}}\r\nRequest options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.USER: 'user'>, 'content': \"Some choices are given below. It is provided in a numbered list (1 to 2), where each item in the list corresponds to a summary.\\n---------------------\\n(1) Useful for translating a natural language query into a SQL query over a table containing the schedule of surgical procedures.\\n\\n(2) Useful for answering semantic questions about how to perform common surgical procedures.\\n---------------------\\nUsing only the choices above and not prior knowledge, generate the selection object and reason that is most relevant to the question: 'Tell me about the author.'\\n\"}], 'model': 'gpt-4', 'stream': False, 'temperature': 0.9, 'tool_choice': {'type': 'function', 'function': {'name': 'SingleSelection'}}, 'tools': [{'type': 'function', 'function': {'name': 'SingleSelection', 'description': 'A single selection of a choice.', 'parameters': {'title': 'SingleSelection', 'description': 'A single selection of a choice.', 'type': 'object', 'properties': {'index': {'title': 'Index', 'type': 'integer'}, 'reason': {'title': 'Reason', 'type': 'string'}}, 'required': ['index', 'reason']}}}]}}\r\nDEBUG:httpcore.connection:close.started\r\nclose.started\r\nDEBUG:httpcore.connection:close.complete\r\nclose.complete\r\nDEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\r\nconnect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\r\nDEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027891E40530>\r\nconnect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027891E40530>\r\nDEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027891ED6ED0> server_hostname='api.openai.com' timeout=60.0\r\nstart_tls.started ssl_context=<ssl.SSLContext object at 0x0000027891ED6ED0> server_hostname='api.openai.com' timeout=60.0\r\nDEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027893B7F440>\r\nstart_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027893B7F440>\r\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\r\nsend_request_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_headers.complete\r\nsend_request_headers.complete\r\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\r\nsend_request_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_body.complete\r\nsend_request_body.complete\r\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\r\nreceive_response_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 00:23:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b'user-vnoy76paarbktt519cuphchn'), (b'openai-processing-ms', b'1136'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-limit-tokens_usage_based', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9843'), (b'x-ratelimit-remaining-tokens_usage_based', b'9843'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'942ms'), (b'x-ratelimit-reset-tokens_usage_based', b'942ms'), (b'x-request-id', b'b22b369ab64ca295b0930a9fea8edc2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83524c456f723508-SMF'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\r\nreceive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 00:23:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b'user-vnoy76paarbktt519cuphchn'), (b'openai-processing-ms', b'1136'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-limit-tokens_usage_based', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9843'), (b'x-ratelimit-remaining-tokens_usage_based', b'9843'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'942ms'), (b'x-ratelimit-reset-tokens_usage_based', b'942ms'), (b'x-request-id', b'b22b369ab64ca295b0930a9fea8edc2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83524c456f723508-SMF'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\r\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\r\nHTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\r\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\r\nreceive_response_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_body.complete\r\nreceive_response_body.complete\r\nDEBUG:httpcore.http11:response_closed.started\r\nresponse_closed.started\r\nDEBUG:httpcore.http11:response_closed.complete\r\nresponse_closed.complete\r\nDEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\r\nHTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9510/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9510/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9509",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9509/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9509/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9509/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9509",
        "id": 2040662265,
        "node_id": "I_kwDOIWuq5855ogj5",
        "number": 9509,
        "title": "[Bug]: RedisVectorStore delete_ref_doc doesn't delete all nodes",
        "user": {
            "login": "josheschulz",
            "id": 1304422,
            "node_id": "MDQ6VXNlcjEzMDQ0MjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1304422?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/josheschulz",
            "html_url": "https://github.com/josheschulz",
            "followers_url": "https://api.github.com/users/josheschulz/followers",
            "following_url": "https://api.github.com/users/josheschulz/following{/other_user}",
            "gists_url": "https://api.github.com/users/josheschulz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/josheschulz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/josheschulz/subscriptions",
            "organizations_url": "https://api.github.com/users/josheschulz/orgs",
            "repos_url": "https://api.github.com/users/josheschulz/repos",
            "events_url": "https://api.github.com/users/josheschulz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/josheschulz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-14T00:20:10Z",
        "updated_at": "2023-12-14T00:22:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n`index.delete_ref_doc(ref_doc_id=doc_id)`\r\n\r\nWon't delete all of the nodes of a document if there are more than 10.\r\n\r\nBecause [the code in delete](https://github.com/run-llama/llama_index/blob/main/llama_index/vector_stores/redis.py#L199) does a search for nodes then deletes what it finds node by node.  However the query default is to limit to 10 items returned.  Documents created using SentenceSplitter often have more than 10 nodes.\r\n\r\nI believe setting setting the limit explicitly in query_params passed to the search in that code, and putting that code in a loop that repeats until the number of nodes returned < limit would do it, but I don't know a lot about redis so there is probably a better way.\r\n\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\n1.  Index a doc with more than 10 nodes.\r\n2. Delete the doc using index.delete_ref_doc(doc_id)\r\n3. Verify nodes are still in the redis data store from that document.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9509/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9509/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9508",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9508/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9508/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9508/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9508",
        "id": 2040627986,
        "node_id": "PR_kwDOIWuq585h8jas",
        "number": 9508,
        "title": "Update PDFReader",
        "user": {
            "login": "JAlexMcGraw",
            "id": 60911060,
            "node_id": "MDQ6VXNlcjYwOTExMDYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/60911060?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JAlexMcGraw",
            "html_url": "https://github.com/JAlexMcGraw",
            "followers_url": "https://api.github.com/users/JAlexMcGraw/followers",
            "following_url": "https://api.github.com/users/JAlexMcGraw/following{/other_user}",
            "gists_url": "https://api.github.com/users/JAlexMcGraw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JAlexMcGraw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JAlexMcGraw/subscriptions",
            "organizations_url": "https://api.github.com/users/JAlexMcGraw/orgs",
            "repos_url": "https://api.github.com/users/JAlexMcGraw/repos",
            "events_url": "https://api.github.com/users/JAlexMcGraw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JAlexMcGraw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T23:35:51Z",
        "updated_at": "2023-12-14T03:45:29Z",
        "closed_at": "2023-12-14T03:45:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9508",
            "html_url": "https://github.com/run-llama/llama_index/pull/9508",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9508.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9508.patch",
            "merged_at": "2023-12-14T03:45:29Z"
        },
        "body": "\r\n\r\n# Description\r\n\r\nAdd to PDFReader so that a user can specify if they want the PDF read in as one whole Document, or each page as a Document. Lacking the functionality to read in a PDF as a whole document, so then a user can split how they see fit, was annoying.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\nTested by loading in a local PDF with and without the return_full_document argument set to True. When set to True, returned one Document. When set to false, returned 32 Documents. \r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9508/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9508/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9507",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9507/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9507/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9507/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9507",
        "id": 2040616658,
        "node_id": "I_kwDOIWuq5855oVbS",
        "number": 9507,
        "title": "[Bug]: UnstructuredElementNodeParser failed on table with <a> tag in cells",
        "user": {
            "login": "adepeuf",
            "id": 43555452,
            "node_id": "MDQ6VXNlcjQzNTU1NDUy",
            "avatar_url": "https://avatars.githubusercontent.com/u/43555452?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adepeuf",
            "html_url": "https://github.com/adepeuf",
            "followers_url": "https://api.github.com/users/adepeuf/followers",
            "following_url": "https://api.github.com/users/adepeuf/following{/other_user}",
            "gists_url": "https://api.github.com/users/adepeuf/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adepeuf/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adepeuf/subscriptions",
            "organizations_url": "https://api.github.com/users/adepeuf/orgs",
            "repos_url": "https://api.github.com/users/adepeuf/repos",
            "events_url": "https://api.github.com/users/adepeuf/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adepeuf/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T23:23:48Z",
        "updated_at": "2023-12-13T23:29:14Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAn HTML table like \r\n\r\n ```\r\n <body>\r\n        <h2>European Countries and Their Telephone Country Codes</h2>\r\n        <table>\r\n            <tr>\r\n                <th>Country</th>\r\n                <th>Telephone Country Code</th>\r\n            </tr>\r\n            <tr>\r\n                <td>Some text<a href=\"http://google.com\">Germany</a></td>\r\n                <td>+49</td>\r\n            </tr>\r\n            <tr>\r\n                <td>France</td>\r\n                <td>+33</td>\r\n            </tr>\r\n...\r\n```\r\nisn't properly processed \n\n### Version\n\n0.9.15\n\n### Steps to Reproduce\n\nGiven file `eutel.html`:\r\n```\r\n<!DOCTYPE html>\r\n<html>\r\n    <head>\r\n        <title>European Countries and Their Telephone Country Codes</title>\r\n    </head>\r\n    <body>\r\n        <h2>European Countries and Their Telephone Country Codes</h2>\r\n        <table>\r\n            <tr>\r\n                <th>Country</th>\r\n                <th>Telephone Country Code</th>\r\n            </tr>\r\n            <tr>\r\n                <td>Some text<a href=\"http://google.com\">Germany</a></td>\r\n                <td>+49</td>\r\n            </tr>\r\n            <tr>\r\n                <td>France</td>\r\n                <td>+33</td>\r\n            </tr>\r\n            <!-- Add more rows as needed -->\r\n        </table>\r\n  \r\n</body>\r\n</html>\r\n```\r\nthe code :\r\n\r\n```\r\nfrom llama_index.readers.file.flat_reader import FlatReader\r\nfrom llama_index.node_parser import (UnstructuredElementNodeParser,)\r\nfrom pathlib import Path\r\n\r\nfile = \"eutel.html\"\r\nreader = FlatReader()\r\neutel_doc = reader.load_data(Path(file))\r\nnode_parser = UnstructuredElementNodeParser()\r\nraw_nodes = node_parser.get_nodes_from_documents(eutel_doc, show_progress=True)\r\nbase_nodes, node_mappings = node_parser.get_base_nodes_and_mappings(raw_nodes)\r\nprint(node_mappings)\r\n```\r\noutputs nothing : {}\r\n\r\nif in the HTML file the text \"Some text\" before the anchor on Germany is removed then it properly outputs\r\n\r\n`{'id_1_table': TextNode(id_='id_1_table', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='id_1_table_ref', node_type=<ObjectType.INDEX: '3'>, metadata={'col_schema': 'Column: Country\\nType: string\\nSummary: Name of the country\\n\\nColumn: Telephone Country Code\\nType: string\\nSummary: International telephone country code for the country'}, hash='c37f994368d3660fee3961ab514b693099af730f4a1d66fdd79f630efad7f816')}, hash='5fd23eded1daf245a9066d0dbae43b27e2cf74913c1f33a8cf25ebda0fcd7b79', text='            Country   Telephone Country Code  \\n0           Germany                      +49  \\n1            France                      +33  \\n2             Italy                      +39  \\n3             Spain                      +34  \\n4    United Kingdom                      +44  ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')}`\r\n\r\n\r\nAnalysis shows that the root cause is in https://github.com/run-llama/llama_index/blob/main/llama_index/node_parser/relational/unstructured_element.py line 71, the text before and after the anchors are counted as separated columns and then the table is considered as malformed\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9507/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9507/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9506",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9506/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9506/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9506/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9506",
        "id": 2040594125,
        "node_id": "I_kwDOIWuq5855oP7N",
        "number": 9506,
        "title": "[Bug]: AttributeError: 'str' object has no attribute 'upsert'",
        "user": {
            "login": "nickjtay",
            "id": 52182102,
            "node_id": "MDQ6VXNlcjUyMTgyMTAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/52182102?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nickjtay",
            "html_url": "https://github.com/nickjtay",
            "followers_url": "https://api.github.com/users/nickjtay/followers",
            "following_url": "https://api.github.com/users/nickjtay/following{/other_user}",
            "gists_url": "https://api.github.com/users/nickjtay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nickjtay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nickjtay/subscriptions",
            "organizations_url": "https://api.github.com/users/nickjtay/orgs",
            "repos_url": "https://api.github.com/users/nickjtay/repos",
            "events_url": "https://api.github.com/users/nickjtay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nickjtay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-13T22:57:04Z",
        "updated_at": "2023-12-13T23:14:58Z",
        "closed_at": "2023-12-13T23:14:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThere seems to be an issue with the PineconeVectorStore()? The code below is very simple and taken from the documentation.\r\n\r\n### Version\r\n\r\nCurrent\r\n\r\n### Steps to Reproduce\r\n\r\n```\r\nimport logging\r\nimport sys\r\nimport os\r\n\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\nfrom llama_index.vector_stores import PineconeVectorStore\r\nfrom IPython.display import Markdown, display\r\nimport pinecone\r\nfrom llama_index import set_global_service_context\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embed_model,\r\n)\r\n\r\nset_global_service_context(service_context)\r\n\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\nindex_name = \"docidx\"\r\napi_key = \"xxxxxxxxxxxxxx\"\r\n\r\npinecone.init(api_key=api_key, environment=\"gcp-starter\")\r\n\r\n# create index once.\r\n# inecone.create_index(index_name, dimension=1536, metric='cosine', pod_type=\"p1\")\r\n\r\nfrom llama_index.storage.storage_context import StorageContext\r\n\r\npinecone_index = pinecone.Index(\"quickstart\")\r\n\r\nvector_store = PineconeVectorStore(pinecone_index=index_name)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n{\r\n\t\"name\": \"AttributeError\",\r\n\t\"message\": \"'str' object has no attribute 'upsert'\",\r\n\t\"stack\": \"---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[23], line 26\r\n     24 vector_store = PineconeVectorStore(pinecone_index=index_name)\r\n     25 storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n---> 26 index = VectorStoreIndex.from_documents(\r\n     27     documents, storage_context=storage_context\r\n     28 )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/base.py:106, in BaseIndex.from_documents(cls, documents, storage_context, service_context, show_progress, **kwargs)\r\n     97     docstore.set_document_hash(doc.get_doc_id(), doc.hash)\r\n     99 nodes = run_transformations(\r\n    100     documents,  # type: ignore\r\n    101     service_context.transformations,\r\n    102     show_progress=show_progress,\r\n    103     **kwargs,\r\n    104 )\r\n--> 106 return cls(\r\n    107     nodes=nodes,\r\n    108     storage_context=storage_context,\r\n    109     service_context=service_context,\r\n    110     show_progress=show_progress,\r\n    111     **kwargs,\r\n    112 )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/vector_store/base.py:49, in VectorStoreIndex.__init__(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\r\n     47 self._use_async = use_async\r\n     48 self._store_nodes_override = store_nodes_override\r\n---> 49 super().__init__(\r\n     50     nodes=nodes,\r\n     51     index_struct=index_struct,\r\n     52     service_context=service_context,\r\n     53     storage_context=storage_context,\r\n     54     show_progress=show_progress,\r\n     55     **kwargs,\r\n     56 )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/base.py:71, in BaseIndex.__init__(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\r\n     69 if index_struct is None:\r\n     70     assert nodes is not None\r\n---> 71     index_struct = self.build_index_from_nodes(nodes)\r\n     72 self._index_struct = index_struct\r\n     73 self._storage_context.index_store.add_index_struct(self._index_struct)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/vector_store/base.py:255, in VectorStoreIndex.build_index_from_nodes(self, nodes, **insert_kwargs)\r\n    244 def build_index_from_nodes(\r\n    245     self,\r\n    246     nodes: Sequence[BaseNode],\r\n    247     **insert_kwargs: Any,\r\n    248 ) -> IndexDict:\r\n    249     \\\"\\\"\\\"Build the index from nodes.\r\n    250 \r\n    251     NOTE: Overrides BaseIndex.build_index_from_nodes.\r\n    252         VectorStoreIndex only stores nodes in document store\r\n    253         if vector store does not store text\r\n    254     \\\"\\\"\\\"\r\n--> 255     return self._build_index_from_nodes(nodes, **insert_kwargs)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/vector_store/base.py:236, in VectorStoreIndex._build_index_from_nodes(self, nodes, **insert_kwargs)\r\n    234     run_async_tasks(tasks)\r\n    235 else:\r\n--> 236     self._add_nodes_to_index(\r\n    237         index_struct,\r\n    238         nodes,\r\n    239         show_progress=self._show_progress,\r\n    240         **insert_kwargs,\r\n    241     )\r\n    242 return index_struct\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/indices/vector_store/base.py:190, in VectorStoreIndex._add_nodes_to_index(self, index_struct, nodes, show_progress, **insert_kwargs)\r\n    187     return\r\n    189 nodes = self._get_node_with_embedding(nodes, show_progress)\r\n--> 190 new_ids = self._vector_store.add(nodes, **insert_kwargs)\r\n    192 if not self._vector_store.stores_text or self._store_nodes_override:\r\n    193     # NOTE: if the vector store doesn't store text,\r\n    194     # we need to add the nodes to the index struct and document store\r\n    195     for node, new_id in zip(nodes, new_ids):\r\n    196         # NOTE: remove embedding from node to avoid duplication\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/vector_stores/pinecone.py:318, in PineconeVectorStore.add(self, nodes, **add_kwargs)\r\n    316     ids.append(node_id)\r\n    317     entries.append(entry)\r\n--> 318 self._pinecone_index.upsert(\r\n    319     entries,\r\n    320     namespace=self.namespace,\r\n    321     batch_size=self.batch_size,\r\n    322     **self.insert_kwargs,\r\n    323 )\r\n    324 return ids\r\n\r\nAttributeError: 'str' object has no attribute 'upsert'\"\r\n}\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9506/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9506/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9505",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9505/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9505/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9505/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9505",
        "id": 2040567338,
        "node_id": "PR_kwDOIWuq585h8WDU",
        "number": 9505,
        "title": "Fixing CHANGELOG for wrong PR ID",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T22:30:32Z",
        "updated_at": "2023-12-13T23:11:26Z",
        "closed_at": "2023-12-13T23:11:25Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9505",
            "html_url": "https://github.com/run-llama/llama_index/pull/9505",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9505.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9505.patch",
            "merged_at": "2023-12-13T23:11:25Z"
        },
        "body": "# Description\r\n\r\nhttps://github.com/run-llama/llama_index/pull/9485 added the wrong ID for a PR, just fixes that.\r\n\r\nAn aside is use of GitHub releases for `CHANGELOG` would eliminate errors like this associated with manual entry\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9505/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9505/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9504",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9504/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9504/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9504/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9504",
        "id": 2040562676,
        "node_id": "PR_kwDOIWuq585h8VAK",
        "number": 9504,
        "title": "Added missing `default=None` to `LLM.system_prompt`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T22:26:49Z",
        "updated_at": "2023-12-14T03:44:52Z",
        "closed_at": "2023-12-14T03:44:51Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9504",
            "html_url": "https://github.com/run-llama/llama_index/pull/9504",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9504.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9504.patch",
            "merged_at": "2023-12-14T03:44:51Z"
        },
        "body": "# Description\r\n\r\nUpgrading to `llama-index==0.9.15`, `mypy==1.7.1` is reporting a lot of type errors for every LLM:\r\n\r\n```\r\nscripts/index.py:76:15: error: Missing named argument \"system_prompt\" for\r\n\"Ollama\"  [call-arg]\r\n            llm = Ollama(model=\"llama2:13b\")\r\n                  ^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n```\r\n\r\nThe issue is a missing default for `system_prompt`. This PR fixes that\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9504/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9504/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9502",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9502/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9502/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9502/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9502",
        "id": 2040555061,
        "node_id": "PR_kwDOIWuq585h8TTg",
        "number": 9502,
        "title": "Allowing `LOCALAI_DEFAULTS` to work with `__ror__`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T22:19:28Z",
        "updated_at": "2023-12-14T05:05:45Z",
        "closed_at": "2023-12-14T05:05:45Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9502",
            "html_url": "https://github.com/run-llama/llama_index/pull/9502",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9502.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9502.patch",
            "merged_at": "2023-12-14T05:05:45Z"
        },
        "body": "# Description\r\n\r\n`mypy==1.7.1` will fail this as of `llama-index==0.9.15`:\r\n\r\n```python\r\nfrom llama_index.llms import LOCALAI_DEFAULTS\r\n\r\noverridden = LOCALAI_DEFAULTS | {\"api_base\": \"foo\"}\r\n```\r\n\r\nThe reason is `No overload variant of \"__ror__\" of \"dict\" matches argument type \"Mapping[str, Any]\"  [operator]`\r\n\r\nThe correct fix here is to use `LOCALAI_DEFAULTS: MappingProxyType[str, Any]`, but that requires Python 3.9+.\r\n\r\nThis PR takes a second best route, using `Dict[str, Any]` which isn't technically type correct but it's close enough.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9502/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9502/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9501",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9501/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9501/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9501/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9501",
        "id": 2040548410,
        "node_id": "PR_kwDOIWuq585h8R0w",
        "number": 9501,
        "title": "Teeny stray link causing weirdness",
        "user": {
            "login": "seldo",
            "id": 185893,
            "node_id": "MDQ6VXNlcjE4NTg5Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/185893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seldo",
            "html_url": "https://github.com/seldo",
            "followers_url": "https://api.github.com/users/seldo/followers",
            "following_url": "https://api.github.com/users/seldo/following{/other_user}",
            "gists_url": "https://api.github.com/users/seldo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seldo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seldo/subscriptions",
            "organizations_url": "https://api.github.com/users/seldo/orgs",
            "repos_url": "https://api.github.com/users/seldo/repos",
            "events_url": "https://api.github.com/users/seldo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seldo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T22:13:19Z",
        "updated_at": "2023-12-13T22:23:47Z",
        "closed_at": "2023-12-13T22:23:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9501",
            "html_url": "https://github.com/run-llama/llama_index/pull/9501",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9501.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9501.patch",
            "merged_at": "2023-12-13T22:23:46Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9501/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9501/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9500",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9500/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9500/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9500/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9500",
        "id": 2040535619,
        "node_id": "PR_kwDOIWuq585h8PAD",
        "number": 9500,
        "title": "Overhauling docs for VectorStoreIndex",
        "user": {
            "login": "seldo",
            "id": 185893,
            "node_id": "MDQ6VXNlcjE4NTg5Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/185893?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seldo",
            "html_url": "https://github.com/seldo",
            "followers_url": "https://api.github.com/users/seldo/followers",
            "following_url": "https://api.github.com/users/seldo/following{/other_user}",
            "gists_url": "https://api.github.com/users/seldo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seldo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seldo/subscriptions",
            "organizations_url": "https://api.github.com/users/seldo/orgs",
            "repos_url": "https://api.github.com/users/seldo/repos",
            "events_url": "https://api.github.com/users/seldo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seldo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T22:01:59Z",
        "updated_at": "2023-12-14T00:38:57Z",
        "closed_at": "2023-12-14T00:38:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9500",
            "html_url": "https://github.com/run-llama/llama_index/pull/9500",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9500.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9500.patch",
            "merged_at": "2023-12-14T00:38:56Z"
        },
        "body": "* Improve SEO\r\n* Remove redundant/deprecated content\r\n* Better emphasize Ingestion Pipeline",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9500/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9500/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9499",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9499/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9499/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9499/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9499",
        "id": 2040516484,
        "node_id": "I_kwDOIWuq5855n8-E",
        "number": 9499,
        "title": "[Bug]: ChatEngine with Gemini model broken.",
        "user": {
            "login": "gich2009",
            "id": 83756959,
            "node_id": "MDQ6VXNlcjgzNzU2OTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/83756959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gich2009",
            "html_url": "https://github.com/gich2009",
            "followers_url": "https://api.github.com/users/gich2009/followers",
            "following_url": "https://api.github.com/users/gich2009/following{/other_user}",
            "gists_url": "https://api.github.com/users/gich2009/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gich2009/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gich2009/subscriptions",
            "organizations_url": "https://api.github.com/users/gich2009/orgs",
            "repos_url": "https://api.github.com/users/gich2009/repos",
            "events_url": "https://api.github.com/users/gich2009/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gich2009/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-13T21:45:38Z",
        "updated_at": "2023-12-13T22:02:08Z",
        "closed_at": "2023-12-13T22:02:08Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe Gemini interface does not recognize the Message.SYSTEM role, so any class that uses this type breaks with Gemini. A suggestion would be to tentatively route all system messages for GEMINI to type Message.USER\n\n### Version\n\n0.9.15\n\n### Steps to Reproduce\n\nRun a ChatEngine with the Gemini interface as the LLM\n\n### Relevant Logs/Tracbacks\n\n```shell\nINFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\r\nHTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\r\nTraceback (most recent call last):\r\n  File  line 412, in <module>\r\n    response = test_chatbot.chat(prompt=prompt[\"prompt\"])\r\n  File line 368, in chat\r\n    response = self.chatbot(input_text=prompt)\r\n  File line 337, in chatbot\r\n    response = chat_engine.chat(message=input_text)\r\n  File line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File line 283, in chat\r\n    chat_response = self._llm.chat(chat_messages)\r\n  File line 97, in wrapped_llm_chat\r\n    f_return_val = f(_self, messages, **kwargs)\r\n  File line 149, in chat\r\n    *history, next_msg = map(chat_message_to_gemini, messages)\r\n  File line 86, in chat_message_to_gemini\r\n    \"role\": ROLES_TO_GEMINI[message.role],\r\nKeyError: <MessageRole.SYSTEM: 'system'>\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9499/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9499/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9498",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9498/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9498/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9498/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9498",
        "id": 2040480423,
        "node_id": "PR_kwDOIWuq585h8C0V",
        "number": 9498,
        "title": "Merge Gemini Same Role Chat Message",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T21:16:36Z",
        "updated_at": "2023-12-13T21:46:27Z",
        "closed_at": "2023-12-13T21:46:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9498",
            "html_url": "https://github.com/run-llama/llama_index/pull/9498",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9498.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9498.patch",
            "merged_at": "2023-12-13T21:46:26Z"
        },
        "body": "# Description\r\n1. Gemini Chat mode only has user and model two roles. For now put system as user.\r\n2. Gemini does not support multiple messages of the same role in a row. So we need to merge same role msgs\r\n3. change Palm embedding to Gemini Embedding\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9498/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9498/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9497",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9497/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9497/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9497/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9497",
        "id": 2040377504,
        "node_id": "PR_kwDOIWuq585h7sX8",
        "number": 9497,
        "title": "Allow build/search params for MilvusVectorStore",
        "user": {
            "login": "wphicks",
            "id": 11039110,
            "node_id": "MDQ6VXNlcjExMDM5MTEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/11039110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wphicks",
            "html_url": "https://github.com/wphicks",
            "followers_url": "https://api.github.com/users/wphicks/followers",
            "following_url": "https://api.github.com/users/wphicks/following{/other_user}",
            "gists_url": "https://api.github.com/users/wphicks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wphicks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wphicks/subscriptions",
            "organizations_url": "https://api.github.com/users/wphicks/orgs",
            "repos_url": "https://api.github.com/users/wphicks/repos",
            "events_url": "https://api.github.com/users/wphicks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wphicks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T19:58:03Z",
        "updated_at": "2023-12-14T18:16:20Z",
        "closed_at": "2023-12-14T18:16:19Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9497",
            "html_url": "https://github.com/run-llama/llama_index/pull/9497",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9497.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9497.patch",
            "merged_at": "2023-12-14T18:16:19Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nThis PR introduces the ability to pass index build and search parameters to the MilvusVectorStore. This is valuable for a few reasons:\r\n\r\n1. It allows more data to be stored in Milvus on the same hardware by providing access to index types that offer compressed representations of their data.\r\n2. It allows for higher throughput or lower latency for vector store requests by providing access to approximate index types and configurations that allow performance tuning.\r\n3. It allows GPU-acceleration of vector indexing and retrieval through selection of one of Milvus's GPU-accelerated index types.\r\n\r\nFixes #9493 \r\n\r\n## Type of Change\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] Added new unit/integration tests\r\n\r\nI have added a test which invokes the MilvusVectorStore with non-default index and search parameters. Specifically, we test with an IVF Flat index type. This can be reproduced with a run of `make test` in an environment with pymilvus available.\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] I have made corresponding changes to the documentation\r\n- [ ] (N/A) I have added Google Colab support for the newly added notebooks.\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n- [X] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9497/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9497/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9495",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9495/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9495/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9495/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9495",
        "id": 2040354094,
        "node_id": "PR_kwDOIWuq585h7nRF",
        "number": 9495,
        "title": "FEATURE: Cohere ReRank Relevancy Metric for Retrieval Eval",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T19:41:47Z",
        "updated_at": "2023-12-13T20:48:17Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9495",
            "html_url": "https://github.com/run-llama/llama_index/pull/9495",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9495.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9495.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\n- Adds a new metric for retriever evaluation, namely: `CohereRerankRelevancyMetric`\r\n- The `compute` method for this metric class involves calling Cohere's `re-rank` api . In particular, we supply the `query` and the retrieved nodes texts (in list form) as the `documents` for which re-rank is executed on.\r\n- This means that if we set `top_k=2` in our retriever, then we should get back 2 relevance scores, one for each chunk. To get to a single score, we apply an agg function, which by default is set to `max`.  This means that `CohereRerankRelevancyMetric` returns by default the maximum relevancy score of retrieved nodes texts with the query.\r\n- To implement the above, introduced a new class called `BaseIndexlessRetrievalMetric` which doesn't require `expected_ids` nor `retrieved_ids` as its counterpart `BaseRetrievalMetric` does.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I updated the retriever eval notebook to optionally include cohere rerank metric and tested that it works with and without this metric\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9495/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9495/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9494",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9494/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9494/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9494/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9494",
        "id": 2040308881,
        "node_id": "PR_kwDOIWuq585h7dbL",
        "number": 9494,
        "title": "Fix small bug in string method of NodeWithScore",
        "user": {
            "login": "maximannrcp",
            "id": 150716622,
            "node_id": "U_kgDOCPvAzg",
            "avatar_url": "https://avatars.githubusercontent.com/u/150716622?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/maximannrcp",
            "html_url": "https://github.com/maximannrcp",
            "followers_url": "https://api.github.com/users/maximannrcp/followers",
            "following_url": "https://api.github.com/users/maximannrcp/following{/other_user}",
            "gists_url": "https://api.github.com/users/maximannrcp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/maximannrcp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/maximannrcp/subscriptions",
            "organizations_url": "https://api.github.com/users/maximannrcp/orgs",
            "repos_url": "https://api.github.com/users/maximannrcp/repos",
            "events_url": "https://api.github.com/users/maximannrcp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/maximannrcp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T19:07:37Z",
        "updated_at": "2023-12-14T03:43:26Z",
        "closed_at": "2023-12-14T03:43:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9494",
            "html_url": "https://github.com/run-llama/llama_index/pull/9494",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9494.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9494.patch",
            "merged_at": "2023-12-14T03:43:26Z"
        },
        "body": "# Description\r\n\r\nAvoid exception in __str__ method of NodeWithScore when the optional member variable self.score is None.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9494/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9494/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9493",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9493/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9493/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9493/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9493",
        "id": 2040273487,
        "node_id": "I_kwDOIWuq5855nBpP",
        "number": 9493,
        "title": "[Feature Request]: Allow MilvusVectorStore to specify index build and search parameters",
        "user": {
            "login": "wphicks",
            "id": 11039110,
            "node_id": "MDQ6VXNlcjExMDM5MTEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/11039110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wphicks",
            "html_url": "https://github.com/wphicks",
            "followers_url": "https://api.github.com/users/wphicks/followers",
            "following_url": "https://api.github.com/users/wphicks/following{/other_user}",
            "gists_url": "https://api.github.com/users/wphicks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wphicks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wphicks/subscriptions",
            "organizations_url": "https://api.github.com/users/wphicks/orgs",
            "repos_url": "https://api.github.com/users/wphicks/repos",
            "events_url": "https://api.github.com/users/wphicks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wphicks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T18:41:30Z",
        "updated_at": "2023-12-14T18:16:21Z",
        "closed_at": "2023-12-14T18:16:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nIt would be useful to allow llama_index workflows more control over the vector search component by passing index build and search configurations to `MilvusVectorStore`. This would allow users to use e.g. IVFPQ, HNSW, or a GPU-accelerated index type for dealing with large collections of data in Milvus.\n\n### Reason\n\nCurrently, the `MilvusVectorStore` API does not include the ability to pass index and search configurations down to the pymilvus layer. By explicitly exposing `index_config` and `search_config` parameters in the constructor, users will be able to customize the vector search component for their specific use case.\n\n### Value of Feature\n\nThis features opens up several possibilities:\r\n\r\n1. Users can store larger datasets using an index type that compresses its vector representation (e.g. IVF PQ)\r\n2. Users can achieve higher throughput or lower latency using a fast approximate index type (e.g. HNSW)\r\n3. Users can accelerate the vector search component of their workflows with GPU index types (e.g. GPU_IVF_FLAT)\r\n4. Users can select the exact index configuration that provides the latency/throughput tradeoff they are looking for",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9493/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9493/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9492",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9492/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9492/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9492/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9492",
        "id": 2040270841,
        "node_id": "I_kwDOIWuq5855nA_5",
        "number": 9492,
        "title": "Connection Timeout with Elastic Search",
        "user": {
            "login": "pranavbhat12",
            "id": 54463581,
            "node_id": "MDQ6VXNlcjU0NDYzNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/54463581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavbhat12",
            "html_url": "https://github.com/pranavbhat12",
            "followers_url": "https://api.github.com/users/pranavbhat12/followers",
            "following_url": "https://api.github.com/users/pranavbhat12/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavbhat12/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavbhat12/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavbhat12/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavbhat12/orgs",
            "repos_url": "https://api.github.com/users/pranavbhat12/repos",
            "events_url": "https://api.github.com/users/pranavbhat12/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavbhat12/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T18:39:40Z",
        "updated_at": "2023-12-14T06:27:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHey,\r\nI am trying to use Query Fusion retriever on top of hybrid retriever.I am getting connection timeout error because for now multiple sub queries are generated for a single query.On troubleshooting I found that request_timeout value should be increased.If this is correct how can we achieve this via Llamaindex? Tried adding vector_store_kwargs while creating retriever but no help.\r\n\r\n**Code**:\r\ndef load_index_query_engine(llama_doc_list):\r\n hybrid_retriever_list=[]\r\nfor pdf_doc in doc_list:\r\nindex = load_index_from_storage(storage_context)\r\nvector_retriever = index.as_retriever(\r\nsimilarity_top_k=10,\r\nvector_store_query_mode=\"hybrid\",\r\n**vector_store_kwargs={\"request_timeout\":30}**\r\n)\r\nnodes = service_context.node_parser.get_nodes_from_documents(llama_doc_list[pdf_doc])\r\nbm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=10)\r\nhybrid_retriever = HybridRetriever(vector_retriever, bm25_retriever)\r\nhybrid_retriever_list.append(hybrid_retriever)\r\nreturn hybrid_retriever_list\r\n\r\nretriever = QueryFusionRetriever(   \r\n    hybrid_retriever_list,\r\n    similarity_top_k=2,\r\n    num_queries=2,  \r\n    use_async=True,\r\n    verbose=True,\r\n    llm=llm\r\n    # query_gen_prompt=\"...\",  # we could override the query generation prompt here\r\n)\r\n\r\nquery_engine = RetrieverQueryEngine.from_args(\r\n    retriever=retriever,\r\n    # node_postprocessors=[reranker],\r\n     service_context=service_context,\r\n    # streaming=True\r\n)\r\nwith torch.no_grad() and torch.inference_mode():\r\n    response = query_engine.query(question)\r\n    print(response)\r\n\r\n**Error**:\r\nConnectionError                           Traceback (most recent call last)\r\nFile <timed exec>:4\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_query_engine.py:30, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     28 if isinstance(str_or_query_bundle, str):\r\n     29     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 30 return self._query(str_or_query_bundle)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py:170, in RetrieverQueryEngine._query(self, query_bundle)\r\n    166 \"\"\"Answer a query.\"\"\"\r\n    167 with self.callback_manager.event(\r\n    168     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\r\n    169 ) as query_event:\r\n--> 170     nodes = self.retrieve(query_bundle)\r\n    171     response = self._response_synthesizer.synthesize(\r\n    172         query=query_bundle,\r\n    173         nodes=nodes,\r\n    174     )\r\n    176     query_event.on_end(payload={EventPayload.RESPONSE: response})\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py:126, in RetrieverQueryEngine.retrieve(self, query_bundle)\r\n    125 def retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\r\n--> 126     nodes = self._retriever.retrieve(query_bundle)\r\n    127     return self._apply_node_postprocessors(nodes, query_bundle=query_bundle)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_retriever.py:54, in BaseRetriever.retrieve(self, str_or_query_bundle)\r\n     49 with self.callback_manager.as_trace(\"query\"):\r\n     50     with self.callback_manager.event(\r\n     51         CBEventType.RETRIEVE,\r\n     52         payload={EventPayload.QUERY_STR: query_bundle.query_str},\r\n     53     ) as retrieve_event:\r\n---> 54         nodes = self._retrieve(query_bundle)\r\n     55         retrieve_event.on_end(\r\n     56             payload={EventPayload.NODES: nodes},\r\n     57         )\r\n     58 return nodes\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/retrievers/fusion_retriever.py:166, in QueryFusionRetriever._retrieve(self, query_bundle)\r\n    163     queries = [query_bundle.query_str]\r\n    165 if self.use_async:\r\n--> 166     results = self._run_nested_async_queries(queries)\r\n    167 else:\r\n    168     results = self._run_sync_queries(queries)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/retrievers/fusion_retriever.py:124, in QueryFusionRetriever._run_nested_async_queries(self, queries)\r\n    121         tasks.append(retriever.aretrieve(query))\r\n    122         task_queries.append(query)\r\n--> 124 task_results = run_async_tasks(tasks)\r\n    126 results = {}\r\n    127 for i, (query, query_result) in enumerate(zip(task_queries, task_results)):\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/async_utils.py:49, in run_async_tasks(tasks, show_progress, progress_bar_desc)\r\n     46 async def _gather() -> List[Any]:\r\n     47     return await asyncio.gather(*tasks_to_execute)\r\n---> 49 outputs: List[Any] = asyncio.run(_gather())\r\n     50 return outputs\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/nest_asyncio.py:31, in _patch_asyncio.<locals>.run(main, debug)\r\n     29 task = asyncio.ensure_future(main)\r\n     30 try:\r\n---> 31     return loop.run_until_complete(task)\r\n     32 finally:\r\n     33     if not task.done():\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/nest_asyncio.py:99, in _patch_loop.<locals>.run_until_complete(self, future)\r\n     96 if not f.done():\r\n     97     raise RuntimeError(\r\n     98         'Event loop stopped before Future completed.')\r\n---> 99 return f.result()\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/futures.py:201, in Future.result(self)\r\n    199 self.__log_traceback = False\r\n    200 if self._exception is not None:\r\n--> 201     raise self._exception.with_traceback(self._exception_tb)\r\n    202 return self._result\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/tasks.py:234, in Task.__step(***failed resolving arguments***)\r\n    232         result = coro.send(None)\r\n    233     else:\r\n--> 234         result = coro.throw(exc)\r\n    235 except StopIteration as exc:\r\n    236     if self._must_cancel:\r\n    237         # Task is cancelled right before coro stops.\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/async_utils.py:47, in run_async_tasks.<locals>._gather()\r\n     46 async def _gather() -> List[Any]:\r\n---> 47     return await asyncio.gather(*tasks_to_execute)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/tasks.py:304, in Task.__wakeup(self, future)\r\n    302 def __wakeup(self, future):\r\n    303     try:\r\n--> 304         future.result()\r\n    305     except BaseException as exc:\r\n    306         # This may also be a cancellation.\r\n    307         self.__step(exc)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/tasks.py:232, in Task.__step(***failed resolving arguments***)\r\n    228 try:\r\n    229     if exc is None:\r\n    230         # We use the `send` method directly, because coroutines\r\n    231         # don't have `__iter__` and `__next__` methods.\r\n--> 232         result = coro.send(None)\r\n    233     else:\r\n    234         result = coro.throw(exc)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_retriever.py:72, in BaseRetriever.aretrieve(self, str_or_query_bundle)\r\n     67 with self.callback_manager.as_trace(\"query\"):\r\n     68     with self.callback_manager.event(\r\n     69         CBEventType.RETRIEVE,\r\n     70         payload={EventPayload.QUERY_STR: query_bundle.query_str},\r\n     71     ) as retrieve_event:\r\n---> 72         nodes = await self._aretrieve(query_bundle)\r\n     73         retrieve_event.on_end(\r\n     74             payload={EventPayload.NODES: nodes},\r\n     75         )\r\n     76 return nodes\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_retriever.py:94, in BaseRetriever._aretrieve(self, query_bundle)\r\n     88 async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\r\n     89     \"\"\"Asynchronously retrieve nodes given query.\r\n     90 \r\n     91     Implemented by the user.\r\n     92 \r\n     93     \"\"\"\r\n---> 94     return self._retrieve(query_bundle)\r\n\r\nCell In[19], line 17, in HybridRetriever._retrieve(self, query, **kwargs)\r\n     15 def _retrieve(self, query, **kwargs):\r\n     16     bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\r\n---> 17     vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\r\n     19     # combine the two lists of nodes\r\n     20     all_nodes = []\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_retriever.py:54, in BaseRetriever.retrieve(self, str_or_query_bundle)\r\n     49 with self.callback_manager.as_trace(\"query\"):\r\n     50     with self.callback_manager.event(\r\n     51         CBEventType.RETRIEVE,\r\n     52         payload={EventPayload.QUERY_STR: query_bundle.query_str},\r\n     53     ) as retrieve_event:\r\n---> 54         nodes = self._retrieve(query_bundle)\r\n     55         retrieve_event.on_end(\r\n     56             payload={EventPayload.NODES: nodes},\r\n     57         )\r\n     58 return nodes\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py:88, in VectorIndexRetriever._retrieve(self, query_bundle)\r\n     82     if query_bundle.embedding is None and len(query_bundle.embedding_strs) > 0:\r\n     83         query_bundle.embedding = (\r\n     84             self._service_context.embed_model.get_agg_embedding_from_queries(\r\n     85                 query_bundle.embedding_strs\r\n     86             )\r\n     87         )\r\n---> 88 return self._get_nodes_with_embeddings(query_bundle)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/indices/vector_store/retrievers/retriever.py:164, in VectorIndexRetriever._get_nodes_with_embeddings(self, query_bundle_with_embeddings)\r\n    160 def _get_nodes_with_embeddings(\r\n    161     self, query_bundle_with_embeddings: QueryBundle\r\n    162 ) -> List[NodeWithScore]:\r\n    163     query = self._build_vector_store_query(query_bundle_with_embeddings)\r\n--> 164     query_result = self._vector_store.query(query, **self._kwargs)\r\n    165     return self._build_node_list_from_query_result(query_result)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/vector_stores/elasticsearch.py:452, in ElasticsearchStore.query(self, query, custom_query, es_filter, **kwargs)\r\n    424 def query(\r\n    425     self,\r\n    426     query: VectorStoreQuery,\r\n   (...)\r\n    431     **kwargs: Any,\r\n    432 ) -> VectorStoreQueryResult:\r\n    433     \"\"\"Query index for top k most similar nodes.\r\n    434 \r\n    435     Args:\r\n   (...)\r\n    450 \r\n    451     \"\"\"\r\n--> 452     return asyncio.get_event_loop().run_until_complete(\r\n    453         self.aquery(query, custom_query, es_filter, **kwargs)\r\n    454     )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/nest_asyncio.py:99, in _patch_loop.<locals>.run_until_complete(self, future)\r\n     96 if not f.done():\r\n     97     raise RuntimeError(\r\n     98         'Event loop stopped before Future completed.')\r\n---> 99 return f.result()\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/futures.py:201, in Future.result(self)\r\n    199 self.__log_traceback = False\r\n    200 if self._exception is not None:\r\n--> 201     raise self._exception.with_traceback(self._exception_tb)\r\n    202 return self._result\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/asyncio/tasks.py:234, in Task.__step(***failed resolving arguments***)\r\n    232         result = coro.send(None)\r\n    233     else:\r\n--> 234         result = coro.throw(exc)\r\n    235 except StopIteration as exc:\r\n    236     if self._must_cancel:\r\n    237         # Task is cancelled right before coro stops.\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/vector_stores/elasticsearch.py:524, in ElasticsearchStore.aquery(self, query, custom_query, es_filter, **kwargs)\r\n    521     logger.debug(f\"Calling custom_query, Query body now: {es_query}\")\r\n    523 async with self.client as client:\r\n--> 524     response = await client.search(\r\n    525         index=self.index_name,\r\n    526         **es_query,\r\n    527         size=query.similarity_top_k,\r\n    528         _source={\"excludes\": [self.vector_field]},\r\n    529     )\r\n    531 top_k_nodes = []\r\n    532 top_k_ids = []\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/elasticsearch/_async/client/__init__.py:3735, in AsyncElasticsearch.search(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\r\n   3733 if __body is not None:\r\n   3734     __headers[\"content-type\"] = \"application/json\"\r\n-> 3735 return await self.perform_request(  # type: ignore[return-value]\r\n   3736     \"POST\", __path, params=__query, headers=__headers, body=__body\r\n   3737 )\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/elasticsearch/_async/client/_base.py:285, in BaseClient.perform_request(self, method, path, params, headers, body)\r\n    282 else:\r\n    283     target = path\r\n--> 285 meta, resp_body = await self.transport.perform_request(\r\n    286     method,\r\n    287     target,\r\n    288     headers=request_headers,\r\n    289     body=body,\r\n    290     request_timeout=self._request_timeout,\r\n    291     max_retries=self._max_retries,\r\n    292     retry_on_status=self._retry_on_status,\r\n    293     retry_on_timeout=self._retry_on_timeout,\r\n    294     client_meta=self._client_meta,\r\n    295 )\r\n    297 # HEAD with a 404 is returned as a normal response\r\n    298 # since this is used as an 'exists' functionality.\r\n    299 if not (method == \"HEAD\" and meta.status == 404) and (\r\n    300     not 200 <= meta.status < 299\r\n    301     and (\r\n   (...)\r\n    305     )\r\n    306 ):\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/elastic_transport/_async_transport.py:258, in AsyncTransport.perform_request(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\r\n    256 start_time = self._loop.time()\r\n    257 try:\r\n--> 258     resp = await node.perform_request(\r\n    259         method,\r\n    260         target,\r\n    261         body=request_body,\r\n    262         headers=request_headers,\r\n    263         request_timeout=request_timeout,\r\n    264     )\r\n    265     _logger.info(\r\n    266         \"%s %s%s [status:%s duration:%.3fs]\"\r\n    267         % (\r\n   (...)\r\n    273         )\r\n    274     )\r\n    276     if method != \"HEAD\":\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/elastic_transport/_node/_http_aiohttp.py:218, in AiohttpHttpNode.perform_request(self, method, target, body, headers, request_timeout)\r\n    210         err = ConnectionError(str(e), errors=(e,))\r\n    211     self._log_request(\r\n    212         method=\"HEAD\" if is_head else method,\r\n    213         target=target,\r\n   (...)\r\n    216         exception=err,\r\n    217     )\r\n--> 218     raise err from None\r\n    220 meta = ApiResponseMeta(\r\n    221     node=self.config,\r\n    222     duration=duration,\r\n   (...)\r\n    225     headers=HttpHeaders(response.headers),\r\n    226 )\r\n    227 self._log_request(\r\n    228     method=\"HEAD\" if is_head else method,\r\n    229     target=target,\r\n   (...)\r\n    233     response=raw_data,\r\n    234 )\r\nConnectionError: Connection error caused by: ConnectionError(Connection error caused by: ClientOSError([Errno 1] [SSL: APPLICATION_DATA_AFTER_CLOSE_NOTIFY] application data after close notify (_ssl.c:2702)))",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9492/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9492/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9491",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9491/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9491/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9491/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9491",
        "id": 2040262641,
        "node_id": "PR_kwDOIWuq585h7TRC",
        "number": 9491,
        "title": "[WIP] Centralize Logger",
        "user": {
            "login": "aaronbannin",
            "id": 6948336,
            "node_id": "MDQ6VXNlcjY5NDgzMzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6948336?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aaronbannin",
            "html_url": "https://github.com/aaronbannin",
            "followers_url": "https://api.github.com/users/aaronbannin/followers",
            "following_url": "https://api.github.com/users/aaronbannin/following{/other_user}",
            "gists_url": "https://api.github.com/users/aaronbannin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aaronbannin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aaronbannin/subscriptions",
            "organizations_url": "https://api.github.com/users/aaronbannin/orgs",
            "repos_url": "https://api.github.com/users/aaronbannin/repos",
            "events_url": "https://api.github.com/users/aaronbannin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aaronbannin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-13T18:33:35Z",
        "updated_at": "2023-12-14T22:10:23Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9491",
            "html_url": "https://github.com/run-llama/llama_index/pull/9491",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9491.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9491.patch",
            "merged_at": null
        },
        "body": "# Description\r\nThis PR seeks to create a simplified method for managing logging for the Llama Index package. The implementation should embrace Python best practices to ensure integration with the greater Python ecosystem.\r\n\r\nThis PR is focused only on implementations of the Python `logging` library. Notably, it does not address:\r\n- Tracing, which requires unique integration with other tools.\r\n- Existing `print()` statements. These are often used with the `verbose` flag and thus have a different lifecycle than application logging. This behavior could be unified with the logging pipeline, but should addressed in an isolated project.\r\n- The `llama_index/logger/base.LlamaLogger` looks to be dead code? It's probably better to not touch it in this PR.\r\n\r\n## Developer Interaction\r\n\r\nA developer sets the logging level for the package with the following line:\r\n```python\r\nlogging.getLogger(\"llama_index\").setLevel(logging.DEBUG))\r\n```\r\n\r\nThe logger can also be configured using [configuration files](https://docs.python.org/3/howto/logging.html#configuring-logging). \r\n\r\n## Problem\r\nThere are currently >100 distinct loggers within the package.\r\n```python\r\nloggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\r\nfor l in loggers:\r\n    if \"llama_index\" in l.name:\r\n        print(l.name)\r\n```\r\n\r\nThe following line is repeated in many files. Each invocation creates a new logger, named after the file where it lives. The most likely explanation for this repeated code is \"copy pasta\"; simply replicating an existing pattern in a new file.\r\n```python\r\nlogger = logging.getLogger(__name__)\r\n```\r\n\r\nTo ensure reliable logging configuration, a developer must set configuration for every logger.\r\n\r\n## Solution\r\nLlama Index should have a single logger that is used across the entire project.\r\n\r\n- Define `logger` in `llama_index/logger/__init__.py`. Placing in this directory seeks to avoid circular imports. All package scoped logging configuration should be done in this file. \r\n- This includes the `.addHandler(NullHandler())` configuration; which is identified as best practice by Python documentation. The `NullHandler()` simply sets the package to send logs to \"nowhere\" (e.g. `/dev/null`). The developer can then choose to route the logs.\r\n- The logger does not need to be exported, so it does not need to live in `llama_index/__init__.py`.\r\n- Use with a simple import statement. `from llama_index.logging import logger`\r\n\r\nFixes #9450 \r\n\r\n\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9491/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9491/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9490",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9490/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9490/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9490/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9490",
        "id": 2040182952,
        "node_id": "I_kwDOIWuq5855mrio",
        "number": 9490,
        "title": "[Bug]: Error when trying to implement LiteLLM model",
        "user": {
            "login": "briannewtonpsyd",
            "id": 872698,
            "node_id": "MDQ6VXNlcjg3MjY5OA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/872698?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/briannewtonpsyd",
            "html_url": "https://github.com/briannewtonpsyd",
            "followers_url": "https://api.github.com/users/briannewtonpsyd/followers",
            "following_url": "https://api.github.com/users/briannewtonpsyd/following{/other_user}",
            "gists_url": "https://api.github.com/users/briannewtonpsyd/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/briannewtonpsyd/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/briannewtonpsyd/subscriptions",
            "organizations_url": "https://api.github.com/users/briannewtonpsyd/orgs",
            "repos_url": "https://api.github.com/users/briannewtonpsyd/repos",
            "events_url": "https://api.github.com/users/briannewtonpsyd/events{/privacy}",
            "received_events_url": "https://api.github.com/users/briannewtonpsyd/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-13T17:35:29Z",
        "updated_at": "2023-12-13T17:39:05Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen I try to use the example code for use LiteLLM:\r\n\r\nllm = LiteLLM(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\r\n\r\nI get the following error:\r\n\r\nModuleNotFoundError: No module named 'litellm'\n\n### Version\n\nv0.9.14.post3\n\n### Steps to Reproduce\n\nRunning this line of code appears to produce this error:\r\n\r\nllm = LiteLLM(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n\n### Relevant Logs/Tracbacks\n\n```shell\nFile ~\\miniconda3\\lib\\site-packages\\llama_index\\llms\\litellm_utils.py:205, in validate_litellm_api_key(api_key, api_type)\r\n    202 def validate_litellm_api_key(\r\n    203     api_key: Optional[str] = None, api_type: Optional[str] = None\r\n    204 ) -> None:\r\n--> 205     import litellm\r\n    207     api_key = litellm.validate_environment()\r\n    208     if api_key is None:\r\n\r\nModuleNotFoundError: No module named 'litellm'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9490/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9490/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9489",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9489/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9489/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9489/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9489",
        "id": 2039971606,
        "node_id": "PR_kwDOIWuq585h6UAl",
        "number": 9489,
        "title": "Fix len check",
        "user": {
            "login": "emilienchvt",
            "id": 18351439,
            "node_id": "MDQ6VXNlcjE4MzUxNDM5",
            "avatar_url": "https://avatars.githubusercontent.com/u/18351439?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/emilienchvt",
            "html_url": "https://github.com/emilienchvt",
            "followers_url": "https://api.github.com/users/emilienchvt/followers",
            "following_url": "https://api.github.com/users/emilienchvt/following{/other_user}",
            "gists_url": "https://api.github.com/users/emilienchvt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/emilienchvt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/emilienchvt/subscriptions",
            "organizations_url": "https://api.github.com/users/emilienchvt/orgs",
            "repos_url": "https://api.github.com/users/emilienchvt/repos",
            "events_url": "https://api.github.com/users/emilienchvt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/emilienchvt/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T15:38:19Z",
        "updated_at": "2023-12-14T22:11:31Z",
        "closed_at": "2023-12-14T22:11:31Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9489",
            "html_url": "https://github.com/run-llama/llama_index/pull/9489",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9489.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9489.patch",
            "merged_at": "2023-12-14T22:11:31Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes https://github.com/run-llama/llama_index/issues/9487\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9489/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9489/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9488",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9488/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9488/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9488/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9488",
        "id": 2039964389,
        "node_id": "PR_kwDOIWuq585h6SZ_",
        "number": 9488,
        "title": "Support for Nvidia Triton LLM",
        "user": {
            "login": "jdye64",
            "id": 2127235,
            "node_id": "MDQ6VXNlcjIxMjcyMzU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2127235?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jdye64",
            "html_url": "https://github.com/jdye64",
            "followers_url": "https://api.github.com/users/jdye64/followers",
            "following_url": "https://api.github.com/users/jdye64/following{/other_user}",
            "gists_url": "https://api.github.com/users/jdye64/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jdye64/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jdye64/subscriptions",
            "organizations_url": "https://api.github.com/users/jdye64/orgs",
            "repos_url": "https://api.github.com/users/jdye64/repos",
            "events_url": "https://api.github.com/users/jdye64/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jdye64/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710949,
                "node_id": "LA_kwDOIWuq588AAAABc3-fJQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XL",
                "name": "size:XL",
                "color": "ff823f",
                "default": false,
                "description": "This PR changes 500-999 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-13T15:34:31Z",
        "updated_at": "2023-12-14T22:13:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9488",
            "html_url": "https://github.com/run-llama/llama_index/pull/9488",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9488.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9488.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nThis PR includes support for the Nvidia Triton Inference Server LLM. To keep the PR as small as possible it only includes the GRPC client for now and not HTTP (follow up PR to come) and also only supports sync `chat` and `complete` methods while all others are marked as `NotImplemented` for now.\r\n\r\nFixes #9185 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] I tested using the Nvidia GenerativeAIExamples repo which has docker scripts for the complete environment setup. Happy to include a notebook but doing so with the Triton server setup seemed like overkill.\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9488/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9488/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9487",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9487/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9487/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9487/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9487",
        "id": 2039918662,
        "node_id": "I_kwDOIWuq5855lrBG",
        "number": 9487,
        "title": "[Bug]: Rate limiting hit for `generate_questions_from_nodes()`",
        "user": {
            "login": "emilienchvt",
            "id": 18351439,
            "node_id": "MDQ6VXNlcjE4MzUxNDM5",
            "avatar_url": "https://avatars.githubusercontent.com/u/18351439?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/emilienchvt",
            "html_url": "https://github.com/emilienchvt",
            "followers_url": "https://api.github.com/users/emilienchvt/followers",
            "following_url": "https://api.github.com/users/emilienchvt/following{/other_user}",
            "gists_url": "https://api.github.com/users/emilienchvt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/emilienchvt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/emilienchvt/subscriptions",
            "organizations_url": "https://api.github.com/users/emilienchvt/orgs",
            "repos_url": "https://api.github.com/users/emilienchvt/repos",
            "events_url": "https://api.github.com/users/emilienchvt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/emilienchvt/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T15:12:08Z",
        "updated_at": "2023-12-14T22:11:32Z",
        "closed_at": "2023-12-14T22:11:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen running `generate_questions_from_nodes` on a large enough document set, we end up getting 429 errors from OpenAI because of rate limiting.\n\n### Version\n\n0.9.15\n\n### Steps to Reproduce\n\nLoad data in a directory reader and generate questions on the documents:\r\n```\r\ndocuments = SimpleDirectoryReader(\"folder_with_a_lot_of_data\").load_data()\r\ndata_generator = DatasetGenerator.from_documents(documents)\r\neval_questions = data_generator.generate_questions_from_nodes()\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nRateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo [...]\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9487/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9487/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9486",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9486/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9486/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9486/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9486",
        "id": 2039897039,
        "node_id": "PR_kwDOIWuq585h6DpS",
        "number": 9486,
        "title": "use persist dir in faiss",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T15:02:22Z",
        "updated_at": "2023-12-13T15:06:42Z",
        "closed_at": "2023-12-13T15:06:41Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9486",
            "html_url": "https://github.com/run-llama/llama_index/pull/9486",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9486.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9486.patch",
            "merged_at": "2023-12-13T15:06:41Z"
        },
        "body": "# Description\r\n\r\nvariable wasn't being used properly\r\n\r\nFixes https://github.com/run-llama/llama_index/issues/9479\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9486/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9486/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9485",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9485/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9485/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9485/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9485",
        "id": 2039858820,
        "node_id": "PR_kwDOIWuq585h57PT",
        "number": 9485,
        "title": "[version] bump to v0.9.15",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-13T14:42:54Z",
        "updated_at": "2023-12-13T21:40:25Z",
        "closed_at": "2023-12-13T14:50:02Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9485",
            "html_url": "https://github.com/run-llama/llama_index/pull/9485",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9485.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9485.patch",
            "merged_at": "2023-12-13T14:50:02Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9485/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9485/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9484",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9484/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9484/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9484/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9484",
        "id": 2039829736,
        "node_id": "I_kwDOIWuq5855lVTo",
        "number": 9484,
        "title": "[Bug]: cannot import name 'OpenAIMultiModal' from 'llama_index.multi_modal_llms'",
        "user": {
            "login": "tolexy",
            "id": 25507684,
            "node_id": "MDQ6VXNlcjI1NTA3Njg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/25507684?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tolexy",
            "html_url": "https://github.com/tolexy",
            "followers_url": "https://api.github.com/users/tolexy/followers",
            "following_url": "https://api.github.com/users/tolexy/following{/other_user}",
            "gists_url": "https://api.github.com/users/tolexy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tolexy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tolexy/subscriptions",
            "organizations_url": "https://api.github.com/users/tolexy/orgs",
            "repos_url": "https://api.github.com/users/tolexy/repos",
            "events_url": "https://api.github.com/users/tolexy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tolexy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-13T14:27:57Z",
        "updated_at": "2023-12-13T14:54:48Z",
        "closed_at": "2023-12-13T14:53:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHello, \r\n\r\nIt seems there may be an incorrect reference in the latest versions of llama-index.\r\n\r\nfrom llama_index.multi_modal_llms import MultiModalLLM, OpenAIMultiModal  causes an import error and I do not see the code in the repo file structure.\n\n### Version\n\n0.9.14post3\n\n### Steps to Reproduce\n\nfrom llama_index.query_engine import RouterQueryEngine \r\n\r\nor \r\n\r\nfrom llama_index.query_engine import KnowledgeGraphQueryEngine\r\n\r\nEither of the above causes an import error now. It seems from the screenshot below that OpenAIMultiModal is not correctly referenced in the repo structure. Unless I am missing something...\r\n\r\n![image](https://github.com/run-llama/llama_index/assets/25507684/c5f0f54c-4bce-402e-beeb-5d6f8db41d1d)\r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nImportError                               Traceback (most recent call last)\r\n<ipython-input-69-5ad27a1b523b> in <cell line: 8>()\r\n      6 from llama_index.storage.storage_context import StorageContext\r\n      7 from llama_index.graph_stores import Neo4jGraphStore\r\n----> 8 from llama_index.query_engine import RouterQueryEngine#KnowledgeGraphQueryEngine\r\n      9 \r\n     10 \r\n\r\n5 frames\r\n/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/__init__.py in <module>\r\n     24 )\r\n     25 from llama_index.query_engine.retry_source_query_engine import RetrySourceQueryEngine\r\n---> 26 from llama_index.query_engine.router_query_engine import (\r\n     27     RetrieverRouterQueryEngine,\r\n     28     RouterQueryEngine,\r\n\r\n/usr/local/lib/python3.10/dist-packages/llama_index/query_engine/router_query_engine.py in <module>\r\n     21 from llama_index.schema import BaseNode, QueryBundle\r\n     22 from llama_index.selectors.types import BaseSelector\r\n---> 23 from llama_index.selectors.utils import get_selector_from_context\r\n     24 from llama_index.service_context import ServiceContext\r\n     25 from llama_index.tools.query_engine import QueryEngineTool\r\n\r\n/usr/local/lib/python3.10/dist-packages/llama_index/selectors/__init__.py in <module>\r\n      1 from llama_index.selectors.embedding_selectors import EmbeddingSingleSelector\r\n      2 from llama_index.selectors.llm_selectors import LLMMultiSelector, LLMSingleSelector\r\n----> 3 from llama_index.selectors.pydantic_selectors import (\r\n      4     PydanticMultiSelector,\r\n      5     PydanticSingleSelector,\r\n\r\n/usr/local/lib/python3.10/dist-packages/llama_index/selectors/pydantic_selectors.py in <module>\r\n      2 \r\n      3 from llama_index.llms.openai import OpenAI\r\n----> 4 from llama_index.program.openai_program import OpenAIPydanticProgram\r\n      5 from llama_index.prompts.mixin import PromptDictType\r\n      6 from llama_index.schema import QueryBundle\r\n\r\n/usr/local/lib/python3.10/dist-packages/llama_index/program/__init__.py in <module>\r\n      2 from llama_index.program.llm_program import LLMTextCompletionProgram\r\n      3 from llama_index.program.lmformatenforcer_program import LMFormatEnforcerPydanticProgram\r\n----> 4 from llama_index.program.multi_modal_llm_program import MultiModalLLMCompletionProgram\r\n      5 from llama_index.program.openai_program import OpenAIPydanticProgram\r\n      6 from llama_index.program.predefined.df import (\r\n\r\n/usr/local/lib/python3.10/dist-packages/llama_index/program/multi_modal_llm_program.py in <module>\r\n      2 \r\n      3 from llama_index.bridge.pydantic import BaseModel\r\n----> 4 from llama_index.multi_modal_llms import MultiModalLLM, OpenAIMultiModal\r\n      5 from llama_index.output_parsers.pydantic import PydanticOutputParser\r\n      6 from llama_index.prompts.base import BasePromptTemplate, PromptTemplate\r\n\r\nImportError: cannot import name 'OpenAIMultiModal' from 'llama_index.multi_modal_llms' (/usr/local/lib/python3.10/dist-packages/llama_index/multi_modal_llms/__init__.py)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9484/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9484/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9483",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9483/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9483/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9483/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9483",
        "id": 2039308758,
        "node_id": "I_kwDOIWuq5855jWHW",
        "number": 9483,
        "title": "[Question]: How to use multi modal large model in local env base llama_index?",
        "user": {
            "login": "llf10811020205",
            "id": 4935062,
            "node_id": "MDQ6VXNlcjQ5MzUwNjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4935062?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/llf10811020205",
            "html_url": "https://github.com/llf10811020205",
            "followers_url": "https://api.github.com/users/llf10811020205/followers",
            "following_url": "https://api.github.com/users/llf10811020205/following{/other_user}",
            "gists_url": "https://api.github.com/users/llf10811020205/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/llf10811020205/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/llf10811020205/subscriptions",
            "organizations_url": "https://api.github.com/users/llf10811020205/orgs",
            "repos_url": "https://api.github.com/users/llf10811020205/repos",
            "events_url": "https://api.github.com/users/llf10811020205/events{/privacy}",
            "received_events_url": "https://api.github.com/users/llf10811020205/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-13T09:33:24Z",
        "updated_at": "2023-12-13T15:18:30Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHow to use multi modal large model in local env base llama_index?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9483/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9483/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9482",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9482/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9482/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9482/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9482",
        "id": 2039297131,
        "node_id": "I_kwDOIWuq5855jTRr",
        "number": 9482,
        "title": "[Question]: how to use multi modal LM in local env base llama_index?",
        "user": {
            "login": "llf10811020205",
            "id": 4935062,
            "node_id": "MDQ6VXNlcjQ5MzUwNjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4935062?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/llf10811020205",
            "html_url": "https://github.com/llf10811020205",
            "followers_url": "https://api.github.com/users/llf10811020205/followers",
            "following_url": "https://api.github.com/users/llf10811020205/following{/other_user}",
            "gists_url": "https://api.github.com/users/llf10811020205/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/llf10811020205/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/llf10811020205/subscriptions",
            "organizations_url": "https://api.github.com/users/llf10811020205/orgs",
            "repos_url": "https://api.github.com/users/llf10811020205/repos",
            "events_url": "https://api.github.com/users/llf10811020205/events{/privacy}",
            "received_events_url": "https://api.github.com/users/llf10811020205/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T09:26:45Z",
        "updated_at": "2023-12-13T09:36:27Z",
        "closed_at": "2023-12-13T09:32:12Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nhow to use Multi Modal LM in local env base llama_index?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9482/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9482/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9481",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9481/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9481/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9481/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9481",
        "id": 2039264574,
        "node_id": "I_kwDOIWuq5855jLU-",
        "number": 9481,
        "title": "[Feature Request]: Support additional entities and anonymization approaches for PII scrubbing",
        "user": {
            "login": "omri374",
            "id": 3776619,
            "node_id": "MDQ6VXNlcjM3NzY2MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3776619?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/omri374",
            "html_url": "https://github.com/omri374",
            "followers_url": "https://api.github.com/users/omri374/followers",
            "following_url": "https://api.github.com/users/omri374/following{/other_user}",
            "gists_url": "https://api.github.com/users/omri374/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/omri374/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/omri374/subscriptions",
            "organizations_url": "https://api.github.com/users/omri374/orgs",
            "repos_url": "https://api.github.com/users/omri374/repos",
            "events_url": "https://api.github.com/users/omri374/events{/privacy}",
            "received_events_url": "https://api.github.com/users/omri374/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T09:07:48Z",
        "updated_at": "2023-12-13T09:10:03Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nThe existing `NERPIINodePostprocessor` calls a NER model for PII detection. The types of detected entities depend on the data the NER model was trained on. A framework like [Presidio](https://github.com/microsoft/presidio) allows the user to extract many more entities using a combination of NER and rule based approaches (e.g. for credit card detection). \r\nIn addition, there are different types of de-identification operations, each serving a different use-case. In some cases we'd like to generate fake data, in some to replace with a placeholder, and in others to do instance anonymization in order to reverse the process later. Allowing the user to use something like Presidio would greatly increase the flexibility in PII scanning and handling.\r\n\r\np.s. I'm one of the maintainers of Presidio, and would be happy to help / work on this feature integration. I love llama-Index, see a lot of customer demand for PII scrubbing, and think that a tighter integration would benefit many users!\n\n### Reason\n\n- Adding an integration with Presidio instead of the existing NER approach would allow many more use cases and PII entity types to be handled, while still being able to use the same NER model as part of the Presidio process.\r\n- Existing NER approaches lack many entity types and are sometimes not accurate enough to completely remove the PII.\r\n- Each use case requires a different de-identification strategy (e.g. replace with fake), while the existing NER approach only does instance anonymization.\r\n\r\nPresidio is already integrated into [LangChain](https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/) and [Rasa](https://rasa.com/docs/rasa/pii-management/).\n\n### Value of Feature\n\nBetter PII handling, compliance, remove the need to pass PII to the LLM.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9481/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9481/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9480",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9480/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9480/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9480/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9480",
        "id": 2039251782,
        "node_id": "I_kwDOIWuq5855jING",
        "number": 9480,
        "title": "[Bug]: Unpickled Index Returns \"AttributeError: _llm\" when Queried ",
        "user": {
            "login": "nickjtay",
            "id": 52182102,
            "node_id": "MDQ6VXNlcjUyMTgyMTAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/52182102?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nickjtay",
            "html_url": "https://github.com/nickjtay",
            "followers_url": "https://api.github.com/users/nickjtay/followers",
            "following_url": "https://api.github.com/users/nickjtay/following{/other_user}",
            "gists_url": "https://api.github.com/users/nickjtay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nickjtay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nickjtay/subscriptions",
            "organizations_url": "https://api.github.com/users/nickjtay/orgs",
            "repos_url": "https://api.github.com/users/nickjtay/repos",
            "events_url": "https://api.github.com/users/nickjtay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nickjtay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-12-13T08:59:52Z",
        "updated_at": "2023-12-14T03:22:59Z",
        "closed_at": "2023-12-14T03:22:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI placed the code below in full to make it easy to understand what I did in order to replicate the problem. The first snippet is the loading, indexing, and storing. The second snippet is reloading the index into memory and querying against it.\r\n\r\nI wrote the script to create an index and store as a pickle file to azure blob storage, so I could retrieve it from the front end app when the user sends a prompt.\r\n\r\nHere is that code:\r\n```\r\n! pip install llama_index\r\n! pip install azure-identity\r\n! pip install docx2txt\r\n! pip install pypdf\r\n\r\nfrom azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\nfrom llama_index.llms import AzureOpenAI\r\nfrom llama_index.embeddings import AzureOpenAIEmbedding\r\nimport logging\r\nimport sys\r\nfrom llama_index import set_global_service_context\r\nfrom llama_index import (\r\n    VectorStoreIndex,\r\n    SimpleDirectoryReader,\r\n    ServiceContext,\r\n    StorageContext,\r\n    LLMPredictor,\r\n    load_index_from_storage,\r\n)\r\nimport pickle\r\nimport io\r\n\r\nstorage_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\r\nstorage_url = \"https://XXXXXX.blob.core.windows.net/\"\r\n\r\ncontainer_client = ContainerClient(account_url=storage_url, \r\n    credential=storage_key, \r\n    container_name=\"powerpoints3\")\r\n\r\nloader = AzStorageBlobReader(account_url=storage_url, \r\n    credential=storage_key, \r\n    container_name=\"powerpoints3\")\r\n\r\ndocuments = loader.load_data()\r\n\r\nlogging.basicConfig(\r\n    stream=sys.stdout, level=logging.INFO\r\n)  # logging.DEBUG for more verbose output\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\napi_key = \"XXXXXXXXXXXXXX\"\r\nendpoint = \"https://XXXXXXXXX.openai.azure.com/\"\r\ndeployment = \"XXXXXXXXX\"\r\napi_version=\"2023-09-01-preview\"\r\n\r\nllm = AzureOpenAI(\r\n    model = \"gpt-35-turbo\",\r\n    deployment_name=deployment,\r\n    api_key=api_key,\r\n    api_version=api_version,\r\n    azure_endpoint=endpoint\r\n)\r\n\r\nembed_model = AzureOpenAIEmbedding(\r\n    model=\"text-embedding-ada-002\",\r\n    deployment_name=\"testembedding\",\r\n    api_key=api_key,\r\n    azure_endpoint=endpoint,\r\n    api_version=api_version,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embed_model,\r\n)\r\n\r\nset_global_service_context(service_context)\r\n\r\nindex_name = \"doc_idx\"\r\nif os.path.exists(index_name):\r\n    index = load_index_from_storage(\r\n        StorageContext.from_defaults(persist_dir=index_name),\r\n        service_context=service_context,\r\n    )\r\nelse:\r\n    index = VectorStoreIndex.from_documents(documents)\r\n    index.storage_context.persist(persist_dir=index_name)\r\n\r\ncontainer_name = \"xxxxxxxxxxx\"\r\nstorage_account_name = \"xxxxxxxxxxx\"\r\nstorage_key = \"xxxxxxxxxxxxxx\"\r\n\r\npickled_object = pickle.dumps(index)\r\nblob_service_client = BlobServiceClient(account_url=f\"https://{storage_account_name}.blob.core.windows.net\", credential=storage_key)\r\nblob_client = blob_service_client.get_blob_client(container=container_name, blob=index_name)\r\nblob_client.upload_blob(io.BytesIO(pickled_object), overwrite=True)\r\n```\r\n\r\nTo test it, I used the same notebook I used to pickle and store the index, but I reset the kernel. Next, I unpickled the vector store index and reinstantiated the LLM, before querying. \r\n\r\nHere's that code:\r\n\r\n```\r\nfrom llama_index import set_global_service_context\r\nfrom llama_index.llms import AzureOpenAI\r\nfrom llama_index.embeddings import AzureOpenAIEmbedding\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\r\nimport logging\r\nimport sys\r\nfrom azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\nimport pickle\r\nimport io\r\n\r\nlogging.basicConfig(\r\n    stream=sys.stdout, level=logging.INFO\r\n)  # logging.DEBUG for more verbose output\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\napi_key = \"XXXXXXXXXXXXX\"\r\nendpoint = \"https://XXXXXXXXXx.openai.azure.com/\"\r\ndeployment = \"XXXXXXXXXXx\"\r\napi_version=\"2023-09-01-preview\"\r\n\r\nllm = AzureOpenAI(\r\n    model = \"gpt-35-turbo\",\r\n    deployment_name=deployment,\r\n    api_key=api_key,\r\n    api_version=api_version,\r\n    azure_endpoint=endpoint\r\n)\r\n\r\nembed_model = AzureOpenAIEmbedding(\r\n    model=\"text-embedding-ada-002\",\r\n    deployment_name=\"testembedding\",\r\n    api_key=api_key,\r\n    azure_endpoint=endpoint,\r\n    api_version=api_version,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embed_model,\r\n)\r\n\r\nset_global_service_context(service_context)\r\n\r\nindex_name = \"doc_idx\"\r\ncontainer_name = \"XXXXXXx\"\r\nstorage_account_name = \"XXXXXXXx\"\r\nstorage_key = \"XXXXXXXXXXXXXXXX\"\r\n\r\nblob_service_client = BlobServiceClient(account_url=f\"https://{storage_account_name}.blob.core.windows.net\", credential=storage_key)\r\n\r\nblob_client = blob_service_client.get_blob_client(container=container_name, blob=index_name)\r\n\r\npickled_index = blob_client.download_blob().readall()\r\nindex = pickle.loads(pickled_index)\r\n\r\nquery = \"Who is widget company? What was our pitch to them?\"\r\nquery_engine = index.as_query_engine()\r\nanswer = query_engine.query(query)\r\n```\r\n\r\nThis returned the error message I reported:\r\n\r\n```\r\n{\r\n\t\"name\": \"AttributeError\",\r\n\t\"message\": \"_llm\",\r\n\t\"stack\": \"---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[9], line 3\r\n      1 query = \\\"Who is champlain investment partners. What was our pitch to them?\\\"\r\n      2 query_engine = index.as_query_engine()\r\n----> 3 answer = query_engine.query(query)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/core/base_query_engine.py:30, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     28 if isinstance(str_or_query_bundle, str):\r\n     29     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 30 return self._query(str_or_query_bundle)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/query_engine/retriever_query_engine.py:171, in RetrieverQueryEngine._query(self, query_bundle)\r\n    167 with self.callback_manager.event(\r\n    168     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\r\n    169 ) as query_event:\r\n    170     nodes = self.retrieve(query_bundle)\r\n--> 171     response = self._response_synthesizer.synthesize(\r\n    172         query=query_bundle,\r\n    173         nodes=nodes,\r\n    174     )\r\n    176     query_event.on_end(payload={EventPayload.RESPONSE: response})\r\n    178 return response\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/base.py:146, in BaseSynthesizer.synthesize(self, query, nodes, additional_source_nodes, **response_kwargs)\r\n    141     query = QueryBundle(query_str=query)\r\n    143 with self._callback_manager.event(\r\n    144     CBEventType.SYNTHESIZE, payload={EventPayload.QUERY_STR: query.query_str}\r\n    145 ) as event:\r\n--> 146     response_str = self.get_response(\r\n    147         query_str=query.query_str,\r\n    148         text_chunks=[\r\n    149             n.node.get_content(metadata_mode=MetadataMode.LLM) for n in nodes\r\n    150         ],\r\n    151         **response_kwargs,\r\n    152     )\r\n    154     additional_source_nodes = additional_source_nodes or []\r\n    155     source_nodes = list(nodes) + list(additional_source_nodes)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/compact_and_refine.py:38, in CompactAndRefine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n     34 # use prompt helper to fix compact text_chunks under the prompt limitation\r\n     35 # TODO: This is a temporary fix - reason it's temporary is that\r\n     36 # the refine template does not account for size of previous answer.\r\n     37 new_texts = self._make_compact_text_chunks(query_str, text_chunks)\r\n---> 38 return super().get_response(\r\n     39     query_str=query_str,\r\n     40     text_chunks=new_texts,\r\n     41     prev_response=prev_response,\r\n     42     **response_kwargs,\r\n     43 )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:146, in Refine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n    142 for text_chunk in text_chunks:\r\n    143     if prev_response is None:\r\n    144         # if this is the first chunk, and text chunk already\r\n    145         # is an answer, then return it\r\n--> 146         response = self._give_response_single(\r\n    147             query_str, text_chunk, **response_kwargs\r\n    148         )\r\n    149     else:\r\n    150         # refine response if possible\r\n    151         response = self._refine_response_single(\r\n    152             prev_response, query_str, text_chunk, **response_kwargs\r\n    153         )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:194, in Refine._give_response_single(self, query_str, text_chunk, **response_kwargs)\r\n    189 text_chunks = self._service_context.prompt_helper.repack(\r\n    190     text_qa_template, [text_chunk]\r\n    191 )\r\n    193 response: Optional[RESPONSE_TEXT_TYPE] = None\r\n--> 194 program = self._program_factory(text_qa_template)\r\n    195 # TODO: consolidate with loop in get_response_default\r\n    196 for cur_text_chunk in text_chunks:\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:177, in Refine._default_program_factory(self, prompt)\r\n    168     return get_program_for_llm(\r\n    169         StructuredRefineResponse,\r\n    170         prompt,\r\n    171         self._service_context.llm,\r\n    172         verbose=self._verbose,\r\n    173     )\r\n    174 else:\r\n    175     return DefaultRefineProgram(\r\n    176         prompt=prompt,\r\n--> 177         llm=self._service_context.llm,\r\n    178         output_cls=self._output_cls,\r\n    179     )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/service_context.py:322, in ServiceContext.llm(self)\r\n    320 @property\r\n    321 def llm(self) -> LLM:\r\n--> 322     return self.llm_predictor.llm\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/llm_predictor/base.py:143, in LLMPredictor.llm(self)\r\n    140 @property\r\n    141 def llm(self) -> LLM:\r\n    142     \\\"\\\"\\\"Get LLM.\\\"\\\"\\\"\r\n--> 143     return self._llm\r\n\r\nAttributeError: _llm\"\r\n}\r\n```\n\n### Version\n\nCurrent\n\n### Steps to Reproduce\n\nRunning the first snippet of code, then resetting your kernel and running the second snippet of code should replicate the problem. Other alternatives would also be helpful, such as how to store an index to Azure storage and retrieve it later to be used by Azure Open AI in the front end app.\n\n### Relevant Logs/Tracbacks\n\n```shell\n{\r\n\t\"name\": \"AttributeError\",\r\n\t\"message\": \"_llm\",\r\n\t\"stack\": \"---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[9], line 3\r\n      1 query = \\\"Who is champlain investment partners. What was our pitch to them?\\\"\r\n      2 query_engine = index.as_query_engine()\r\n----> 3 answer = query_engine.query(query)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/core/base_query_engine.py:30, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     28 if isinstance(str_or_query_bundle, str):\r\n     29     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 30 return self._query(str_or_query_bundle)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/query_engine/retriever_query_engine.py:171, in RetrieverQueryEngine._query(self, query_bundle)\r\n    167 with self.callback_manager.event(\r\n    168     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\r\n    169 ) as query_event:\r\n    170     nodes = self.retrieve(query_bundle)\r\n--> 171     response = self._response_synthesizer.synthesize(\r\n    172         query=query_bundle,\r\n    173         nodes=nodes,\r\n    174     )\r\n    176     query_event.on_end(payload={EventPayload.RESPONSE: response})\r\n    178 return response\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/base.py:146, in BaseSynthesizer.synthesize(self, query, nodes, additional_source_nodes, **response_kwargs)\r\n    141     query = QueryBundle(query_str=query)\r\n    143 with self._callback_manager.event(\r\n    144     CBEventType.SYNTHESIZE, payload={EventPayload.QUERY_STR: query.query_str}\r\n    145 ) as event:\r\n--> 146     response_str = self.get_response(\r\n    147         query_str=query.query_str,\r\n    148         text_chunks=[\r\n    149             n.node.get_content(metadata_mode=MetadataMode.LLM) for n in nodes\r\n    150         ],\r\n    151         **response_kwargs,\r\n    152     )\r\n    154     additional_source_nodes = additional_source_nodes or []\r\n    155     source_nodes = list(nodes) + list(additional_source_nodes)\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/compact_and_refine.py:38, in CompactAndRefine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n     34 # use prompt helper to fix compact text_chunks under the prompt limitation\r\n     35 # TODO: This is a temporary fix - reason it's temporary is that\r\n     36 # the refine template does not account for size of previous answer.\r\n     37 new_texts = self._make_compact_text_chunks(query_str, text_chunks)\r\n---> 38 return super().get_response(\r\n     39     query_str=query_str,\r\n     40     text_chunks=new_texts,\r\n     41     prev_response=prev_response,\r\n     42     **response_kwargs,\r\n     43 )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:146, in Refine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n    142 for text_chunk in text_chunks:\r\n    143     if prev_response is None:\r\n    144         # if this is the first chunk, and text chunk already\r\n    145         # is an answer, then return it\r\n--> 146         response = self._give_response_single(\r\n    147             query_str, text_chunk, **response_kwargs\r\n    148         )\r\n    149     else:\r\n    150         # refine response if possible\r\n    151         response = self._refine_response_single(\r\n    152             prev_response, query_str, text_chunk, **response_kwargs\r\n    153         )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:194, in Refine._give_response_single(self, query_str, text_chunk, **response_kwargs)\r\n    189 text_chunks = self._service_context.prompt_helper.repack(\r\n    190     text_qa_template, [text_chunk]\r\n    191 )\r\n    193 response: Optional[RESPONSE_TEXT_TYPE] = None\r\n--> 194 program = self._program_factory(text_qa_template)\r\n    195 # TODO: consolidate with loop in get_response_default\r\n    196 for cur_text_chunk in text_chunks:\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/response_synthesizers/refine.py:177, in Refine._default_program_factory(self, prompt)\r\n    168     return get_program_for_llm(\r\n    169         StructuredRefineResponse,\r\n    170         prompt,\r\n    171         self._service_context.llm,\r\n    172         verbose=self._verbose,\r\n    173     )\r\n    174 else:\r\n    175     return DefaultRefineProgram(\r\n    176         prompt=prompt,\r\n--> 177         llm=self._service_context.llm,\r\n    178         output_cls=self._output_cls,\r\n    179     )\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/service_context.py:322, in ServiceContext.llm(self)\r\n    320 @property\r\n    321 def llm(self) -> LLM:\r\n--> 322     return self.llm_predictor.llm\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/llm_predictor/base.py:143, in LLMPredictor.llm(self)\r\n    140 @property\r\n    141 def llm(self) -> LLM:\r\n    142     \\\"\\\"\\\"Get LLM.\\\"\\\"\\\"\r\n--> 143     return self._llm\r\n\r\nAttributeError: _llm\"\r\n}\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9480/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9480/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9479",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9479/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9479/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9479/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9479",
        "id": 2039138174,
        "node_id": "I_kwDOIWuq5855isd-",
        "number": 9479,
        "title": "[Bug]: persist_dir is passed but never used ",
        "user": {
            "login": "tanmaylaud",
            "id": 31733620,
            "node_id": "MDQ6VXNlcjMxNzMzNjIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/31733620?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tanmaylaud",
            "html_url": "https://github.com/tanmaylaud",
            "followers_url": "https://api.github.com/users/tanmaylaud/followers",
            "following_url": "https://api.github.com/users/tanmaylaud/following{/other_user}",
            "gists_url": "https://api.github.com/users/tanmaylaud/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tanmaylaud/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tanmaylaud/subscriptions",
            "organizations_url": "https://api.github.com/users/tanmaylaud/orgs",
            "repos_url": "https://api.github.com/users/tanmaylaud/repos",
            "events_url": "https://api.github.com/users/tanmaylaud/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tanmaylaud/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T07:43:03Z",
        "updated_at": "2023-12-13T15:06:42Z",
        "closed_at": "2023-12-13T15:06:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe persist_dir variable is passed in the function but not used causing loading issues. \n\n### Version\n\n0.9.14\n\n### Steps to Reproduce\n\n```python\r\nFaissVectorStore.from_persist_dir(index_name)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9479/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9479/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9478",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9478/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9478/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9478/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9478",
        "id": 2039047777,
        "node_id": "I_kwDOIWuq5855iWZh",
        "number": 9478,
        "title": "[Bug]: ObjectIndex +VectorStoreIndex gets 'code': '404', 'message': 'Resource not found'",
        "user": {
            "login": "dgaoh",
            "id": 86749605,
            "node_id": "MDQ6VXNlcjg2NzQ5NjA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/86749605?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dgaoh",
            "html_url": "https://github.com/dgaoh",
            "followers_url": "https://api.github.com/users/dgaoh/followers",
            "following_url": "https://api.github.com/users/dgaoh/following{/other_user}",
            "gists_url": "https://api.github.com/users/dgaoh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dgaoh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dgaoh/subscriptions",
            "organizations_url": "https://api.github.com/users/dgaoh/orgs",
            "repos_url": "https://api.github.com/users/dgaoh/repos",
            "events_url": "https://api.github.com/users/dgaoh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dgaoh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-13T06:31:59Z",
        "updated_at": "2023-12-13T15:07:27Z",
        "closed_at": "2023-12-13T15:07:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n directly run the first set of code in your object_index.ipynb, the provide code of ObjectIndex doesn't work well\r\n docs\\examples\\objects\\object_index.ipynb\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\n1. directly run the first set of code in your object_index.ipynb, the provide code doesn't work well\r\n\r\n```\r\nobject_index = ObjectIndex(\r\n    index=VectorStoreIndex(nodes=nodes), object_node_mapping=obj_node_mapping\r\n)\r\n\r\n```\r\nGet error:  openai.NotFoundError: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\r\n\r\n2. Slightly change to add llm, it goes to another error:\r\n```\r\nllm = AzureOpenAI(\r\n    model=\"gpt-35-turbo-16k\", \r\n    deployment_name=\"qagpt-35-turbo-16k\", \r\n    api_key=os.environ[\"OPENAI_API_KEY\"],\r\n    azure_endpoint=os.environ[\"OPENAI_API_BASE\"],\r\n    api_version=os.environ[\"OPENAI_API_VERSION\"],\r\n)\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embedding_llm)\r\n\r\n# some really arbitrary objects\r\nobj1 = {\"input\": \"Hey, how's it going\"}\r\nobj2 = [\"a\", \"b\", \"c\", \"d\"]\r\nobj3 = \"llamaindex is an awesome library!\"\r\narbitrary_objects = [obj1, obj2, obj3]\r\n\r\n# object-node mapping\r\nobj_node_mapping = SimpleObjectNodeMapping.from_objects(arbitrary_objects)\r\nnodes = obj_node_mapping.to_nodes(arbitrary_objects)\r\n\r\n# object index\r\nobject_index = ObjectIndex(\r\n    index=VectorStoreIndex(nodes=nodes, service_context=service_context), object_node_mapping=obj_node_mapping\r\n)\r\n```\r\nIt gets another error:\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Too many inputs. The max number of inputs is 1.  We hope to increase the number of inputs per request soon. Please contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 for further questions.', 'type': 'invalid_request_error', 'param': None, 'code': None}}\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9478/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9478/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9477",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9477/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9477/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9477/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9477",
        "id": 2038925579,
        "node_id": "I_kwDOIWuq5855h4kL",
        "number": 9477,
        "title": "[Bug]: VLLM Streaming Not Working",
        "user": {
            "login": "Sajalj98",
            "id": 35100919,
            "node_id": "MDQ6VXNlcjM1MTAwOTE5",
            "avatar_url": "https://avatars.githubusercontent.com/u/35100919?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Sajalj98",
            "html_url": "https://github.com/Sajalj98",
            "followers_url": "https://api.github.com/users/Sajalj98/followers",
            "following_url": "https://api.github.com/users/Sajalj98/following{/other_user}",
            "gists_url": "https://api.github.com/users/Sajalj98/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Sajalj98/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Sajalj98/subscriptions",
            "organizations_url": "https://api.github.com/users/Sajalj98/orgs",
            "repos_url": "https://api.github.com/users/Sajalj98/repos",
            "events_url": "https://api.github.com/users/Sajalj98/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Sajalj98/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T04:23:52Z",
        "updated_at": "2023-12-13T04:31:50Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHi Team, \r\nI am trying to use llama-index with vllm, I want to stream the response first on notebook than to an api response.\r\nBut its not working. Vllm - 0.2.4\r\n### Version\r\n\r\n0.9.14.post1\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index.llms.vllm import Vllm\r\n\r\nllm = Vllm(\r\n    model=\"meta-llama/Llama-2-7b-chat-hf\",\r\n    tensor_parallel_size=2,\r\n    max_new_tokens=500,\r\n    vllm_kwargs={\"gpu_memory_utilization\": 0.5},\r\n)\r\n\r\nmessage = [ChatMessage(content=\"what is a black hole\", author=\"user\")]\r\n[x for x in llm.stream_chat(message)][-1]\r\n\r\nalso with - \r\nfrom llama_index.llms import ChatMessage\r\nawait llm.acomplete(\"What is a black hole\")\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n![image](https://github.com/run-llama/llama_index/assets/35100919/cc4cb4cc-750d-40bd-9be0-d7e3c4d77b09)\r\n\r\n![image](https://github.com/run-llama/llama_index/assets/35100919/acebaf2d-006e-41f8-91ef-46506f077364)\r\n\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9477/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9477/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9476",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9476/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9476/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9476/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9476",
        "id": 2038912307,
        "node_id": "PR_kwDOIWuq585h2rfz",
        "number": 9476,
        "title": "Gemini Embedding",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T04:06:36Z",
        "updated_at": "2023-12-13T18:23:50Z",
        "closed_at": "2023-12-13T18:23:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9476",
            "html_url": "https://github.com/run-llama/llama_index/pull/9476",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9476.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9476.patch",
            "merged_at": "2023-12-13T18:23:49Z"
        },
        "body": "# Description\r\n\r\nTitle vs content, what is the difference? \r\n\r\nTOOD: Async calls once Gemini support for embedding\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9476/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9476/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9475",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9475/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9475/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9475/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9475",
        "id": 2038855664,
        "node_id": "I_kwDOIWuq5855hnfw",
        "number": 9475,
        "title": "[Bug]: SimpleDirectoryReader() Fails on Corrupted PPTX File with \"File is not a zip file\" Error  ",
        "user": {
            "login": "nickjtay",
            "id": 52182102,
            "node_id": "MDQ6VXNlcjUyMTgyMTAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/52182102?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nickjtay",
            "html_url": "https://github.com/nickjtay",
            "followers_url": "https://api.github.com/users/nickjtay/followers",
            "following_url": "https://api.github.com/users/nickjtay/following{/other_user}",
            "gists_url": "https://api.github.com/users/nickjtay/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nickjtay/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nickjtay/subscriptions",
            "organizations_url": "https://api.github.com/users/nickjtay/orgs",
            "repos_url": "https://api.github.com/users/nickjtay/repos",
            "events_url": "https://api.github.com/users/nickjtay/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nickjtay/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-13T02:47:55Z",
        "updated_at": "2023-12-13T02:53:43Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe loader is failing on a powerpoint file in my azure blob directory. I am unsure why, but I suspect the file could be corrupted. Instead of logging an exception, the load for the entire directory fails. I don't want the full load to fail because of a single file. Should this line be modified to use try-except?\r\n\r\n```extracted_documents = reader.load_data(file=input_file, extra_info=metadata)```\n\n### Version\n\nCurrent\n\n### Steps to Reproduce\n\nTry loading a corrupted powerpoint file using the SimpleDirectoryReader().\n\n### Relevant Logs/Tracbacks\n\n```shell\n---------------------------------------------------------------------------\r\nBadZipFile                                Traceback (most recent call last)\r\nCell In[10], line 14\r\n      6 container_client = ContainerClient(account_url=storage_url, \r\n      7     credential=storage_key, \r\n      8     container_name=\"powerpoints3\")\r\n     10 loader = AzStorageBlobReader(account_url=storage_url, \r\n     11     credential=storage_key, \r\n     12     container_name=\"powerpoints3\")\r\n---> 14 documents = loader.load_data()\r\n\r\nCell In[6], line 130\r\n    127     SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\r\n    128 loader = SimpleDirectoryReader(temp_dir, file_extractor=self.file_extractor, errors=\"ignore\")\r\n--> 130 return loader.load_data()\r\n\r\nFile /anaconda/envs/azureml_py38/lib/python3.8/site-packages/llama_index/download/llamahub_modules/file/base.py:143, in SimpleDirectoryReader.load_data(self)\r\n    141         reader = download_loader(reader)()\r\n    142 # try:\r\n--> 143 extracted_documents = reader.load_data(\r\n    144     file=input_file, extra_info=metadata\r\n    145 )\r\n    146 # except:\r\n    147 #     pass\r\n    148 documents.extend(extracted_documents)\r\n...\r\n-> 1336     raise BadZipFile(\"File is not a zip file\")\r\n   1337 if self.debug > 1:\r\n   1338     print(endrec)\r\n\r\nBadZipFile: File is not a zip file\r\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9475/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9475/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9474",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9474/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9474/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9474/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9474",
        "id": 2038834590,
        "node_id": "I_kwDOIWuq5855hiWe",
        "number": 9474,
        "title": "[Question]: I only want to chunk text, not metadata, how can I do that?",
        "user": {
            "login": "Plusholic",
            "id": 97847752,
            "node_id": "U_kgDOBdUJyA",
            "avatar_url": "https://avatars.githubusercontent.com/u/97847752?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Plusholic",
            "html_url": "https://github.com/Plusholic",
            "followers_url": "https://api.github.com/users/Plusholic/followers",
            "following_url": "https://api.github.com/users/Plusholic/following{/other_user}",
            "gists_url": "https://api.github.com/users/Plusholic/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Plusholic/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Plusholic/subscriptions",
            "organizations_url": "https://api.github.com/users/Plusholic/orgs",
            "repos_url": "https://api.github.com/users/Plusholic/repos",
            "events_url": "https://api.github.com/users/Plusholic/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Plusholic/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-13T02:19:12Z",
        "updated_at": "2023-12-13T02:28:51Z",
        "closed_at": "2023-12-13T02:28:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nTo use the RecursiveRetriver, I wrote the following\r\nBut ValueError: Metadata length (75) is longer than chunk size (64). Consider increasing the chunk size or decreasing the size of your metadata to avoid this. .\r\nI have about 5000 files, each stored in different folders, so the metadata (file paths) are long. Is it possible to keep the metadata and only chunk the text? I have specified the include_metadata=False option, but it doesn't seem to work.\r\n\r\n`Isub_chunk_sizes = [64,128]\r\nsub_node_parsers = [\r\n    SimpleNodeParser.from_defaults(chunk_size=c, chunk_overlap=0, include_metadata=False) for c in sub_chunk_sizes\r\n]\r\n\r\nall_nodes = []\r\nfor base_node in base_nodes:\r\n    for n in sub_node_parsers:\r\n        sub_nodes = n.get_nodes_from_documents([base_node])\r\n        sub_inodes = [\r\n            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\r\n        ]\r\n        all_nodes.extend(sub_inodes)\r\n\r\n    # also add original node to node\r\n    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\r\n    all_nodes.append(original_node)\r\n    \r\nall_nodes_dict = {n.node_id: n for n in all_nodes}`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9474/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9474/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9473",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9473/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9473/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9473/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9473",
        "id": 2038829448,
        "node_id": "PR_kwDOIWuq585h2aJW",
        "number": 9473,
        "title": "Fix Bedrock LLMs",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-13T02:12:47Z",
        "updated_at": "2023-12-14T22:23:42Z",
        "closed_at": "2023-12-14T22:12:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9473",
            "html_url": "https://github.com/run-llama/llama_index/pull/9473",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9473.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9473.patch",
            "merged_at": "2023-12-14T22:12:11Z"
        },
        "body": "# Description\r\n\r\nThis PR fixes Bedrock LLMs.\r\nSince https://github.com/run-llama/llama_index/pull/9388, Bedrock+Anthropic doesn't work anymore because the completion is used instead of the chat and the completion has an incorrect format (it passes the completion prompt as-is without adding the `Human: /Assistant: ` prefixes)\r\nThis change does the following:\r\n* set `is_chat_model` for CHAT_ONLY_MODELS\r\n* create Provider classes to group behaviors\r\n* use messages_to_prompt and completion_to_prompt to convert to prompt. The order of resolution is:\r\n   * user-defined ones\r\n   * provider specific ones\r\n   * generic ones \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9473/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9473/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9472",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9472/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9472/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9472/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9472",
        "id": 2038672599,
        "node_id": "I_kwDOIWuq5855g6zX",
        "number": 9472,
        "title": "[Feature Request]: Add stop words to ReAct agent",
        "user": {
            "login": "cyberkaida",
            "id": 118712366,
            "node_id": "U_kgDOBxNoLg",
            "avatar_url": "https://avatars.githubusercontent.com/u/118712366?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyberkaida",
            "html_url": "https://github.com/cyberkaida",
            "followers_url": "https://api.github.com/users/cyberkaida/followers",
            "following_url": "https://api.github.com/users/cyberkaida/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyberkaida/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyberkaida/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyberkaida/subscriptions",
            "organizations_url": "https://api.github.com/users/cyberkaida/orgs",
            "repos_url": "https://api.github.com/users/cyberkaida/repos",
            "events_url": "https://api.github.com/users/cyberkaida/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyberkaida/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T23:01:15Z",
        "updated_at": "2023-12-12T23:06:53Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nThe ReAct agent does not use any stop words and the current API does not allow these to be passed to the LLM API.\r\nWhen using the ReAct agent chat abstraction the LLM often will generate an entire conversation before this output is collected by llama-index and then trimmed to the first `Thought:`, `Action:` set.\r\n\r\nThis is very, very slow for some models.\r\n\r\nA better approach would be to use any available stop word setting in the APIs llama-index calls, or to instead use a streaming approach and implement stop words when possible this way.\r\n\r\nAdditionally stop words should be plumbed up to the chat, query, etc API. This could probably be its own issue.\n\n### Reason\n\n`ReActOutputParser` selects the first `Thought:`, `Action:` set to act on. This hides that the LLM is doing a lot of useless work.\r\n\r\n`ReActAgent` should probably inject a stop word. If you build a chat or query from this the LLM will do a lot of work before its output is truncated to the first `Thought:`, `Action:` block.\n\n### Value of Feature\n\nLLM usage is expensive and especially slow when working locally. Currently with a variety of models, the ReAct agent is very inefficient because it generates large outputs containing many `Thought:`, `Action:` blocks and truncates to the first one. It should just avoid generating these large blocks with a stop word or by using streaming if available and stopping after the first block.\r\n\r\nThis would reduce cost and significantly increase speed for local inference.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9472/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9472/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9471",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9471/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9471/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9471/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9471",
        "id": 2038645641,
        "node_id": "I_kwDOIWuq5855g0OJ",
        "number": 9471,
        "title": "[Feature Request]: Support AzureOpenAIMultiModal",
        "user": {
            "login": "mingqxu7",
            "id": 50094870,
            "node_id": "MDQ6VXNlcjUwMDk0ODcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/50094870?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mingqxu7",
            "html_url": "https://github.com/mingqxu7",
            "followers_url": "https://api.github.com/users/mingqxu7/followers",
            "following_url": "https://api.github.com/users/mingqxu7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mingqxu7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mingqxu7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mingqxu7/subscriptions",
            "organizations_url": "https://api.github.com/users/mingqxu7/orgs",
            "repos_url": "https://api.github.com/users/mingqxu7/repos",
            "events_url": "https://api.github.com/users/mingqxu7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mingqxu7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-12T22:31:59Z",
        "updated_at": "2023-12-13T00:48:13Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nAzure OpenAI now has gpt-4-vision in their preview.  We should support AzureOpenAIMultiModal class.  \n\n### Reason\n\nMy customers are using Azure OpenAI and would like to evaluate gpt-4-vision models.  \n\n### Value of Feature\n\nAs llama-index have been supporting Azure models, it is self-evident that customers would be interested in evaluating the innovative capabilities that gpt-4-vision has to offer.  ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9471/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9471/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9470",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9470/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9470/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9470/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9470",
        "id": 2038519124,
        "node_id": "PR_kwDOIWuq585h1Xw6",
        "number": 9470,
        "title": "Add Anyscale Embedding model support",
        "user": {
            "login": "kylehh",
            "id": 24217337,
            "node_id": "MDQ6VXNlcjI0MjE3MzM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/24217337?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylehh",
            "html_url": "https://github.com/kylehh",
            "followers_url": "https://api.github.com/users/kylehh/followers",
            "following_url": "https://api.github.com/users/kylehh/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylehh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylehh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylehh/subscriptions",
            "organizations_url": "https://api.github.com/users/kylehh/orgs",
            "repos_url": "https://api.github.com/users/kylehh/repos",
            "events_url": "https://api.github.com/users/kylehh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylehh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T20:41:03Z",
        "updated_at": "2023-12-14T21:24:33Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9470",
            "html_url": "https://github.com/run-llama/llama_index/pull/9470",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9470.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9470.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9470/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9470/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9469",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9469/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9469/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9469/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9469",
        "id": 2038456743,
        "node_id": "I_kwDOIWuq5855gGGn",
        "number": 9469,
        "title": "[Bug]: cant retrieve image which are indexed using redis..retrieved_image is an empty list...the same code works without issue for qdrant database which is in llaamaindex documentation",
        "user": {
            "login": "Johnbathappully",
            "id": 114779060,
            "node_id": "U_kgDOBtdjtA",
            "avatar_url": "https://avatars.githubusercontent.com/u/114779060?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Johnbathappully",
            "html_url": "https://github.com/Johnbathappully",
            "followers_url": "https://api.github.com/users/Johnbathappully/followers",
            "following_url": "https://api.github.com/users/Johnbathappully/following{/other_user}",
            "gists_url": "https://api.github.com/users/Johnbathappully/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Johnbathappully/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Johnbathappully/subscriptions",
            "organizations_url": "https://api.github.com/users/Johnbathappully/orgs",
            "repos_url": "https://api.github.com/users/Johnbathappully/repos",
            "events_url": "https://api.github.com/users/Johnbathappully/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Johnbathappully/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-12T19:54:22Z",
        "updated_at": "2023-12-13T04:58:20Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\ni migrated from qdrant database documentation to redis ..image retrieval not taking place properly..\r\n\r\nfrom llama_index import VectorStoreIndex, StorageContext\r\nfrom llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\r\nfrom llama_index.vector_stores.redis import RedisVectorStore\r\nimport redis\r\nimport urllib.parse\r\nfrom llama_index import (\r\n    ServiceContext,\r\n    SimpleDirectoryReader,\r\n)\r\n\r\npassword = \"purposefullyhid\"\r\nencoded_password = urllib.parse.quote(password)\r\nREDIS_HOST = \"13.72.116.240\"\r\nREDIS_PORT = 6380\r\nredis_url = f\"redis://:{encoded_password}@{REDIS_HOST}:{REDIS_PORT}\"\r\n\r\nredis_client = redis.Redis.from_url(redis_url)\r\n\r\ntext_vector_store = RedisVectorStore(\r\n    index_name=\"text_index11\",\r\n    index_prefix=\"llama_text3\",\r\n    redis_url=redis_url,\r\n    overwrite=True,\r\n)\r\n\r\nimage_vector_store = RedisVectorStore(\r\n    index_name=\"image_index11\",\r\n    index_prefix=\"llama_image3\",\r\n    redis_url=redis_url,\r\n    overwrite=True,\r\n)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    vector_store=text_vector_store, image_store=image_vector_store\r\n)\r\n\r\n\r\ndocuments = SimpleDirectoryReader(\"./data_wiki/\").load_data()\r\nindex = MultiModalVectorStoreIndex.from_documents(\r\n    documents,\r\n    storage_context=storage_context,\r\n)\r\n\r\nfrom PIL import Image\r\nimport matplotlib.pyplot as plt\r\nimport os\r\n\r\ndef plot_images(image_metadata_dict):\r\n    original_images_urls = []\r\n    images_shown = 0\r\n    for image_id in image_metadata_dict:\r\n        img_path = image_metadata_dict[image_id][\"img_path\"]\r\n        if os.path.isfile(img_path) and os.path.getsize(img_path) > 0:\r\n            try:\r\n                image = Image.open(img_path).convert(\"RGB\")\r\n\r\n                plt.subplot(8, 8, len(original_images_urls) + 1)\r\n                plt.imshow(image)\r\n                plt.xticks([])\r\n                plt.yticks([])\r\n\r\n                original_images_urls.append(image_metadata_dict[image_id][\"filename\"])\r\n                images_shown += 1\r\n                if images_shown >= 64:\r\n                    break\r\n            except Exception as e:\r\n                print(f\"Error opening {img_path}: {e}\")\r\n\r\n    plt.tight_layout()\r\n\r\nplot_images(image_metadata_dict)                                                                                                                                                                      \r\n\r\ndef plot_images(image_paths):\r\n    images_shown = 0\r\n    plt.figure(figsize=(16, 9))\r\n    for img_path in image_paths:\r\n        if os.path.isfile(img_path):\r\n            image = Image.open(img_path)\r\n\r\n            plt.subplot(2, 3, images_shown + 1)\r\n            plt.imshow(image)\r\n            plt.xticks([])\r\n            plt.yticks([])\r\n\r\n            images_shown += 1\r\n            if images_shown >= 9:\r\n                break\r\n\r\n              test_query = \"who are BTS team members\"\r\n# generate  retrieval results\r\nretriever = index.as_retriever(similarity_top_k=3, image_similarity_top_k=2)\r\nretrieval_results = retriever.retrieve(test_query)\r\n\r\nfrom llama_index.response.notebook_utils import display_source_node\r\nfrom llama_index.schema import ImageNode\r\n\r\nretrieved_image = []\r\nfor res_node in retrieval_results:\r\n    if isinstance(res_node.node, ImageNode):\r\n        retrieved_image.append(res_node.node.metadata[\"file_path\"])\r\n    else:\r\n        display_source_node(res_node, source_length=200)\r\n\r\nplot_images(retrieved_image)\r\n\r\n**output is** \r\nNode ID: 38351381-ac1a-4b8a-9107-cf2ddd8a539a\r\nSimilarity: 0.816846907139\r\nText: == Members == Jin (\uc9c4) \u2013 vocalist Suga (\uc288\uac00) \u2013 rapper J-Hope (\uc81c\uc774\ud649) \u2013 rapper RM (\uc54c\uc570) \u2013 leader, rapper Jimin (\uc9c0\ubbfc) \u2013 vocalist V (\ubdd4) \u2013 vocalist Jungkook (\uc815\uad6d) \u2013 vocalist\r\n\r\n== Discography ==\r\n\r\n== Fi...\r\n\r\nNode ID: baf75f27-1929-42a4-bac9-1c52609a7fac\r\nSimilarity: 0.816846907139\r\nText: == Members == Jin (\uc9c4) \u2013 vocalist Suga (\uc288\uac00) \u2013 rapper J-Hope (\uc81c\uc774\ud649) \u2013 rapper RM (\uc54c\uc570) \u2013 leader, rapper Jimin (\uc9c0\ubbfc) \u2013 vocalist V (\ubdd4) \u2013 vocalist Jungkook (\uc815\uad6d) \u2013 vocalist\r\n\r\n== Discography ==\r\n\r\n== Fi...\r\n\r\nNode ID: bc322ea3-a8f2-4e5a-a0fd-32adef23ed09\r\nSimilarity: 0.808160722256\r\nText: BTS (Korean: \ubc29\ud0c4\uc18c\ub144\ub2e8; RR: Bangtan Sonyeondan; lit. Bulletproof Boy Scouts), also known as the Bangtan Boys, is a South Korean boy band formed in 2010. The band consists of Jin, Suga, J-Hope, RM, Jimi...\r\n\r\nNode ID: 0f9194de-6cdc-489b-8051-50f1cad77af9\r\nSimilarity: 0.28735196590400003\r\nText:\r\n\r\nNode ID: debfe5b4-ffc7-43f3-9a40-40e3efcf2ff7\r\nSimilarity: 0.28735196590400003\r\nText:\r\n\r\n<Figure size 1600x900 with 0 Axes>\r\nthe image output is empty\r\n<img width=\"619\" alt=\"llamaindex issue\" src=\"https://github.com/run-llama/llama_index/assets/114779060/05a53e12-1a4d-4326-8875-0c04d2d80536\">\r\n\r\n\r\n\r\n\r\n\r\n\n\n### Version\n\n0.9.14.post3\n\n### Steps to Reproduce\n\nfrom llama_index import VectorStoreIndex, StorageContext\r\nfrom llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\r\nfrom llama_index.vector_stores.redis import RedisVectorStore\r\nimport redis\r\nimport urllib.parse\r\nfrom llama_index import (\r\n    ServiceContext,\r\n    SimpleDirectoryReader,\r\n)\r\n\r\npassword = \"purposefullyhid\"\r\nencoded_password = urllib.parse.quote(password)\r\nREDIS_HOST = \"13.72.116.240\"\r\nREDIS_PORT = 6380\r\nredis_url = f\"redis://:{encoded_password}@{REDIS_HOST}:{REDIS_PORT}\"\r\n\r\nredis_client = redis.Redis.from_url(redis_url)\r\n\r\ntext_vector_store = RedisVectorStore(\r\n    index_name=\"text_index11\",\r\n    index_prefix=\"llama_text3\",\r\n    redis_url=redis_url,\r\n    overwrite=True,\r\n)\r\n\r\nimage_vector_store = RedisVectorStore(\r\n    index_name=\"image_index11\",\r\n    index_prefix=\"llama_image3\",\r\n    redis_url=redis_url,\r\n    overwrite=True,\r\n)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    vector_store=text_vector_store, image_store=image_vector_store\r\n)\r\n\r\n\r\ndocuments = SimpleDirectoryReader(\"./data_wiki/\").load_data()\r\nindex = MultiModalVectorStoreIndex.from_documents(\r\n    documents,\r\n    storage_context=storage_context,\r\n)\r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nNode ID: 1f790011-b6a5-4d8a-82a5-ebe6585f3c53\r\nSimilarity: 0.871842324734\r\nText: Van Gogh turned to well-known Hague School artists like Weissenbruch and Blommers, and he received technical advice from them as well as from painters like De Bock and Van der Weele, both of the Ha...\r\n\r\nNode ID: 5ca18ec4-77e4-4d71-9018-ec8f50cea1ca\r\nSimilarity: 0.871842324734\r\nText: Van Gogh turned to well-known Hague School artists like Weissenbruch and Blommers, and he received technical advice from them as well as from painters like De Bock and Van der Weele, both of the Ha...\r\n\r\nNode ID: c94421e1-c152-4625-908b-b82338e90c59\r\nSimilarity: 0.867530286312\r\nText: Vincent Willem van Gogh (Dutch: [\u02c8v\u026ans\u025bnt \u02c8\u028b\u026al\u0259\u0271 v\u0251\u014b \u02c8\u0263\u0254x] ; 30 March 1853 \u2013 29 July 1890) was a Dutch Post-Impressionist painter who is among the most famous and influential figures in the history...\r\n\r\nNode ID: 70affaa1-e308-4cdc-83f7-9adf36efa20f\r\nSimilarity: 0.315268814564\r\nText:\r\n\r\nNode ID: 46fc8e9f-5658-44b2-b8c6-7906d5d84101\r\nSimilarity: 0.315268814564\r\nText:\r\n\r\nNode ID: 3c765355-b23d-43f3-9581-249051987e5b\r\nSimilarity: 0.313244283199\r\nText:\r\n\r\nNode ID: c75047ee-99dc-4a56-871d-e0849667a5c9\r\nSimilarity: 0.313244283199\r\nText:\r\n\r\nNode ID: 91d61107-0a17-40ba-b27b-a55f0218979e\r\nSimilarity: 0.30464488267900003\r\nText:\r\n\r\n<Figure size 1600x900 with 0 Axes>\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9469/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9469/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9468",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9468/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9468/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9468/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9468",
        "id": 2038433439,
        "node_id": "PR_kwDOIWuq585h1FUQ",
        "number": 9468,
        "title": "update maintainers",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T19:36:54Z",
        "updated_at": "2023-12-12T19:40:58Z",
        "closed_at": "2023-12-12T19:40:57Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9468",
            "html_url": "https://github.com/run-llama/llama_index/pull/9468",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9468.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9468.patch",
            "merged_at": "2023-12-12T19:40:57Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9468/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9468/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9467",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9467/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9467/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9467/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9467",
        "id": 2038351875,
        "node_id": "PR_kwDOIWuq585h0zk2",
        "number": 9467,
        "title": "Refactor OpenAI MM model api key to resolve_openai_credentials",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T18:38:16Z",
        "updated_at": "2023-12-12T18:44:52Z",
        "closed_at": "2023-12-12T18:44:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9467",
            "html_url": "https://github.com/run-llama/llama_index/pull/9467",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9467.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9467.patch",
            "merged_at": "2023-12-12T18:44:50Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9467/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9467/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9466",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9466/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9466/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9466/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9466",
        "id": 2038228462,
        "node_id": "PR_kwDOIWuq585h0YsD",
        "number": 9466,
        "title": "Add async support for mistral embeddings",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T17:19:23Z",
        "updated_at": "2023-12-12T18:16:43Z",
        "closed_at": "2023-12-12T18:16:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9466",
            "html_url": "https://github.com/run-llama/llama_index/pull/9466",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9466.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9466.patch",
            "merged_at": "2023-12-12T18:16:43Z"
        },
        "body": "# Description\r\n\r\nPR to add async support for mistral embeddings and syntax fix for mistral llm.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9466/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9466/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9465",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9465/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9465/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9465/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9465",
        "id": 2038038630,
        "node_id": "PR_kwDOIWuq585hzu_X",
        "number": 9465,
        "title": "post3",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T15:40:13Z",
        "updated_at": "2023-12-12T15:45:05Z",
        "closed_at": "2023-12-12T15:45:04Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9465",
            "html_url": "https://github.com/run-llama/llama_index/pull/9465",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9465.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9465.patch",
            "merged_at": "2023-12-12T15:45:04Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9465/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9465/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9464",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9464/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9464/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9464/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9464",
        "id": 2038026073,
        "node_id": "PR_kwDOIWuq585hzsMt",
        "number": 9464,
        "title": "Add OpenRouter, with Mixtral demo",
        "user": {
            "login": "alexanderatallah",
            "id": 1011391,
            "node_id": "MDQ6VXNlcjEwMTEzOTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1011391?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/alexanderatallah",
            "html_url": "https://github.com/alexanderatallah",
            "followers_url": "https://api.github.com/users/alexanderatallah/followers",
            "following_url": "https://api.github.com/users/alexanderatallah/following{/other_user}",
            "gists_url": "https://api.github.com/users/alexanderatallah/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/alexanderatallah/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/alexanderatallah/subscriptions",
            "organizations_url": "https://api.github.com/users/alexanderatallah/orgs",
            "repos_url": "https://api.github.com/users/alexanderatallah/repos",
            "events_url": "https://api.github.com/users/alexanderatallah/events{/privacy}",
            "received_events_url": "https://api.github.com/users/alexanderatallah/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T15:34:22Z",
        "updated_at": "2023-12-12T19:48:15Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9464",
            "html_url": "https://github.com/run-llama/llama_index/pull/9464",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9464.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9464.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nAdds support for OpenRouter: openrouter.ai. Also adds a demo Collab file using Mixtral 8x7b: https://openrouter.ai/models/mistralai/mixtral-8x7b-instruct\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9464/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9464/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9463",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9463/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9463/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9463/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9463",
        "id": 2038017038,
        "node_id": "PR_kwDOIWuq585hzqKJ",
        "number": 9463,
        "title": "Logan/hf llm patch",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T15:30:57Z",
        "updated_at": "2023-12-12T15:37:48Z",
        "closed_at": "2023-12-12T15:37:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9463",
            "html_url": "https://github.com/run-llama/llama_index/pull/9463",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9463.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9463.patch",
            "merged_at": "2023-12-12T15:37:47Z"
        },
        "body": "Fixes https://github.com/run-llama/llama_index/issues/9458",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9463/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9463/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9462",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9462/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9462/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9462/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9462",
        "id": 2038015709,
        "node_id": "PR_kwDOIWuq585hzp3n",
        "number": 9462,
        "title": "[version] bump version to 0.9.14.post2",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T15:30:13Z",
        "updated_at": "2023-12-12T15:36:11Z",
        "closed_at": "2023-12-12T15:36:10Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9462",
            "html_url": "https://github.com/run-llama/llama_index/pull/9462",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9462.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9462.patch",
            "merged_at": "2023-12-12T15:36:10Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9462/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9462/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9461",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9461/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9461/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9461/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9461",
        "id": 2037922255,
        "node_id": "PR_kwDOIWuq585hzVIL",
        "number": 9461,
        "title": "Update MM pydantic example",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T14:49:32Z",
        "updated_at": "2023-12-12T15:08:05Z",
        "closed_at": "2023-12-12T15:08:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9461",
            "html_url": "https://github.com/run-llama/llama_index/pull/9461",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9461.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9461.patch",
            "merged_at": "2023-12-12T15:08:04Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9461/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9461/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9460",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9460/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9460/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9460/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9460",
        "id": 2037768715,
        "node_id": "I_kwDOIWuq5855deIL",
        "number": 9460,
        "title": "Facing issue with Sub Question Query Engine.",
        "user": {
            "login": "pranavbhat12",
            "id": 54463581,
            "node_id": "MDQ6VXNlcjU0NDYzNTgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/54463581?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pranavbhat12",
            "html_url": "https://github.com/pranavbhat12",
            "followers_url": "https://api.github.com/users/pranavbhat12/followers",
            "following_url": "https://api.github.com/users/pranavbhat12/following{/other_user}",
            "gists_url": "https://api.github.com/users/pranavbhat12/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pranavbhat12/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pranavbhat12/subscriptions",
            "organizations_url": "https://api.github.com/users/pranavbhat12/orgs",
            "repos_url": "https://api.github.com/users/pranavbhat12/repos",
            "events_url": "https://api.github.com/users/pranavbhat12/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pranavbhat12/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-12T13:35:02Z",
        "updated_at": "2023-12-12T16:23:34Z",
        "closed_at": "2023-12-12T15:30:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nHey,\r\n\r\nI am facing issue when implementing the sub question query engine.We have created separate elastic search indexes and hybrid retriever for each pdf docs.After this creating query engine tools and creating sub question query engine getting this error:\r\n\r\n_ValueError                                Traceback (most recent call last)\r\nFile <timed exec>:4\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/core/base_query_engine.py:30, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     28 if isinstance(str_or_query_bundle, str):\r\n     29     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 30 return self._query(str_or_query_bundle)\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/query_engine/sub_question_query_engine.py:132, in SubQuestionQueryEngine._query(self, query_bundle)\r\n    128 def _query(self, query_bundle: QueryBundle) -> RESPONSE_TYPE:\r\n    129     with self.callback_manager.event(\r\n    130         CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\r\n    131     ) as query_event:\r\n--> 132         sub_questions = self._question_gen.generate(self._metadatas, query_bundle)\r\n    134         colors = get_color_mapping([str(i) for i in range(len(sub_questions))])\r\n    136         if self._verbose:\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/question_gen/llm_generators.py:73, in LLMQuestionGenerator.generate(self, tools, query)\r\n     66 prediction = self._llm_predictor.predict(\r\n     67     prompt=self._prompt,\r\n     68     tools_str=tools_str,\r\n     69     query_str=query_str,\r\n     70 )\r\n     72 assert self._prompt.output_parser is not None\r\n---> 73 parse = self._prompt.output_parser.parse(prediction)\r\n     74 parse = cast(StructuredOutput, parse)\r\n     75 return parse.parsed_output\r\n\r\nFile ~/anaconda3/envs/python3/lib/python3.10/site-packages/llama_index/question_gen/output_parser.py:13, in SubQuestionOutputParser.parse(self, output)\r\n     11 json_dict = parse_json_markdown(output)\r\n     12 if not json_dict:\r\n---> 13     raise ValueError(f\"No valid JSON found in output: {output}\")\r\n     15 sub_questions = [SubQuestion.parse_obj(item) for item in json_dict]\r\n     16 return StructuredOutput(raw_output=output, parsed_output=sub_questions)\r\n\r\nValueError: No valid JSON found in output:_\r\n__\r\n\r\n\r\n**Code**:\r\ndef load_index_query_engine(llama_doc_list):\r\n     query_engine_list={}\r\n    for pdf_doc in doc_list:\r\n           index = load_index_from_storage(storage_context) \r\n            vector_retriever = index.as_retriever(\r\n            similarity_top_k=10,\r\n        )\r\n        nodes = service_context.node_parser.get_nodes_from_documents(llama_doc_list[pdf_doc])\r\n        bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=10)       \r\n        hybrid_retriever = HybridRetriever(vector_retriever, bm25_retriever)\r\n        reranker = CohereRerank(api_key=api_key,top_n=3)\r\n        query_engine = RetrieverQueryEngine.from_args(\r\n            retriever=hybrid_retriever,\r\n            node_postprocessors=[reranker],\r\n            service_context=service_context,\r\n        )     \r\n        query_engine_list[pdf_doc]=query_engine           \r\nreturn query_engine_list\r\n\r\nfor query_eng in query_engine_list:  \r\n\r\n    query_tool=QueryEngineTool(\r\n        query_engine=query_engine_list[query_eng],\r\n        metadata=ToolMetadata(\r\n            name=query_eng,\r\n            description=(\r\n                \"Description\",\r\n            ),\r\n        ),\r\n    )\r\n    query_engine_tools.append(query_tool)\r\n\r\nsub_que_query_engine = SubQuestionQueryEngine.from_defaults(\r\n    query_engine_tools=query_engine_tools,\r\n    service_context=service_context,\r\n    use_async=False,  \r\n)\r\n\r\nwith torch.no_grad() and torch.inference_mode():\r\n    response = sub_que_query_engine.query(\"question\")\r\n    print(response)\r\n\r\n\r\nHow can we resolve this?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9460/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9460/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9459",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9459/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9459/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9459/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9459",
        "id": 2037546208,
        "node_id": "I_kwDOIWuq5855cnzg",
        "number": 9459,
        "title": "[Feature Request]: Use search engine as query engine",
        "user": {
            "login": "SingL3",
            "id": 20473466,
            "node_id": "MDQ6VXNlcjIwNDczNDY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/20473466?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SingL3",
            "html_url": "https://github.com/SingL3",
            "followers_url": "https://api.github.com/users/SingL3/followers",
            "following_url": "https://api.github.com/users/SingL3/following{/other_user}",
            "gists_url": "https://api.github.com/users/SingL3/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SingL3/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SingL3/subscriptions",
            "organizations_url": "https://api.github.com/users/SingL3/orgs",
            "repos_url": "https://api.github.com/users/SingL3/repos",
            "events_url": "https://api.github.com/users/SingL3/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SingL3/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T11:24:10Z",
        "updated_at": "2023-12-12T11:26:23Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nUse search engine(google, bing, etc) as query engine.\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9459/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9459/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9458",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9458/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9458/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9458/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9458",
        "id": 2037498412,
        "node_id": "I_kwDOIWuq5855ccIs",
        "number": 9458,
        "title": "[Bug]: ValueError: \"HuggingFaceLLM\" object has no field \"_messages_to_prompt\"",
        "user": {
            "login": "joergwa",
            "id": 94534396,
            "node_id": "U_kgDOBaJ6_A",
            "avatar_url": "https://avatars.githubusercontent.com/u/94534396?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/joergwa",
            "html_url": "https://github.com/joergwa",
            "followers_url": "https://api.github.com/users/joergwa/followers",
            "following_url": "https://api.github.com/users/joergwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/joergwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/joergwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/joergwa/subscriptions",
            "organizations_url": "https://api.github.com/users/joergwa/orgs",
            "repos_url": "https://api.github.com/users/joergwa/repos",
            "events_url": "https://api.github.com/users/joergwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/joergwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-12T10:56:10Z",
        "updated_at": "2023-12-12T15:37:48Z",
        "closed_at": "2023-12-12T15:37:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nIn llama_index/llms/huggingface.py line 132 has been removed.\r\n```\r\n_messages_to_prompt: Callable = PrivateAttr() \r\n```\r\nLeading to:\r\n```\r\nValueError: \"HuggingFaceLLM\" object has no field \"_messages_to_prompt\"\r\n```\n\n### Version\n\nv0.9.14.post1\n\n### Steps to Reproduce\n\n```\r\nfrom llama_index.llms import HuggingFaceLLM\r\nllm = HuggingFaceLLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.1\", tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.1\", device_map=\"auto\")\r\n```\r\nResult:\r\n```\r\nLoading checkpoint shards: 100%\r\n2/2 [00:06<00:00, 2.90s/it]\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[5], line 2\r\n      1 from llama_index.llms import HuggingFaceLLM\r\n----> 2 llm = HuggingFaceLLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.1\", tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.1\", device_map=\"auto\")\r\n\r\nFile /usr/local/lib/python3.10/dist-packages/llama_index/llms/huggingface.py:226, in HuggingFaceLLM.__init__(self, context_window, max_new_tokens, query_wrapper_prompt, tokenizer_name, model_name, model, tokenizer, device_map, stopping_ids, tokenizer_kwargs, tokenizer_outputs_to_remove, model_kwargs, generate_kwargs, is_chat_model, callback_manager, system_prompt, messages_to_prompt, completion_to_prompt, pydantic_program_mode, output_parser)\r\n    223 if isinstance(query_wrapper_prompt, str):\r\n    224     query_wrapper_prompt = PromptTemplate(query_wrapper_prompt)\r\n--> 226 self._messages_to_prompt = (\r\n    227     messages_to_prompt or self._tokenizer_messages_to_prompt\r\n    228 )\r\n    230 super().__init__(\r\n    231     context_window=context_window,\r\n    232     max_new_tokens=max_new_tokens,\r\n   (...)\r\n    248     output_parser=output_parser,\r\n    249 )\r\n\r\nFile /usr/local/lib/python3.10/dist-packages/pydantic/main.py:357, in pydantic.main.BaseModel.__setattr__()\r\n\r\nValueError: \"HuggingFaceLLM\" object has no field \"_messages_to_prompt\"\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9458/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9458/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9457",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9457/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9457/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9457/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9457",
        "id": 2037497708,
        "node_id": "I_kwDOIWuq5855cb9s",
        "number": 9457,
        "title": "[Question]: run queries on multiple indices in parallel",
        "user": {
            "login": "r3shma",
            "id": 109542613,
            "node_id": "U_kgDOBod81Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/109542613?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/r3shma",
            "html_url": "https://github.com/r3shma",
            "followers_url": "https://api.github.com/users/r3shma/followers",
            "following_url": "https://api.github.com/users/r3shma/following{/other_user}",
            "gists_url": "https://api.github.com/users/r3shma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/r3shma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/r3shma/subscriptions",
            "organizations_url": "https://api.github.com/users/r3shma/orgs",
            "repos_url": "https://api.github.com/users/r3shma/repos",
            "events_url": "https://api.github.com/users/r3shma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/r3shma/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-12-12T10:55:46Z",
        "updated_at": "2023-12-13T06:45:27Z",
        "closed_at": "2023-12-12T21:04:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHello, I have multiple indices, each one containing an article. How can I execute the same query against all the indices simultaneously and collect the response for each article? \r\n\r\nPreviously, I tried storing all articles as separate nodes in an index and querying in accumulate mode. But I observed some weird behavior there where I felt the entire article was not getting sent in the context due to length issues (would appreciate if someone could throw more light on this - doesn't chucking happen within a node too?)\r\n\r\nTIA.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9457/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9457/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9456",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9456/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9456/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9456/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9456",
        "id": 2037349272,
        "node_id": "PR_kwDOIWuq585hxXqC",
        "number": 9456,
        "title": "Fixed some grammatical mistakes",
        "user": {
            "login": "ShorthillsAI",
            "id": 141953346,
            "node_id": "U_kgDOCHYJQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141953346?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ShorthillsAI",
            "html_url": "https://github.com/ShorthillsAI",
            "followers_url": "https://api.github.com/users/ShorthillsAI/followers",
            "following_url": "https://api.github.com/users/ShorthillsAI/following{/other_user}",
            "gists_url": "https://api.github.com/users/ShorthillsAI/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ShorthillsAI/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ShorthillsAI/subscriptions",
            "organizations_url": "https://api.github.com/users/ShorthillsAI/orgs",
            "repos_url": "https://api.github.com/users/ShorthillsAI/repos",
            "events_url": "https://api.github.com/users/ShorthillsAI/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ShorthillsAI/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T09:35:54Z",
        "updated_at": "2023-12-13T05:23:00Z",
        "closed_at": "2023-12-13T05:22:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9456",
            "html_url": "https://github.com/run-llama/llama_index/pull/9456",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9456.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9456.patch",
            "merged_at": "2023-12-13T05:22:59Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixed some grammatical issues in the documentation.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9456/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9456/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9455",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9455/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9455/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9455/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9455",
        "id": 2037285719,
        "node_id": "PR_kwDOIWuq585hxJ56",
        "number": 9455,
        "title": "Make ollama support additional_kwargs correctly",
        "user": {
            "login": "samx81",
            "id": 20315145,
            "node_id": "MDQ6VXNlcjIwMzE1MTQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/20315145?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/samx81",
            "html_url": "https://github.com/samx81",
            "followers_url": "https://api.github.com/users/samx81/followers",
            "following_url": "https://api.github.com/users/samx81/following{/other_user}",
            "gists_url": "https://api.github.com/users/samx81/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/samx81/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/samx81/subscriptions",
            "organizations_url": "https://api.github.com/users/samx81/orgs",
            "repos_url": "https://api.github.com/users/samx81/repos",
            "events_url": "https://api.github.com/users/samx81/events{/privacy}",
            "received_events_url": "https://api.github.com/users/samx81/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T08:59:10Z",
        "updated_at": "2023-12-13T05:24:49Z",
        "closed_at": "2023-12-13T05:24:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9455",
            "html_url": "https://github.com/run-llama/llama_index/pull/9455",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9455.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9455.patch",
            "merged_at": "2023-12-13T05:24:49Z"
        },
        "body": "# Description\r\n\r\nFix how the options passed to ollama api, so now options like `context_window`, `temperature` works correctly.\r\nthe full list of options is [right here](https://github.com/jmorganca/ollama/blob/main/docs/api.md#request-with-options)\r\n\r\nI didn't found the doc describing the way to pass options when calling `complete() / stream_complete()`, but according to the code it should be like this?\r\n`llm.stream_complete(message, temperature=temperature)`\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] Try to pass `num_ctx=10` and it triggered ollama to rebuild the model\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9455/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9455/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9453",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9453/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9453/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9453/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9453",
        "id": 2037223478,
        "node_id": "I_kwDOIWuq5855bZA2",
        "number": 9453,
        "title": "[Feature Request]: ",
        "user": {
            "login": "jzhao62",
            "id": 25937657,
            "node_id": "MDQ6VXNlcjI1OTM3NjU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/25937657?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jzhao62",
            "html_url": "https://github.com/jzhao62",
            "followers_url": "https://api.github.com/users/jzhao62/followers",
            "following_url": "https://api.github.com/users/jzhao62/following{/other_user}",
            "gists_url": "https://api.github.com/users/jzhao62/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jzhao62/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jzhao62/subscriptions",
            "organizations_url": "https://api.github.com/users/jzhao62/orgs",
            "repos_url": "https://api.github.com/users/jzhao62/repos",
            "events_url": "https://api.github.com/users/jzhao62/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jzhao62/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-12T08:21:22Z",
        "updated_at": "2023-12-12T15:22:34Z",
        "closed_at": "2023-12-12T15:22:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nSupport for GraphDatabase like Neo4J ?\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n- graph database is gaining popularity these days and turned out to be more suitable than nosql or sql in many complex situations.\r\n- graph database has an intrinsic relationship with LLM due to its network structure as opposed to tabular structure you see in sql or nosql",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9453/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9453/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9452",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9452/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9452/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9452/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9452",
        "id": 2037101326,
        "node_id": "PR_kwDOIWuq585hwihC",
        "number": 9452,
        "title": "Add a Gemini models for text and multi-modal.",
        "user": {
            "login": "markmcd",
            "id": 109308,
            "node_id": "MDQ6VXNlcjEwOTMwOA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/109308?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/markmcd",
            "html_url": "https://github.com/markmcd",
            "followers_url": "https://api.github.com/users/markmcd/followers",
            "following_url": "https://api.github.com/users/markmcd/following{/other_user}",
            "gists_url": "https://api.github.com/users/markmcd/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/markmcd/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/markmcd/subscriptions",
            "organizations_url": "https://api.github.com/users/markmcd/orgs",
            "repos_url": "https://api.github.com/users/markmcd/repos",
            "events_url": "https://api.github.com/users/markmcd/events{/privacy}",
            "received_events_url": "https://api.github.com/users/markmcd/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710958,
                "node_id": "LA_kwDOIWuq588AAAABc3-fLg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XXL",
                "name": "size:XXL",
                "color": "ffb8b8",
                "default": false,
                "description": "This PR changes 1000+ lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-12-12T06:51:07Z",
        "updated_at": "2023-12-13T14:35:43Z",
        "closed_at": "2023-12-13T14:35:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9452",
            "html_url": "https://github.com/run-llama/llama_index/pull/9452",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9452.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9452.patch",
            "merged_at": "2023-12-13T14:35:43Z"
        },
        "body": "# Description\r\n\r\nIncludes each of {text, mm} x {completion, chat} x {stream, one-shot} x {sync, async} for Gemini's Developer API.\r\n\r\nAnd two notebooks - regular text & multi-modal.\r\n\r\n*NOTE*: This will not work until Gemini-supported SDKs are published.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9452/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9452/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9451",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9451/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9451/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9451/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9451",
        "id": 2036994512,
        "node_id": "PR_kwDOIWuq585hwL2w",
        "number": 9451,
        "title": "add query transform guide",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710949,
                "node_id": "LA_kwDOIWuq588AAAABc3-fJQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XL",
                "name": "size:XL",
                "color": "ff823f",
                "default": false,
                "description": "This PR changes 500-999 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T05:09:26Z",
        "updated_at": "2023-12-12T07:03:43Z",
        "closed_at": "2023-12-12T07:03:42Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9451",
            "html_url": "https://github.com/run-llama/llama_index/pull/9451",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9451.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9451.patch",
            "merged_at": "2023-12-12T07:03:42Z"
        },
        "body": "cookbook on how to use our modules for different types of query transforms (sub-questions, routing, agentic tool picking, and more).",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9451/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9451/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9450",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9450/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9450/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9450/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9450",
        "id": 2036987290,
        "node_id": "I_kwDOIWuq5855afWa",
        "number": 9450,
        "title": "[Bug]: Logging level overrides",
        "user": {
            "login": "aaronbannin",
            "id": 6948336,
            "node_id": "MDQ6VXNlcjY5NDgzMzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6948336?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aaronbannin",
            "html_url": "https://github.com/aaronbannin",
            "followers_url": "https://api.github.com/users/aaronbannin/followers",
            "following_url": "https://api.github.com/users/aaronbannin/following{/other_user}",
            "gists_url": "https://api.github.com/users/aaronbannin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aaronbannin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aaronbannin/subscriptions",
            "organizations_url": "https://api.github.com/users/aaronbannin/orgs",
            "repos_url": "https://api.github.com/users/aaronbannin/repos",
            "events_url": "https://api.github.com/users/aaronbannin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aaronbannin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-12T05:01:06Z",
        "updated_at": "2023-12-12T16:12:10Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n## Overview\r\nLogging configs in files over ride developer configs, leading to unexpected behavior. Repro included below.\r\n\r\n\r\n## Possible Solutions\r\n1. Have only one `logger.setLevel()` invocations in package.\r\n2. Allow developer to configure log level with env var or singleton.\r\n```LLAMA_INDEX_LOG_LEVEL=DEBUG```\r\n```llama_index.logger.level = \"DEBUG\"```\r\n\r\nHappy to help out here if there is preferred implementation.\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nAs a developer, I want to see debug level log lines to understand how Llama Index is working. I implement the following lines from the [documentation](https://docs.llamaindex.ai/en/stable/understanding/tracing_and_debugging/tracing_and_debugging.html#basic-logging):\r\n\r\n```python\r\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n```\r\n\r\nI expect to see the [this log line](https://github.com/run-llama/llama_index/blob/771219236021c9cf906c598bb6f750539c791e65/llama_index/agent/openai_agent.py#L366) in the console, but it does not appear.\r\n\r\nIf I remove the [logging config in the file](https://github.com/run-llama/llama_index/blob/771219236021c9cf906c598bb6f750539c791e65/llama_index/agent/openai_agent.py#L30), the debug configuration works as expected.\n\n### Relevant Logs/Tracbacks\n\n```shell\nLogging excerpt AFTER removing the logging config override:\r\n\r\nDEBUG:httpcore.http11:response_closed.complete\r\nresponse_closed.complete\r\nDEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\r\nHTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\r\nDEBUG:llama_index.agent.openai_agent:Break: should continue False\r\nBreak: should continue False\r\n```\r\n\r\nThe last 2 lines do not appear in released library.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9450/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9450/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9449",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9449/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9449/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9449/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9449",
        "id": 2036866205,
        "node_id": "PR_kwDOIWuq585hvwRa",
        "number": 9449,
        "title": "Revert \"fix: validate api key (#9447)\"",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T02:38:33Z",
        "updated_at": "2023-12-12T02:40:29Z",
        "closed_at": "2023-12-12T02:40:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9449",
            "html_url": "https://github.com/run-llama/llama_index/pull/9449",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9449.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9449.patch",
            "merged_at": "2023-12-12T02:40:28Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9449/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9449/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9448",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9448/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9448/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9448/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9448",
        "id": 2036856533,
        "node_id": "I_kwDOIWuq5855Z_bV",
        "number": 9448,
        "title": "[Bug]: SubQuestionQueryEngine raises an error at line: query_engine = self._query_engines[sub_q.tool_name] KeyError:",
        "user": {
            "login": "wuzhongmiao",
            "id": 60603266,
            "node_id": "MDQ6VXNlcjYwNjAzMjY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/60603266?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wuzhongmiao",
            "html_url": "https://github.com/wuzhongmiao",
            "followers_url": "https://api.github.com/users/wuzhongmiao/followers",
            "following_url": "https://api.github.com/users/wuzhongmiao/following{/other_user}",
            "gists_url": "https://api.github.com/users/wuzhongmiao/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wuzhongmiao/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wuzhongmiao/subscriptions",
            "organizations_url": "https://api.github.com/users/wuzhongmiao/orgs",
            "repos_url": "https://api.github.com/users/wuzhongmiao/repos",
            "events_url": "https://api.github.com/users/wuzhongmiao/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wuzhongmiao/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-12T02:27:06Z",
        "updated_at": "2023-12-12T15:28:42Z",
        "closed_at": "2023-12-12T15:27:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nhi!\r\nAs always thanks to your amazing tools, I've been playing with SubQuestionQueryEngine, but the following problem occurred\uff1a\r\n\r\n```python\r\nFile \"D:\\tools\\Anaconda\\install\\envs\\paddle_cpu\\lib\\site-packages\\llama_index\\query_engine\\sub_question_query_engine.py\", line 221, in _aquery_subq\r\n    query_engine = self._query_engines[sub_q.tool_name]\r\nKeyError: '\u4fe1\u7528\u89c2\u70b91'\r\n```\r\nMy code when I am using this is basically copy paste from tutorial:\r\n\r\n```python\r\n# define query engines and tools\r\nxy_engine = get_query_engine(xy_index)\r\nhg_engine = get_query_engine(hg_index)\r\n\r\nquery_engine_tools = [\r\n    QueryEngineTool(\r\n        query_engine=xy_engine,\r\n        metadata=ToolMetadata(\r\n            name=\"\u4fe1\u7528\u503a\u89c2\u70b91\",\r\n            description=\"\u63d0\u4f9b\u4e86\u4fe1\u7528\u503a\u89c2\u70b9\u548c\u7ecf\u6d4e\u89c2\u70b9\",\r\n        ),\r\n    ),\r\n    QueryEngineTool(\r\n        query_engine=hg_engine,\r\n        metadata=ToolMetadata(\r\n            name=\"\u5b8f\u89c2\u7ecf\u6d4e\u89c2\u70b91\",\r\n            description=\"\u63d0\u4f9b\u4e86\u5b8f\u89c2\u7ecf\u6d4e\u89c2\u70b9\",\r\n        ),\r\n    )\r\n]\r\nquery_engine = SubQuestionQueryEngine.from_defaults(\r\n    query_engine_tools=query_engine_tools\r\n)\r\n```\r\nI intercepted the debug message:\r\ncode\uff1aquery_engine = self._query_engines[sub_q.tool_name]\r\n![bug1](https://github.com/run-llama/llama_index/assets/60603266/7475c619-aa83-4c9d-9a3b-3deef60f55b9)\r\n![bug2](https://github.com/run-llama/llama_index/assets/60603266/cdff0c70-9fea-473f-9338-b3a179261e9f)\r\n\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nIt seems that this does not support Chinese, and one of the words is missing. I have tried several times in both Chinese and English, but there is no problem, is that right?\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9448/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9448/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9447",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9447/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9447/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9447/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9447",
        "id": 2036819905,
        "node_id": "PR_kwDOIWuq585hvmiJ",
        "number": 9447,
        "title": "fix: validate api key",
        "user": {
            "login": "himself65",
            "id": 14026360,
            "node_id": "MDQ6VXNlcjE0MDI2MzYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/14026360?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/himself65",
            "html_url": "https://github.com/himself65",
            "followers_url": "https://api.github.com/users/himself65/followers",
            "following_url": "https://api.github.com/users/himself65/following{/other_user}",
            "gists_url": "https://api.github.com/users/himself65/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/himself65/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/himself65/subscriptions",
            "organizations_url": "https://api.github.com/users/himself65/orgs",
            "repos_url": "https://api.github.com/users/himself65/repos",
            "events_url": "https://api.github.com/users/himself65/events{/privacy}",
            "received_events_url": "https://api.github.com/users/himself65/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T01:38:31Z",
        "updated_at": "2023-12-12T02:36:17Z",
        "closed_at": "2023-12-12T02:35:47Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9447",
            "html_url": "https://github.com/run-llama/llama_index/pull/9447",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9447.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9447.patch",
            "merged_at": "2023-12-12T02:35:47Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9447/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9447/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9446",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9446/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9446/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9446/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9446",
        "id": 2036812700,
        "node_id": "PR_kwDOIWuq585hvk_s",
        "number": 9446,
        "title": "[version] bump version to 0.9.14.post1",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-12T01:29:12Z",
        "updated_at": "2023-12-12T01:34:04Z",
        "closed_at": "2023-12-12T01:34:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9446",
            "html_url": "https://github.com/run-llama/llama_index/pull/9446",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9446.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9446.patch",
            "merged_at": "2023-12-12T01:34:03Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9446/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9446/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9445",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9445/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9445/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9445/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9445",
        "id": 2036799100,
        "node_id": "PR_kwDOIWuq585hviDI",
        "number": 9445,
        "title": "Remove MistralAI Apikey",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-12T01:13:45Z",
        "updated_at": "2023-12-12T01:20:06Z",
        "closed_at": "2023-12-12T01:20:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9445",
            "html_url": "https://github.com/run-llama/llama_index/pull/9445",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9445.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9445.patch",
            "merged_at": "2023-12-12T01:20:06Z"
        },
        "body": "# Description\r\n\r\nPR to remove MistralAI api key.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9445/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9445/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9444",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9444/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9444/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9444/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9444",
        "id": 2036703741,
        "node_id": "PR_kwDOIWuq585hvNNC",
        "number": 9444,
        "title": "Add MistralAI LLM Endpoint.",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710949,
                "node_id": "LA_kwDOIWuq588AAAABc3-fJQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XL",
                "name": "size:XL",
                "color": "ff823f",
                "default": false,
                "description": "This PR changes 500-999 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T23:24:38Z",
        "updated_at": "2023-12-12T01:09:31Z",
        "closed_at": "2023-12-12T01:09:31Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9444",
            "html_url": "https://github.com/run-llama/llama_index/pull/9444",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9444.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9444.patch",
            "merged_at": "2023-12-12T01:09:31Z"
        },
        "body": "# Description\r\n\r\nPR to add MistralAI LLM endpoint.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9444/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9444/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9443",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9443/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9443/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9443/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9443",
        "id": 2036670497,
        "node_id": "I_kwDOIWuq5855ZSAh",
        "number": 9443,
        "title": "[Bug]: LlamaIndex incompatibility as of 0.9.14",
        "user": {
            "login": "anticorrelator",
            "id": 1688064,
            "node_id": "MDQ6VXNlcjE2ODgwNjQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1688064?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anticorrelator",
            "html_url": "https://github.com/anticorrelator",
            "followers_url": "https://api.github.com/users/anticorrelator/followers",
            "following_url": "https://api.github.com/users/anticorrelator/following{/other_user}",
            "gists_url": "https://api.github.com/users/anticorrelator/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anticorrelator/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anticorrelator/subscriptions",
            "organizations_url": "https://api.github.com/users/anticorrelator/orgs",
            "repos_url": "https://api.github.com/users/anticorrelator/repos",
            "events_url": "https://api.github.com/users/anticorrelator/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anticorrelator/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-11T22:52:33Z",
        "updated_at": "2023-12-11T23:21:47Z",
        "closed_at": "2023-12-11T22:53:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Sorry I opened an issue in the wrong repo :(",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9443/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9443/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9442",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9442/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9442/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9442/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9442",
        "id": 2036611412,
        "node_id": "PR_kwDOIWuq585hu4uR",
        "number": 9442,
        "title": "[version] bump version to 0.9.14",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-11T22:05:06Z",
        "updated_at": "2023-12-11T22:37:22Z",
        "closed_at": "2023-12-11T22:37:21Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9442",
            "html_url": "https://github.com/run-llama/llama_index/pull/9442",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9442.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9442.patch",
            "merged_at": "2023-12-11T22:37:21Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9442/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9442/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9441",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9441/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9441/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9441/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9441",
        "id": 2036494256,
        "node_id": "PR_kwDOIWuq585hueq_",
        "number": 9441,
        "title": "Add MistralAI Embeddings",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T20:43:44Z",
        "updated_at": "2023-12-11T21:15:03Z",
        "closed_at": "2023-12-11T21:15:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9441",
            "html_url": "https://github.com/run-llama/llama_index/pull/9441",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9441.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9441.patch",
            "merged_at": "2023-12-11T21:15:03Z"
        },
        "body": "# Description\r\n\r\nPR to add Mistral AI Embeddings.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9441/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9441/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9440",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9440/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9440/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9440/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9440",
        "id": 2036458539,
        "node_id": "PR_kwDOIWuq585huWzE",
        "number": 9440,
        "title": "Introduce Google Generative Language Semantic Retriever",
        "user": {
            "login": "pikalaw",
            "id": 144591,
            "node_id": "MDQ6VXNlcjE0NDU5MQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/144591?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pikalaw",
            "html_url": "https://github.com/pikalaw",
            "followers_url": "https://api.github.com/users/pikalaw/followers",
            "following_url": "https://api.github.com/users/pikalaw/following{/other_user}",
            "gists_url": "https://api.github.com/users/pikalaw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pikalaw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pikalaw/subscriptions",
            "organizations_url": "https://api.github.com/users/pikalaw/orgs",
            "repos_url": "https://api.github.com/users/pikalaw/repos",
            "events_url": "https://api.github.com/users/pikalaw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pikalaw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710958,
                "node_id": "LA_kwDOIWuq588AAAABc3-fLg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XXL",
                "name": "size:XXL",
                "color": "ffb8b8",
                "default": false,
                "description": "This PR changes 1000+ lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T20:18:28Z",
        "updated_at": "2023-12-13T14:32:14Z",
        "closed_at": "2023-12-13T14:32:14Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9440",
            "html_url": "https://github.com/run-llama/llama_index/pull/9440",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9440.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9440.patch",
            "merged_at": "2023-12-13T14:32:14Z"
        },
        "body": "# Description\r\n\r\nIntroducing two new features from Google's Generative Language API.\r\n\r\n1. Bundled embeddings calculation and vector storage for enabling semantic retrieval.\r\n2. State-of-the-art fine-tuned model for answering questions grounded in passages.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] Added new unit/integration tests\r\n- [X] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] I have added Google Colab support for the newly added notebooks.\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n- [X] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9440/reactions",
            "total_count": 3,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 3,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9440/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9439",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9439/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9439/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9439/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9439",
        "id": 2036409288,
        "node_id": "I_kwDOIWuq5855YSPI",
        "number": 9439,
        "title": "[Bug]: Metadata filter not working with Elastic search indexing ",
        "user": {
            "login": "amitguptadumka",
            "id": 39477047,
            "node_id": "MDQ6VXNlcjM5NDc3MDQ3",
            "avatar_url": "https://avatars.githubusercontent.com/u/39477047?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/amitguptadumka",
            "html_url": "https://github.com/amitguptadumka",
            "followers_url": "https://api.github.com/users/amitguptadumka/followers",
            "following_url": "https://api.github.com/users/amitguptadumka/following{/other_user}",
            "gists_url": "https://api.github.com/users/amitguptadumka/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/amitguptadumka/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/amitguptadumka/subscriptions",
            "organizations_url": "https://api.github.com/users/amitguptadumka/orgs",
            "repos_url": "https://api.github.com/users/amitguptadumka/repos",
            "events_url": "https://api.github.com/users/amitguptadumka/events{/privacy}",
            "received_events_url": "https://api.github.com/users/amitguptadumka/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-11T19:46:13Z",
        "updated_at": "2023-12-12T04:01:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhile retrieving from ES with multiple metadatafilter condition(OR/AND) its not taking it into account. It always performs an AND operation even if its explicitly mentioned OR.\r\nExample below code should filter and retrieve only 'mafia' or \"Stephen King\" bit its not doing as expected.\r\n\r\nfilters = MetadataFilters(\r\n    filters=[\r\n        MetadataFilter(key=\"theme\", value=\"Mafia\"),\r\n        MetadataFilter(key=\"author\", value=\"Stephen King\"),\r\n    ],\r\n    condition=FilterCondition.OR,\r\n)\r\n\r\nretriever = index.as_retriever(filters=filters)\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nnodes = [\r\nTextNode(\r\ntext=\"The Shawshank Redemption\",\r\nmetadata={\r\n\"author\": \"Stephen King\",\r\n\"theme\": \"Friendship\",\r\n},\r\n),\r\nTextNode(\r\ntext=\"The Godfather\",\r\nmetadata={\r\n\"director\": \"Francis Ford Coppola\",\r\n\"theme\": \"Mafia\",\r\n},\r\n),\r\nTextNode(\r\ntext=\"Inception\",\r\nmetadata={\r\n\"director\": \"Christopher Nolan\",\r\n},\r\n),\r\n]\r\n\r\nfilters = MetadataFilters(\r\n    filters=[\r\n        MetadataFilter(key=\"theme\", value=\"Mafia\"),\r\n        MetadataFilter(key=\"author\", value=\"Stephen King\"),\r\n    ],\r\n    condition=FilterCondition.OR,\r\n)\r\n\r\nretriever = index.as_retriever(filters=filters)\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9439/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9439/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9438",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9438/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9438/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9438/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9438",
        "id": 2036403663,
        "node_id": "PR_kwDOIWuq585huKv8",
        "number": 9438,
        "title": "code fix azurecosmosmongo.py",
        "user": {
            "login": "pcisterna",
            "id": 12159553,
            "node_id": "MDQ6VXNlcjEyMTU5NTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/12159553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pcisterna",
            "html_url": "https://github.com/pcisterna",
            "followers_url": "https://api.github.com/users/pcisterna/followers",
            "following_url": "https://api.github.com/users/pcisterna/following{/other_user}",
            "gists_url": "https://api.github.com/users/pcisterna/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pcisterna/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pcisterna/subscriptions",
            "organizations_url": "https://api.github.com/users/pcisterna/orgs",
            "repos_url": "https://api.github.com/users/pcisterna/repos",
            "events_url": "https://api.github.com/users/pcisterna/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pcisterna/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T19:42:23Z",
        "updated_at": "2023-12-11T19:51:44Z",
        "closed_at": "2023-12-11T19:51:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9438",
            "html_url": "https://github.com/run-llama/llama_index/pull/9438",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9438.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9438.patch",
            "merged_at": "2023-12-11T19:51:44Z"
        },
        "body": "# Description\r\n\r\nI removed multiplication by 10 since more nodes are obtained than required\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9438/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9438/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9437",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9437/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9437/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9437/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9437",
        "id": 2036395016,
        "node_id": "I_kwDOIWuq5855YOwI",
        "number": 9437,
        "title": "[Bug]: AzureCosmosMongo gets more nodes than expected",
        "user": {
            "login": "pcisterna",
            "id": 12159553,
            "node_id": "MDQ6VXNlcjEyMTU5NTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/12159553?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pcisterna",
            "html_url": "https://github.com/pcisterna",
            "followers_url": "https://api.github.com/users/pcisterna/followers",
            "following_url": "https://api.github.com/users/pcisterna/following{/other_user}",
            "gists_url": "https://api.github.com/users/pcisterna/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pcisterna/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pcisterna/subscriptions",
            "organizations_url": "https://api.github.com/users/pcisterna/orgs",
            "repos_url": "https://api.github.com/users/pcisterna/repos",
            "events_url": "https://api.github.com/users/pcisterna/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pcisterna/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-11T19:37:00Z",
        "updated_at": "2023-12-11T23:18:02Z",
        "closed_at": "2023-12-11T23:18:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nthe similarity_top_k is being multiplied by 10, exceeding the token limit.\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nadd breakpoint to chat_engine/context.py line 239 and you can see all nodes in the currents vars.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9437/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9437/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9435",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9435/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9435/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9435/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9435",
        "id": 2035754356,
        "node_id": "I_kwDOIWuq5855VyV0",
        "number": 9435,
        "title": "[Bug]: [nltk_data] Error loading punkt: <urlopen error [WinError 10060] A",
        "user": {
            "login": "umang299",
            "id": 64629040,
            "node_id": "MDQ6VXNlcjY0NjI5MDQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/64629040?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/umang299",
            "html_url": "https://github.com/umang299",
            "followers_url": "https://api.github.com/users/umang299/followers",
            "following_url": "https://api.github.com/users/umang299/following{/other_user}",
            "gists_url": "https://api.github.com/users/umang299/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/umang299/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/umang299/subscriptions",
            "organizations_url": "https://api.github.com/users/umang299/orgs",
            "repos_url": "https://api.github.com/users/umang299/repos",
            "events_url": "https://api.github.com/users/umang299/events{/privacy}",
            "received_events_url": "https://api.github.com/users/umang299/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T14:03:19Z",
        "updated_at": "2023-12-11T14:12:36Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am using a vector Index which connects to a chromaDB client as my database. I have initialized the index as a chat engine. When the query the chat engine, two things happen:\r\n\r\n1. The response time is nearly 2-3mins.\r\n2. It throws the below warning\r\n\r\n```\r\n[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\r\n[nltk_data]     connection attempt failed because the connected party\r\n[nltk_data]     did not properly respond after a period of time, or\r\n[nltk_data]     established connection failed because connected host\r\n[nltk_data]     has failed to respond>\r\n```\r\n \n\n### Version\n\n0.9.8.post1\n\n### Steps to Reproduce\n\nClone, setup and run the below repository: (Follow readme for instructions)\r\nhttps://github.com/umang299/document-gpt\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9435/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9435/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9434",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9434/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9434/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9434/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9434",
        "id": 2035727204,
        "node_id": "I_kwDOIWuq5855Vrtk",
        "number": 9434,
        "title": "[Question]: How to access responses array in \"accumulate\" response mode?",
        "user": {
            "login": "r3shma",
            "id": 109542613,
            "node_id": "U_kgDOBod81Q",
            "avatar_url": "https://avatars.githubusercontent.com/u/109542613?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/r3shma",
            "html_url": "https://github.com/r3shma",
            "followers_url": "https://api.github.com/users/r3shma/followers",
            "following_url": "https://api.github.com/users/r3shma/following{/other_user}",
            "gists_url": "https://api.github.com/users/r3shma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/r3shma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/r3shma/subscriptions",
            "organizations_url": "https://api.github.com/users/r3shma/orgs",
            "repos_url": "https://api.github.com/users/r3shma/repos",
            "events_url": "https://api.github.com/users/r3shma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/r3shma/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-11T13:51:04Z",
        "updated_at": "2023-12-11T19:14:55Z",
        "closed_at": "2023-12-11T15:01:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI am running a query on a set of source nodes in accumulate response mode and I get a string response that looks like:\r\n![image](https://github.com/run-llama/llama_index/assets/109542613/e453f5b8-84a7-4667-9844-836d756079c9)\r\nIs there any way to access this response in the form of an array? I have a use case where I need to map each response to it's source node id and save the mapping. \r\n\r\nAlso, is it possible to run queries in parallel on the document nodes instead of having to query each node sequentially?\r\nTIA.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9434/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9434/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9433",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9433/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9433/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9433/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9433",
        "id": 2035557387,
        "node_id": "PR_kwDOIWuq585hrQAk",
        "number": 9433,
        "title": "AstraDB: handle MetadataFilters and not only ExactMatchFilter",
        "user": {
            "login": "eolivelli",
            "id": 9469110,
            "node_id": "MDQ6VXNlcjk0NjkxMTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9469110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eolivelli",
            "html_url": "https://github.com/eolivelli",
            "followers_url": "https://api.github.com/users/eolivelli/followers",
            "following_url": "https://api.github.com/users/eolivelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/eolivelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eolivelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eolivelli/subscriptions",
            "organizations_url": "https://api.github.com/users/eolivelli/orgs",
            "repos_url": "https://api.github.com/users/eolivelli/repos",
            "events_url": "https://api.github.com/users/eolivelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eolivelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T12:20:58Z",
        "updated_at": "2023-12-11T16:53:33Z",
        "closed_at": "2023-12-11T16:53:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9433",
            "html_url": "https://github.com/run-llama/llama_index/pull/9433",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9433.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9433.patch",
            "merged_at": "2023-12-11T16:53:27Z"
        },
        "body": "# Description\r\n\r\nAstraDB Vector store didn't handle generic MetadataFilters, only ExactMatchFilter. \r\nThis patch adds support for ExactMatchFilter with the EQ operator\r\n\r\nFixes #9432\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9433/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9433/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9432",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9432/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9432/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9432/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9432",
        "id": 2035422782,
        "node_id": "I_kwDOIWuq5855UhY-",
        "number": 9432,
        "title": "[Bug]: Problem with MetadataFilter and AstraDBVectorStore",
        "user": {
            "login": "eolivelli",
            "id": 9469110,
            "node_id": "MDQ6VXNlcjk0NjkxMTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9469110?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eolivelli",
            "html_url": "https://github.com/eolivelli",
            "followers_url": "https://api.github.com/users/eolivelli/followers",
            "following_url": "https://api.github.com/users/eolivelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/eolivelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eolivelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eolivelli/subscriptions",
            "organizations_url": "https://api.github.com/users/eolivelli/orgs",
            "repos_url": "https://api.github.com/users/eolivelli/repos",
            "events_url": "https://api.github.com/users/eolivelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eolivelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T11:08:25Z",
        "updated_at": "2023-12-11T16:53:28Z",
        "closed_at": "2023-12-11T16:53:28Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI have this code using LlamaIndex and AstraDB Vector Store\r\n\r\n```\r\n   astra_db_store = AstraDBVectorStore(\r\n        token=token,\r\n        api_endpoint=api_endpoint,\r\n        collection_name=collection,\r\n        embedding_dimension=1536\r\n    )\r\n    embed_model = .....\r\n    llm = ....\r\n    service_context = ....\r\n    index = VectorStoreIndex.from_vector_store(\r\n        vector_store=astra_db_store, service_context=service_context\r\n    )\r\n\r\n   \r\n   filters = MetadataFilters(filters=[MetadataFilter(key=\"source\", value=\"llama-index-ingest\")])\r\n   retriever = index.as_retriever(filters=filters)\r\n```\r\n \r\nI see this error:\r\n```\r\n  @staticmethod\r\n    def _query_filters_to_dict(query_filters: MetadataFilters) -> Dict[str, Any]:\r\n        if any(not isinstance(f, ExactMatchFilter) for f in query_filters.filters):\r\n>           raise NotImplementedError(\"Only `ExactMatchFilter` filters are supported\")\r\nE           NotImplementedError: Only `ExactMatchFilter` filters are supported\r\n\r\n../../../../../Library/Caches/pypoetry/virtualenvs/ragstack-ai-1_8bFyNQ-py3.11/lib/python3.11/site-packages/llama_index/vector_stores/astra.py:166: NotImplementedError\r\n2023-12-11 12:04:47,472 [INFO] Test report line: test_astra.py::test_ingest_langchain_retrieve_llama_index -> \u274c <ExceptionInfo NotImplementedError('Only `ExactMatchFilter` filters are supported') tblen=22>   \r\n```\r\n   \r\nEven if I change my code to using ExactMatchFilter\r\n\r\n```\r\n  filters = MetadataFilters(filters=[ExactMatchFilter(key=\"source\", value=\"llama-index-ingest\")])\r\n  retriever = index.as_retriever(filters=filters)\r\n```\r\n\r\nThe error is the same.\r\nWith the debugger I see that magically the MetadataFilters object contains a MetadataFilter filter object with the EQ operator.\n\n### Version\n\n0.9.11\n\n### Steps to Reproduce\n\nSee the description above\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9432/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9432/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9431",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9431/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9431/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9431/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9431",
        "id": 2035317027,
        "node_id": "PR_kwDOIWuq585hqamw",
        "number": 9431,
        "title": "Dev awiss",
        "user": {
            "login": "Martindkchr",
            "id": 6279917,
            "node_id": "MDQ6VXNlcjYyNzk5MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6279917?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Martindkchr",
            "html_url": "https://github.com/Martindkchr",
            "followers_url": "https://api.github.com/users/Martindkchr/followers",
            "following_url": "https://api.github.com/users/Martindkchr/following{/other_user}",
            "gists_url": "https://api.github.com/users/Martindkchr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Martindkchr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Martindkchr/subscriptions",
            "organizations_url": "https://api.github.com/users/Martindkchr/orgs",
            "repos_url": "https://api.github.com/users/Martindkchr/repos",
            "events_url": "https://api.github.com/users/Martindkchr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Martindkchr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-11T10:17:52Z",
        "updated_at": "2023-12-13T14:04:17Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9431",
            "html_url": "https://github.com/run-llama/llama_index/pull/9431",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9431.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9431.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nTry to use clickhouse as vectorDB.\r\nTry to chunk docs with independent parser service.\r\nSpecial designed schema and tricks for better query and retriever. \r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9431/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9431/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9430",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9430/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9430/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9430/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9430",
        "id": 2035143938,
        "node_id": "PR_kwDOIWuq585hp0gK",
        "number": 9430,
        "title": "Issue 8605",
        "user": {
            "login": "chnsagitchen",
            "id": 34412583,
            "node_id": "MDQ6VXNlcjM0NDEyNTgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/34412583?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chnsagitchen",
            "html_url": "https://github.com/chnsagitchen",
            "followers_url": "https://api.github.com/users/chnsagitchen/followers",
            "following_url": "https://api.github.com/users/chnsagitchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/chnsagitchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chnsagitchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chnsagitchen/subscriptions",
            "organizations_url": "https://api.github.com/users/chnsagitchen/orgs",
            "repos_url": "https://api.github.com/users/chnsagitchen/repos",
            "events_url": "https://api.github.com/users/chnsagitchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chnsagitchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T08:53:24Z",
        "updated_at": "2023-12-11T16:55:34Z",
        "closed_at": "2023-12-11T16:55:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9430",
            "html_url": "https://github.com/run-llama/llama_index/pull/9430",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9430.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9430.patch",
            "merged_at": "2023-12-11T16:55:33Z"
        },
        "body": "# Description\r\n\r\nAdd the feature of hybrid query for open search\r\n\r\nFixes #8605 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n- [ ] I tested it with my local open search cluster and updated the  jupyter notebook\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9430/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9430/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]