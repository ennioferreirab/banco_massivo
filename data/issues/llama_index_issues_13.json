[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8092",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8092/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8092/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8092/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8092",
        "id": 1940056453,
        "node_id": "I_kwDOIWuq585zoumF",
        "number": 8092,
        "title": "[Question]: max_token auto adjust for completion requests but not chat requests",
        "user": {
            "login": "chamilton61",
            "id": 4068813,
            "node_id": "MDQ6VXNlcjQwNjg4MTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4068813?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chamilton61",
            "html_url": "https://github.com/chamilton61",
            "followers_url": "https://api.github.com/users/chamilton61/followers",
            "following_url": "https://api.github.com/users/chamilton61/following{/other_user}",
            "gists_url": "https://api.github.com/users/chamilton61/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chamilton61/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chamilton61/subscriptions",
            "organizations_url": "https://api.github.com/users/chamilton61/orgs",
            "repos_url": "https://api.github.com/users/chamilton61/repos",
            "events_url": "https://api.github.com/users/chamilton61/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chamilton61/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-12T13:53:20Z",
        "updated_at": "2023-10-24T06:32:06Z",
        "closed_at": "2023-10-24T06:32:06Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI recently ran into an issue where our gpt 3 turbo requests were producing too many tokens which would put us over the limit causing an error. After looking into solutions i noticed that completions [automatically adjust the max token limit](https://github.com/run-llama/llama_index/blob/06127ec09966e8df2fcd4f03a1b53ec566b4a43d/llama_index/llms/openai.py#L271) for the request while chat requests [don't](https://github.com/run-llama/llama_index/blob/06127ec09966e8df2fcd4f03a1b53ec566b4a43d/llama_index/llms/openai.py#L189). \r\n\r\nI was curious if i was missing some alternative way of handling this case or if there was a specific reason why the functionality existed for one version but not the other.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8092/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8092/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8091",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8091/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8091/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8091/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8091",
        "id": 1939973030,
        "node_id": "I_kwDOIWuq585zoaOm",
        "number": 8091,
        "title": "[Bug]: Langchain parser breaks with llama 70b",
        "user": {
            "login": "smyja",
            "id": 20070770,
            "node_id": "MDQ6VXNlcjIwMDcwNzcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/20070770?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/smyja",
            "html_url": "https://github.com/smyja",
            "followers_url": "https://api.github.com/users/smyja/followers",
            "following_url": "https://api.github.com/users/smyja/following{/other_user}",
            "gists_url": "https://api.github.com/users/smyja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/smyja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/smyja/subscriptions",
            "organizations_url": "https://api.github.com/users/smyja/orgs",
            "repos_url": "https://api.github.com/users/smyja/repos",
            "events_url": "https://api.github.com/users/smyja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/smyja/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-12T13:11:24Z",
        "updated_at": "2023-10-12T17:02:27Z",
        "closed_at": "2023-10-12T17:02:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nTried to use llama 70b from anyscale with this [langchain parser](https://docs.llamaindex.ai/en/stable/examples/output_parsing/LangchainOutputParserDemo.html) and got this error.\r\n\r\n\r\n```\r\n******\r\nCould not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\nTraceback (most recent call last):\r\n  File \"/Users/mac/Documents/GitHub/datagpt/pluralsh/dev/lib/python3.8/site-packages/llama_index/llms/llama_cpp.py\", line 88, in __init__\r\n    from llama_cpp import Llama\r\nModuleNotFoundError: No module named 'llama_cpp'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"llamas.py\", line 32, in <module>\r\n    llm_predictor = StructuredLLMPredictor()\r\n  File \"/Users/mac/Documents/GitHub/datagpt/pluralsh/dev/lib/python3.8/site-packages/llama_index/llm_predictor/base.py\", line 88, in __init__\r\n    self._llm = resolve_llm(llm)\r\n  File \"/Users/mac/Documents/GitHub/datagpt/pluralsh/dev/lib/python3.8/site-packages/llama_index/llms/utils.py\", line 40, in resolve_llm\r\n    llm = LlamaCPP(\r\n  File \"/Users/mac/Documents/GitHub/datagpt/pluralsh/dev/lib/python3.8/site-packages/llama_index/llms/llama_cpp.py\", line 90, in __init__\r\n    raise ImportError(\r\nImportError: Could not import llama_cpp library.Please install llama_cpp with `pip install llama-cpp-python`.See the full installation guide for GPU support at `https://github.com/abetlen/llama-cpp-python`\r\n```\n\n### Version\n\n0.8.43\n\n### Steps to Reproduce\n\nfollow the [guide ](https://docs.llamaindex.ai/en/stable/examples/output_parsing/LangchainOutputParserDemo.html) then setup a custom llm, specifically anyscale.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8091/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8091/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8090",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8090/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8090/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8090/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8090",
        "id": 1939916322,
        "node_id": "I_kwDOIWuq585zoMYi",
        "number": 8090,
        "title": "[Bug]: Cannot serialize VectorStoreIndex object",
        "user": {
            "login": "BrianP8701",
            "id": 108380487,
            "node_id": "U_kgDOBnXBRw",
            "avatar_url": "https://avatars.githubusercontent.com/u/108380487?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/BrianP8701",
            "html_url": "https://github.com/BrianP8701",
            "followers_url": "https://api.github.com/users/BrianP8701/followers",
            "following_url": "https://api.github.com/users/BrianP8701/following{/other_user}",
            "gists_url": "https://api.github.com/users/BrianP8701/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/BrianP8701/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/BrianP8701/subscriptions",
            "organizations_url": "https://api.github.com/users/BrianP8701/orgs",
            "repos_url": "https://api.github.com/users/BrianP8701/repos",
            "events_url": "https://api.github.com/users/BrianP8701/events{/privacy}",
            "received_events_url": "https://api.github.com/users/BrianP8701/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-12T12:42:04Z",
        "updated_at": "2023-10-12T16:36:05Z",
        "closed_at": "2023-10-12T16:36:05Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI want to save the VectorStoreIndex to GCS so i don't need to reindex everytime, but I cant serialize the VectorStoreIndex object\n\n### Version\n\n0.8.43\n\n### Steps to Reproduce\n\nfrom llama_index import VectorStoreIndex\r\nfrom llama_index import SimpleDirectoryReader\r\nimport time\r\n\r\nstart_time = time.time()\r\nindex=VectorStoreIndex([])\r\n\r\ndocuments = SimpleDirectoryReader('test_library', recursive=True).load_data()\r\nfor doc in documents:\r\n    index.insert(doc)\r\nretriever = index.as_retriever()\r\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\r\nprint(dir(index))\r\n\r\n# Assuming you have a VectorStoreIndex object named index\r\nindex = VectorStoreIndex.from_vector_store(index)\r\n\r\n# Persist the index\r\nindex.persist('saved_index.json')\r\n\r\n\r\n\r\nInside of test_library is just a small pdf\n\n### Relevant Logs/Tracbacks\n\n```shell\n(venv) (base) brianprzezdziecki@Brians-MacBook-Pro-6 OI_Memory % /Users/brianprzezdziecki/Code/OI_Memory/venv/bin/python /Users/brianprzezdziecki/Code/OI_Mem\r\nory/oi_cloud/test.py\r\n--- 4.245954990386963 seconds ---\r\n['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add_nodes_to_index', '_aget_node_with_embedding', '_async_add_nodes_to_index', '_build_index_from_nodes', '_delete_node', '_docstore', '_get_node_with_embedding', '_graph_store', '_index_struct', '_insert', '_is_protocol', '_service_context', '_show_progress', '_storage_context', '_store_nodes_override', '_use_async', '_vector_store', 'as_chat_engine', 'as_query_engine', 'as_retriever', 'build_index_from_nodes', 'delete', 'delete_nodes', 'delete_ref_doc', 'docstore', 'from_documents', 'from_vector_store', 'index_id', 'index_struct', 'index_struct_cls', 'insert', 'insert_nodes', 'ref_doc_info', 'refresh', 'refresh_ref_docs', 'service_context', 'set_index_id', 'storage_context', 'summary', 'update', 'update_ref_doc', 'vector_store']\r\nTraceback (most recent call last):\r\n  File \"/Users/brianprzezdziecki/Code/OI_Memory/oi_cloud/test.py\", line 18, in <module>\r\n    index = VectorStoreIndex.from_vector_store(index)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/brianprzezdziecki/Code/OI_Memory/venv/lib/python3.11/site-packages/llama_index/indices/vector_store/base.py\", line 65, in from_vector_store\r\n    if not vector_store.stores_text:\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'VectorStoreIndex' object has no attribute 'stores_text'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8090/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8090/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8089",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8089/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8089/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8089/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8089",
        "id": 1939737457,
        "node_id": "I_kwDOIWuq585zngtx",
        "number": 8089,
        "title": "[Question]: Index creation without LLM ",
        "user": {
            "login": "DSOBoy",
            "id": 133762639,
            "node_id": "U_kgDOB_kOTw",
            "avatar_url": "https://avatars.githubusercontent.com/u/133762639?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DSOBoy",
            "html_url": "https://github.com/DSOBoy",
            "followers_url": "https://api.github.com/users/DSOBoy/followers",
            "following_url": "https://api.github.com/users/DSOBoy/following{/other_user}",
            "gists_url": "https://api.github.com/users/DSOBoy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DSOBoy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DSOBoy/subscriptions",
            "organizations_url": "https://api.github.com/users/DSOBoy/orgs",
            "repos_url": "https://api.github.com/users/DSOBoy/repos",
            "events_url": "https://api.github.com/users/DSOBoy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DSOBoy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-12T10:57:32Z",
        "updated_at": "2023-10-13T08:13:56Z",
        "closed_at": "2023-10-12T16:36:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am looking for a method of retrieving context information from a set of documents and returning either the most relevant document nodes or the wrapped prompt with the query and context included. \r\n\r\nThe issue I am currently having is constructing the index without using an LLM. I have been using VectorStoreIndex with a local embedding model. Is there a method of running this without hitting the LLM authentication error.\r\n\r\nThank you. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8089/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8089/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8088",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8088/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8088/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8088/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8088",
        "id": 1939609848,
        "node_id": "I_kwDOIWuq585znBj4",
        "number": 8088,
        "title": "[Documentation]: Advanced Text-to-SQL guide does not add other tables",
        "user": {
            "login": "AbhiPawar5",
            "id": 45484556,
            "node_id": "MDQ6VXNlcjQ1NDg0NTU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/45484556?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AbhiPawar5",
            "html_url": "https://github.com/AbhiPawar5",
            "followers_url": "https://api.github.com/users/AbhiPawar5/followers",
            "following_url": "https://api.github.com/users/AbhiPawar5/following{/other_user}",
            "gists_url": "https://api.github.com/users/AbhiPawar5/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AbhiPawar5/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AbhiPawar5/subscriptions",
            "organizations_url": "https://api.github.com/users/AbhiPawar5/orgs",
            "repos_url": "https://api.github.com/users/AbhiPawar5/repos",
            "events_url": "https://api.github.com/users/AbhiPawar5/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AbhiPawar5/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-12T09:40:49Z",
        "updated_at": "2023-10-12T10:51:21Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nIn the guide, there is no code to add the other tables except city_stats in the SQL database. And the guide mentions it can search on large number of tables to get the SQL from natural query. However, we see only a single table is added to the SQL DB instance in the following line:\r\n```\r\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\r\n```\r\n\r\nCan you please post the correct code before updating the documentation? Thanks.\r\nP.S New to Llama Index.\n\n### Documentation Link\n\nhttps://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/duckdb_sql_query.html#advanced-text-to-sql-with-our-sqltableretrieverqueryengine",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8088/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8088/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8087",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8087/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8087/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8087/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8087",
        "id": 1939459179,
        "node_id": "PR_kwDOIWuq585cmw72",
        "number": 8087,
        "title": "add pgvector sql query engine",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-12T08:15:18Z",
        "updated_at": "2023-10-12T08:43:19Z",
        "closed_at": "2023-10-12T08:43:18Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8087",
            "html_url": "https://github.com/run-llama/llama_index/pull/8087",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8087.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8087.patch",
            "merged_at": "2023-10-12T08:43:18Z"
        },
        "body": "make text-to-sql do hybrid sql + vector search by writing raw pgvector code ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8087/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8087/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8086",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8086/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8086/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8086/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8086",
        "id": 1939271716,
        "node_id": "PR_kwDOIWuq585cmH1c",
        "number": 8086,
        "title": "Minor agent updates",
        "user": {
            "login": "vishhvak",
            "id": 30690855,
            "node_id": "MDQ6VXNlcjMwNjkwODU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/30690855?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishhvak",
            "html_url": "https://github.com/vishhvak",
            "followers_url": "https://api.github.com/users/vishhvak/followers",
            "following_url": "https://api.github.com/users/vishhvak/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishhvak/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishhvak/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishhvak/subscriptions",
            "organizations_url": "https://api.github.com/users/vishhvak/orgs",
            "repos_url": "https://api.github.com/users/vishhvak/repos",
            "events_url": "https://api.github.com/users/vishhvak/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishhvak/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-12T06:28:46Z",
        "updated_at": "2023-10-16T16:49:31Z",
        "closed_at": "2023-10-16T16:49:31Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8086",
            "html_url": "https://github.com/run-llama/llama_index/pull/8086",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8086.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8086.patch",
            "merged_at": "2023-10-16T16:49:31Z"
        },
        "body": "# Description\r\n\r\nThis PR includes changes that fix issue #8085 and implement feature #8084. The changes involve modifications to the `BaseAgent` and `ReActAgent` classes to handle `sources` correctly. `ReActAgent` now returns `sources` with its response. Agents now correctly return source_nodes when they are used as `QueryEngineTool`s using their `query` and `aquery` methods from the `BaseAgent` class.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\nFixes #8085, Implements #8084\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8086/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8086/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8085",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8085/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8085/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8085/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8085",
        "id": 1939262187,
        "node_id": "I_kwDOIWuq585zlsrr",
        "number": 8085,
        "title": "[Bug]: Sources not returned by OpenAI Agent query methods in cases where tools are also OpenAI Agents",
        "user": {
            "login": "vishhvak",
            "id": 30690855,
            "node_id": "MDQ6VXNlcjMwNjkwODU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/30690855?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishhvak",
            "html_url": "https://github.com/vishhvak",
            "followers_url": "https://api.github.com/users/vishhvak/followers",
            "following_url": "https://api.github.com/users/vishhvak/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishhvak/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishhvak/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishhvak/subscriptions",
            "organizations_url": "https://api.github.com/users/vishhvak/orgs",
            "repos_url": "https://api.github.com/users/vishhvak/repos",
            "events_url": "https://api.github.com/users/vishhvak/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishhvak/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-12T06:20:58Z",
        "updated_at": "2023-10-16T16:49:32Z",
        "closed_at": "2023-10-16T16:49:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nResponse returned by `BaseAgent` in its `query` methods does not include `source_nodes` in the object returned. This results in `source_nodes` not being populated correctly when Agents are also used as `QueryEngineTools`\r\n\r\n### Version\r\n\r\n0.8.43.post1\r\n\r\n### Steps to Reproduce\r\n\r\n- Create multiple VectorStore Indices, and corresponding query engines. \r\n- Create query engine tools for each engine, and make OpenAIAgents (sub-agents) with those tools. \r\n- Create a \"master\" OpenAI Agent with tools, where the tools are OpenAIAgents from the previous step wrapped in QueryEngineTools (query engines for these tools are the sub-agents). \r\n- Use the \"master\" OpenAIAgent to answer a query, and print response.sources or response.source_nodes, which should yield empty lists. \r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8085/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8085/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8084",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8084/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8084/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8084/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8084",
        "id": 1939254703,
        "node_id": "I_kwDOIWuq585zlq2v",
        "number": 8084,
        "title": "[Feature Request]: Sources with ReAct agent",
        "user": {
            "login": "vishhvak",
            "id": 30690855,
            "node_id": "MDQ6VXNlcjMwNjkwODU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/30690855?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishhvak",
            "html_url": "https://github.com/vishhvak",
            "followers_url": "https://api.github.com/users/vishhvak/followers",
            "following_url": "https://api.github.com/users/vishhvak/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishhvak/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishhvak/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishhvak/subscriptions",
            "organizations_url": "https://api.github.com/users/vishhvak/orgs",
            "repos_url": "https://api.github.com/users/vishhvak/repos",
            "events_url": "https://api.github.com/users/vishhvak/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishhvak/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 6129428377,
                "node_id": "LA_kwDOIWuq588AAAABbVenmQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/request%20contribution%20board",
                "name": "request contribution board",
                "color": "D93F0B",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-12T06:14:28Z",
        "updated_at": "2023-10-30T19:45:57Z",
        "closed_at": "2023-10-30T19:45:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nCurrently, the ReAct agent does not return sources with nodes in its response, like the OpenAI Agent does. This can be accomplished with simple additions in the codebase for the ReAct agent.\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8084/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8084/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8083",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8083/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8083/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8083/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8083",
        "id": 1939172456,
        "node_id": "I_kwDOIWuq585zlWxo",
        "number": 8083,
        "title": "[Question]: BM25 Hybrid Retriever",
        "user": {
            "login": "yashdeepyds",
            "id": 31975772,
            "node_id": "MDQ6VXNlcjMxOTc1Nzcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/31975772?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yashdeepyds",
            "html_url": "https://github.com/yashdeepyds",
            "followers_url": "https://api.github.com/users/yashdeepyds/followers",
            "following_url": "https://api.github.com/users/yashdeepyds/following{/other_user}",
            "gists_url": "https://api.github.com/users/yashdeepyds/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yashdeepyds/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yashdeepyds/subscriptions",
            "organizations_url": "https://api.github.com/users/yashdeepyds/orgs",
            "repos_url": "https://api.github.com/users/yashdeepyds/repos",
            "events_url": "https://api.github.com/users/yashdeepyds/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yashdeepyds/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-12T04:52:44Z",
        "updated_at": "2023-10-12T05:26:48Z",
        "closed_at": "2023-10-12T05:26:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n@jerry\r\nHow to use the BM25 hybrid retriever using the already indexed milvus collection.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8083/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8083/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8082",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8082/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8082/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8082/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8082",
        "id": 1939146740,
        "node_id": "PR_kwDOIWuq585cls9e",
        "number": 8082,
        "title": "Add max_chunk_bytes default arg to OpensearchVectorClient",
        "user": {
            "login": "tobby-lie",
            "id": 26800302,
            "node_id": "MDQ6VXNlcjI2ODAwMzAy",
            "avatar_url": "https://avatars.githubusercontent.com/u/26800302?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tobby-lie",
            "html_url": "https://github.com/tobby-lie",
            "followers_url": "https://api.github.com/users/tobby-lie/followers",
            "following_url": "https://api.github.com/users/tobby-lie/following{/other_user}",
            "gists_url": "https://api.github.com/users/tobby-lie/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tobby-lie/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tobby-lie/subscriptions",
            "organizations_url": "https://api.github.com/users/tobby-lie/orgs",
            "repos_url": "https://api.github.com/users/tobby-lie/repos",
            "events_url": "https://api.github.com/users/tobby-lie/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tobby-lie/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-12T04:20:21Z",
        "updated_at": "2023-10-12T22:09:46Z",
        "closed_at": "2023-10-12T22:09:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8082",
            "html_url": "https://github.com/run-llama/llama_index/pull/8082",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8082.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8082.patch",
            "merged_at": "2023-10-12T22:09:46Z"
        },
        "body": "# Description\r\n\r\nIn `llama_index.vector_stores.opensearch`, [OpensearchVectorClient.index_results](https://github.com/run-llama/llama_index/blob/main/llama_index/vector_stores/opensearch.py#L240) contains a `max_chunk_bytes` arg into `_bulk_ingest_embeddings` that is not accessible from where `OpensearchVectorStore.add` is called in [VectorStoreIndex](https://github.com/run-llama/llama_index/blob/main/llama_index/indices/vector_store/base.py#L187)\r\n\r\nThis change will allow users to pass a `max_chunk_bytes` arg into `OpensearchVectorClient` so that it can be used when bulk inserting into Opensearch.\r\n\r\nRough example usage:\r\n\r\n```\r\nclient = OpensearchVectorClient(\r\n    endpoint=\"https://fake-endpoint.com:443\",\r\n    index=\"fake-index\",\r\n    dim=1536,\r\n    max_chunk_bytes=(2 * 1024 * 1024),\r\n)\r\n\r\nvector_store = OpensearchVectorStore(client)\r\n\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\nindex = VectorStoreIndex.from_vector_store(vector_store=self.storage_context.vector_store)\r\n\r\nnode_parser = SimpleNodeParser.from_defaults()\r\nnodes = node_parser.get_nodes_from_documents(documents)\r\n\r\nindex.insert_nodes(nodes)  # changes in PR take effect here\r\n```\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8082/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8082/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8081",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8081/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8081/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8081/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8081",
        "id": 1938996227,
        "node_id": "I_kwDOIWuq585zkrwD",
        "number": 8081,
        "title": "[Question]: Llama_index fails to recognize number of pages in a pdf",
        "user": {
            "login": "tytung2020",
            "id": 37324680,
            "node_id": "MDQ6VXNlcjM3MzI0Njgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/37324680?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tytung2020",
            "html_url": "https://github.com/tytung2020",
            "followers_url": "https://api.github.com/users/tytung2020/followers",
            "following_url": "https://api.github.com/users/tytung2020/following{/other_user}",
            "gists_url": "https://api.github.com/users/tytung2020/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tytung2020/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tytung2020/subscriptions",
            "organizations_url": "https://api.github.com/users/tytung2020/orgs",
            "repos_url": "https://api.github.com/users/tytung2020/repos",
            "events_url": "https://api.github.com/users/tytung2020/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tytung2020/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-10-12T01:12:16Z",
        "updated_at": "2023-10-12T04:47:26Z",
        "closed_at": "2023-10-12T01:34:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nas seen in this screenshot, there are 21 pages, but when asked via Davinci, it says only 3 pages:\r\n\r\n![Screenshot (588)](https://github.com/run-llama/llama_index/assets/37324680/bdcaee9a-f91f-43df-9ae2-b37f34b64cc7)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8081/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8081/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8080",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8080/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8080/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8080/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8080",
        "id": 1938910437,
        "node_id": "PR_kwDOIWuq585ck6R_",
        "number": 8080,
        "title": "Add `PGVectorStore` schema param.",
        "user": {
            "login": "DezLitz",
            "id": 4271492,
            "node_id": "MDQ6VXNlcjQyNzE0OTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4271492?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DezLitz",
            "html_url": "https://github.com/DezLitz",
            "followers_url": "https://api.github.com/users/DezLitz/followers",
            "following_url": "https://api.github.com/users/DezLitz/following{/other_user}",
            "gists_url": "https://api.github.com/users/DezLitz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DezLitz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DezLitz/subscriptions",
            "organizations_url": "https://api.github.com/users/DezLitz/orgs",
            "repos_url": "https://api.github.com/users/DezLitz/repos",
            "events_url": "https://api.github.com/users/DezLitz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DezLitz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-11T23:28:11Z",
        "updated_at": "2023-10-22T04:37:38Z",
        "closed_at": "2023-10-22T04:37:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8080",
            "html_url": "https://github.com/run-llama/llama_index/pull/8080",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8080.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8080.patch",
            "merged_at": "2023-10-22T04:37:38Z"
        },
        "body": "# Description\r\n\r\nAdded option for custom Postgres schema on PGVectorStore instead of only allowing `public` schema. \r\n\r\nMotivation is to allow an extra degree of separation in the DB for generated indexes. In my project for example I am creating many indexes, each of which exist in their own table. Instead of these tables existing alongside my main DB tables, it is advantageous for me to create them all in a `vector_indexes_v1` schema. That way, if I need to drop all indexes and regenerate I can simply drop the schema. I may also want to generate another `vector_indexes_v2` version of my index, in that case each index version could be placed in its own schema.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nExisiting PGVectorStore tests have been modified to take in the new `schema_name` param alongside the existing `table_name` param.\r\n\r\n# Suggested Checklist:\r\n\r\nI could not find the PGVectorStore docs in the latest version of the website.\r\n\r\n- [x] My changes generate no new warnings\r\n- [x] I have `modified` tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8080/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8080/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8079",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8079/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8079/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8079/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8079",
        "id": 1938833653,
        "node_id": "PR_kwDOIWuq585cko5M",
        "number": 8079,
        "title": "[version] bump to 0.8.43.post1",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T22:28:26Z",
        "updated_at": "2023-10-11T22:47:47Z",
        "closed_at": "2023-10-11T22:47:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8079",
            "html_url": "https://github.com/run-llama/llama_index/pull/8079",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8079.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8079.patch",
            "merged_at": "2023-10-11T22:47:46Z"
        },
        "body": "Fix for relaxed dependencies ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8079/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8079/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8078",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8078/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8078/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8078/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8078",
        "id": 1938809847,
        "node_id": "PR_kwDOIWuq585ckjpV",
        "number": 8078,
        "title": "relax pandas and numpy reqs",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T22:02:58Z",
        "updated_at": "2023-10-11T22:25:55Z",
        "closed_at": "2023-10-11T22:25:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8078",
            "html_url": "https://github.com/run-llama/llama_index/pull/8078",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8078.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8078.patch",
            "merged_at": "2023-10-11T22:25:54Z"
        },
        "body": "This was causing issues on installing/running in google colab",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8078/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8078/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8076",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8076/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8076/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8076/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8076",
        "id": 1938672862,
        "node_id": "PR_kwDOIWuq585ckFKC",
        "number": 8076,
        "title": "`ImportChecker` for standardized import failovers",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T20:26:53Z",
        "updated_at": "2023-10-11T21:22:40Z",
        "closed_at": "2023-10-11T21:22:34Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8076",
            "html_url": "https://github.com/run-llama/llama_index/pull/8076",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8076.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8076.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nCommon mistakes in the `try`-`except` about missing pip installs:\r\n- Forgot to use `from` keyword\r\n- Using `ImportError` over `ModuleNotFoundError`\r\n- Not using backtick for readability\r\n\r\nThis PR makes a context manager to standardize all of this\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8076/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8076/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8075",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8075/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8075/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8075/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8075",
        "id": 1938548639,
        "node_id": "PR_kwDOIWuq585cjpmG",
        "number": 8075,
        "title": "Fixed `HuggingFaceLLM` missing f-str",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T19:14:28Z",
        "updated_at": "2023-10-11T22:04:56Z",
        "closed_at": "2023-10-11T22:04:55Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8075",
            "html_url": "https://github.com/run-llama/llama_index/pull/8075",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8075.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8075.patch",
            "merged_at": "2023-10-11T22:04:55Z"
        },
        "body": "# Description\r\n\r\nFixing a forgotten f-str in `HuggingFaceLLM`\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8075/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8075/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8074",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8074/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8074/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8074/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8074",
        "id": 1938256478,
        "node_id": "I_kwDOIWuq585zh3Je",
        "number": 8074,
        "title": "[Question]: How to save multiple index for different users and maintain uniqueness for each index",
        "user": {
            "login": "kashiftriffort",
            "id": 438943,
            "node_id": "MDQ6VXNlcjQzODk0Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/438943?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kashiftriffort",
            "html_url": "https://github.com/kashiftriffort",
            "followers_url": "https://api.github.com/users/kashiftriffort/followers",
            "following_url": "https://api.github.com/users/kashiftriffort/following{/other_user}",
            "gists_url": "https://api.github.com/users/kashiftriffort/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kashiftriffort/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kashiftriffort/subscriptions",
            "organizations_url": "https://api.github.com/users/kashiftriffort/orgs",
            "repos_url": "https://api.github.com/users/kashiftriffort/repos",
            "events_url": "https://api.github.com/users/kashiftriffort/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kashiftriffort/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T16:51:41Z",
        "updated_at": "2023-10-24T06:32:05Z",
        "closed_at": "2023-10-24T06:32:05Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am developing a chatbot application using Flask, and I've successfully created an index for specific documents and implemented a process for fetching questions and answers from storage while working locally. However, I'm facing an issue when it comes to deploying this application on a server. My challenge is identifying a method to uniquely save the index for each user on the server side. This is crucial because there might be situations where multiple users are simultaneously uploading PDFs for Q&A. I need a solution that allows the chatbot to differentiate between these users and provide answers for their unique queries. How can I achieve this user-specific index storage on the server?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8074/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8074/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8072",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8072/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8072/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8072/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8072",
        "id": 1938050263,
        "node_id": "PR_kwDOIWuq585ch6i4",
        "number": 8072,
        "title": "`prettier` in `pre-commit`: formatting non-Python",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "jamesbraza",
                "id": 8990777,
                "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
                "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/jamesbraza",
                "html_url": "https://github.com/jamesbraza",
                "followers_url": "https://api.github.com/users/jamesbraza/followers",
                "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
                "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
                "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
                "repos_url": "https://api.github.com/users/jamesbraza/repos",
                "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
                "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T15:10:16Z",
        "updated_at": "2023-10-12T03:57:14Z",
        "closed_at": "2023-10-12T03:57:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8072",
            "html_url": "https://github.com/run-llama/llama_index/pull/8072",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8072.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8072.patch",
            "merged_at": "2023-10-12T03:57:11Z"
        },
        "body": "# Description\r\n\r\nAdded `prettier` to `pre-commit` to autoformat non-Python files (e.g. JSON, Markdown, YAML)\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8072/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8072/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8071",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8071/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8071/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8071/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8071",
        "id": 1937658837,
        "node_id": "I_kwDOIWuq585zflPV",
        "number": 8071,
        "title": "[Feature Request]: Lazy loading of external blobs",
        "user": {
            "login": "laurens-gs",
            "id": 139150507,
            "node_id": "U_kgDOCEtEqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/139150507?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laurens-gs",
            "html_url": "https://github.com/laurens-gs",
            "followers_url": "https://api.github.com/users/laurens-gs/followers",
            "following_url": "https://api.github.com/users/laurens-gs/following{/other_user}",
            "gists_url": "https://api.github.com/users/laurens-gs/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laurens-gs/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laurens-gs/subscriptions",
            "organizations_url": "https://api.github.com/users/laurens-gs/orgs",
            "repos_url": "https://api.github.com/users/laurens-gs/repos",
            "events_url": "https://api.github.com/users/laurens-gs/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laurens-gs/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 6129428377,
                "node_id": "LA_kwDOIWuq588AAAABbVenmQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/request%20contribution%20board",
                "name": "request contribution board",
                "color": "D93F0B",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-11T12:30:45Z",
        "updated_at": "2023-10-30T20:51:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nTo avoid any issues in offline installations or restricted environments, any external dependencies that need to be downloaded should be downloaded lazily once they are required. Ideally, it should be possible to manually provide the blobs if necessary. This restricted scenario should be included in the test suite, to ensure that people can import this package in all environments and still use the most basic features using local models.\n\n### Reason\n\nI work for a large firm where production environments and even development environments are strictly secured behind a firewall. I cannot even import the package because `tiktoken` immediately attempts to load binaries for OpenAIs GPT2 tokenizer. I am required to run all my models locally, so any optional OpenAI stuff should not need to be loaded at all.\n\n### Value of Feature\n\nThe MIT license allows for commercial use, but for many firms commercial application of this library is not possible if it cannot be run behind a firewall. Adding this feature would open up this library to all potential users.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8071/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8071/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8069",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8069/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8069/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8069/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8069",
        "id": 1937594801,
        "node_id": "I_kwDOIWuq585zfVmx",
        "number": 8069,
        "title": "[Question]: How to improve the accuracy on the large Milvus index?",
        "user": {
            "login": "nithin-nk",
            "id": 94159710,
            "node_id": "U_kgDOBZzDXg",
            "avatar_url": "https://avatars.githubusercontent.com/u/94159710?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nithin-nk",
            "html_url": "https://github.com/nithin-nk",
            "followers_url": "https://api.github.com/users/nithin-nk/followers",
            "following_url": "https://api.github.com/users/nithin-nk/following{/other_user}",
            "gists_url": "https://api.github.com/users/nithin-nk/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nithin-nk/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nithin-nk/subscriptions",
            "organizations_url": "https://api.github.com/users/nithin-nk/orgs",
            "repos_url": "https://api.github.com/users/nithin-nk/repos",
            "events_url": "https://api.github.com/users/nithin-nk/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nithin-nk/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T11:52:31Z",
        "updated_at": "2023-10-24T06:32:04Z",
        "closed_at": "2023-10-24T06:32:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nWe are using Milvus for the vector store. We were getting very good accuracy when the index was small(1000+ records). Right now we have a collection with 200K+ records and accuracy is not good. How to improve the accuracy on the large Milvus index?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8069/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8069/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8068",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8068/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8068/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8068/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8068",
        "id": 1937498163,
        "node_id": "I_kwDOIWuq585ze-Az",
        "number": 8068,
        "title": "[Question] How to catch exception timeout when llamaindex call openai",
        "user": {
            "login": "anhquyetnguyen",
            "id": 23186613,
            "node_id": "MDQ6VXNlcjIzMTg2NjEz",
            "avatar_url": "https://avatars.githubusercontent.com/u/23186613?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anhquyetnguyen",
            "html_url": "https://github.com/anhquyetnguyen",
            "followers_url": "https://api.github.com/users/anhquyetnguyen/followers",
            "following_url": "https://api.github.com/users/anhquyetnguyen/following{/other_user}",
            "gists_url": "https://api.github.com/users/anhquyetnguyen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anhquyetnguyen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anhquyetnguyen/subscriptions",
            "organizations_url": "https://api.github.com/users/anhquyetnguyen/orgs",
            "repos_url": "https://api.github.com/users/anhquyetnguyen/repos",
            "events_url": "https://api.github.com/users/anhquyetnguyen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anhquyetnguyen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T11:06:29Z",
        "updated_at": "2023-10-24T06:32:02Z",
        "closed_at": "2023-10-24T06:32:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHow to catch exception timeout when llamaindex call openai? I only see warning timeout to console? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8068/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8068/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8067",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8067/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8067/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8067/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8067",
        "id": 1937354487,
        "node_id": "I_kwDOIWuq585zea73",
        "number": 8067,
        "title": "[Question]: The test case is not responding",
        "user": {
            "login": "denghao1120",
            "id": 90663781,
            "node_id": "MDQ6VXNlcjkwNjYzNzgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/90663781?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/denghao1120",
            "html_url": "https://github.com/denghao1120",
            "followers_url": "https://api.github.com/users/denghao1120/followers",
            "following_url": "https://api.github.com/users/denghao1120/following{/other_user}",
            "gists_url": "https://api.github.com/users/denghao1120/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/denghao1120/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/denghao1120/subscriptions",
            "organizations_url": "https://api.github.com/users/denghao1120/orgs",
            "repos_url": "https://api.github.com/users/denghao1120/repos",
            "events_url": "https://api.github.com/users/denghao1120/events{/privacy}",
            "received_events_url": "https://api.github.com/users/denghao1120/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-11T09:56:44Z",
        "updated_at": "2023-10-12T16:37:03Z",
        "closed_at": "2023-10-12T16:37:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\n**python version: 3.11.4\r\nllama_index: 0.8.43**\r\n\r\n**### code:** \r\n`\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\n\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\nindex = VectorStoreIndex.from_documents(documents)\r\n\r\nquery_engine = index.as_query_engine()\r\nresponse = query_engine.query(\"What did the author do growing up?\")\r\nprint(response)\r\n`\r\n\r\n\r\n**### console result:**\r\n`\r\nPS D:\\Desktop\\llama> & D:/Python/python.exe d:/Desktop/llama/test01.py\r\n\r\nCould not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\nllama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from C:\\Users\\dengh\\AppData\\Local\\llama_index\\models\\llama-2-13b-chat.Q4_0.gguf (version GGUF V2 (latest))\r\nllama_model_loader: - tensor    0:                token_embd.weight q4_0     [  5120, 32000,     1,     1 ]\r\nllama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor    2:            blk.0.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor    9:              blk.0.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   11:            blk.1.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   18:              blk.1.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   20:           blk.10.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   27:             blk.10.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   29:           blk.11.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   36:             blk.11.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   56:           blk.14.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   63:             blk.14.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   64:             blk.15.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   65:             blk.15.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   67:            blk.2.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   69:              blk.2.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   71:              blk.2.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   72:         blk.2.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   73:              blk.2.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   74:              blk.2.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   76:            blk.3.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   78:              blk.3.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   80:              blk.3.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   81:         blk.3.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   82:              blk.3.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   83:              blk.3.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   85:            blk.4.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   87:              blk.4.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   89:              blk.4.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   90:         blk.4.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   91:              blk.4.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   92:              blk.4.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   94:            blk.5.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   96:              blk.5.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor   98:              blk.5.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor   99:         blk.5.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  100:              blk.5.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  101:              blk.5.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  103:            blk.6.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  105:              blk.6.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  107:              blk.6.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  108:         blk.6.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  109:              blk.6.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  110:              blk.6.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  112:            blk.7.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  114:              blk.7.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  116:              blk.7.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  117:         blk.7.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  118:              blk.7.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  119:              blk.7.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  121:            blk.8.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  123:              blk.8.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  125:              blk.8.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  126:         blk.8.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  127:              blk.8.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  128:              blk.8.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  130:            blk.9.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  132:              blk.9.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  134:              blk.9.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  135:         blk.9.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  136:              blk.9.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  137:              blk.9.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  139:           blk.15.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  143:        blk.15.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  144:             blk.15.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  146:           blk.16.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  148:             blk.16.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  150:             blk.16.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  151:        blk.16.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  152:             blk.16.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  153:             blk.16.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  155:           blk.17.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  157:             blk.17.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  159:             blk.17.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  160:        blk.17.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  161:             blk.17.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  162:             blk.17.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  164:           blk.18.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  166:             blk.18.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  168:             blk.18.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  169:        blk.18.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  170:             blk.18.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  171:             blk.18.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  173:           blk.19.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  175:             blk.19.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  177:             blk.19.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  178:        blk.19.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  179:             blk.19.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  180:             blk.19.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  182:           blk.20.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  184:             blk.20.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  186:             blk.20.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  187:        blk.20.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  188:             blk.20.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  189:             blk.20.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  191:           blk.21.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  193:             blk.21.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  195:             blk.21.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  196:        blk.21.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  197:             blk.21.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  198:             blk.21.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  200:           blk.22.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  202:             blk.22.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  204:             blk.22.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  205:        blk.22.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  206:             blk.22.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  207:             blk.22.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  209:           blk.23.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  211:             blk.23.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  213:             blk.23.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  214:        blk.23.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  215:             blk.23.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  216:             blk.23.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  218:           blk.24.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  220:             blk.24.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  222:             blk.24.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  223:        blk.24.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  224:             blk.24.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  225:             blk.24.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  227:           blk.25.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  229:             blk.25.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  231:             blk.25.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  232:        blk.25.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  233:             blk.25.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  234:             blk.25.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  236:           blk.26.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  238:             blk.26.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  240:             blk.26.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  241:        blk.26.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  242:             blk.26.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  243:             blk.26.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  245:           blk.27.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  247:             blk.27.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  249:             blk.27.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  250:        blk.27.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  251:             blk.27.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  252:             blk.27.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  254:           blk.28.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  256:             blk.28.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  258:             blk.28.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  259:        blk.28.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  260:             blk.28.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  261:             blk.28.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  263:           blk.29.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  265:             blk.29.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  267:             blk.29.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  268:        blk.29.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  269:             blk.29.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  270:             blk.29.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  272:             blk.30.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  273:             blk.30.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  275:             blk.30.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  276:             blk.30.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\r\nllama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  279:           blk.30.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  282:           blk.31.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  289:             blk.31.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  291:           blk.32.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  293:             blk.32.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  295:             blk.32.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  296:        blk.32.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  297:             blk.32.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  298:             blk.32.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  300:           blk.33.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  302:             blk.33.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  304:             blk.33.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  305:        blk.33.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  306:             blk.33.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  307:             blk.33.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  309:           blk.34.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  311:             blk.34.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  313:             blk.34.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  314:        blk.34.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  315:             blk.34.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  316:             blk.34.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  318:           blk.35.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  320:             blk.35.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  322:             blk.35.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  323:        blk.35.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  324:             blk.35.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  325:             blk.35.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  327:           blk.36.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  329:             blk.36.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  331:             blk.36.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  332:        blk.36.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  333:             blk.36.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  334:             blk.36.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  336:           blk.37.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  338:             blk.37.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  340:             blk.37.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  341:        blk.37.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  342:             blk.37.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  343:             blk.37.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  345:           blk.38.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  347:             blk.38.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  349:             blk.38.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  350:        blk.38.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  351:             blk.38.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  352:             blk.38.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  354:           blk.39.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  356:             blk.39.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\r\nllama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - tensor  358:             blk.39.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  359:        blk.39.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  360:             blk.39.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  361:             blk.39.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\r\nllama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\r\nllama_model_loader: - kv   0:                       general.architecture str\r\nllama_model_loader: - kv   1:                               general.name str\r\nllama_model_loader: - kv   2:                       llama.context_length u32\r\nllama_model_loader: - kv   3:                     llama.embedding_length u32\r\nllama_model_loader: - kv   4:                          llama.block_count u32\r\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32\r\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32\r\nllama_model_loader: - kv   7:                 llama.attention.head_count u32\r\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32\r\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32\r\nllama_model_loader: - kv  10:                          general.file_type u32\r\nllama_model_loader: - kv  11:                       tokenizer.ggml.model str\r\nllama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr\r\nllama_model_loader: - kv  13:                      tokenizer.ggml.scores arr\r\nllama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr\r\nllama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32\r\nllama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32\r\nllama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32\r\nllama_model_loader: - kv  18:               general.quantization_version u32\r\nllama_model_loader: - type  f32:   81 tensors\r\nllama_model_loader: - type q4_0:  281 tensors\r\nllama_model_loader: - type q6_K:    1 tensors\r\nllm_load_print_meta: format           = GGUF V2 (latest)\r\nllm_load_print_meta: arch             = llama\r\nllm_load_print_meta: vocab type       = SPM\r\nllm_load_print_meta: n_vocab          = 32000\r\nllm_load_print_meta: n_merges         = 0\r\nllm_load_print_meta: n_ctx_train      = 4096\r\nllm_load_print_meta: n_embd           = 5120\r\nllm_load_print_meta: n_head           = 40\r\nllm_load_print_meta: n_head_kv        = 40\r\nllm_load_print_meta: n_layer          = 40\r\nllm_load_print_meta: n_rot            = 128\r\nllm_load_print_meta: n_gqa            = 1\r\nllm_load_print_meta: f_norm_eps       = 0.0e+00\r\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\r\nllm_load_print_meta: n_ff             = 13824\r\nllm_load_print_meta: freq_base_train  = 10000.0\r\nllm_load_print_meta: freq_scale_train = 1\r\nllm_load_print_meta: model type       = 13B\r\nllm_load_print_meta: model ftype      = mostly Q4_0\r\nllm_load_print_meta: model params     = 13.02 B\r\nllm_load_print_meta: model size       = 6.86 GiB (4.53 BPW)\r\nllm_load_print_meta: general.name   = LLaMA v2\r\nllm_load_print_meta: BOS token = 1 '<s>'\r\nllm_load_print_meta: EOS token = 2 '</s>'\r\nllm_load_print_meta: UNK token = 0 '<unk>'\r\nllm_load_print_meta: LF token  = 13 '<0x0A>'\r\nllm_load_tensors: ggml ctx size =    0.12 MB\r\nllm_load_tensors: mem required  = 7024.01 MB\r\n...................................................................................................\r\nllama_new_context_with_model: n_ctx      = 3900\r\nllama_new_context_with_model: freq_base  = 10000.0\r\nllama_new_context_with_model: freq_scale = 1\r\nllama_new_context_with_model: kv self size  = 3046.88 MB\r\nllama_new_context_with_model: compute buffer total size = 348.18 MB\r\nAVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 |\r\n\r\nCould not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\nPS D:\\Desktop\\llama>\r\n `\r\n\r\n\r\n**When I tested the test case, I did not get the desired return value, but the program terminated after a period of time, with no return value and no exception message**",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8067/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8067/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8065",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8065/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8065/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8065/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8065",
        "id": 1937048089,
        "node_id": "PR_kwDOIWuq585cedaT",
        "number": 8065,
        "title": "add multi-document agents v1",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T07:25:42Z",
        "updated_at": "2023-10-11T15:20:33Z",
        "closed_at": "2023-10-11T15:20:32Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8065",
            "html_url": "https://github.com/run-llama/llama_index/pull/8065",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8065.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8065.patch",
            "merged_at": "2023-10-11T15:20:32Z"
        },
        "body": "- made dataset our own documentation\r\n- added reranking for tool retrieval (document retrieval)\r\n- added a dynamic compare tool using SubQuestionQueryEngine",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8065/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8065/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8064",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8064/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8064/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8064/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8064",
        "id": 1936995442,
        "node_id": "I_kwDOIWuq585zdDRy",
        "number": 8064,
        "title": "[Bug]: SQLDatabase wrapper does not include schema while getting column/foreign keys",
        "user": {
            "login": "ashpytho",
            "id": 45519043,
            "node_id": "MDQ6VXNlcjQ1NTE5MDQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/45519043?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashpytho",
            "html_url": "https://github.com/ashpytho",
            "followers_url": "https://api.github.com/users/ashpytho/followers",
            "following_url": "https://api.github.com/users/ashpytho/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashpytho/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashpytho/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashpytho/subscriptions",
            "organizations_url": "https://api.github.com/users/ashpytho/orgs",
            "repos_url": "https://api.github.com/users/ashpytho/repos",
            "events_url": "https://api.github.com/users/ashpytho/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashpytho/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-11T06:54:31Z",
        "updated_at": "2023-10-24T00:43:08Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen initializing the SQLDatabase wrapper, schema name can be provided as an argument. However, when retrieving column and foreign key details from the database, the schema name is not consistently passed as an argument. This can result in issues with certain databases that require the specification of a schema name. \r\nSQLAlchemy has designated the schema as an optional parameter, with its default value set to None. Nevertheless, when a schema name has been explicitly defined in the SQLDatabase class during initialization, it should be automatically included in subsequent database operations to ensure proper compatibility and adherence to the defined schema structure.\n\n### Version\n\n0.8.36\n\n### Steps to Reproduce\n\n1. Create an instance of SQLDatabase class. Make sure we pass schema name as argument when initializing.\r\n2. Create node mappings for a database. Make sure DB requires schema name while fetching data.\r\n3. Create object index  for the same.\r\n4. An error will occur when index is being created mentioning that no such table is present in the DB.\n\n### Relevant Logs/Tracbacks\n\n```shell\nc:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\langchain\\__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\r\n  warnings.warn(\r\nProcess SpawnProcess-2:\r\nTraceback (most recent call last):\r\n  File \"C:\\Python310\\lib\\multiprocessing\\process.py\", line 315, in _bootstrap\r\n    self.run()\r\n  File \"C:\\Python310\\lib\\multiprocessing\\process.py\", line 108, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\uvicorn\\_subprocess.py\", line 76, in subprocess_started\r\n    target(sockets=sockets)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\uvicorn\\server.py\", line 61, in run\r\n    return asyncio.run(self.serve(sockets=sockets))\r\n  File \"C:\\Python310\\lib\\asyncio\\runners.py\", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File \"C:\\Python310\\lib\\asyncio\\base_events.py\", line 646, in run_until_complete\r\n    return future.result()\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\uvicorn\\server.py\", line 68, in serve\r\n    config.load()\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\uvicorn\\config.py\", line 467, in load\r\n    self.loaded_app = import_from_string(self.app)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\uvicorn\\importer.py\", line 21, in import_from_string   \r\n    module = importlib.import_module(module_str)\r\n  File \"C:\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\main.py\", line 3, in <module>\r\n    from apis import endpoints\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\apis\\endpoints.py\", line 4, in <module>\r\n    from controller.text_to_sql_controller import text_to_sql_controller\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\controller\\__init__.py\", line 1, in <module>\r\n    from .text_to_sql_controller import text_to_sql_controller\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\controller\\text_to_sql_controller.py\", line 2, in <module>\r\n    from llama_utils import QUERY_ENGINE\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\llama_utils\\__init__.py\", line 5, in <module>\r\n    QUERY_ENGINE = initialize_llama()\r\n  File \"C:\\Other Projects\\text-to-sql-generator\\backend\\llama_utils\\build_engine.py\", line 30, in initialize_llama\r\n    obj_index = ObjectIndex.from_objects(\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\llama_index\\objects\\base.py\", line 50, in from_objects\r\n    nodes = object_mapping.to_nodes(objects)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\llama_index\\objects\\base_node_mapping.py\", line 55, in to_nodes      \r\n    return [self.to_node(obj) for obj in objs]\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\llama_index\\objects\\base_node_mapping.py\", line 55, in <listcomp>    \r\n    return [self.to_node(obj) for obj in objs]\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\llama_index\\objects\\table_node_mapping.py\", line 47, in to_node\r\n    f\"{self._sql_database.get_single_table_info(obj.table_name)}\\n\"\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\llama_index\\langchain_helpers\\sql_wrapper.py\", line 52, in get_single_table_info\r\n    for column in self._inspector.get_columns(table_name):\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\sqlalchemy\\engine\\reflection.py\", line 859, in get_columns\r\n    col_defs = self.dialect.get_columns(\r\n  File \"<string>\", line 2, in get_columns\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\sqlalchemy\\engine\\reflection.py\", line 97, in cache\r\n    ret = fn(self, con, *args, **kw)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\base.py\", line 3484, in get_columns   \r\n    return self._value_or_raise(data, table_name, schema)\r\n  File \"c:\\Other Projects\\text-to-sql-generator\\backend\\env\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\base.py\", line 3452, in _value_or_raise\r\n    raise exc.NoSuchTableError(\r\nsqlalchemy.exc.NoSuchTableError: crawled_products\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8064/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8064/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8063",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8063/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8063/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8063/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8063",
        "id": 1936853226,
        "node_id": "I_kwDOIWuq585zcgjq",
        "number": 8063,
        "title": "[Question]: cannot import name 'VectorStoreIndex' from 'llama_index'",
        "user": {
            "login": "DataLearnerGitHub",
            "id": 139040169,
            "node_id": "U_kgDOCEmVqQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/139040169?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DataLearnerGitHub",
            "html_url": "https://github.com/DataLearnerGitHub",
            "followers_url": "https://api.github.com/users/DataLearnerGitHub/followers",
            "following_url": "https://api.github.com/users/DataLearnerGitHub/following{/other_user}",
            "gists_url": "https://api.github.com/users/DataLearnerGitHub/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DataLearnerGitHub/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DataLearnerGitHub/subscriptions",
            "organizations_url": "https://api.github.com/users/DataLearnerGitHub/orgs",
            "repos_url": "https://api.github.com/users/DataLearnerGitHub/repos",
            "events_url": "https://api.github.com/users/DataLearnerGitHub/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DataLearnerGitHub/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-11T05:23:26Z",
        "updated_at": "2023-10-12T16:37:13Z",
        "closed_at": "2023-10-12T16:37:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi,\r\nI'm having trouble importing the VectorStoreIndex class from the llama_index package. I've installed the package using pip, but I'm getting an ImportError when trying to import the class. Is there any known issue or workaround for this problem? I've followed the documentation, but I can't seem to resolve the ImportError.\r\n\r\nUsed :\r\npip install llama-index\r\nfrom llama_index import VectorStoreIndex",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8063/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8063/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8062",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8062/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8062/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8062/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8062",
        "id": 1936847479,
        "node_id": "I_kwDOIWuq585zcfJ3",
        "number": 8062,
        "title": "[Question]: Custom Callback when error is triggered by query response Azure OpenAI",
        "user": {
            "login": "skanda1005",
            "id": 53397947,
            "node_id": "MDQ6VXNlcjUzMzk3OTQ3",
            "avatar_url": "https://avatars.githubusercontent.com/u/53397947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/skanda1005",
            "html_url": "https://github.com/skanda1005",
            "followers_url": "https://api.github.com/users/skanda1005/followers",
            "following_url": "https://api.github.com/users/skanda1005/following{/other_user}",
            "gists_url": "https://api.github.com/users/skanda1005/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/skanda1005/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/skanda1005/subscriptions",
            "organizations_url": "https://api.github.com/users/skanda1005/orgs",
            "repos_url": "https://api.github.com/users/skanda1005/repos",
            "events_url": "https://api.github.com/users/skanda1005/events{/privacy}",
            "received_events_url": "https://api.github.com/users/skanda1005/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-11T05:16:36Z",
        "updated_at": "2023-10-12T16:37:40Z",
        "closed_at": "2023-10-12T16:37:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am looking to create and call a custom callback handler function which is triggered when AzureOpenAI RetrieverQueryResponse fails due to an error in AzureOpenAI. This should be handled by returning an empty string.\r\nI am using RetrieverQueryResponse with response mode as 'accumulate' and sometimes AzureOpenAI triggers an error which I would like to manually catch and handle by returning an empty string for the query response",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8062/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8062/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8061",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8061/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8061/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8061/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8061",
        "id": 1936845016,
        "node_id": "I_kwDOIWuq585zcejY",
        "number": 8061,
        "title": "KnowledgeGraph building using KnowledgeGraphIndex is very slow",
        "user": {
            "login": "rajendra-t",
            "id": 99479687,
            "node_id": "U_kgDOBe3whw",
            "avatar_url": "https://avatars.githubusercontent.com/u/99479687?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajendra-t",
            "html_url": "https://github.com/rajendra-t",
            "followers_url": "https://api.github.com/users/rajendra-t/followers",
            "following_url": "https://api.github.com/users/rajendra-t/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajendra-t/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajendra-t/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajendra-t/subscriptions",
            "organizations_url": "https://api.github.com/users/rajendra-t/orgs",
            "repos_url": "https://api.github.com/users/rajendra-t/repos",
            "events_url": "https://api.github.com/users/rajendra-t/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajendra-t/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-11T05:13:39Z",
        "updated_at": "2023-10-24T06:32:01Z",
        "closed_at": "2023-10-24T06:32:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi Team, \r\nWe have observed very slow performance while building KG for email data (extracted in txt format) vs building Vector Index. We have tried to run this as K8 Jobs but no improvement in performance. \r\n\r\nThe current throughput to build KG using KnowledgeGraphIndex is 500 emails per hour. \r\nPlease note building Vector Index using llama index for the same set of email text data takes - 2500 mails per hour \r\n(email is already deduplicated and curated - contains about 500 words in average. ) \r\n\r\nBelow are the details of configuration - \r\nllm - Azure Open AI (gpt-35-turbo for llm and text-embedding-ada-002 for embedding) \r\nGraph DB - Nebula v3.6 installed on K8\r\nllama-index==0.8.30\r\npymilvus==2.3.1\r\n\r\nPlease suggest if there is way to improve the performance of KG building ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8061/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8061/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8060",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8060/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8060/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8060/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8060",
        "id": 1936755438,
        "node_id": "PR_kwDOIWuq585cdb7-",
        "number": 8060,
        "title": "Javier/llama 485 support sqlalchemy<2",
        "user": {
            "login": "Javtor",
            "id": 8462127,
            "node_id": "MDQ6VXNlcjg0NjIxMjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8462127?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Javtor",
            "html_url": "https://github.com/Javtor",
            "followers_url": "https://api.github.com/users/Javtor/followers",
            "following_url": "https://api.github.com/users/Javtor/following{/other_user}",
            "gists_url": "https://api.github.com/users/Javtor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Javtor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Javtor/subscriptions",
            "organizations_url": "https://api.github.com/users/Javtor/orgs",
            "repos_url": "https://api.github.com/users/Javtor/repos",
            "events_url": "https://api.github.com/users/Javtor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Javtor/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-11T04:09:09Z",
        "updated_at": "2023-10-12T15:05:59Z",
        "closed_at": "2023-10-12T04:05:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8060",
            "html_url": "https://github.com/run-llama/llama_index/pull/8060",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8060.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8060.patch",
            "merged_at": "2023-10-12T04:05:53Z"
        },
        "body": "# Description\r\n\r\nSome database drivers don't support sqlalchemy 2.0 yet (snowflake, bigquery). This PR makes the changes so our minimum sqlalchemy version is 1.4, while still working with version 2.0.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8060/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8060/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8059",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8059/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8059/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8059/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8059",
        "id": 1936755162,
        "node_id": "PR_kwDOIWuq585cdb4J",
        "number": 8059,
        "title": "only specify name for gpt-index publish",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T04:08:44Z",
        "updated_at": "2023-10-11T04:12:52Z",
        "closed_at": "2023-10-11T04:12:51Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8059",
            "html_url": "https://github.com/run-llama/llama_index/pull/8059",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8059.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8059.patch",
            "merged_at": "2023-10-11T04:12:51Z"
        },
        "body": "Should help poetry publish work?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8059/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8059/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8058",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8058/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8058/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8058/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8058",
        "id": 1936753688,
        "node_id": "PR_kwDOIWuq585cdbkL",
        "number": 8058,
        "title": "add zephyr to docs",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T04:06:39Z",
        "updated_at": "2023-10-11T04:10:59Z",
        "closed_at": "2023-10-11T04:10:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8058",
            "html_url": "https://github.com/run-llama/llama_index/pull/8058",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8058.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8058.patch",
            "merged_at": "2023-10-11T04:10:58Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8058/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8058/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8057",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8057/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8057/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8057/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8057",
        "id": 1936735169,
        "node_id": "PR_kwDOIWuq585cdXrc",
        "number": 8057,
        "title": "[version] bump to v0.8.43",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T03:40:17Z",
        "updated_at": "2023-10-11T03:53:02Z",
        "closed_at": "2023-10-11T03:53:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8057",
            "html_url": "https://github.com/run-llama/llama_index/pull/8057",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8057.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8057.patch",
            "merged_at": "2023-10-11T03:53:01Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8057/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8057/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8056",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8056/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8056/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8056/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8056",
        "id": 1936720500,
        "node_id": "PR_kwDOIWuq585cdUlV",
        "number": 8056,
        "title": "Logan/selector llm prompt",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T03:19:54Z",
        "updated_at": "2023-10-11T03:27:02Z",
        "closed_at": "2023-10-11T03:27:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8056",
            "html_url": "https://github.com/run-llama/llama_index/pull/8056",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8056.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8056.patch",
            "merged_at": "2023-10-11T03:27:01Z"
        },
        "body": "Minor tweaks to help make prompts more straightforward and errors easier to debug",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8056/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8056/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8055",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8055/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8055/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8055/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8055",
        "id": 1936710350,
        "node_id": "I_kwDOIWuq585zb9rO",
        "number": 8055,
        "title": "[Help]:  How to combine multiple indexes into one ?",
        "user": {
            "login": "byronz3d",
            "id": 43394496,
            "node_id": "MDQ6VXNlcjQzMzk0NDk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/43394496?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/byronz3d",
            "html_url": "https://github.com/byronz3d",
            "followers_url": "https://api.github.com/users/byronz3d/followers",
            "following_url": "https://api.github.com/users/byronz3d/following{/other_user}",
            "gists_url": "https://api.github.com/users/byronz3d/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/byronz3d/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/byronz3d/subscriptions",
            "organizations_url": "https://api.github.com/users/byronz3d/orgs",
            "repos_url": "https://api.github.com/users/byronz3d/repos",
            "events_url": "https://api.github.com/users/byronz3d/events{/privacy}",
            "received_events_url": "https://api.github.com/users/byronz3d/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-11T03:08:29Z",
        "updated_at": "2023-10-24T06:31:59Z",
        "closed_at": "2023-10-24T06:31:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi,\r\n\r\nI want to create several collections in my Zep server, and then when a prompt/query arrives, I want to combine several collections into one index and be able to query the combined index.\r\nIs this even possible?\r\n\r\nWhat I tried to do, unsuccessfully, is something like:\r\n\r\n```\r\ndef load_zep(collection_name):\r\n        vector_store = ZepVectorStore(\r\n            api_url=zep_api_url, collection_name=collection_name\r\n        )\r\n\r\n        return StorageContext.from_defaults(vector_store=vector_store,persist_dir=f'./storage/{collection_name}')\r\n```\r\n\r\n```\r\n                from llama_index import load_index_from_storage, StorageContext\r\n\r\n                #load different collections \r\n                storage_context1 = load_zep('collection1')\r\n                storage_context2 = load_zep('collection2')\r\n                storage_context3 = load_zep('collection3')\r\n\r\n                #some how combine the above 3 collections into one\r\n\r\n                #tried various ways like combined = list(), but nothing worked\r\n\r\n                #load index from above combined \r\n                index = load_index_from_storage(combined) \r\n```\r\n\r\nThe logic behind this is I have various user levels and based on the user I want to give them a different index. Higher level users gets more indexes, while low level user gets a single index to query. I don't want to create the same index over and over if I can combine them somehow.\r\n\r\nThanks in advance!\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8055/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8055/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8054",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8054/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8054/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8054/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8054",
        "id": 1936535586,
        "node_id": "PR_kwDOIWuq585ccrmu",
        "number": 8054,
        "title": "open source structured output improvements",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-11T00:36:58Z",
        "updated_at": "2023-10-11T01:28:06Z",
        "closed_at": "2023-10-11T01:28:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8054",
            "html_url": "https://github.com/run-llama/llama_index/pull/8054",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8054.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8054.patch",
            "merged_at": "2023-10-11T01:28:05Z"
        },
        "body": "# Description\r\n\r\nVarious small tweaks to improve reliability of open-source models and structured outputs\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8054/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8054/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8053",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8053/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8053/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8053/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8053",
        "id": 1936484667,
        "node_id": "I_kwDOIWuq585zbGk7",
        "number": 8053,
        "title": "[Question]: How to use an OpenAI compatible API?",
        "user": {
            "login": "decentropy",
            "id": 7456235,
            "node_id": "MDQ6VXNlcjc0NTYyMzU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7456235?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/decentropy",
            "html_url": "https://github.com/decentropy",
            "followers_url": "https://api.github.com/users/decentropy/followers",
            "following_url": "https://api.github.com/users/decentropy/following{/other_user}",
            "gists_url": "https://api.github.com/users/decentropy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/decentropy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/decentropy/subscriptions",
            "organizations_url": "https://api.github.com/users/decentropy/orgs",
            "repos_url": "https://api.github.com/users/decentropy/repos",
            "events_url": "https://api.github.com/users/decentropy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/decentropy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-10T23:53:27Z",
        "updated_at": "2023-10-24T06:31:57Z",
        "closed_at": "2023-10-24T06:31:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFor example, GooseAI is AI compatible...\r\n\r\nThis works\r\n\r\n```\r\nimport openai\r\nopenai.api_key = \"sk-hidemykey\"\r\nopenai.api_base = \"https://api.goose.ai/v1\"\r\ncompletion = openai.Completion.create(\r\n  engine=\"gpt-j-6b\",\r\n  prompt=\"What is a Goose?\",\r\n  max_tokens=250,\r\n  stream=True)\r\nfor c in completion:\r\n  print (c.choices[0].text, end = '')\r\n```\r\nbut this fails\r\n\r\n```\r\nfrom llama_index.llms import OpenAI\r\nresp = OpenAI(\r\n    model=\"gpt-j-6b\",\r\n    api_key=\"sk-hidemykey\", \r\n    api_base=\"https://api.goose.ai/v1\").complete(\"What is a goose?\")\r\n```\r\nValueError: Unknown model 'gpt-j-6b'. Please provide a valid OpenAI model name in: gpt-4, gpt-4-32k, gpt-4-0613, gpt-4-32k-0613, gpt-4-0314, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-3.5-turbo-0301, text-davinci-003, text-davinci-002, gpt-3.5-turbo-instruct, text-ada-001, text-babbage-001, text-curie-001, ada, babbage, curie, davinci, gpt-35-turbo-16k, gpt-35-turbo\r\n\r\n\r\nIt seems that even though I change the api_base, it restricts itself to static openai models",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8053/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8053/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8052",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8052/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8052/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8052/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8052",
        "id": 1936391238,
        "node_id": "I_kwDOIWuq585zavxG",
        "number": 8052,
        "title": "[Question]: HierarchicalNodeParser sets each leafs ref_doc_id to the doc_id from the second level node. Is this intended?",
        "user": {
            "login": "mphipps2",
            "id": 5166558,
            "node_id": "MDQ6VXNlcjUxNjY1NTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5166558?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mphipps2",
            "html_url": "https://github.com/mphipps2",
            "followers_url": "https://api.github.com/users/mphipps2/followers",
            "following_url": "https://api.github.com/users/mphipps2/following{/other_user}",
            "gists_url": "https://api.github.com/users/mphipps2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mphipps2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mphipps2/subscriptions",
            "organizations_url": "https://api.github.com/users/mphipps2/orgs",
            "repos_url": "https://api.github.com/users/mphipps2/repos",
            "events_url": "https://api.github.com/users/mphipps2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mphipps2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-10-10T22:44:43Z",
        "updated_at": "2023-10-24T06:31:54Z",
        "closed_at": "2023-10-24T06:31:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm using the HierarchicalNodeParser as shown in this documentation: https://gpt-index.readthedocs.io/en/stable/examples/retrievers/auto_merging_retriever.html\r\n\r\nBut I noticed that each leaf node ref_doc_id is being set to the Node ID of its parent node (the second level node). So then when the retriever is called the response synthesizer acts across all the leaf chunks for a given second level node. So for example, if a given second level node has 4 children, those children would be compacted or refined based off the response_mode being used for the response_synthesizer, meaning we end up with one response back from our llm instead of 4. As I understand, this effectively turns the second level nodes into the new leaves. Was this the intended effect?\r\n\r\nTo prevent this from happening I have to hack together something like this: \r\nnode_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[2048,512,512]) ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8052/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8052/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8051",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8051/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8051/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8051/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8051",
        "id": 1936353393,
        "node_id": "I_kwDOIWuq585zamhx",
        "number": 8051,
        "title": "[Question]: Slowness of LLM inference step using chat engine",
        "user": {
            "login": "Swarnashree",
            "id": 8558897,
            "node_id": "MDQ6VXNlcjg1NTg4OTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8558897?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Swarnashree",
            "html_url": "https://github.com/Swarnashree",
            "followers_url": "https://api.github.com/users/Swarnashree/followers",
            "following_url": "https://api.github.com/users/Swarnashree/following{/other_user}",
            "gists_url": "https://api.github.com/users/Swarnashree/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Swarnashree/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Swarnashree/subscriptions",
            "organizations_url": "https://api.github.com/users/Swarnashree/orgs",
            "repos_url": "https://api.github.com/users/Swarnashree/repos",
            "events_url": "https://api.github.com/users/Swarnashree/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Swarnashree/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-10-10T22:11:01Z",
        "updated_at": "2023-10-24T06:31:52Z",
        "closed_at": "2023-10-24T06:31:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nHi, I am trying to setup a basic RAG chat pipeline with the below code and I am using [Mistral 7B instruct model](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1). I am noticing the generate function under the hood is a lot slower than the generate function from [liltom-eth/llama2-webui](https://github.com/liltom-eth/llama2-webui/blob/379273b408462ed04cdb8622f7f9fa080fdfff6c/llama2_wrapper/model.py#L251) setup for mistral model. (all other steps of retrieving nodes to be used in the prompt etc are fast enough. Only the step of generating content from the LLM is slow)\r\n\r\nI made sure to have the same settings for the LLM on both the webui project and also the llama-index project by setting these in the llama-index project:\r\n```python\r\nmodel_kwargs={\"torch_dtype\": torch.float16},\r\ngenerate_kwargs={\"do_sample\": True, \"top_p\": 0.95, \"top_k\": 50, \"temperature\": 0.8, \"num_beams\":1}\r\n```\r\n\r\nLlama-index RAG pipeline is as follows:\r\n```python\r\nfrom llama_index.llms import HuggingFaceLLM\r\nfrom llama_index import LangchainEmbedding\r\nfrom llama_index.langchain_helpers.text_splitter import SentenceSplitter\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\n\r\nllm = HuggingFaceLLM(\r\n    system_prompt=\"Consider you are a smart finanical assistant who has the capability to interpret SEC filings and answer the questions for the given text as expected.\",\r\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.1\",\r\n    model_name=\"mistralai/Mistral-7B-Instruct-v0.1\",\r\n    device_map=\"auto\",\r\n   model_kwargs={\"torch_dtype\": torch.float16},\r\n   generate_kwargs={\"do_sample\": True, \"top_p\": 0.95, \"top_k\": 50, \"temperature\": 0.8, \"num_beams\":1}\r\n)\r\n\r\nprompt_helper = PromptHelper.from_llm_metadata(llm_metadata=llm.metadata)\r\nembed_model = LangchainEmbedding(langchain_embeddings=HuggingFaceEmbeddings(\r\n        model_name=\"sentence-transformers/all-mpnet-base-v2\",\r\n    model_kwargs={'device': 'cuda:1'},\r\n    encode_kwargs={'normalize_embeddings': False}\r\n    ))\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    prompt_helper=prompt_helper,\r\n    node_parser=SimpleNodeParser(text_splitter=SentenceSplitter()),\r\n    embed_model=embed_model)\r\n\r\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\nchat_engine = index.as_chat_engine(chat_mode='context',retriever_mode='embedding', similarity_top_k=2)\r\n        \r\nstream_response=chat_engine.stream_chat(\"what are the tax implications of the said filing?\")\r\nstream_response.print_response_stream()\r\n```\r\n\r\nAny help on where the speed difference is coming, would be appreciated\r\nI am running them on 4 T4 GPUs and also noticed the GPU utilization during the generate function in the webui project is much higher % than that in the llama-index project which makes me wonder if there is some inefficiency of GPU utilization with the way I am setting up the RAG pipeline",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8051/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8051/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8050",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8050/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8050/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8050/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8050",
        "id": 1936240794,
        "node_id": "PR_kwDOIWuq585cbrG4",
        "number": 8050,
        "title": "feature: adds support for embeddings from gradient.ai",
        "user": {
            "login": "mhaligowski",
            "id": 158472,
            "node_id": "MDQ6VXNlcjE1ODQ3Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/158472?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mhaligowski",
            "html_url": "https://github.com/mhaligowski",
            "followers_url": "https://api.github.com/users/mhaligowski/followers",
            "following_url": "https://api.github.com/users/mhaligowski/following{/other_user}",
            "gists_url": "https://api.github.com/users/mhaligowski/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mhaligowski/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mhaligowski/subscriptions",
            "organizations_url": "https://api.github.com/users/mhaligowski/orgs",
            "repos_url": "https://api.github.com/users/mhaligowski/repos",
            "events_url": "https://api.github.com/users/mhaligowski/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mhaligowski/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-10T20:59:54Z",
        "updated_at": "2023-10-11T00:51:51Z",
        "closed_at": "2023-10-11T00:51:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8050",
            "html_url": "https://github.com/run-llama/llama_index/pull/8050",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8050.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8050.patch",
            "merged_at": "2023-10-11T00:51:50Z"
        },
        "body": "# Description\r\n\r\nAdds a new module for obtaining embeddings from [Gradient](https://docs.gradient.ai).\r\n\r\n> [!NOTE]\r\n> This feature needs [Gradient Python SDK](https://pypi.org/project/gradientai/) installed, with version at least `1.1.0`.\r\n\r\n\r\n\r\n## Type of Change\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nThe change is tested with a new unit test `tests/embeddings/test_gradient.py` that obtains some embeddings for simple examples from Gradient, using the [public client](https://pypi.org/project/gradientai/). To work correctly the Gradient SDK needs to be installed:\r\n\r\n```\r\npip install -U gradientai\r\n```\r\n\r\nThe test requires the change in the fixtures to provide the access token and workspace id. They can be generated from either:\r\n\r\n1. [Gradient website](https://auth.gradient.ai) or,\r\n1. [Gradient CLI](https://docs.gradient.ai/docs/cli-quickstart) with `gradient env --json` command.\r\n\r\n\r\n- [X] Added new unit/integration tests\r\n- [X] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n- [X] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8050/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8050/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8049",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8049/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8049/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8049/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8049",
        "id": 1935946486,
        "node_id": "PR_kwDOIWuq585caozH",
        "number": 8049,
        "title": "migrate setup.py to pyproject.toml",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-10T18:18:47Z",
        "updated_at": "2023-10-11T19:51:50Z",
        "closed_at": "2023-10-11T03:37:43Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8049",
            "html_url": "https://github.com/run-llama/llama_index/pull/8049",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8049.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8049.patch",
            "merged_at": "2023-10-11T03:37:43Z"
        },
        "body": "# Description\r\n\r\nThis PR is a first attempt at migrating from the old `setup.py` to a modern `pyproject.toml`\r\n\r\nI've add some extras, so that users can do something like `pip install llama-index[dataloaders, postrgres]` -- If users need other options, they can be contributed.\r\n\r\nI've also updated the CI to use poetry. Ran into some weird quirks along the way\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# TODO:\r\n\r\n- [x] update docs that mention installing from source\r\n- [x] update contribution guides for code and docs\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8049/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8049/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8048",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8048/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8048/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8048/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8048",
        "id": 1935932420,
        "node_id": "I_kwDOIWuq585zY_wE",
        "number": 8048,
        "title": "[Question]: Why is pickling the query engine not working, and how can I pickle it?",
        "user": {
            "login": "Idank96",
            "id": 56994399,
            "node_id": "MDQ6VXNlcjU2OTk0Mzk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/56994399?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Idank96",
            "html_url": "https://github.com/Idank96",
            "followers_url": "https://api.github.com/users/Idank96/followers",
            "following_url": "https://api.github.com/users/Idank96/following{/other_user}",
            "gists_url": "https://api.github.com/users/Idank96/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Idank96/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Idank96/subscriptions",
            "organizations_url": "https://api.github.com/users/Idank96/orgs",
            "repos_url": "https://api.github.com/users/Idank96/repos",
            "events_url": "https://api.github.com/users/Idank96/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Idank96/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-10-10T18:08:40Z",
        "updated_at": "2023-10-20T11:01:56Z",
        "closed_at": "2023-10-10T22:25:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, \r\nI would like to be able to pickle the query engine variable if the folder of documents did not change, for efficiency and cost savings. This would allow me to avoid rebuilding the index every time I want to query the documents.\r\n\r\nI have the following code:\r\n```\r\n        #  Loads a collection of documents from a directory\r\n        documents = SimpleDirectoryReader(\"data\").load_data()\r\n        # Creates a vector store index\r\n        index = VectorStoreIndex.from_documents(documents) \r\n        # Creates a query engine\r\n        query_engine = index.as_query_engine()\r\n        # Pickle the query_engine\r\n        with open(\"query_engine.pkl\", \"wb\") as file:\r\n            pickle.dump(query_engine, file)\r\n```\r\n\r\nI've tried with Pickle library and dll library but I got this error:\r\n`TypeError: cannot pickle 'builtins.CoreBPE' object\r\n`\r\n\r\nHow to save the query_engine variable? (its also occurs with index variable)\r\n\r\nAlso, if there is another solution for cost savings let please me know.\r\n\r\nThanks,\r\nIdan\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8048/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8048/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8047",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8047/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8047/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8047/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8047",
        "id": 1935323275,
        "node_id": "I_kwDOIWuq585zWrCL",
        "number": 8047,
        "title": "[Question]: Can chat engine be enabled for graph index?",
        "user": {
            "login": "sumitsahoo",
            "id": 6181114,
            "node_id": "MDQ6VXNlcjYxODExMTQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6181114?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sumitsahoo",
            "html_url": "https://github.com/sumitsahoo",
            "followers_url": "https://api.github.com/users/sumitsahoo/followers",
            "following_url": "https://api.github.com/users/sumitsahoo/following{/other_user}",
            "gists_url": "https://api.github.com/users/sumitsahoo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sumitsahoo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sumitsahoo/subscriptions",
            "organizations_url": "https://api.github.com/users/sumitsahoo/orgs",
            "repos_url": "https://api.github.com/users/sumitsahoo/repos",
            "events_url": "https://api.github.com/users/sumitsahoo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sumitsahoo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 23,
        "created_at": "2023-10-10T13:00:51Z",
        "updated_at": "2023-10-13T12:18:59Z",
        "closed_at": "2023-10-10T15:51:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI have gone through the document but my use case is to use a graph index. In short, I have multiple sources of information i.e. Database, File, and Directory. Hence I created a ListIndex for each and combine them to store it as a graph index. Now the issue is Graph index does not have `chat_engine` option i.e. `index.as_chat_engine(...)`.  It only has `query_engine`.\r\n\r\nI need the `chat_engine` option because I want to retain history and query from history which acts like memory while is same is not available for `query_engine`. Example below:\r\n\r\n```\r\nstream_response = chat_engine.stream_chat(message, chat_history=message_history)\r\n```\r\nHere `message_history` is an array of `ChatMessage`. \r\n\r\nAny recommendations, please? What is the best way to have index from different sources and use `chat_engine` to have a memory as well? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8047/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8047/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8046",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8046/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8046/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8046/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8046",
        "id": 1935049335,
        "node_id": "I_kwDOIWuq585zVoJ3",
        "number": 8046,
        "title": "[Bug]: Requested tokens (2065) exceed context window of 1800",
        "user": {
            "login": "DaveScream",
            "id": 3002276,
            "node_id": "MDQ6VXNlcjMwMDIyNzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3002276?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DaveScream",
            "html_url": "https://github.com/DaveScream",
            "followers_url": "https://api.github.com/users/DaveScream/followers",
            "following_url": "https://api.github.com/users/DaveScream/following{/other_user}",
            "gists_url": "https://api.github.com/users/DaveScream/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DaveScream/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DaveScream/subscriptions",
            "organizations_url": "https://api.github.com/users/DaveScream/orgs",
            "repos_url": "https://api.github.com/users/DaveScream/repos",
            "events_url": "https://api.github.com/users/DaveScream/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DaveScream/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-10T10:46:46Z",
        "updated_at": "2023-10-10T15:50:17Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI specified to use 1800 tokens max. But at some point have error that requested tokens exeeds max tokens limit.\n\n### Version\n\nllama_index-0.8.41\n\n### Steps to Reproduce\n\n```\r\nimport llama_index.embeddings.adapter\r\nimport llama_index\r\n\r\nfrom llama_index import (\r\n    SimpleDirectoryReader,\r\n    VectorStoreIndex,\r\n    ServiceContext,\r\n    StorageContext,\r\n)\r\nfrom llama_index.llms import LlamaCPP\r\nfrom llama_index.callbacks import CallbackManager\r\n\r\nLLM_TEMPLATE = \"### Instruction:\\n\\n{instruction}\\n\\n### Response:\\n\\n\"\r\n\r\ndef messages_to_prompt(messages):\r\n    message_str = \"\\n\".join([str(x) for x in messages])\r\n    prompt = LLM_TEMPLATE.format(instruction=message_str)\r\n    return prompt\r\n\r\ndef completion_to_prompt(completion):\r\n    prompt = LLM_TEMPLATE.format(instruction=completion)\r\n    return prompt\r\n\r\nllm = LlamaCPP(\r\n    model_path='C:/LLMs/oobabooga_windows/text-generation-webui/models/openorca-platypus2-13b.Q4_K_M.gguf',\r\n    temperature=0.75,\r\n    max_new_tokens=256,\r\n    context_window=1800,\r\n    generate_kwargs={\"top_p\": 1,},\r\n    model_kwargs={\"n_gpu_layers\": 32, \"n_batch\": 512, \"n_threads\": 10},\r\n    verbose=True,\r\n    messages_to_prompt=messages_to_prompt,\r\n    completion_to_prompt=completion_to_prompt)\r\n\r\nservice_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\r\ndata = SimpleDirectoryReader(input_dir=\"C:/temp_my/text_embeddings\").load_data()\r\nindex = VectorStoreIndex.from_documents(data, service_context=service_context)\r\n\r\nfrom llama_index.chat_engine.types import ChatMode\r\nchat_engine = index.as_chat_engine(service_context=service_context, chat_mode=ChatMode.CONTEXT, verbose=True)\r\n\r\nresponse = chat_engine.chat(\"What this book is about? List the names of main characters. And tell the story short.\")\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nException has occurred: ValueError       (note: full exception trace is shown but execution is paused at: _run_module_as_main)\r\nRequested tokens (2065) exceed context window of 1800\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_cpp\\llama.py\", line 947, in _create_completion\r\n    raise ValueError(\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_cpp\\llama.py\", line 1442, in create_completion\r\n    completion: Completion = next(completion_or_chunks)  # type: ignore\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_cpp\\llama.py\", line 1491, in __call__\r\n    return self.create_completion(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\llms\\llama_cpp.py\", line 223, in complete\r\n    response = self._model(prompt=prompt, **self.generate_kwargs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\llms\\base.py\", line 277, in wrapped_llm_predict\r\n    f_return_val = f(_self, *args, **kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\llms\\llama_cpp.py\", line 204, in chat\r\n    completion_response = self.complete(prompt, formatted=True, **kwargs)\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\llms\\base.py\", line 151, in wrapped_llm_chat\r\n    f_return_val = f(_self, messages, **kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\chat_engine\\context.py\", line 159, in chat\r\n    chat_response = self._llm.chat(all_messages)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\.venv\\Lib\\site-packages\\llama_index\\callbacks\\utils.py\", line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\Projects\\SharikAI\\My_llama_index.py\", line 87, in <module>\r\n    response = chat_engine.chat(\"What this book is about? List the names of main characters. And tell the story short.\")\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Python311\\Lib\\runpy.py\", line 88, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Python311\\Lib\\runpy.py\", line 198, in _run_module_as_main (Current frame)\r\n    return _run_code(code, main_globals, None,\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nValueError: Requested tokens (2065) exceed context window of 1800\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8046/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8046/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8045",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8045/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8045/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8045/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8045",
        "id": 1934839436,
        "node_id": "I_kwDOIWuq585zU06M",
        "number": 8045,
        "title": "[Bug]: Chat Prompts Customization",
        "user": {
            "login": "malinphy",
            "id": 55249305,
            "node_id": "MDQ6VXNlcjU1MjQ5MzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/55249305?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/malinphy",
            "html_url": "https://github.com/malinphy",
            "followers_url": "https://api.github.com/users/malinphy/followers",
            "following_url": "https://api.github.com/users/malinphy/following{/other_user}",
            "gists_url": "https://api.github.com/users/malinphy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/malinphy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/malinphy/subscriptions",
            "organizations_url": "https://api.github.com/users/malinphy/orgs",
            "repos_url": "https://api.github.com/users/malinphy/repos",
            "events_url": "https://api.github.com/users/malinphy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/malinphy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-10T09:04:29Z",
        "updated_at": "2023-10-10T15:47:39Z",
        "closed_at": "2023-10-10T15:47:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nversion llama_index\n\n### Version\n\n0.8.42\n\n### Steps to Reproduce\n\nfirst example at Chat Prompts Customization: https://gpt-index.readthedocs.io/en/v0.7.11/examples/customization/prompts/chat_prompts.html\r\n\r\nllama_index gives the following error at following versions.\r\n![image](https://github.com/run-llama/llama_index/assets/55249305/72aefd6e-6bc7-4409-b5b5-a18f49f4943b)\r\n\r\nHowever, It works for the combination of llama_index==0.6.15  & langchain==0.0.200\n\n### Relevant Logs/Tracbacks\n\n```shell\nAttributeError                            Traceback (most recent call last)\r\n\r\n<ipython-input-7-c40219eb336e> in <cell line: 24>()\r\n     22 ]\r\n     23 chat_text_qa_msgs_lc = ChatPromptTemplate.from_messages(chat_text_qa_msgs)\r\n---> 24 text_qa_template = Prompt.from_langchain_prompt(chat_text_qa_msgs_lc)\r\n\r\nAttributeError: type object 'PromptTemplate' has no attribute 'from_langchain_prompt'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8045/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8045/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8044",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8044/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8044/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8044/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8044",
        "id": 1934769680,
        "node_id": "I_kwDOIWuq585zUj4Q",
        "number": 8044,
        "title": "[Feature Request]:  Add user specific items inside the JSON in the LLMSingSelector",
        "user": {
            "login": "terilias",
            "id": 37142366,
            "node_id": "MDQ6VXNlcjM3MTQyMzY2",
            "avatar_url": "https://avatars.githubusercontent.com/u/37142366?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/terilias",
            "html_url": "https://github.com/terilias",
            "followers_url": "https://api.github.com/users/terilias/followers",
            "following_url": "https://api.github.com/users/terilias/following{/other_user}",
            "gists_url": "https://api.github.com/users/terilias/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/terilias/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/terilias/subscriptions",
            "organizations_url": "https://api.github.com/users/terilias/orgs",
            "repos_url": "https://api.github.com/users/terilias/repos",
            "events_url": "https://api.github.com/users/terilias/events{/privacy}",
            "received_events_url": "https://api.github.com/users/terilias/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-10T08:37:37Z",
        "updated_at": "2023-10-12T19:14:28Z",
        "closed_at": "2023-10-12T19:14:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nLet's say that we use LLMSingleSelector in the RouterQueryEngine. According to the [documentation](https://docs.llamaindex.ai/en/stable/examples/query_engine/RouterQueryEngine.html#llmsingleselector) we ask LLM to choose between some query engines by providing it with their descriptions. We ask LLM to give its answer in  JSON format. The format of the JSON is defined using an output parser and we can find it in the [selection.py](https://github.com/run-llama/llama_index/blob/main/llama_index/output_parsers/selection.py). Then the LLMSingleSelector reads this JSON and choose the query engine that will use. \r\n\r\nBut what if we need some extra information from the LLM? In my use case I want to ask LLM one more thing when using LLMSingleSelector. I need to ask for example \"If your choise is to use the query about the plants of my garden, please give me the optimal K that I need to use if I want to perform KNN similarity search to answer the user's query. Give me the choise of K in a key-value pair.\"\r\n\r\nMaybe I have understand something wrong. Or probably the value of the feature is very minor but I decided to report it just in case that you consider it useful. Thank you anyway for the time and effort you put to make LlamaIndex!\n\n### Reason\n\nI am thinking that I can send a different call to LLM to ask for K. But this requires an extra call. Maybe it is a good idea to have it inside the Selection process.\n\n### Value of Feature\n\nTo avoid making an extra LLM call. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8044/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8044/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8043",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8043/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8043/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8043/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8043",
        "id": 1934747927,
        "node_id": "I_kwDOIWuq585zUekX",
        "number": 8043,
        "title": "[Bug]: ",
        "user": {
            "login": "mihir-wai",
            "id": 133767498,
            "node_id": "U_kgDOB_khSg",
            "avatar_url": "https://avatars.githubusercontent.com/u/133767498?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mihir-wai",
            "html_url": "https://github.com/mihir-wai",
            "followers_url": "https://api.github.com/users/mihir-wai/followers",
            "following_url": "https://api.github.com/users/mihir-wai/following{/other_user}",
            "gists_url": "https://api.github.com/users/mihir-wai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mihir-wai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mihir-wai/subscriptions",
            "organizations_url": "https://api.github.com/users/mihir-wai/orgs",
            "repos_url": "https://api.github.com/users/mihir-wai/repos",
            "events_url": "https://api.github.com/users/mihir-wai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mihir-wai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-10T08:24:56Z",
        "updated_at": "2023-10-10T08:54:17Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nUsing TokenCountingHandler on agents doesn't take into account the function descriptions sent as custom tools and doesn't return the right number of tokens.\n\n### Version\n\nllama-index 0.8.33\n\n### Steps to Reproduce\n\n```\r\nimport warnings\r\nfrom datetime import date\r\nfrom typing import Any, Sequence\r\n\r\nfrom llama_index.llms import OpenAI\r\nfrom llama_index.agent import OpenAIAgent\r\nfrom llama_index.tools import FunctionTool\r\nfrom llama_index.llms.base import ChatMessage, ChatResponse\r\nfrom llama_index.llms.openai_utils import (\r\n    completion_with_retry,\r\n    from_openai_message_dict,\r\n    to_openai_message_dicts,\r\n)\r\n\r\nimport tiktoken\r\nfrom llama_index.callbacks import CallbackManager, TokenCountingHandler\r\nfrom llama_index import ServiceContext, set_global_service_context\r\n\r\n\r\nimport logging\r\n\r\nwarnings.filterwarnings(\"ignore\")\r\n\r\ndef _chat(self, messages: Sequence[ChatMessage], **kwargs: Any) -> ChatResponse:\r\n    global prompt_token_counter, completion_token_counter\r\n    message_dicts = to_openai_message_dicts(messages)\r\n    response = completion_with_retry(\r\n        is_chat_model=True,\r\n        max_retries=self.max_retries,\r\n        messages=message_dicts,\r\n        stream=False,\r\n        **self._get_all_kwargs(**kwargs),\r\n    )\r\n\r\n    message_dict = response[\"choices\"][0][\"message\"]\r\n    message = from_openai_message_dict(message_dict)\r\n    print(\"Usage as given by OpenAI API\")\r\n    print(response[\"usage\"])\r\n    print()\r\n\r\n    return ChatResponse(\r\n        message=message,\r\n        raw=response,\r\n        additional_kwargs=self._get_response_token_counts(response),\r\n    )\r\n\r\nOpenAI._chat = _chat\r\n\r\ndef get_todays_date():\r\n    \"\"\"\r\n    Use this to get today's date\r\n    \"\"\"\r\n    return str(date.today())\r\n\r\nclass Agent:\r\n    def __init__(self):\r\n        self.llm = OpenAI(temperature=0.2, model=\"gpt-3.5-turbo-0613\")\r\n        self.date_tool = FunctionTool.from_defaults(fn=get_todays_date)\r\n        self.agent = OpenAIAgent.from_tools(\r\n            [self.date_tool],\r\n            llm=self.llm,\r\n            verbose=True,\r\n        )\r\n\r\n        self.token_counter = TokenCountingHandler(\r\n        tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo-0613\").encode, verbose=False)\r\n        callback_manager = CallbackManager([self.token_counter])\r\n        service_context = ServiceContext.from_defaults(llm=self.llm, callback_manager=callback_manager)\r\n        set_global_service_context(service_context)\r\n\r\n    def get_response(self, query):\r\n        response = str(self.agent.chat(query))\r\n        logging.info(f\"The response from the agent is: {response}\")\r\n        return response\r\n\r\nagent = Agent()\r\ntoken_counter = agent.token_counter\r\nprint(agent.get_response(\"What is today's date?\"))\r\nprint()\r\nprint(\"Usage as given by TokenCountingHandler\")\r\nprint(\r\n    f\"LLM Prompt Tokens: {token_counter.prompt_llm_token_count}\\n\",\r\n    f\"LLM Completion Tokens: {token_counter.completion_llm_token_count}\\n\",\r\n    f\"Total LLM Token Count: {token_counter.total_llm_token_count}\\n\",\r\n)\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nUsage as given by OpenAI API\r\n{\r\n  \"completion_tokens\": 10,\r\n  \"prompt_tokens\": 56,\r\n  \"total_tokens\": 66\r\n}\r\n\r\n=== Calling Function ===\r\nCalling function: get_todays_date with args: {}\r\nGot output: 2023-10-10\r\n========================\r\nUsage as given by OpenAI API\r\n{\r\n  \"completion_tokens\": 13,\r\n  \"prompt_tokens\": 83,\r\n  \"total_tokens\": 96\r\n}\r\n\r\nToday's date is October 10, 2023.\r\n\r\nUsage as given by TokenCountingHandler\r\nLLM Prompt Tokens: 29\r\n LLM Completion Tokens: 17\r\n Total LLM Token Count: 46\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8043/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8043/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8042",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8042/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8042/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8042/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8042",
        "id": 1934740186,
        "node_id": "I_kwDOIWuq585zUcra",
        "number": 8042,
        "title": "[Bug]: RecursionError when indexing files",
        "user": {
            "login": "thunderbug1",
            "id": 1395321,
            "node_id": "MDQ6VXNlcjEzOTUzMjE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1395321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thunderbug1",
            "html_url": "https://github.com/thunderbug1",
            "followers_url": "https://api.github.com/users/thunderbug1/followers",
            "following_url": "https://api.github.com/users/thunderbug1/following{/other_user}",
            "gists_url": "https://api.github.com/users/thunderbug1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thunderbug1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thunderbug1/subscriptions",
            "organizations_url": "https://api.github.com/users/thunderbug1/orgs",
            "repos_url": "https://api.github.com/users/thunderbug1/repos",
            "events_url": "https://api.github.com/users/thunderbug1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thunderbug1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-10T08:20:37Z",
        "updated_at": "2023-10-20T00:21:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nWhen Indexing a number of pdf documents the code runs into a RecursionError when creating the index and calculating the embeddings.\r\n\r\n### Version\r\n\r\ntested in: llama-index==0.8.36 + llama-index==0.8.42\r\n\r\n### Steps to Reproduce\r\n\r\nI sadly cannot provide the documents since they are confidential but I hope with the stacktrace we can already work out a solution for the bug or to handle it more gracefully\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nFile \"/code/llm.py\", line 223, in _build_index\r\n    index = GPTVectorStoreIndex.from_documents(documents, \r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/indices/base.py\", line 98, in from_documents\r\n    nodes = service_context.node_parser.get_nodes_from_documents(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/node_parser/simple.py\", line 95, in get_nodes_from_documents\r\n    nodes = get_nodes_from_document(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/node_parser/node_utils.py\", line 106, in get_nodes_from_document\r\n    return get_nodes_from_node(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/node_parser/node_utils.py\", line 125, in get_nodes_from_node\r\n    text_splits = text_splitter.split_text_metadata_aware(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 139, in split_text_metadata_aware\r\n    return self._split_text(text, chunk_size=effective_chunk_size)\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 156, in _split_text\r\n    splits = self._split(text, chunk_size)\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 183, in _split\r\n    recursive_text_splits = self._split(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 183, in _split\r\n    recursive_text_splits = self._split(\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 183, in _split\r\n    recursive_text_splits = self._split(\r\n  [Previous line repeated 970 more times]\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 176, in _split\r\n    text_splits_by_fns, is_sentence = self._get_splits_by_fns(text)\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 273, in _get_splits_by_fns\r\n    splits = split_fn(text)\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/utils.py\", line 58, in split\r\n    spans = [s for s in tokenizer.span_tokenize(text)]\r\n  File \"/usr/local/lib/python3.9/site-packages/llama_index/text_splitter/utils.py\", line 58, in <listcomp>\r\n    spans = [s for s in tokenizer.span_tokenize(text)]\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1329, in span_tokenize\r\n    for sentence in slices:\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1459, in _realign_boundaries\r\n    for sentence1, sentence2 in _pair_iter(slices):\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 321, in _pair_iter\r\n    prev = next(iterator)\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1432, in _slices_from_text\r\n    if self.text_contains_sentbreak(context):\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1480, in text_contains_sentbreak\r\n    for tok in self._annotate_tokens(self._tokenize_words(text)):\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1622, in _annotate_second_pass\r\n    for token1, token2 in _pair_iter(tokens):\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 321, in _pair_iter\r\n    prev = next(iterator)\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 603, in _annotate_first_pass\r\n    for aug_tok in tokens:\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 572, in _tokenize_words\r\n    yield self._Token(tok, parastart=parastart, linestart=True)\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 403, in __init__\r\n    self.type = self._get_type(tok)\r\n  File \"/usr/local/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 426, in _get_type\r\n    return self._RE_NUMERIC.sub(\"##number##\", tok.lower())\r\nRecursionError: maximum recursion depth exceeded while calling a Python object\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8042/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8042/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8041",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8041/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8041/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8041/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8041",
        "id": 1934633205,
        "node_id": "PR_kwDOIWuq585cWD33",
        "number": 8041,
        "title": "[version] bump version to 0.8.42",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-10T07:48:05Z",
        "updated_at": "2023-10-10T07:59:35Z",
        "closed_at": "2023-10-10T07:59:35Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8041",
            "html_url": "https://github.com/run-llama/llama_index/pull/8041",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8041.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8041.patch",
            "merged_at": "2023-10-10T07:59:35Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8041/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8041/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8040",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8040/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8040/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8040/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8040",
        "id": 1934439910,
        "node_id": "PR_kwDOIWuq585cVY3x",
        "number": 8040,
        "title": "`codespell` in `pre-commit`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-10T06:00:16Z",
        "updated_at": "2023-10-11T08:23:03Z",
        "closed_at": "2023-10-11T08:23:00Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8040",
            "html_url": "https://github.com/run-llama/llama_index/pull/8040",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8040.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8040.patch",
            "merged_at": "2023-10-11T08:23:00Z"
        },
        "body": "# Description\r\n\r\n- Moves `codespell` to be run and version managed by `pre-commit`\r\n- Fixes more typos\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8040/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8040/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8039",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8039/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8039/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8039/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8039",
        "id": 1934327825,
        "node_id": "I_kwDOIWuq585zS4AR",
        "number": 8039,
        "title": "[Feature Request]: Configurable `retry time` for LLM calls",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 6129428377,
                "node_id": "LA_kwDOIWuq588AAAABbVenmQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/request%20contribution%20board",
                "name": "request contribution board",
                "color": "D93F0B",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-10T04:31:35Z",
        "updated_at": "2023-11-02T17:14:13Z",
        "closed_at": "2023-11-02T17:14:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nCurrently, the `min_seconds` and `max_seconds` for retrying an LLM call have a fixed default value. Allowing users to configure these values can provide more flexibility in different scenarios.\r\n\r\nReference:\r\n\r\n`https://github.com/run-llama/llama_index/blob/f4c14c331b62a9d25b80cf63fe1d5cdf2abe4a1d/llama_index/llms/openai_utils.py#L111`\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\nDifferent applications might have varying requirements for retry mechanisms. By allowing users to set their desired retry times, the LLM can be more adaptable to a broader range of applications.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8039/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8039/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8038",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8038/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8038/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8038/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8038",
        "id": 1934296183,
        "node_id": "PR_kwDOIWuq585cU4pL",
        "number": 8038,
        "title": "More `ruff` enables (PYI, SIM, etc.)",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-10T04:09:20Z",
        "updated_at": "2023-10-10T16:04:15Z",
        "closed_at": "2023-10-10T15:55:22Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8038",
            "html_url": "https://github.com/run-llama/llama_index/pull/8038",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8038.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8038.patch",
            "merged_at": "2023-10-10T15:55:22Z"
        },
        "body": "# Description\r\n\r\n- Manually fixes a few ruff errors\r\n- Enables more ruff rules that support autofixing or already pass\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8038/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8038/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8037",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8037/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8037/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8037/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8037",
        "id": 1933995700,
        "node_id": "I_kwDOIWuq585zRm60",
        "number": 8037,
        "title": "[Bug]: document_summary/retrievers.py scores missing for returned node results ",
        "user": {
            "login": "mphipps2",
            "id": 5166558,
            "node_id": "MDQ6VXNlcjUxNjY1NTg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5166558?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mphipps2",
            "html_url": "https://github.com/mphipps2",
            "followers_url": "https://api.github.com/users/mphipps2/followers",
            "following_url": "https://api.github.com/users/mphipps2/following{/other_user}",
            "gists_url": "https://api.github.com/users/mphipps2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mphipps2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mphipps2/subscriptions",
            "organizations_url": "https://api.github.com/users/mphipps2/orgs",
            "repos_url": "https://api.github.com/users/mphipps2/repos",
            "events_url": "https://api.github.com/users/mphipps2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mphipps2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-09T23:21:49Z",
        "updated_at": "2023-10-09T23:30:07Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe DocumentSummaryIndexEmbeddingRetriever is not storing the node similarity scores as it should in its returned results. \r\n\r\n\r\nTo fix, store the scores returned from get_top_k_embeddings and initialize each NodeWithScore like this:\r\n            # Using the scores returned by get_top_k_embeddings\r\n            for node in nodes:\r\n                results.append(NodeWithScore(node=node, score=result_similarities[i]))  \r\n                \r\nSo the corrected code should look like:\r\n\r\nclass DocumentSummaryIndexEmbeddingRetriever(BaseRetriever):\r\n    \"\"\"Document Summary Index Embedding Retriever.\r\n\r\n    Generates embeddings on the fly, attaches to each summary node.\r\n\r\n    NOTE: implementation is similar to SummaryIndexEmbeddingRetriever.\r\n\r\n    Args:\r\n        index (DocumentSummaryIndex): The index to retrieve from.\r\n\r\n    \"\"\"\r\n\r\n    def __init__(\r\n        self, index: DocumentSummaryIndex, similarity_top_k: int = 1, **kwargs: Any\r\n    ) -> None:\r\n        \"\"\"Init params.\"\"\"\r\n        self._index = index\r\n        self._similarity_top_k = similarity_top_k\r\n\r\n    def _retrieve(\r\n        self,\r\n        query_bundle: QueryBundle,\r\n    ) -> List[NodeWithScore]:\r\n        \"\"\"Retrieve nodes.\"\"\"\r\n        summary_ids = self._index.index_struct.summary_ids\r\n        summary_nodes = self._index.docstore.get_nodes(summary_ids)\r\n        query_embedding, node_embeddings = self._get_embeddings(\r\n            query_bundle, summary_nodes\r\n        )\r\n\r\n        result_similarities, top_idxs = get_top_k_embeddings(\r\n            query_embedding,\r\n            node_embeddings,\r\n            similarity_top_k=self._similarity_top_k,\r\n            embedding_ids=list(range(len(summary_nodes))),\r\n        )\r\n\r\n        top_k_summary_ids = [summary_ids[i] for i in top_idxs]\r\n        results = []\r\n        for i, summary_id in enumerate(top_k_summary_ids):\r\n            node_ids = self._index.index_struct.summary_id_to_node_ids[summary_id]\r\n            nodes = self._index.docstore.get_nodes(node_ids)\r\n            # Using the scores returned by get_top_k_embeddings\r\n            for node in nodes:\r\n                results.append(NodeWithScore(node=node, score=result_similarities[i]))        \r\n        return results\n\n### Version\n\n0.8.38\n\n### Steps to Reproduce\n\nInitialize a DocumentSummaryIndexEmbeddingRetriever and inspect the returned node objects. The scores are missing\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8037/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8037/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8036",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8036/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8036/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8036/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8036",
        "id": 1933984317,
        "node_id": "PR_kwDOIWuq585cTzVh",
        "number": 8036,
        "title": "add unstructured table element node parser ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-09T23:10:10Z",
        "updated_at": "2023-10-10T07:41:48Z",
        "closed_at": "2023-10-10T07:41:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8036",
            "html_url": "https://github.com/run-llama/llama_index/pull/8036",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8036.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8036.patch",
            "merged_at": "2023-10-10T07:41:47Z"
        },
        "body": "this notebook is able to parse any HTML document object into a set of nodes. \r\n\r\nusage is similar to our node parsers here: #7863\r\n\r\nincludes a `get_base_nodes_and_mappings` function so that users can extract our the \"base\" nodes + underlying table nodes, and setup recursive retrieval \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8036/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8036/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8035",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8035/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8035/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8035/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8035",
        "id": 1933842331,
        "node_id": "PR_kwDOIWuq585cTTEi",
        "number": 8035,
        "title": "Updating Reference to RAGAS LlamaIndex Integration",
        "user": {
            "login": "chris-alexiuk",
            "id": 19699016,
            "node_id": "MDQ6VXNlcjE5Njk5MDE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/19699016?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chris-alexiuk",
            "html_url": "https://github.com/chris-alexiuk",
            "followers_url": "https://api.github.com/users/chris-alexiuk/followers",
            "following_url": "https://api.github.com/users/chris-alexiuk/following{/other_user}",
            "gists_url": "https://api.github.com/users/chris-alexiuk/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chris-alexiuk/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chris-alexiuk/subscriptions",
            "organizations_url": "https://api.github.com/users/chris-alexiuk/orgs",
            "repos_url": "https://api.github.com/users/chris-alexiuk/repos",
            "events_url": "https://api.github.com/users/chris-alexiuk/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chris-alexiuk/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-09T21:22:51Z",
        "updated_at": "2023-10-09T21:41:17Z",
        "closed_at": "2023-10-09T21:41:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8035",
            "html_url": "https://github.com/run-llama/llama_index/pull/8035",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8035.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8035.patch",
            "merged_at": "2023-10-09T21:41:16Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] I clicked the link, and verified it went where I wanted it to go!\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8035/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8035/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8034",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8034/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8034/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8034/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8034",
        "id": 1933760364,
        "node_id": "I_kwDOIWuq585zQtds",
        "number": 8034,
        "title": "[Bug]: 'Llama' object has no attribute 'context_params'",
        "user": {
            "login": "DaveScream",
            "id": 3002276,
            "node_id": "MDQ6VXNlcjMwMDIyNzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3002276?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DaveScream",
            "html_url": "https://github.com/DaveScream",
            "followers_url": "https://api.github.com/users/DaveScream/followers",
            "following_url": "https://api.github.com/users/DaveScream/following{/other_user}",
            "gists_url": "https://api.github.com/users/DaveScream/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DaveScream/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DaveScream/subscriptions",
            "organizations_url": "https://api.github.com/users/DaveScream/orgs",
            "repos_url": "https://api.github.com/users/DaveScream/repos",
            "events_url": "https://api.github.com/users/DaveScream/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DaveScream/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-09T20:34:52Z",
        "updated_at": "2023-10-09T20:39:25Z",
        "closed_at": "2023-10-09T20:39:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nIm getting error 'Llama' object has no attribute 'context_params' here:\r\n`service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")`\r\n\r\nHere is merged pull request containing this fix: https://github.com/run-llama/llama_index/pull/7945\r\n\r\nBut Im on latest version now (pip install llama-index --upgrade) and its not working.\r\n\r\n### Version\r\n\r\nllama_index-0.8.41\r\n\r\n### Steps to Reproduce\r\n\r\nimport llama_index.embeddings.adapter\r\nimport llama_index\r\n\r\nfrom llama_index import (\r\n    SimpleDirectoryReader,\r\n    VectorStoreIndex,\r\n    ServiceContext,\r\n    #KeywordTableIndex,\r\n    #LLMPredictor\r\n)\r\nfrom llama_index.llms import LlamaCPP\r\n\r\n....\r\n\r\n\r\nllm = LlamaCPP(\r\n    # optionally, you can set the path to a pre-downloaded model instead of model_url\r\n    model_path='C:/LLMs/oobabooga_windows/text-generation-webui/models/openorca-platypus2-13b.Q4_K_M.gguf',\r\n    temperature=0.75,\r\n    # The maximum number of tokens to generate.\r\n    max_new_tokens=256,\r\n    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\r\n    context_window=3900,\r\n    #max_tokens=3900,\r\n    # kwargs to pass to __call__()\r\n    generate_kwargs={\"top_p\": 1,},\r\n    # kwargs to pass to __init__()\r\n    # set to at least 1 to use GPU\r\n    model_kwargs={\"n_gpu_layers\": 32, \"n_batch\": 512, \"n_threads\": 10},\r\n    #n_gpu_layers=32,\r\n    #n_batch=512\r\n    #n_threads=10,\r\n    \r\n    #callback_manager=callback_manager,\r\n    verbose=True,\r\n\r\n    # transform inputs into Llama2 format\r\n    # The function to convert messages to a prompt\r\n    messages_to_prompt=messages_to_prompt,\r\n    # The function to convert a completion to a prompt.\r\n    completion_to_prompt=completion_to_prompt,\r\n    )\r\n# load data and build index\r\nservice_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nException has occurred: AttributeError\r\n'Llama' object has no attribute 'context_params'\r\n  File \"F:\\Projects\\SharikAI\\My_llama_index.py\", line 65, in <module>\r\n    service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local\")\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'Llama' object has no attribute 'context_params'\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8034/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8034/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8033",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8033/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8033/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8033/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8033",
        "id": 1933731863,
        "node_id": "I_kwDOIWuq585zQmgX",
        "number": 8033,
        "title": "[Bug]: No module named 'llama_index.embeddings.adapter' after update",
        "user": {
            "login": "DaveScream",
            "id": 3002276,
            "node_id": "MDQ6VXNlcjMwMDIyNzY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3002276?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DaveScream",
            "html_url": "https://github.com/DaveScream",
            "followers_url": "https://api.github.com/users/DaveScream/followers",
            "following_url": "https://api.github.com/users/DaveScream/following{/other_user}",
            "gists_url": "https://api.github.com/users/DaveScream/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DaveScream/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DaveScream/subscriptions",
            "organizations_url": "https://api.github.com/users/DaveScream/orgs",
            "repos_url": "https://api.github.com/users/DaveScream/repos",
            "events_url": "https://api.github.com/users/DaveScream/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DaveScream/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-09T20:20:15Z",
        "updated_at": "2023-10-09T20:26:26Z",
        "closed_at": "2023-10-09T20:26:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAfter update Iam getting error No module named 'llama_index.embeddings.adapter'\n\n### Version\n\nSuccessfully installed llama-index-0.8.41\n\n### Steps to Reproduce\n\nimport llama_index\n\n### Relevant Logs/Tracbacks\n\n```shell\nException has occurred: ModuleNotFoundError       (note: full exception trace is shown but execution is paused at: <module>)\r\nNo module named 'llama_index.embeddings.adapter'\r\n  File \"F:\\Projects\\SharikAI\\My_llama_index.py\", line 1, in <module> (Current frame)\r\n    import llama_index\r\nModuleNotFoundError: No module named 'llama_index.embeddings.adapter'\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8033/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8033/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8032",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8032/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8032/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8032/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8032",
        "id": 1933396693,
        "node_id": "PR_kwDOIWuq585cRwSd",
        "number": 8032,
        "title": "Vectara bugfix",
        "user": {
            "login": "ofermend",
            "id": 1823547,
            "node_id": "MDQ6VXNlcjE4MjM1NDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1823547?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ofermend",
            "html_url": "https://github.com/ofermend",
            "followers_url": "https://api.github.com/users/ofermend/followers",
            "following_url": "https://api.github.com/users/ofermend/following{/other_user}",
            "gists_url": "https://api.github.com/users/ofermend/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ofermend/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ofermend/subscriptions",
            "organizations_url": "https://api.github.com/users/ofermend/orgs",
            "repos_url": "https://api.github.com/users/ofermend/repos",
            "events_url": "https://api.github.com/users/ofermend/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ofermend/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-09T16:08:37Z",
        "updated_at": "2023-10-09T16:25:34Z",
        "closed_at": "2023-10-09T16:25:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8032",
            "html_url": "https://github.com/run-llama/llama_index/pull/8032",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8032.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8032.patch",
            "merged_at": "2023-10-09T16:25:34Z"
        },
        "body": "# Description\r\n\r\n* Simplified VectaraRetriever constructor and how it deals with default values (removed \"Optional\")\r\n* Bug fix: when n_sentences_before or n_sentences_after were set to 0, it changed the value to 2.\r\n\r\nFixes # (issue)\r\n* Issue when n_sentences_before/after were set to 0\r\n\r\n## Type of Change\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [X] using existing tests\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] My changes generate no new warnings\r\n- [X] New and existing unit tests pass locally with my changes\r\n- [X] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8032/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8032/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8031",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8031/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8031/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8031/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8031",
        "id": 1932373815,
        "node_id": "I_kwDOIWuq585zLa83",
        "number": 8031,
        "title": "[Bug]: Unable to get node from Azure Cognitive Vector Store Index using node_id",
        "user": {
            "login": "zachlim98",
            "id": 68678549,
            "node_id": "MDQ6VXNlcjY4Njc4NTQ5",
            "avatar_url": "https://avatars.githubusercontent.com/u/68678549?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zachlim98",
            "html_url": "https://github.com/zachlim98",
            "followers_url": "https://api.github.com/users/zachlim98/followers",
            "following_url": "https://api.github.com/users/zachlim98/following{/other_user}",
            "gists_url": "https://api.github.com/users/zachlim98/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zachlim98/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zachlim98/subscriptions",
            "organizations_url": "https://api.github.com/users/zachlim98/orgs",
            "repos_url": "https://api.github.com/users/zachlim98/repos",
            "events_url": "https://api.github.com/users/zachlim98/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zachlim98/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-09T06:17:15Z",
        "updated_at": "2023-10-10T08:24:32Z",
        "closed_at": "2023-10-10T08:24:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI created a Azure Cognitive Search Index store following the guide on the documentation. \r\n\r\n```py\r\nvector_store = CognitiveSearchVectorStore(  \r\n    search_or_index_client=index_client,  \r\n    index_name=index_name,  \r\n    filterable_metadata_field_keys=metadata_fields,  \r\n    index_management=IndexManagement.CREATE_IF_NOT_EXISTS,  \r\n    id_field_key=\"id\",  \r\n    chunk_field_key=\"content\",  \r\n    embedding_field_key=\"content_vector\",  \r\n    metadata_string_field_key=\"metadata\",  \r\n    doc_id_field_key=\"doc_id\",  \r\n)\r\n```\r\n\r\nI then performed a search as follows and retrieved the node id from the node\r\n\r\n```py\r\nvector_node = index.as_retriever().retrieve(\"Some query\")\r\nid = vector_node[0].node.id_\r\n```\r\n\r\nI then tried to retrieve this from the index doc store\r\n\r\n```py\r\nindex.docstore.get_node(id)\r\n```\r\n\r\nwhich returns the error that `id` is not found. \r\n\r\nI have also tried \r\n\r\n```py\r\nindex.docstore.get_document(id)\r\n```\r\n\r\nwhich returns the same error. \r\n\r\nAdditionally, I have tried defining `id` as: \r\n```py\r\nid = list(vector_node[0].node.relationships.values())[0].node_id\r\n```\r\n\r\nwhich returns the node_id rather than the doc_id. However, this still returns the error as mentioned above, wherein the node cannot be found.\r\n\n\n### Version\n\n0.8.36\n\n### Steps to Reproduce\n\nAs described above.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8031/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8031/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8030",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8030/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8030/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8030/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8030",
        "id": 1932110885,
        "node_id": "PR_kwDOIWuq585cNW1c",
        "number": 8030,
        "title": "zep/fix: imports & typing",
        "user": {
            "login": "danielchalef",
            "id": 131175,
            "node_id": "MDQ6VXNlcjEzMTE3NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/131175?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danielchalef",
            "html_url": "https://github.com/danielchalef",
            "followers_url": "https://api.github.com/users/danielchalef/followers",
            "following_url": "https://api.github.com/users/danielchalef/following{/other_user}",
            "gists_url": "https://api.github.com/users/danielchalef/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danielchalef/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danielchalef/subscriptions",
            "organizations_url": "https://api.github.com/users/danielchalef/orgs",
            "repos_url": "https://api.github.com/users/danielchalef/repos",
            "events_url": "https://api.github.com/users/danielchalef/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danielchalef/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-08T23:44:58Z",
        "updated_at": "2023-10-09T02:39:44Z",
        "closed_at": "2023-10-09T02:33:13Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8030",
            "html_url": "https://github.com/run-llama/llama_index/pull/8030",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8030.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8030.patch",
            "merged_at": "2023-10-09T02:33:13Z"
        },
        "body": "- fix imports in docs & example \r\n- fix type hints\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- [X] Ran existing notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8030/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8030/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8029",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8029/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8029/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8029/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8029",
        "id": 1931993436,
        "node_id": "PR_kwDOIWuq585cM_Cd",
        "number": 8029,
        "title": "Add support for multiline answers in ReActOutputParser (Fixes #7690)",
        "user": {
            "login": "jensmeder",
            "id": 3153817,
            "node_id": "MDQ6VXNlcjMxNTM4MTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3153817?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jensmeder",
            "html_url": "https://github.com/jensmeder",
            "followers_url": "https://api.github.com/users/jensmeder/followers",
            "following_url": "https://api.github.com/users/jensmeder/following{/other_user}",
            "gists_url": "https://api.github.com/users/jensmeder/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jensmeder/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jensmeder/subscriptions",
            "organizations_url": "https://api.github.com/users/jensmeder/orgs",
            "repos_url": "https://api.github.com/users/jensmeder/repos",
            "events_url": "https://api.github.com/users/jensmeder/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jensmeder/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-08T18:30:22Z",
        "updated_at": "2023-10-09T02:58:26Z",
        "closed_at": "2023-10-09T02:58:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8029",
            "html_url": "https://github.com/run-llama/llama_index/pull/8029",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8029.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8029.patch",
            "merged_at": "2023-10-09T02:58:26Z"
        },
        "body": "# Description\r\n\r\nThis change fixes issue #7690 and adds support for multiline answers to the ReActAgentOutputParser. This can happen when the agent uses a tool and generates structured output such as html snippets, e.g., the following answer:\r\n\r\n```\r\nHere is a list of files in an html table:\r\n\r\n<table>\r\n   <tr>\r\n      <td>File1.pdf</td>\r\n   </tr>\r\n   <tr>\r\n      <td>File2.pdf</td>\r\n   </tr>\r\n   <tr>\r\n      <td>File3.pdf</td>\r\n   </tr>\r\n</table>\r\n```\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8029/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8029/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8028",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8028/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8028/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8028/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8028",
        "id": 1931861414,
        "node_id": "PR_kwDOIWuq585cMhuj",
        "number": 8028,
        "title": "`LocalAI` intuitive module-level var names",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-08T15:29:49Z",
        "updated_at": "2023-10-09T02:34:15Z",
        "closed_at": "2023-10-09T02:33:55Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8028",
            "html_url": "https://github.com/run-llama/llama_index/pull/8028",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8028.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8028.patch",
            "merged_at": "2023-10-09T02:33:55Z"
        },
        "body": "# Description\r\n\r\nMade the module-level vars in `LocalAI` both more intuitive and matching `OpenAI` namings\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8028/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8028/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8027",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8027/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8027/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8027/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8027",
        "id": 1931729161,
        "node_id": "PR_kwDOIWuq585cMG-J",
        "number": 8027,
        "title": "Avoid ZeroDivisionError",
        "user": {
            "login": "yasyf",
            "id": 709645,
            "node_id": "MDQ6VXNlcjcwOTY0NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/709645?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yasyf",
            "html_url": "https://github.com/yasyf",
            "followers_url": "https://api.github.com/users/yasyf/followers",
            "following_url": "https://api.github.com/users/yasyf/following{/other_user}",
            "gists_url": "https://api.github.com/users/yasyf/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yasyf/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yasyf/subscriptions",
            "organizations_url": "https://api.github.com/users/yasyf/orgs",
            "repos_url": "https://api.github.com/users/yasyf/repos",
            "events_url": "https://api.github.com/users/yasyf/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yasyf/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-08T09:30:13Z",
        "updated_at": "2023-10-09T09:38:37Z",
        "closed_at": "2023-10-09T02:34:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8027",
            "html_url": "https://github.com/run-llama/llama_index/pull/8027",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8027.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8027.patch",
            "merged_at": "2023-10-09T02:34:53Z"
        },
        "body": "# Description\n\nAvoid denominator being 0.\n\n## Type of Change\n\nPlease delete options that are not relevant.\n\n- [x] Bug fix (non-breaking change which fixes an issue)\n- [ ] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [ ] This change requires a documentation update\n\n# How Has This Been Tested?\n\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\n\n- [ ] Added new unit/integration tests\n- [ ] Added new notebook (that tests end-to-end)\n- [x] I stared at the code and made sure it makes sense\n\n# Suggested Checklist:\n\n- [x] I have performed a self-review of my own code\n- [ ] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [ ] My changes generate no new warnings\n- [ ] I have added tests that prove my fix is effective or that my feature works\n- [x] New and existing unit tests pass locally with my changes\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8027/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8027/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8026",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8026/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8026/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8026/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8026",
        "id": 1931722700,
        "node_id": "I_kwDOIWuq585zI7_M",
        "number": 8026,
        "title": "[Question]: when i query, whey always the same contents being sent to LLM",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-08T09:14:50Z",
        "updated_at": "2023-10-24T06:31:50Z",
        "closed_at": "2023-10-24T06:31:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nwhen i query, whey always the same contents being sent to LLM",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8026/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8026/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8025",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8025/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8025/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8025/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8025",
        "id": 1931522350,
        "node_id": "PR_kwDOIWuq585cLdyw",
        "number": 8025,
        "title": "[version] bump version to 0.8.41",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-07T22:09:35Z",
        "updated_at": "2023-10-07T22:21:16Z",
        "closed_at": "2023-10-07T22:21:15Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8025",
            "html_url": "https://github.com/run-llama/llama_index/pull/8025",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8025.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8025.patch",
            "merged_at": "2023-10-07T22:21:15Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8025/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8025/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8024",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8024/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8024/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8024/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8024",
        "id": 1931482890,
        "node_id": "PR_kwDOIWuq585cLVx4",
        "number": 8024,
        "title": "add You.com Retriever",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-07T19:58:15Z",
        "updated_at": "2023-10-07T22:07:39Z",
        "closed_at": "2023-10-07T22:07:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8024",
            "html_url": "https://github.com/run-llama/llama_index/pull/8024",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8024.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8024.patch",
            "merged_at": "2023-10-07T22:07:38Z"
        },
        "body": "haven't tested this, awaiting API key ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8024/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8024/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8023",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8023/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8023/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8023/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8023",
        "id": 1931461305,
        "node_id": "PR_kwDOIWuq585cLRfW",
        "number": 8023,
        "title": "Add cohere llm",
        "user": {
            "login": "NeilBotelho",
            "id": 39030675,
            "node_id": "MDQ6VXNlcjM5MDMwNjc1",
            "avatar_url": "https://avatars.githubusercontent.com/u/39030675?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NeilBotelho",
            "html_url": "https://github.com/NeilBotelho",
            "followers_url": "https://api.github.com/users/NeilBotelho/followers",
            "following_url": "https://api.github.com/users/NeilBotelho/following{/other_user}",
            "gists_url": "https://api.github.com/users/NeilBotelho/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NeilBotelho/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NeilBotelho/subscriptions",
            "organizations_url": "https://api.github.com/users/NeilBotelho/orgs",
            "repos_url": "https://api.github.com/users/NeilBotelho/repos",
            "events_url": "https://api.github.com/users/NeilBotelho/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NeilBotelho/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-07T18:45:25Z",
        "updated_at": "2023-10-10T04:14:30Z",
        "closed_at": "2023-10-09T21:46:12Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8023",
            "html_url": "https://github.com/run-llama/llama_index/pull/8023",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8023.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8023.patch",
            "merged_at": "2023-10-09T21:46:12Z"
        },
        "body": "# Description\r\n\r\nThis commit adds support for [Cohere](https://cohere.com/) LLMs. I've also added unit tests for the basic as well as async functionality. I've added an example notebook for the llm. I haven't been able to figure out how to add unit tests for the streaming functionality yet. \r\n\r\n## Type of Change\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8023/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8023/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8022",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8022/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8022/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8022/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8022",
        "id": 1931421124,
        "node_id": "PR_kwDOIWuq585cLJQu",
        "number": 8022,
        "title": "Fixed: React Agent only accept \"input keyword\" in Action Input, other keyword would raise TypeError",
        "user": {
            "login": "azurewtl",
            "id": 5175672,
            "node_id": "MDQ6VXNlcjUxNzU2NzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5175672?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/azurewtl",
            "html_url": "https://github.com/azurewtl",
            "followers_url": "https://api.github.com/users/azurewtl/followers",
            "following_url": "https://api.github.com/users/azurewtl/following{/other_user}",
            "gists_url": "https://api.github.com/users/azurewtl/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/azurewtl/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/azurewtl/subscriptions",
            "organizations_url": "https://api.github.com/users/azurewtl/orgs",
            "repos_url": "https://api.github.com/users/azurewtl/repos",
            "events_url": "https://api.github.com/users/azurewtl/events{/privacy}",
            "received_events_url": "https://api.github.com/users/azurewtl/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-07T16:51:37Z",
        "updated_at": "2023-10-12T04:01:26Z",
        "closed_at": "2023-10-12T04:00:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8022",
            "html_url": "https://github.com/run-llama/llama_index/pull/8022",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8022.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8022.patch",
            "merged_at": null
        },
        "body": "- change cast to str() because cast do not cast data type in runtime\r\n\r\n# Description\r\n\r\nIn react agent, `action input` should have various of keys as shown in prompt template`{{\"text\": \"hello, world \", \"num_beams\": 5}}`.\r\n\r\nIf you to create such useful action input, following error will be raised:\r\n```shell\r\n  File \"/Users/azure/Documents/Workspace/Datasci/lib/python3.10/site-packages/llama_index/agent/react/base.py\", line 158, in _process_actions\r\n    tool_output = tool.call(**reasoning_step.action_input)\r\nTypeError: QueryEngineTool.call() got an unexpected keyword argument 'University'\r\n```\r\n\r\n### Fixes \r\nAllow react agent pass full action input into queryEngine. while fixed another bug that fail to cast data type\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8022/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8022/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8021",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8021/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8021/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8021/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8021",
        "id": 1931416614,
        "node_id": "I_kwDOIWuq585zHxQm",
        "number": 8021,
        "title": "[Question]: . A user will ask a question, create an embedding of the question, and compare it against the collection of embeddings in the vectorbase.",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-07T16:37:56Z",
        "updated_at": "2023-10-24T06:31:48Z",
        "closed_at": "2023-10-24T06:31:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n A user will ask a question, \r\ncreate an embedding of the question,\r\n and compare it against the collection of embeddings in the vectorbase\r\n\r\nmay i know if llama_index can do this? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8021/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8021/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8020",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8020/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8020/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8020/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8020",
        "id": 1931414089,
        "node_id": "PR_kwDOIWuq585cLH1t",
        "number": 8020,
        "title": "refactor: use `str.join`",
        "user": {
            "login": "david20571015",
            "id": 51911434,
            "node_id": "MDQ6VXNlcjUxOTExNDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/51911434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david20571015",
            "html_url": "https://github.com/david20571015",
            "followers_url": "https://api.github.com/users/david20571015/followers",
            "following_url": "https://api.github.com/users/david20571015/following{/other_user}",
            "gists_url": "https://api.github.com/users/david20571015/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david20571015/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david20571015/subscriptions",
            "organizations_url": "https://api.github.com/users/david20571015/orgs",
            "repos_url": "https://api.github.com/users/david20571015/repos",
            "events_url": "https://api.github.com/users/david20571015/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david20571015/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-07T16:31:28Z",
        "updated_at": "2023-10-12T16:30:38Z",
        "closed_at": "2023-10-07T23:08:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8020",
            "html_url": "https://github.com/run-llama/llama_index/pull/8020",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8020.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8020.patch",
            "merged_at": "2023-10-07T23:08:52Z"
        },
        "body": "# Description\r\n\r\nUse `str.join` instead of `str +=` to [improve the performance](https://google.github.io/styleguide/pyguide.html#310-strings). Also, add a seperator parameter.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8020/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8020/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8019",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8019/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8019/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8019/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8019",
        "id": 1931264103,
        "node_id": "PR_kwDOIWuq585cKqKG",
        "number": 8019,
        "title": "Fix: ChromaVectorStore can attempt to add in excess of chromadb batch\u2026",
        "user": {
            "login": "Brad-Edwards",
            "id": 56809295,
            "node_id": "MDQ6VXNlcjU2ODA5Mjk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/56809295?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Brad-Edwards",
            "html_url": "https://github.com/Brad-Edwards",
            "followers_url": "https://api.github.com/users/Brad-Edwards/followers",
            "following_url": "https://api.github.com/users/Brad-Edwards/following{/other_user}",
            "gists_url": "https://api.github.com/users/Brad-Edwards/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Brad-Edwards/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Brad-Edwards/subscriptions",
            "organizations_url": "https://api.github.com/users/Brad-Edwards/orgs",
            "repos_url": "https://api.github.com/users/Brad-Edwards/repos",
            "events_url": "https://api.github.com/users/Brad-Edwards/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Brad-Edwards/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-07T08:52:10Z",
        "updated_at": "2023-10-09T03:00:06Z",
        "closed_at": "2023-10-09T03:00:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8019",
            "html_url": "https://github.com/run-llama/llama_index/pull/8019",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8019.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8019.patch",
            "merged_at": "2023-10-09T03:00:06Z"
        },
        "body": "\u2026 size\r\n\r\n# Description\r\n\r\nChanged `ChromaVectorStore.add` to batch inputs at one less than chromadb's max to avoid the oversize error. Adds a class method to do chunking.\r\n\r\nFixes #7648 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nI have passing unit tests on my branch but have not included them. The unit test to add a large number of nodes takes ~5 secs to run. If that's acceptable, I can submit the unit tests for `add`\r\n\r\nI noticed tests were missing for all of the llama_index.vector_stores.chroma.py. So I also implemented tests for several other methods.\r\n\r\nLet me know if you want all the unit tests, all the tests excluding `add`, or none of them.\r\n\r\n- [see above] Added new unit/integration tests\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [N/A ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [see above] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n- [X] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8019/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8019/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8018",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8018/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8018/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8018/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8018",
        "id": 1931246650,
        "node_id": "PR_kwDOIWuq585cKmwA",
        "number": 8018,
        "title": "add document comparisons section to tesla 10k recursive retrieval example ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-07T07:59:42Z",
        "updated_at": "2023-10-07T08:09:14Z",
        "closed_at": "2023-10-07T08:09:13Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8018",
            "html_url": "https://github.com/run-llama/llama_index/pull/8018",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8018.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8018.patch",
            "merged_at": "2023-10-07T08:09:13Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8018/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8018/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8017",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8017/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8017/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8017/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8017",
        "id": 1931240309,
        "node_id": "PR_kwDOIWuq585cKlfG",
        "number": 8017,
        "title": "Apply kwarg filters in WeaviateVectorStore",
        "user": {
            "login": "yasyf",
            "id": 709645,
            "node_id": "MDQ6VXNlcjcwOTY0NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/709645?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yasyf",
            "html_url": "https://github.com/yasyf",
            "followers_url": "https://api.github.com/users/yasyf/followers",
            "following_url": "https://api.github.com/users/yasyf/following{/other_user}",
            "gists_url": "https://api.github.com/users/yasyf/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yasyf/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yasyf/subscriptions",
            "organizations_url": "https://api.github.com/users/yasyf/orgs",
            "repos_url": "https://api.github.com/users/yasyf/repos",
            "events_url": "https://api.github.com/users/yasyf/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yasyf/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-07T07:39:29Z",
        "updated_at": "2023-10-09T09:38:45Z",
        "closed_at": "2023-10-09T02:37:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8017",
            "html_url": "https://github.com/run-llama/llama_index/pull/8017",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8017.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8017.patch",
            "merged_at": "2023-10-09T02:37:49Z"
        },
        "body": "# Description\n\nPreviously was not being used!\n\n\n## Type of Change\n\nPlease delete options that are not relevant.\n\n- [x] Bug fix (non-breaking change which fixes an issue)\n- [ ] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\n- [ ] This change requires a documentation update\n\n# How Has This Been Tested?\n\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\n\n- [ ] Added new unit/integration tests\n- [ ] Added new notebook (that tests end-to-end)\n- [x] I stared at the code and made sure it makes sense\n\n# Suggested Checklist:\n\n- [x] I have performed a self-review of my own code\n- [ ] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [x] My changes generate no new warnings\n- [ ] I have added tests that prove my fix is effective or that my feature works\n- [x] New and existing unit tests pass locally with my changes\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8017/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8017/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8016",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8016/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8016/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8016/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8016",
        "id": 1931056438,
        "node_id": "PR_kwDOIWuq585cJ-xy",
        "number": 8016,
        "title": "Update GuardrailsOutputParser, can now support Guard initialization from all methods supported by Guardrails",
        "user": {
            "login": "thekaranacharya",
            "id": 27991278,
            "node_id": "MDQ6VXNlcjI3OTkxMjc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/27991278?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thekaranacharya",
            "html_url": "https://github.com/thekaranacharya",
            "followers_url": "https://api.github.com/users/thekaranacharya/followers",
            "following_url": "https://api.github.com/users/thekaranacharya/following{/other_user}",
            "gists_url": "https://api.github.com/users/thekaranacharya/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thekaranacharya/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thekaranacharya/subscriptions",
            "organizations_url": "https://api.github.com/users/thekaranacharya/orgs",
            "repos_url": "https://api.github.com/users/thekaranacharya/repos",
            "events_url": "https://api.github.com/users/thekaranacharya/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thekaranacharya/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-06T23:58:23Z",
        "updated_at": "2023-10-22T07:39:22Z",
        "closed_at": "2023-10-22T07:39:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8016",
            "html_url": "https://github.com/run-llama/llama_index/pull/8016",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8016.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8016.patch",
            "merged_at": "2023-10-22T07:39:21Z"
        },
        "body": "# Description\r\n## Summary\r\nGuardrails supports initialization of Guard using multiple ways - `from_rail()`, `from_rail_string()`, `from_pydantic()`, and `from_string()`. The current version of llama_index supports only the first 2 methods to initialize `GuardrailsOutputParser`. This PR will enable creating a Guard object using all of the supported methods from Guardrails.\r\n\r\n## Implementation details:\r\n- Deprecated 2 class methods: `from_rail()` and `from_rail_string()` from `GuardrailsOutputParser`.\r\n- Instead, users can now create a Guard object separately and pass that as an argument when initializing `GuardrailsOutputParser`.\r\n\r\n## Motivation & Context\r\n- Motivated by [this closed PR](https://github.com/run-llama/llama_index/pull/6809)\r\n- This will enable users to not only define the output schema using Pydantic but also in whichever format they wish as supported by Guardrails, create a Guard object and then pass that to `GuardrailsOutputParser`. In future, if/when new methods of defining output schema are supported by Guardrails, there would be no need to add that relevant method and update the `GuardrailsOutputParser` implementation.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8016/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8016/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8015",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8015/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8015/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8015/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8015",
        "id": 1930967637,
        "node_id": "I_kwDOIWuq585zGDpV",
        "number": 8015,
        "title": "[Feature Request]: Citations on chat engine",
        "user": {
            "login": "gich2009",
            "id": 83756959,
            "node_id": "MDQ6VXNlcjgzNzU2OTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/83756959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gich2009",
            "html_url": "https://github.com/gich2009",
            "followers_url": "https://api.github.com/users/gich2009/followers",
            "following_url": "https://api.github.com/users/gich2009/following{/other_user}",
            "gists_url": "https://api.github.com/users/gich2009/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gich2009/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gich2009/subscriptions",
            "organizations_url": "https://api.github.com/users/gich2009/orgs",
            "repos_url": "https://api.github.com/users/gich2009/repos",
            "events_url": "https://api.github.com/users/gich2009/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gich2009/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-06T21:44:25Z",
        "updated_at": "2023-10-06T22:58:53Z",
        "closed_at": "2023-10-06T22:58:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nPlease Add a list of source_nodes or metadata to the chat_engine() similar to the one in query_engine()\n\n### Reason\n\nTo make extracting references easier\n\n### Value of Feature\n\nIncrease bot credibility when necessary.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8015/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8015/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8014",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8014/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8014/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8014/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8014",
        "id": 1930965088,
        "node_id": "I_kwDOIWuq585zGDBg",
        "number": 8014,
        "title": "[Bug]: Incomplete Response when streaming from a chat engine",
        "user": {
            "login": "gich2009",
            "id": 83756959,
            "node_id": "MDQ6VXNlcjgzNzU2OTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/83756959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gich2009",
            "html_url": "https://github.com/gich2009",
            "followers_url": "https://api.github.com/users/gich2009/followers",
            "following_url": "https://api.github.com/users/gich2009/following{/other_user}",
            "gists_url": "https://api.github.com/users/gich2009/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gich2009/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gich2009/subscriptions",
            "organizations_url": "https://api.github.com/users/gich2009/orgs",
            "repos_url": "https://api.github.com/users/gich2009/repos",
            "events_url": "https://api.github.com/users/gich2009/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gich2009/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-06T21:41:34Z",
        "updated_at": "2023-10-08T20:10:35Z",
        "closed_at": "2023-10-08T20:10:35Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am getting a response that doesn't contain the first token(or two) when using the stream_chat() method for a chat_engine. Any ideas how I can solve this? Has anyone else encountered this small yet troublesome behaviour?\n\n### Version\n\n0.8.40\n\n### Steps to Reproduce\n\nquery_engine = index.as_chat_engine()\r\n\r\nresponse = query_engine.stream_chat(\"Hi, how are you?\")\r\n\r\nfor token in response.response_gen:\r\n    yield token\r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nan\r\n AI\r\n,\r\n I\r\n don\r\n't\r\n have\r\n feelings\r\n,\r\n but\r\n I\r\n'm\r\n here\r\n to\r\n help\r\n you\r\n.\r\n How\r\n can\r\n I\r\n assist\r\n you\r\n today\r\n?\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8014/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8014/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8013",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8013/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8013/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8013/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8013",
        "id": 1930904347,
        "node_id": "PR_kwDOIWuq585cJdnD",
        "number": 8013,
        "title": "docs(eval): fix typo",
        "user": {
            "login": "revolunet",
            "id": 124937,
            "node_id": "MDQ6VXNlcjEyNDkzNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/124937?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/revolunet",
            "html_url": "https://github.com/revolunet",
            "followers_url": "https://api.github.com/users/revolunet/followers",
            "following_url": "https://api.github.com/users/revolunet/following{/other_user}",
            "gists_url": "https://api.github.com/users/revolunet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/revolunet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/revolunet/subscriptions",
            "organizations_url": "https://api.github.com/users/revolunet/orgs",
            "repos_url": "https://api.github.com/users/revolunet/repos",
            "events_url": "https://api.github.com/users/revolunet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/revolunet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T20:37:04Z",
        "updated_at": "2023-10-07T05:37:15Z",
        "closed_at": "2023-10-07T05:37:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8013",
            "html_url": "https://github.com/run-llama/llama_index/pull/8013",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8013.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8013.patch",
            "merged_at": "2023-10-07T05:37:15Z"
        },
        "body": "just a typo",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8013/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8013/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8012",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8012/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8012/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8012/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8012",
        "id": 1930881436,
        "node_id": "PR_kwDOIWuq585cJYjk",
        "number": 8012,
        "title": "Fix get_content method in Mbox reader",
        "user": {
            "login": "sumansid",
            "id": 53033648,
            "node_id": "MDQ6VXNlcjUzMDMzNjQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/53033648?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sumansid",
            "html_url": "https://github.com/sumansid",
            "followers_url": "https://api.github.com/users/sumansid/followers",
            "following_url": "https://api.github.com/users/sumansid/following{/other_user}",
            "gists_url": "https://api.github.com/users/sumansid/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sumansid/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sumansid/subscriptions",
            "organizations_url": "https://api.github.com/users/sumansid/orgs",
            "repos_url": "https://api.github.com/users/sumansid/repos",
            "events_url": "https://api.github.com/users/sumansid/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sumansid/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-06T20:15:29Z",
        "updated_at": "2023-10-09T02:46:31Z",
        "closed_at": "2023-10-09T02:46:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8012",
            "html_url": "https://github.com/run-llama/llama_index/pull/8012",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8012.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8012.patch",
            "merged_at": "2023-10-09T02:46:30Z"
        },
        "body": "# Description\r\n\r\n - change get_content to get_text on the BeautifulSoup object\r\n - get_content doesn't exist on soup object\r\n\r\nFixes # (issue)\r\nParsing issue for Mbox format\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n- [x] Tested on a Mbox exported from gmail\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8012/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8012/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8011",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8011/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8011/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8011/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8011",
        "id": 1930748310,
        "node_id": "PR_kwDOIWuq585cI8Fw",
        "number": 8011,
        "title": "Added retriever_mode super call to other KeywordTableIndexes",
        "user": {
            "login": "ryanpeach",
            "id": 14838729,
            "node_id": "MDQ6VXNlcjE0ODM4NzI5",
            "avatar_url": "https://avatars.githubusercontent.com/u/14838729?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ryanpeach",
            "html_url": "https://github.com/ryanpeach",
            "followers_url": "https://api.github.com/users/ryanpeach/followers",
            "following_url": "https://api.github.com/users/ryanpeach/following{/other_user}",
            "gists_url": "https://api.github.com/users/ryanpeach/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ryanpeach/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ryanpeach/subscriptions",
            "organizations_url": "https://api.github.com/users/ryanpeach/orgs",
            "repos_url": "https://api.github.com/users/ryanpeach/repos",
            "events_url": "https://api.github.com/users/ryanpeach/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ryanpeach/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T18:25:56Z",
        "updated_at": "2023-10-09T02:50:32Z",
        "closed_at": "2023-10-09T02:50:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8011",
            "html_url": "https://github.com/run-llama/llama_index/pull/8011",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8011.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8011.patch",
            "merged_at": "2023-10-09T02:50:32Z"
        },
        "body": "# Description\r\n\r\nRedeclare `as_retriever` in each subclass with different default values and then call super.\r\n\r\nFixes #8010\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8011/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8011/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8010",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8010/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8010/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8010/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8010",
        "id": 1930742019,
        "node_id": "I_kwDOIWuq585zFMkD",
        "number": 8010,
        "title": "[Bug]: SimpleKeywordTableIndex.as_query_engine() does not, by default, use KeywordTableRetrieverMode.SIMPLE",
        "user": {
            "login": "ryanpeach",
            "id": 14838729,
            "node_id": "MDQ6VXNlcjE0ODM4NzI5",
            "avatar_url": "https://avatars.githubusercontent.com/u/14838729?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ryanpeach",
            "html_url": "https://github.com/ryanpeach",
            "followers_url": "https://api.github.com/users/ryanpeach/followers",
            "following_url": "https://api.github.com/users/ryanpeach/following{/other_user}",
            "gists_url": "https://api.github.com/users/ryanpeach/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ryanpeach/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ryanpeach/subscriptions",
            "organizations_url": "https://api.github.com/users/ryanpeach/orgs",
            "repos_url": "https://api.github.com/users/ryanpeach/repos",
            "events_url": "https://api.github.com/users/ryanpeach/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ryanpeach/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-06T18:20:46Z",
        "updated_at": "2023-10-09T02:50:33Z",
        "closed_at": "2023-10-09T02:50:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThis took a while to figure out, but because you only implement `as_retriever` in the BaseKeywordTableIndex and set its default retriever mode to KeywordTableRetrieverMode.DEFAULT, all other keyword table indexes still use this retriever type by default. You have to set retriever_mode manually, and this is hidden behind a `**kwargs` in `as_query_engine(**kwargs)` so it's very hard to discover.\r\n\r\nSolution:\r\n\r\nRedeclare `as_retriever` in each subclass with different default values and then call `super`.\n\n### Version\n\n0.7.1\n\n### Steps to Reproduce\n\nDescribed in the issue.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8010/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8010/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8009",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8009/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8009/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8009/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8009",
        "id": 1930393111,
        "node_id": "PR_kwDOIWuq585cHw9v",
        "number": 8009,
        "title": "Various docs fixes",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T15:10:15Z",
        "updated_at": "2023-10-06T15:15:38Z",
        "closed_at": "2023-10-06T15:15:37Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8009",
            "html_url": "https://github.com/run-llama/llama_index/pull/8009",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8009.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8009.patch",
            "merged_at": "2023-10-06T15:15:37Z"
        },
        "body": "# Description\r\n\r\nJust fixing various typos uncovered with codespell\r\n\r\nFixes #7897\r\nFixes #7895\r\nFixes #8003\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8009/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8009/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8008",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8008/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8008/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8008/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8008",
        "id": 1930345280,
        "node_id": "PR_kwDOIWuq585cHm-Q",
        "number": 8008,
        "title": "llm feature validation",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T14:51:26Z",
        "updated_at": "2023-10-07T05:55:48Z",
        "closed_at": "2023-10-07T05:55:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8008",
            "html_url": "https://github.com/run-llama/llama_index/pull/8008",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8008.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8008.patch",
            "merged_at": "2023-10-07T05:55:47Z"
        },
        "body": "# Description\r\n\r\nThis PR introduces a section to the docs that both\r\n- shows the capabilities of LLMs in LlamaIndex\r\n- shows how to setup the LLM in LlamaIndex\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8008/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8008/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8007",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8007/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8007/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8007/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8007",
        "id": 1930180370,
        "node_id": "I_kwDOIWuq585zDDcS",
        "number": 8007,
        "title": "[Question]: replicate api issue",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-10-06T13:23:37Z",
        "updated_at": "2023-10-06T19:31:11Z",
        "closed_at": "2023-10-06T19:31:10Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n\r\nhttps://replicate.com/p/ae55hc3beupa7zvba6psrk7mei\r\n\r\n\r\nwhen I do the index query using llama_index, only one fragment of document can be imported to the promt, what is the error \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8007/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8007/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8006",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8006/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8006/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8006/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8006",
        "id": 1930154478,
        "node_id": "I_kwDOIWuq585zC9Hu",
        "number": 8006,
        "title": "[Question]: from llama_index.llms import Replicate  ",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-06T13:09:24Z",
        "updated_at": "2023-10-06T15:13:59Z",
        "closed_at": "2023-10-06T15:13:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "#solved",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8006/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8006/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8005",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8005/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8005/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8005/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8005",
        "id": 1929859630,
        "node_id": "I_kwDOIWuq585zB1Iu",
        "number": 8005,
        "title": "[Question]: DataException: expected 1536 dimensions, not 768 ",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-10-06T10:21:51Z",
        "updated_at": "2023-10-06T15:14:55Z",
        "closed_at": "2023-10-06T15:14:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nhow to solve this when using postgresml vector database",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8005/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8005/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8004",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8004/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8004/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8004/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8004",
        "id": 1929699318,
        "node_id": "I_kwDOIWuq585zBN_2",
        "number": 8004,
        "title": "[Question]: How can I specify to use Azure openAI model for finetunning in `OpenAIFinetuneEngine`",
        "user": {
            "login": "AchintyaX",
            "id": 39014560,
            "node_id": "MDQ6VXNlcjM5MDE0NTYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/39014560?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AchintyaX",
            "html_url": "https://github.com/AchintyaX",
            "followers_url": "https://api.github.com/users/AchintyaX/followers",
            "following_url": "https://api.github.com/users/AchintyaX/following{/other_user}",
            "gists_url": "https://api.github.com/users/AchintyaX/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AchintyaX/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AchintyaX/subscriptions",
            "organizations_url": "https://api.github.com/users/AchintyaX/orgs",
            "repos_url": "https://api.github.com/users/AchintyaX/repos",
            "events_url": "https://api.github.com/users/AchintyaX/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AchintyaX/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-10-06T08:39:35Z",
        "updated_at": "2023-10-09T23:44:21Z",
        "closed_at": "2023-10-09T23:44:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI wanted to finetune a model on Azure OpenAI, but I am not seeing any way in the documentation to specify to use Azure OpenAI for finetuning. \r\nI can see that we can directly using `AzureOpenAI` for LLM to be passed but can't see a way to specify the same for the finetuning job",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8004/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8004/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8003",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8003/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8003/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8003/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/8003",
        "id": 1929695160,
        "node_id": "I_kwDOIWuq585zBM-4",
        "number": 8003,
        "title": "[Documentation]: A doc bug on Vector Store Index",
        "user": {
            "login": "mingqxu7",
            "id": 50094870,
            "node_id": "MDQ6VXNlcjUwMDk0ODcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/50094870?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mingqxu7",
            "html_url": "https://github.com/mingqxu7",
            "followers_url": "https://api.github.com/users/mingqxu7/followers",
            "following_url": "https://api.github.com/users/mingqxu7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mingqxu7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mingqxu7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mingqxu7/subscriptions",
            "organizations_url": "https://api.github.com/users/mingqxu7/orgs",
            "repos_url": "https://api.github.com/users/mingqxu7/repos",
            "events_url": "https://api.github.com/users/mingqxu7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mingqxu7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T08:36:48Z",
        "updated_at": "2023-10-06T15:15:40Z",
        "closed_at": "2023-10-06T15:15:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nThere is a typo in \r\n\r\nhttps://docs.llamaindex.ai/en/stable/core_modules/data_modules/storage/customization.html\r\n\r\n# can also set index_id to save multiple indexes to the same folder\r\nindex.set_index_id = \"<index_id>\"\r\n\r\nShould be:\r\n\r\nindex.set_index_id(\"<index_id>\")\r\n\r\n\n\n### Documentation Link\n\nhttps://docs.llamaindex.ai/en/stable/core_modules/data_modules/storage/customization.html",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8003/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8003/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8002",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8002/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8002/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8002/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8002",
        "id": 1929619044,
        "node_id": "PR_kwDOIWuq585cFLvC",
        "number": 8002,
        "title": "feat: able to concatenate list fields",
        "user": {
            "login": "david20571015",
            "id": 51911434,
            "node_id": "MDQ6VXNlcjUxOTExNDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/51911434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david20571015",
            "html_url": "https://github.com/david20571015",
            "followers_url": "https://api.github.com/users/david20571015/followers",
            "following_url": "https://api.github.com/users/david20571015/following{/other_user}",
            "gists_url": "https://api.github.com/users/david20571015/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david20571015/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david20571015/subscriptions",
            "organizations_url": "https://api.github.com/users/david20571015/orgs",
            "repos_url": "https://api.github.com/users/david20571015/repos",
            "events_url": "https://api.github.com/users/david20571015/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david20571015/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T07:44:46Z",
        "updated_at": "2023-10-06T15:26:49Z",
        "closed_at": "2023-10-06T15:26:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8002",
            "html_url": "https://github.com/run-llama/llama_index/pull/8002",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8002.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8002.patch",
            "merged_at": "2023-10-06T15:26:49Z"
        },
        "body": "# Description\r\n\r\nSometimes, we store an article splited into paragraphs in MongoDB as a list of string. This PR make it able to concatenate such field.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8002/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8002/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8001",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8001/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8001/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8001/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8001",
        "id": 1929596555,
        "node_id": "PR_kwDOIWuq585cFG2P",
        "number": 8001,
        "title": "feat: adding metadata to Document",
        "user": {
            "login": "david20571015",
            "id": 51911434,
            "node_id": "MDQ6VXNlcjUxOTExNDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/51911434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david20571015",
            "html_url": "https://github.com/david20571015",
            "followers_url": "https://api.github.com/users/david20571015/followers",
            "following_url": "https://api.github.com/users/david20571015/following{/other_user}",
            "gists_url": "https://api.github.com/users/david20571015/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david20571015/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david20571015/subscriptions",
            "organizations_url": "https://api.github.com/users/david20571015/orgs",
            "repos_url": "https://api.github.com/users/david20571015/repos",
            "events_url": "https://api.github.com/users/david20571015/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david20571015/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T07:28:25Z",
        "updated_at": "2023-10-12T16:31:49Z",
        "closed_at": "2023-10-06T15:58:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8001",
            "html_url": "https://github.com/run-llama/llama_index/pull/8001",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8001.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8001.patch",
            "merged_at": "2023-10-06T15:58:25Z"
        },
        "body": "# Description\r\n\r\nLet user able to add metadata to the document.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8001/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8001/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/8000",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/8000/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/8000/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/8000/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/8000",
        "id": 1929574052,
        "node_id": "PR_kwDOIWuq585cFCDd",
        "number": 8000,
        "title": "remove unnecessary transformers requirement",
        "user": {
            "login": "fcakyon",
            "id": 34196005,
            "node_id": "MDQ6VXNlcjM0MTk2MDA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34196005?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fcakyon",
            "html_url": "https://github.com/fcakyon",
            "followers_url": "https://api.github.com/users/fcakyon/followers",
            "following_url": "https://api.github.com/users/fcakyon/following{/other_user}",
            "gists_url": "https://api.github.com/users/fcakyon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fcakyon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fcakyon/subscriptions",
            "organizations_url": "https://api.github.com/users/fcakyon/orgs",
            "repos_url": "https://api.github.com/users/fcakyon/repos",
            "events_url": "https://api.github.com/users/fcakyon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fcakyon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T07:12:15Z",
        "updated_at": "2023-10-06T16:14:52Z",
        "closed_at": "2023-10-06T16:02:07Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/8000",
            "html_url": "https://github.com/run-llama/llama_index/pull/8000",
            "diff_url": "https://github.com/run-llama/llama_index/pull/8000.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/8000.patch",
            "merged_at": "2023-10-06T16:02:07Z"
        },
        "body": "# Description\r\n\r\nThis PR removes the unnecessary need for transformers dependency when `add_sparse_vector=False` (which is the default value) in `PineconeVectorStore` class.\r\n\r\nFixes https://github.com/run-llama/llama_index/issues/7999\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/8000/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/8000/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7999",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7999/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7999/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7999/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7999",
        "id": 1929564244,
        "node_id": "I_kwDOIWuq585zAtBU",
        "number": 7999,
        "title": "[Feature Request]: Remove unnecessary transformers dependency in PineconeVectorStore",
        "user": {
            "login": "fcakyon",
            "id": 34196005,
            "node_id": "MDQ6VXNlcjM0MTk2MDA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/34196005?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fcakyon",
            "html_url": "https://github.com/fcakyon",
            "followers_url": "https://api.github.com/users/fcakyon/followers",
            "following_url": "https://api.github.com/users/fcakyon/following{/other_user}",
            "gists_url": "https://api.github.com/users/fcakyon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fcakyon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fcakyon/subscriptions",
            "organizations_url": "https://api.github.com/users/fcakyon/orgs",
            "repos_url": "https://api.github.com/users/fcakyon/repos",
            "events_url": "https://api.github.com/users/fcakyon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fcakyon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T07:04:49Z",
        "updated_at": "2023-10-06T16:02:08Z",
        "closed_at": "2023-10-06T16:02:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\r\n\r\nIn the current implementation, even if I dont use the sparse vector feature of the PineconeVectorStore class, llama-index implementation enforces transformers package to be installed. This is not the case with other VectorStore implementations.\r\n\r\n\r\n\r\n### Reason\r\n\r\nhttps://github.com/run-llama/llama_index/blob/6b0c63f1f6c59592204ead14aedab4ce46c5df39/llama_index/vector_stores/pinecone.py#L172\r\n\r\nIn this line, transformers package is imported even if `add_sparse_vector=False`. Moreover, `self._tokenizer` is never used when `add_sparse_vector=False`.\r\n\r\n### Value of Feature\r\n\r\nIf I don't need/use the `transformers` package, llama-index should not force me to install the `transformers` package.\r\nThere is no transformers package dependency with other VectorStore implementations. This issue is present only with the PineconeVector Store class.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7999/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7999/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7998",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7998/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7998/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7998/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7998",
        "id": 1929556108,
        "node_id": "PR_kwDOIWuq585cE-La",
        "number": 7998,
        "title": "refactor: simplify the logic",
        "user": {
            "login": "david20571015",
            "id": 51911434,
            "node_id": "MDQ6VXNlcjUxOTExNDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/51911434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/david20571015",
            "html_url": "https://github.com/david20571015",
            "followers_url": "https://api.github.com/users/david20571015/followers",
            "following_url": "https://api.github.com/users/david20571015/following{/other_user}",
            "gists_url": "https://api.github.com/users/david20571015/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/david20571015/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/david20571015/subscriptions",
            "organizations_url": "https://api.github.com/users/david20571015/orgs",
            "repos_url": "https://api.github.com/users/david20571015/repos",
            "events_url": "https://api.github.com/users/david20571015/events{/privacy}",
            "received_events_url": "https://api.github.com/users/david20571015/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-06T07:00:08Z",
        "updated_at": "2023-10-12T16:31:54Z",
        "closed_at": "2023-10-06T16:17:52Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7998",
            "html_url": "https://github.com/run-llama/llama_index/pull/7998",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7998.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7998.patch",
            "merged_at": "2023-10-06T16:17:52Z"
        },
        "body": "# Description\r\n\r\nSimplify the logic of connecting to MongoDB by uri or host&port.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7998/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7998/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7997",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7997/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7997/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7997/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7997",
        "id": 1929449672,
        "node_id": "I_kwDOIWuq585zARDI",
        "number": 7997,
        "title": "[Bug]: pydantic_class.schema() Generates schema[\"title\"] but Fails to Generate schema[\"description\"]",
        "user": {
            "login": "kaeruko",
            "id": 4452841,
            "node_id": "MDQ6VXNlcjQ0NTI4NDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4452841?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kaeruko",
            "html_url": "https://github.com/kaeruko",
            "followers_url": "https://api.github.com/users/kaeruko/followers",
            "following_url": "https://api.github.com/users/kaeruko/following{/other_user}",
            "gists_url": "https://api.github.com/users/kaeruko/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kaeruko/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kaeruko/subscriptions",
            "organizations_url": "https://api.github.com/users/kaeruko/orgs",
            "repos_url": "https://api.github.com/users/kaeruko/repos",
            "events_url": "https://api.github.com/users/kaeruko/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kaeruko/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-06T05:13:39Z",
        "updated_at": "2023-10-06T15:13:04Z",
        "closed_at": "2023-10-06T15:13:04Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI tried following the instructions on [this page](https://gpt-index.readthedocs.io/en/latest/examples/finetuning/openai_fine_tuning_functions.html), but I encountered an error. The error occurs in the file /usr/local/lib/python3.10/site-packages/llama_index/llms/openai_utils.py, specifically at line 265, in the to_openai_function method. The issue seems to be that pydantic_class.schema() generates a schema[\"title\"] but does not generate a schema[\"description\"].\r\n\r\n### Version\r\n\r\nv0.8.40\r\n\r\n### Steps to Reproduce\r\n\r\n```python\r\nclass Workflow(BaseModel):\r\n    workname: str = Field(title=\"workname\",description=\"\u696d\u52d9\u30d5\u30ed\u30fc\u306e\u540d\u524d\")\r\n    players: List[player] = Field(title=\"players\",description=\"\u5f79\u5272\")\r\n    nodes: List[node] = Field(title=\"nodes\",description=\"\u696d\u52d9\u30d5\u30ed\u30fc\u4e0a\u306e\u5404\u30b9\u30c6\u30c3\u30d7\")\r\n    datum: List[data] = Field(title=\"data\",description=\"\u696d\u52d9\u4e0a\u3067\u4f7f\u7528\u3055\u308c\u308b\u30c7\u30fc\u30bf\")\r\n    edges: List[edge] = Field(title=\"edge\",description=\"\u696d\u52d9\u30d5\u30ed\u30fc\u4e0a\u306e\u5206\u5c90\u3084\u6b21\u306e\u30b9\u30c6\u30c3\u30d7\")\r\nopenai.api_key = xxx\r\nlocale.getpreferredencoding = lambda: \"UTF-8\"\r\nquestion_gen_query = (\r\n...\r\n)\r\n\r\nnode_parser = SimpleNodeParser.from_defaults()\r\n\r\nfrom llama_index.evaluation import DatasetGenerator\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\ndocuments = SimpleDirectoryReader('new-service-datasets/datasets/tmp/').load_data()\r\nnode_parser = SimpleNodeParser.from_defaults()\r\nnodes = node_parser.get_nodes_from_documents(documents)\r\n\r\nwith open(\"new-service-datasets/qa_pairs/qa_pairs_test.jsonl\", \"a+\") as fp:\r\n      for idx, node in enumerate(nodes):\r\n          print(node)\r\n\r\n      dataset_generator = DatasetGenerator(\r\n          [node],\r\n          question_gen_query=question_gen_query,\r\n          # service_context=service_context,\r\n          service_context=ServiceContext.from_defaults(),\r\n          metadata_mode=\"all\",\r\n      )\r\n      node_questions_0 = dataset_generator.generate_questions_from_nodes(num=1)\r\n      print(f\"[Node {idx}] Generated questions:\\n {node_questions_0}\", node_questions_0)\r\n      for question in (node_questions_0):\r\n          index = VectorStoreIndex.from_documents(documents, service_context=ServiceContext.from_defaults())\r\n          query_engine = index.as_query_engine(output_cls=Workflow, response_mode=\"compact\")\r\n          response = query_engine.query(question)\r\n          out_dict = {\"query\": question, \"response\": str(response)}\r\n          print(f\"[Node {idx}] Outputs: {out_dict}\")\r\n          fp.write(json.dumps(out_dict) + \"\\n\")\r\n\r\nfp.close()\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nTraceback (most recent call last):\r\n  File \"/Users/yokina/work/python/ragtest/test.py\", line 136, in <module>\r\n    response = query_engine.query(question)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    return self._query(str_or_query_bundle)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 177, in _query\r\n    response = self._response_synthesizer.synthesize(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/base.py\", line 140, in synthesize\r\n    response_str = self.get_response(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/compact_and_refine.py\", line 33, in get_response\r\n    return super().get_response(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 114, in get_response\r\n    response = self._give_response_single(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 170, in _give_response_single\r\n    program(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/response_synthesizers/refine.py\", line 52, in __call__\r\n    answer = self._llm_predictor.predict(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 166, in predict\r\n    output = self._run_program(output_cls, prompt, **prompt_args)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/llm_predictor/base.py\", line 140, in _run_program\r\n    chat_response = program(**prompt_args)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/program/openai_program.py\", line 106, in __call__\r\n    openai_fn_spec = to_openai_function(self._output_cls)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/llms/openai_utils.py\", line 265, in to_openai_function\r\n    \"description\": schema[\"description\"],\r\nKeyError: 'description'\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7997/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7997/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7996",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7996/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7996/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7996/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7996",
        "id": 1929362245,
        "node_id": "I_kwDOIWuq585y_7tF",
        "number": 7996,
        "title": "[Bug]:  Reproduce ElasticSearch vector store example, AttributeError: 'NodeWithEmbedding' object has no attribute 'get_embedding'",
        "user": {
            "login": "ricoyudog",
            "id": 73219750,
            "node_id": "MDQ6VXNlcjczMjE5NzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/73219750?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ricoyudog",
            "html_url": "https://github.com/ricoyudog",
            "followers_url": "https://api.github.com/users/ricoyudog/followers",
            "following_url": "https://api.github.com/users/ricoyudog/following{/other_user}",
            "gists_url": "https://api.github.com/users/ricoyudog/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ricoyudog/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ricoyudog/subscriptions",
            "organizations_url": "https://api.github.com/users/ricoyudog/orgs",
            "repos_url": "https://api.github.com/users/ricoyudog/repos",
            "events_url": "https://api.github.com/users/ricoyudog/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ricoyudog/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-06T03:10:00Z",
        "updated_at": "2023-10-09T23:46:27Z",
        "closed_at": "2023-10-09T23:46:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI am trying to reproduce the example provide from the [Elasticsearch Vector Store]( https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/ElasticsearchIndexDemo.html)\r\n\r\nWhen it goes to create index, it return the error : \r\n```python\r\nAttributeError: 'NodeWithEmbedding' object has no attribute 'get_embedding'\r\n``` \r\n\r\n\r\n\r\n### Version\r\n\r\n0.8.39.post2\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index.vector_stores.elasticsearch import (\r\n    ElasticsearchStore,\r\n)\r\n```python\r\nes = ElasticsearchStore(\r\n    index_name=\"my_index\",\r\n    es_url=\"http://localhost:9200\",\r\n)\r\n``` \r\n```python\r\n\r\nfrom llama_index.schema import TextNode\r\n\r\nnodes = [\r\n    TextNode(\r\n        text=\"The Shawshank Redemption\",\r\n        metadata={\r\n            \"author\": \"Stephen King\",\r\n            \"theme\": \"Friendship\",\r\n        },\r\n    ),\r\n    TextNode(\r\n        text=\"The Godfather\",\r\n        metadata={\r\n            \"director\": \"Francis Ford Coppola\",\r\n            \"theme\": \"Mafia\",\r\n        },\r\n    ),\r\n    TextNode(\r\n        text=\"Inception\",\r\n        metadata={\r\n            \"director\": \"Christopher Nolan\",\r\n        },\r\n    ),\r\n]\r\n\r\n# initialize the vector store\r\nvector_store_metadata_example = ElasticsearchStore(\r\n    index_name=\"movies_metadata_example\",\r\n    es_url=\"http://localhost:9200\",\r\n)\r\nstorage_context = StorageContext.from_defaults(\r\n    vector_store=vector_store_metadata_example\r\n)\r\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\r\n\r\n\r\n# Metadata filter\r\nfrom llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\r\n\r\nfilters = MetadataFilters(filters=[ExactMatchFilter(key=\"theme\", value=\"Mafia\")])\r\n\r\nretriever = index.as_retriever(filters=filters)\r\n\r\nretriever.retrieve(\"What is inception about?\")\r\n``` \r\n\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[250], line 34\r\n     27 vector_store_metadata_example = ElasticsearchStore(\r\n     28     index_name=\"movies_metadata_example\",\r\n     29     es_url=\"http://localhost:9200/\",\r\n     30 )\r\n     31 storage_context = StorageContext.from_defaults(\r\n     32     vector_store=vector_store_metadata_example\r\n     33 )\r\n---> 34 index = VectorStoreIndex(nodes, storage_context=storage_context)\r\n     37 # Metadata filter\r\n     38 from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:46](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/indices/vector_store/base.py:46), in VectorStoreIndex.__init__(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\r\n     44 self._use_async = use_async\r\n     45 self._store_nodes_override = store_nodes_override\r\n---> 46 super().__init__(\r\n     47     nodes=nodes,\r\n     48     index_struct=index_struct,\r\n     49     service_context=service_context,\r\n     50     storage_context=storage_context,\r\n     51     show_progress=show_progress,\r\n     52     **kwargs,\r\n     53 )\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\indices\\base.py:71](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/indices/base.py:71), in BaseIndex.__init__(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\r\n     69 if index_struct is None:\r\n     70     assert nodes is not None\r\n---> 71     index_struct = self.build_index_from_nodes(nodes)\r\n     72 self._index_struct = index_struct\r\n     73 self._storage_context.index_store.add_index_struct(self._index_struct)\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:241](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/indices/vector_store/base.py:241), in VectorStoreIndex.build_index_from_nodes(self, nodes)\r\n    234 def build_index_from_nodes(self, nodes: Sequence[BaseNode]) -> IndexDict:\r\n    235     \"\"\"Build the index from nodes.\r\n    236 \r\n    237     NOTE: Overrides BaseIndex.build_index_from_nodes.\r\n    238         VectorStoreIndex only stores nodes in document store\r\n    239         if vector store does not store text\r\n    240     \"\"\"\r\n--> 241     return self._build_index_from_nodes(nodes)\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:229](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/indices/vector_store/base.py:229), in VectorStoreIndex._build_index_from_nodes(self, nodes)\r\n    227     run_async_tasks(tasks)\r\n    228 else:\r\n--> 229     self._add_nodes_to_index(\r\n    230         index_struct, nodes, show_progress=self._show_progress\r\n    231     )\r\n    232 return index_struct\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:202](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/indices/vector_store/base.py:202), in _add_nodes_to_index(self, index_struct, nodes, show_progress)\r\n    197         index_struct.add_node(node_without_embedding, text_id=new_id)\r\n    198         self._docstore.add_documents(\r\n    199             [node_without_embedding], allow_update=True\r\n    200         )\r\n    201 else:\r\n--> 202     # NOTE: if the vector store keeps text,\r\n    203     # we only need to add image and index nodes\r\n    204     for node, new_id in zip(nodes, new_ids):\r\n    205         if isinstance(node, (ImageNode, IndexNode)):\r\n    206             # NOTE: remove embedding from node to avoid duplication\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\vector_stores\\elasticsearch.py:291](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/vector_stores/elasticsearch.py:291), in ElasticsearchStore.add(self, nodes, create_index_if_not_exists)\r\n    269 def add(\r\n    270     self,\r\n    271     nodes: List[BaseNode],\r\n    272     *,\r\n    273     create_index_if_not_exists: bool = True,\r\n    274 ) -> List[str]:\r\n    275     \"\"\"Add nodes to Elasticsearch index.\r\n    276 \r\n    277     Args:\r\n   (...)\r\n    289         BulkIndexError: If AsyncElasticsearch async_bulk indexing fails.\r\n    290     \"\"\"\r\n--> 291     return asyncio.get_event_loop().run_until_complete(\r\n    292         self.async_add(nodes, create_index_if_not_exists=create_index_if_not_exists)\r\n    293     )\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\nest_asyncio.py:99](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/nest_asyncio.py:99), in _patch_loop..run_until_complete(self, future)\r\n     96 if not f.done():\r\n     97     raise RuntimeError(\r\n     98         'Event loop stopped before Future completed.')\r\n---> 99 return f.result()\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\asyncio\\futures.py:201](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/asyncio/futures.py:201), in Future.result(self)\r\n    199 self.__log_traceback = False\r\n    200 if self._exception is not None:\r\n--> 201     raise self._exception\r\n    202 return self._result\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\asyncio\\tasks.py:256](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/asyncio/tasks.py:256), in Task.__step(***failed resolving arguments***)\r\n    252 try:\r\n    253     if exc is None:\r\n    254         # We use the `send` method directly, because coroutines\r\n    255         # don't have `__iter__` and `__next__` methods.\r\n--> 256         result = coro.send(None)\r\n    257     else:\r\n    258         result = coro.throw(exc)\r\n\r\nFile [c:\\Users\\YURI3\\AppData\\Local\\anaconda3\\envs\\aicd_local3\\lib\\site-packages\\llama_index\\vector_stores\\elasticsearch.py:329](file:///C:/Users/YURI3/AppData/Local/anaconda3/envs/aicd_local3/lib/site-packages/llama_index/vector_stores/elasticsearch.py:329), in ElasticsearchStore.async_add(self, nodes, create_index_if_not_exists)\r\n    326     return []\r\n    328 if create_index_if_not_exists:\r\n--> 329     dims_length = len(nodes[0].get_embedding())\r\n    330     await self._create_index_if_not_exists(\r\n    331         index_name=self.index_name, dims_length=dims_length\r\n    332     )\r\n    334 embeddings: List[List[float]] = []\r\n\r\nAttributeError: 'NodeWithEmbedding' object has no attribute 'get_embedding'\r\n``` ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7996/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7996/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7995",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7995/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7995/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7995/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7995",
        "id": 1929344736,
        "node_id": "I_kwDOIWuq585y_3bg",
        "number": 7995,
        "title": "[Question]: Maximum recursion depth exceeded while calling a Python object",
        "user": {
            "login": "benhgm",
            "id": 80461537,
            "node_id": "MDQ6VXNlcjgwNDYxNTM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/80461537?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/benhgm",
            "html_url": "https://github.com/benhgm",
            "followers_url": "https://api.github.com/users/benhgm/followers",
            "following_url": "https://api.github.com/users/benhgm/following{/other_user}",
            "gists_url": "https://api.github.com/users/benhgm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/benhgm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/benhgm/subscriptions",
            "organizations_url": "https://api.github.com/users/benhgm/orgs",
            "repos_url": "https://api.github.com/users/benhgm/repos",
            "events_url": "https://api.github.com/users/benhgm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/benhgm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-06T02:43:46Z",
        "updated_at": "2023-10-24T06:31:46Z",
        "closed_at": "2023-10-24T06:31:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFollowing the tutorial for [Single Query Transformation](https://github.com/run-llama/llama_index/blob/main/docs/examples/composable_indices/city_analysis/City_Analysis-Decompose.ipynb), I got the error `RecursionError: maximum recursion depth exceeded while calling a Python object`\r\n\r\nI am following the notebook closely. My dataset is different. I am using excel data that is converted to text format. The text length is between 50000 to 100000 characters. Could this be an issue? How can I solve this?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7995/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7995/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7994",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7994/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7994/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7994/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7994",
        "id": 1929251175,
        "node_id": "PR_kwDOIWuq585cD9CP",
        "number": 7994,
        "title": "One-click observability with HoneyHive",
        "user": {
            "login": "michael-hhai",
            "id": 138688447,
            "node_id": "U_kgDOCEQ3vw",
            "avatar_url": "https://avatars.githubusercontent.com/u/138688447?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/michael-hhai",
            "html_url": "https://github.com/michael-hhai",
            "followers_url": "https://api.github.com/users/michael-hhai/followers",
            "following_url": "https://api.github.com/users/michael-hhai/following{/other_user}",
            "gists_url": "https://api.github.com/users/michael-hhai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/michael-hhai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/michael-hhai/subscriptions",
            "organizations_url": "https://api.github.com/users/michael-hhai/orgs",
            "repos_url": "https://api.github.com/users/michael-hhai/repos",
            "events_url": "https://api.github.com/users/michael-hhai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/michael-hhai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-10-06T00:19:57Z",
        "updated_at": "2023-10-12T10:10:10Z",
        "closed_at": "2023-10-12T04:16:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7994",
            "html_url": "https://github.com/run-llama/llama_index/pull/7994",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7994.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7994.patch",
            "merged_at": "2023-10-12T04:16:32Z"
        },
        "body": "# Description\r\n\r\nAdded one-click integration for [HoneyHive](honeyhive.ai) with related documentation. See the documentation for further details.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nAdded the `HoneyHiveLlamaIndexTracer.ipynb` notebook.\r\n\r\n- [ ] Added new unit/integration tests\r\n- [X] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7994/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7994/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7993",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7993/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7993/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7993/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7993",
        "id": 1929228076,
        "node_id": "I_kwDOIWuq585y_a8s",
        "number": 7993,
        "title": "[Question]: ",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-05T23:48:19Z",
        "updated_at": "2023-10-24T06:31:44Z",
        "closed_at": "2023-10-24T06:31:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n<img width=\"920\" alt=\"image\" src=\"https://github.com/run-llama/llama_index/assets/100378946/961ec637-95eb-4f38-9263-b1c8f9b7d4f3\">\r\n\r\n\r\nOnly half the answer showed, after index query ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7993/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7993/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7992",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7992/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7992/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7992/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7992",
        "id": 1929187538,
        "node_id": "PR_kwDOIWuq585cDvGl",
        "number": 7992,
        "title": "fix: missing template vars when logging template data",
        "user": {
            "login": "RogerHYang",
            "id": 80478925,
            "node_id": "MDQ6VXNlcjgwNDc4OTI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/80478925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RogerHYang",
            "html_url": "https://github.com/RogerHYang",
            "followers_url": "https://api.github.com/users/RogerHYang/followers",
            "following_url": "https://api.github.com/users/RogerHYang/following{/other_user}",
            "gists_url": "https://api.github.com/users/RogerHYang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RogerHYang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RogerHYang/subscriptions",
            "organizations_url": "https://api.github.com/users/RogerHYang/orgs",
            "repos_url": "https://api.github.com/users/RogerHYang/repos",
            "events_url": "https://api.github.com/users/RogerHYang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RogerHYang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-05T22:53:17Z",
        "updated_at": "2023-10-06T15:34:04Z",
        "closed_at": "2023-10-06T15:34:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7992",
            "html_url": "https://github.com/run-llama/llama_index/pull/7992",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7992.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7992.patch",
            "merged_at": "2023-10-06T15:34:04Z"
        },
        "body": "# Description\r\n\r\nAdd to the payload of `CBEventType.TEMPLATING` the template vars that have been partially filled out.\r\n\r\nScreenshot below shows the template vars being in two different places. This PR unites them.\r\n\r\n<img width=\"884\" alt=\"Screenshot 2023-10-05 at 3 32 02 PM\" src=\"https://github.com/run-llama/llama_index/assets/80478925/67873a3e-799a-4ba4-a6a7-3700ef9f85e9\">\r\n\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7992/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7992/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7991",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7991/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7991/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7991/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7991",
        "id": 1929116981,
        "node_id": "PR_kwDOIWuq585cDfQl",
        "number": 7991,
        "title": "Add support for SingleStoreDB as vectorstore",
        "user": {
            "login": "apeng-singlestore",
            "id": 127370261,
            "node_id": "U_kgDOB5eEFQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/127370261?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apeng-singlestore",
            "html_url": "https://github.com/apeng-singlestore",
            "followers_url": "https://api.github.com/users/apeng-singlestore/followers",
            "following_url": "https://api.github.com/users/apeng-singlestore/following{/other_user}",
            "gists_url": "https://api.github.com/users/apeng-singlestore/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apeng-singlestore/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apeng-singlestore/subscriptions",
            "organizations_url": "https://api.github.com/users/apeng-singlestore/orgs",
            "repos_url": "https://api.github.com/users/apeng-singlestore/repos",
            "events_url": "https://api.github.com/users/apeng-singlestore/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apeng-singlestore/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "apeng-singlestore",
            "id": 127370261,
            "node_id": "U_kgDOB5eEFQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/127370261?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apeng-singlestore",
            "html_url": "https://github.com/apeng-singlestore",
            "followers_url": "https://api.github.com/users/apeng-singlestore/followers",
            "following_url": "https://api.github.com/users/apeng-singlestore/following{/other_user}",
            "gists_url": "https://api.github.com/users/apeng-singlestore/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apeng-singlestore/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apeng-singlestore/subscriptions",
            "organizations_url": "https://api.github.com/users/apeng-singlestore/orgs",
            "repos_url": "https://api.github.com/users/apeng-singlestore/repos",
            "events_url": "https://api.github.com/users/apeng-singlestore/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apeng-singlestore/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "apeng-singlestore",
                "id": 127370261,
                "node_id": "U_kgDOB5eEFQ",
                "avatar_url": "https://avatars.githubusercontent.com/u/127370261?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/apeng-singlestore",
                "html_url": "https://github.com/apeng-singlestore",
                "followers_url": "https://api.github.com/users/apeng-singlestore/followers",
                "following_url": "https://api.github.com/users/apeng-singlestore/following{/other_user}",
                "gists_url": "https://api.github.com/users/apeng-singlestore/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/apeng-singlestore/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/apeng-singlestore/subscriptions",
                "organizations_url": "https://api.github.com/users/apeng-singlestore/orgs",
                "repos_url": "https://api.github.com/users/apeng-singlestore/repos",
                "events_url": "https://api.github.com/users/apeng-singlestore/events{/privacy}",
                "received_events_url": "https://api.github.com/users/apeng-singlestore/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-10-05T21:49:55Z",
        "updated_at": "2023-11-01T06:21:39Z",
        "closed_at": "2023-11-01T06:21:39Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7991",
            "html_url": "https://github.com/run-llama/llama_index/pull/7991",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7991.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7991.patch",
            "merged_at": "2023-11-01T06:21:39Z"
        },
        "body": "# Description\r\n\r\nAdds support for SingleStoreDB in LlamaIndex as a vectorstore. \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x ] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7991/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7991/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7990",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7990/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7990/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7990/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7990",
        "id": 1929057291,
        "node_id": "PR_kwDOIWuq585cDSDy",
        "number": 7990,
        "title": "Added `PDFReader` to `readers.__init__` for convenience",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-10-05T21:06:40Z",
        "updated_at": "2023-10-06T16:07:27Z",
        "closed_at": "2023-10-06T15:45:51Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7990",
            "html_url": "https://github.com/run-llama/llama_index/pull/7990",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7990.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7990.patch",
            "merged_at": "2023-10-06T15:45:50Z"
        },
        "body": "# Description\r\n\r\nSee PR title\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7990/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7990/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7989",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7989/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7989/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7989/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7989",
        "id": 1929023624,
        "node_id": "PR_kwDOIWuq585cDKs0",
        "number": 7989,
        "title": "Fixing `HuggingFaceLLM.device_map` type hint",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-10-05T20:42:48Z",
        "updated_at": "2023-10-06T16:07:52Z",
        "closed_at": "2023-10-06T15:45:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7989",
            "html_url": "https://github.com/run-llama/llama_index/pull/7989",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7989.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7989.patch",
            "merged_at": "2023-10-06T15:45:58Z"
        },
        "body": "# Description\r\n\r\nAt https://github.com/huggingface/transformers/blob/v4.34.0/src/transformers/modeling_utils.py#L634 we see `device_map` actually defaults to `None` in `transformers`.  So this PR updates its typing to reflect its potential to be `None`.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7989/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7989/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]