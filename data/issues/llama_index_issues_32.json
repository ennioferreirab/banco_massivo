[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3834",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3834/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3834/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3834/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3834",
        "id": 1723217054,
        "node_id": "I_kwDOIWuq585mtjSe",
        "number": 3834,
        "title": "TypeError when importing GPTVectorStoreIndex with Python 3.10.11 and llama_index==0.6.10",
        "user": {
            "login": "apptaro",
            "id": 998626,
            "node_id": "MDQ6VXNlcjk5ODYyNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/998626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/apptaro",
            "html_url": "https://github.com/apptaro",
            "followers_url": "https://api.github.com/users/apptaro/followers",
            "following_url": "https://api.github.com/users/apptaro/following{/other_user}",
            "gists_url": "https://api.github.com/users/apptaro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/apptaro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/apptaro/subscriptions",
            "organizations_url": "https://api.github.com/users/apptaro/orgs",
            "repos_url": "https://api.github.com/users/apptaro/repos",
            "events_url": "https://api.github.com/users/apptaro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/apptaro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-24T05:45:15Z",
        "updated_at": "2023-05-29T01:41:27Z",
        "closed_at": "2023-05-29T01:41:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "from llama_index import GPTVectorStoreIndex\r\nraises\r\nTypeError: Instance and class checks can only be used with @runtime_checkable protocols\r\n\r\nworks fine with llama_index==0.6.9\r\n\r\n![image](https://github.com/jerryjliu/llama_index/assets/998626/93fded1f-fa0d-4bd9-b908-ff70a03fc23b)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3834/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3834/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3833",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3833/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3833/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3833/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3833",
        "id": 1723077362,
        "node_id": "PR_kwDOIWuq585RMx1U",
        "number": 3833,
        "title": "Resolve CVE-2023-32681 by accepting requests>=2.31.0",
        "user": {
            "login": "mai-nakagawa",
            "id": 2883424,
            "node_id": "MDQ6VXNlcjI4ODM0MjQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2883424?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mai-nakagawa",
            "html_url": "https://github.com/mai-nakagawa",
            "followers_url": "https://api.github.com/users/mai-nakagawa/followers",
            "following_url": "https://api.github.com/users/mai-nakagawa/following{/other_user}",
            "gists_url": "https://api.github.com/users/mai-nakagawa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mai-nakagawa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mai-nakagawa/subscriptions",
            "organizations_url": "https://api.github.com/users/mai-nakagawa/orgs",
            "repos_url": "https://api.github.com/users/mai-nakagawa/repos",
            "events_url": "https://api.github.com/users/mai-nakagawa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mai-nakagawa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-24T02:32:06Z",
        "updated_at": "2023-05-25T21:32:07Z",
        "closed_at": "2023-05-25T19:09:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3833",
            "html_url": "https://github.com/run-llama/llama_index/pull/3833",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3833.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3833.patch",
            "merged_at": "2023-05-25T19:09:33Z"
        },
        "body": "Accepting `requests>=2.31.0` to resolve [CVE-2023-32681 (Unintended leak of Proxy-Authorization header)](https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q).\r\n\r\n`requests` was previously pinned to `<2.30.0` by #2099 because requests version (2.30.0) breaks download_loader in llama_hub. I think the root cause of the breaks is that `requests 2.30.0` starts to support `urllib3 2.0`, which may contain minor breaking changes. As per [Release History of `requests`](https://github.com/psf/requests/blob/main/HISTORY.md), we can stay on `urllib3 1.x` with `requests>=2.30.0`.\r\n\r\nHence the better solution is to pin `urllib3<2` instead of pinning `requests<2.30.0`.\r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3833/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3833/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3831",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3831/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3831/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3831/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3831",
        "id": 1722984217,
        "node_id": "I_kwDOIWuq585msqcZ",
        "number": 3831,
        "title": "If in a Chinese question answering system  \uff0chow to make  the answers complete",
        "user": {
            "login": "pythonmanGo",
            "id": 32951840,
            "node_id": "MDQ6VXNlcjMyOTUxODQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/32951840?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pythonmanGo",
            "html_url": "https://github.com/pythonmanGo",
            "followers_url": "https://api.github.com/users/pythonmanGo/followers",
            "following_url": "https://api.github.com/users/pythonmanGo/following{/other_user}",
            "gists_url": "https://api.github.com/users/pythonmanGo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pythonmanGo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pythonmanGo/subscriptions",
            "organizations_url": "https://api.github.com/users/pythonmanGo/orgs",
            "repos_url": "https://api.github.com/users/pythonmanGo/repos",
            "events_url": "https://api.github.com/users/pythonmanGo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pythonmanGo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-24T00:38:29Z",
        "updated_at": "2023-09-10T16:58:04Z",
        "closed_at": "2023-09-10T16:58:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "If in a Chinese question answering system make sure the answers are complete. A few questions about the use of llama_index:\r\n\r\n\r\n1: If I do not load md at once (there are many md files entered into the project as documents) or if I do not cache index.storage_context.persist(\" dir \") locally, I may need to reload many md at a time, which will consume a large amount of tokesn. This is obviously not scientific.\r\n\r\n\r\n2: If I  serialized md files to the local cache first(serialized  jason)\u3002I only need   use the token required to raise the problem each time, it  is more economical in terms of token usage. However, I need to build the index by loading the cache:\r\n\r\n storage_context = StorageContext.from_defaults(persist_dir=datadir)\r\n\r\n    # build index\r\n    #index = GPTVectorStoreIndex.from_documents(documents)\r\n    index = load_index_from_storage(storage_context)\r\n\r\n\r\nThe problem with the second method is that if the Chinese Q&A is used to feed the data, subsequent users will ask questions, but cannot give complete answers. Maybe it's because max_tokens is limited in size by default. But loading index through a local cache doesn't seem to reset max_tokens.I need to konw how to set max_tokens  while user answer question, or  mybe the cause is i do not set the correct  split character?how to fix it .Let the system run correct.\r\n\r\n\r\ncode\r\n\r\n`\r\ndef LoadMixSearchGPT(dirdata):\r\n\r\n    # define LLM\r\n    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=512))\r\n\r\n    # define prompt helper\r\n    # set maximum input size\r\n    max_input_size = 4096\r\n    # set number of output tokens\r\n    num_output = 512\r\n    # set maximum chunk overlap\r\n    max_chunk_overlap = 20\r\n    prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\r\n\r\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\r\n\r\n    index = GPTVectorStoreIndex.from_documents(\r\n        documents, service_context=service_context\r\n    )\r\n\r\n    index.storage_context.persist(persist_dir=dirdata)\r\n\r\n\r\ndef MixSerchGPT(prompt, datadir):\r\n    prompt=prompt.strip()\r\n   \r\n    try:\r\n\r\n        storage_context = StorageContext.from_defaults(persist_dir=datadir)\r\n\r\n        # build index\r\n        #index = GPTVectorStoreIndex.from_documents(documents)\r\n        index = load_index_from_storage(storage_context)\r\n\r\n        # configure retriever\r\n        retriever = VectorIndexRetriever(\r\n            index=index, \r\n            similarity_top_k=1,\r\n            \r\n        )\r\n\r\n        # configure response synthesizer\r\n        response_synthesizer = ResponseSynthesizer.from_args(\r\n            node_postprocessors=[\r\n                SimilarityPostprocessor(similarity_cutoff=0.7)\r\n            ]\r\n        )\r\n        #retriever = index.as_retriever(retriever_mode='embedding')\r\n\r\n        # assemble query engine\r\n        query_engine = RetrieverQueryEngine(\r\n            retriever=retriever,\r\n            response_synthesizer=response_synthesizer,\r\n        )\r\n\r\n        # query\r\n        response = query_engine.query(prompt)\r\n        \r\n\r\n    except Exception as e:\r\n        \r\n            \r\n            print(\"erro:\",e)\r\n\r\n    return response `",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3831/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3831/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3830",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3830/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3830/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3830/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3830",
        "id": 1722966763,
        "node_id": "PR_kwDOIWuq585RMaFy",
        "number": 3830,
        "title": "Skip loop intended for debug mode when it's not enabled.",
        "user": {
            "login": "ttsugriy",
            "id": 172294,
            "node_id": "MDQ6VXNlcjE3MjI5NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/172294?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ttsugriy",
            "html_url": "https://github.com/ttsugriy",
            "followers_url": "https://api.github.com/users/ttsugriy/followers",
            "following_url": "https://api.github.com/users/ttsugriy/following{/other_user}",
            "gists_url": "https://api.github.com/users/ttsugriy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ttsugriy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ttsugriy/subscriptions",
            "organizations_url": "https://api.github.com/users/ttsugriy/orgs",
            "repos_url": "https://api.github.com/users/ttsugriy/repos",
            "events_url": "https://api.github.com/users/ttsugriy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ttsugriy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-24T00:17:21Z",
        "updated_at": "2023-05-26T02:03:05Z",
        "closed_at": "2023-05-26T02:03:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3830",
            "html_url": "https://github.com/run-llama/llama_index/pull/3830",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3830.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3830.patch",
            "merged_at": "2023-05-26T02:03:04Z"
        },
        "body": "`logger.debug` will not print anything in debug mode, but the loop itself would still run and for each iteration overhead involved in checking whether logging is enabled will be performed, which is totally unnecessary.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3830/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3830/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3829",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3829/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3829/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3829/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3829",
        "id": 1722962685,
        "node_id": "PR_kwDOIWuq585RMZMX",
        "number": 3829,
        "title": "[nit][perf] Replace list comprehension with list.",
        "user": {
            "login": "ttsugriy",
            "id": 172294,
            "node_id": "MDQ6VXNlcjE3MjI5NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/172294?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ttsugriy",
            "html_url": "https://github.com/ttsugriy",
            "followers_url": "https://api.github.com/users/ttsugriy/followers",
            "following_url": "https://api.github.com/users/ttsugriy/following{/other_user}",
            "gists_url": "https://api.github.com/users/ttsugriy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ttsugriy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ttsugriy/subscriptions",
            "organizations_url": "https://api.github.com/users/ttsugriy/orgs",
            "repos_url": "https://api.github.com/users/ttsugriy/repos",
            "events_url": "https://api.github.com/users/ttsugriy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ttsugriy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-24T00:11:28Z",
        "updated_at": "2023-05-24T16:03:08Z",
        "closed_at": "2023-05-24T06:33:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3829",
            "html_url": "https://github.com/run-llama/llama_index/pull/3829",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3829.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3829.patch",
            "merged_at": "2023-05-24T06:33:59Z"
        },
        "body": "It's shorter and more efficient.\r\nIn [colab](https://colab.research.google.com/gist/ttsugriy/1a34380f6d9c5e78307c2b263cb3f61d/cache-member-function.ipynb) you can see that `list` is more than 2X faster than corresponding list comprehension. Not that it's a huge deal, but still.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3829/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3829/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3824",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3824/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3824/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3824/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3824",
        "id": 1722916720,
        "node_id": "PR_kwDOIWuq585RMPOv",
        "number": 3824,
        "title": "[version] bump version to 0.6.10 ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-23T23:11:20Z",
        "updated_at": "2023-05-24T05:10:46Z",
        "closed_at": "2023-05-24T05:10:45Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3824",
            "html_url": "https://github.com/run-llama/llama_index/pull/3824",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3824.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3824.patch",
            "merged_at": "2023-05-24T05:10:45Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3824/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3824/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3823",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3823/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3823/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3823/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3823",
        "id": 1722895949,
        "node_id": "PR_kwDOIWuq585RMKvZ",
        "number": 3823,
        "title": "Hongyi error correction",
        "user": {
            "login": "hongyishi",
            "id": 7098202,
            "node_id": "MDQ6VXNlcjcwOTgyMDI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/7098202?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hongyishi",
            "html_url": "https://github.com/hongyishi",
            "followers_url": "https://api.github.com/users/hongyishi/followers",
            "following_url": "https://api.github.com/users/hongyishi/following{/other_user}",
            "gists_url": "https://api.github.com/users/hongyishi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hongyishi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hongyishi/subscriptions",
            "organizations_url": "https://api.github.com/users/hongyishi/orgs",
            "repos_url": "https://api.github.com/users/hongyishi/repos",
            "events_url": "https://api.github.com/users/hongyishi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hongyishi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-23T22:52:31Z",
        "updated_at": "2023-05-31T17:19:03Z",
        "closed_at": "2023-05-31T17:19:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3823",
            "html_url": "https://github.com/run-llama/llama_index/pull/3823",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3823.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3823.patch",
            "merged_at": "2023-05-31T17:19:03Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3823/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3823/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3820",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3820/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3820/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3820/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3820",
        "id": 1722831479,
        "node_id": "PR_kwDOIWuq585RL8sI",
        "number": 3820,
        "title": "pin typing versions",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-23T21:45:22Z",
        "updated_at": "2023-05-23T21:56:55Z",
        "closed_at": "2023-05-23T21:56:55Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3820",
            "html_url": "https://github.com/run-llama/llama_index/pull/3820",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3820.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3820.patch",
            "merged_at": "2023-05-23T21:56:55Z"
        },
        "body": "This popped up on llama-hub, and seems to be popping up for llama-index as well\r\n\r\nhttps://github.com/jerryjliu/llama_index/actions/runs/5055323639/jobs/9081596479?pr=3778\r\n\r\nhttps://github.com/jerryjliu/llama_index/issues/3802\r\n\r\nThis should fix the issue :) \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3820/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3820/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3802",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3802/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3802/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3802/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3802",
        "id": 1722559069,
        "node_id": "I_kwDOIWuq585mrCpd",
        "number": 3802,
        "title": "TypeError: issubclass() arg 1 must be a class",
        "user": {
            "login": "jacinticow",
            "id": 48676437,
            "node_id": "MDQ6VXNlcjQ4Njc2NDM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/48676437?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jacinticow",
            "html_url": "https://github.com/jacinticow",
            "followers_url": "https://api.github.com/users/jacinticow/followers",
            "following_url": "https://api.github.com/users/jacinticow/following{/other_user}",
            "gists_url": "https://api.github.com/users/jacinticow/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jacinticow/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jacinticow/subscriptions",
            "organizations_url": "https://api.github.com/users/jacinticow/orgs",
            "repos_url": "https://api.github.com/users/jacinticow/repos",
            "events_url": "https://api.github.com/users/jacinticow/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jacinticow/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-05-23T18:11:38Z",
        "updated_at": "2023-07-17T02:02:34Z",
        "closed_at": "2023-07-10T20:03:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "<img width=\"1126\" alt=\"Screenshot 2023-05-23 at 20 10 17\" src=\"https://github.com/jerryjliu/llama_index/assets/48676437/1cf0d28f-ac3c-443c-8ff8-325f92660142\">\r\nWhen importing either the GPTVectorStoreIndex or SimpleDirectoryReader I get the TypeError. I am using python version 3.10.10, with llama-index version 0.6.9.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3802/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3802/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3791",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3791/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3791/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3791/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3791",
        "id": 1722305816,
        "node_id": "I_kwDOIWuq585mqE0Y",
        "number": 3791,
        "title": "GPTVectorStoreIndex.from_documents stuck",
        "user": {
            "login": "tomgelu",
            "id": 16277892,
            "node_id": "MDQ6VXNlcjE2Mjc3ODky",
            "avatar_url": "https://avatars.githubusercontent.com/u/16277892?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tomgelu",
            "html_url": "https://github.com/tomgelu",
            "followers_url": "https://api.github.com/users/tomgelu/followers",
            "following_url": "https://api.github.com/users/tomgelu/following{/other_user}",
            "gists_url": "https://api.github.com/users/tomgelu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tomgelu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tomgelu/subscriptions",
            "organizations_url": "https://api.github.com/users/tomgelu/orgs",
            "repos_url": "https://api.github.com/users/tomgelu/repos",
            "events_url": "https://api.github.com/users/tomgelu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tomgelu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-23T15:24:50Z",
        "updated_at": "2023-06-14T03:08:17Z",
        "closed_at": "2023-05-23T15:31:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi. I'm trying to run the example of the tutorial for using local LLM (Writer/camel-5b-hf).\r\n\r\nMy service context is well initialized, so are my documents, but once i try to `index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)`. I get stucked and does not stop running (2h) now, for a pdf of 172 pages.\r\nIs it supposed to be that slow or something is going wrong ?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3791/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3791/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3788",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3788/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3788/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3788/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3788",
        "id": 1721678286,
        "node_id": "I_kwDOIWuq585mnrnO",
        "number": 3788,
        "title": "ValueError while querying on OpensearchVectorClient.do_approx_knn",
        "user": {
            "login": "chankoo",
            "id": 38183218,
            "node_id": "MDQ6VXNlcjM4MTgzMjE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38183218?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chankoo",
            "html_url": "https://github.com/chankoo",
            "followers_url": "https://api.github.com/users/chankoo/followers",
            "following_url": "https://api.github.com/users/chankoo/following{/other_user}",
            "gists_url": "https://api.github.com/users/chankoo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chankoo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chankoo/subscriptions",
            "organizations_url": "https://api.github.com/users/chankoo/orgs",
            "repos_url": "https://api.github.com/users/chankoo/repos",
            "events_url": "https://api.github.com/users/chankoo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chankoo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-23T09:54:15Z",
        "updated_at": "2023-05-31T07:14:03Z",
        "closed_at": "2023-05-31T07:14:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Description:\r\nI encountered a ValueError while using the query_engine.query() function. The error occurred in the \"OpensearchVectorClient.do_approx_knn()\" method, within llama_index.vector_stores.opensearch.py on line 146. \r\n\r\n`node = Node(text=text, extra_info=source, doc_id=doc_id)`\r\n\r\nAn error has occurred while initializing 'Node' because of a function called '_validate_is_flat_dict' that is included in the 'post_init' method. This function expects the parameter 'extra_info' to be a flat dictionary, but the value of 'extra_info' (which is the value of \"_source\" below) has a value of type <list>.\r\n\r\n```\r\n{\r\n        \"_index\" :<str>,\r\n        \"_type\" : \"_doc\",\r\n        \"_id\" : <str>,\r\n        \"_score\" : 1.0,\r\n        \"_source\" : {\r\n          \"content\" : <str>,\r\n          \"embedding\" : <list>\r\n        }\r\n}\r\n```\r\n\r\nEnvironment:\r\n- llama_index version: 0.6.9\r\n- AWS opensearch: 1.3\r\n\r\nError Message:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nInput In [1], in <module>\r\n      1 from wishket.applications.news.services import NewsGPTService\r\n      3 s = NewsGPTService()\r\n----> 4 res = s.query(\"\ucfe0\ubc84\ub124\ud2f0\uc2a4 \ud65c\uc6a9\ubc95\uc744 \uc54c\ub824\uc918\")\r\n      5 res\r\n\r\nFile ~/sites/wishket/wishket/applications/news/services.py:413, in NewsGPTService.query(self, query_str, **kwargs)\r\n    404 service_context = self.builder.service_context\r\n    405 query_engine = self.index.as_query_engine(\r\n    406     service_context=service_context,\r\n    407     response_mode=ResponseMode.COMPACT,\r\n   (...)\r\n    411     verbose=True,\r\n    412 )\r\n--> 413 response = query_engine.query(query_str)\r\n    414 return response\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/indices/query/base.py:18, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     16 if isinstance(str_or_query_bundle, str):\r\n     17     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 18 return self._query(str_or_query_bundle)\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/query_engine/retriever_query_engine.py:139, in RetrieverQueryEngine._query(self, query_bundle)\r\n    136 query_id = self.callback_manager.on_event_start(CBEventType.QUERY)\r\n    138 retrieve_id = self.callback_manager.on_event_start(CBEventType.RETRIEVE)\r\n--> 139 nodes = self._retriever.retrieve(query_bundle)\r\n    140 self.callback_manager.on_event_end(\r\n    141     CBEventType.RETRIEVE, payload={\"nodes\": nodes}, event_id=retrieve_id\r\n    142 )\r\n    144 synth_id = self.callback_manager.on_event_start(CBEventType.SYNTHESIZE)\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/indices/base_retriever.py:21, in BaseRetriever.retrieve(self, str_or_query_bundle)\r\n     19 if isinstance(str_or_query_bundle, str):\r\n     20     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 21 return self._retrieve(str_or_query_bundle)\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/token_counter/token_counter.py:78, in llm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict(_self, *args, **kwargs)\r\n     76 def wrapped_llm_predict(_self: Any, *args: Any, **kwargs: Any) -> Any:\r\n     77     with wrapper_logic(_self):\r\n---> 78         f_return_val = f(_self, *args, **kwargs)\r\n     80     return f_return_val\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/indices/vector_store/retrievers/retriever.py:84, in VectorIndexRetriever._retrieve(self, query_bundle)\r\n     69         query_bundle.embedding = (\r\n     70             self._service_context.embed_model.get_agg_embedding_from_queries(\r\n     71                 query_bundle.embedding_strs\r\n     72             )\r\n     73         )\r\n     75 query = VectorStoreQuery(\r\n     76     query_embedding=query_bundle.embedding,\r\n     77     similarity_top_k=self._similarity_top_k,\r\n   (...)\r\n     82     filters=self._filters,\r\n     83 )\r\n---> 84 query_result = self._vector_store.query(query, **self._kwargs)\r\n     86 if query_result.nodes is None:\r\n     87     # NOTE: vector store does not keep text and returns node indices.\r\n     88     # Need to recover all nodes from docstore\r\n     89     if query_result.ids is None:\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/vector_stores/opensearch.py:215, in OpensearchVectorStore.query(self, query, **kwargs)\r\n    212     raise ValueError(\"Metadata filters not implemented for OpenSearch yet.\")\r\n    214 query_embedding = cast(List[float], query.query_embedding)\r\n--> 215 return self._client.do_approx_knn(query_embedding, query.similarity_top_k)\r\n\r\nFile ~/sites/wishket/wishket/core/llm/vector_stores.py:46, in WOpensearchVectorClient.do_approx_knn(self, query_embedding, k)\r\n     43     ic(type(val))\r\n     45 doc_id = hit[\"_id\"]\r\n---> 46 node = Node(text=text, extra_info=source, doc_id=doc_id)\r\n     47 ids.append(doc_id)\r\n     48 nodes.append(node)\r\n\r\nFile <string>:10, in __init__(self, text, doc_id, embedding, doc_hash, extra_info, node_info, relationships)\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/data_structs/node.py:63, in Node.__post_init__(self)\r\n     61 def __post_init__(self) -> None:\r\n     62     \"\"\"Post init.\"\"\"\r\n---> 63     super().__post_init__()\r\n     64     # NOTE: for Node objects, the text field is required\r\n     65     if self.text is None:\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/schema.py:58, in BaseDocument.__post_init__(self)\r\n     55     self.doc_hash = self._generate_doc_hash()\r\n     57 if self.extra_info is not None:\r\n---> 58     _validate_is_flat_dict(self.extra_info)\r\n\r\nFile ~/.pyenv/versions/3.8.14/lib/python3.8/site-packages/llama_index/schema.py:21, in _validate_is_flat_dict(metadata_dict)\r\n     19     raise ValueError(\"Metadata key must be str!\")\r\n     20 if not isinstance(val, (str, int, float)):\r\n---> 21     raise ValueError(\"Value must be one of (str, int, float)\")\r\n\r\nValueError: Value must be one of (str, int, float)\r\n```\r\n\r\nPlease let me know if any further information is required to investigate and resolve this issue.\r\n\r\nThank you for your so helpful project. I'll keep an eye on it.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3788/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3788/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3784",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3784/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3784/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3784/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3784",
        "id": 1721387093,
        "node_id": "PR_kwDOIWuq585RHDE_",
        "number": 3784,
        "title": "fixed typo",
        "user": {
            "login": "sad-mathematician",
            "id": 134358999,
            "node_id": "U_kgDOCAIn1w",
            "avatar_url": "https://avatars.githubusercontent.com/u/134358999?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sad-mathematician",
            "html_url": "https://github.com/sad-mathematician",
            "followers_url": "https://api.github.com/users/sad-mathematician/followers",
            "following_url": "https://api.github.com/users/sad-mathematician/following{/other_user}",
            "gists_url": "https://api.github.com/users/sad-mathematician/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sad-mathematician/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sad-mathematician/subscriptions",
            "organizations_url": "https://api.github.com/users/sad-mathematician/orgs",
            "repos_url": "https://api.github.com/users/sad-mathematician/repos",
            "events_url": "https://api.github.com/users/sad-mathematician/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sad-mathematician/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-23T07:15:29Z",
        "updated_at": "2023-05-25T05:56:00Z",
        "closed_at": "2023-05-25T04:39:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3784",
            "html_url": "https://github.com/run-llama/llama_index/pull/3784",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3784.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3784.patch",
            "merged_at": "2023-05-25T04:39:32Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3784/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3784/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3783",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3783/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3783/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3783/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3783",
        "id": 1721319327,
        "node_id": "I_kwDOIWuq585mmT-f",
        "number": 3783,
        "title": "Getting Broken Words or not getting words in proper format when using generator response_stream.response_gen",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-23T06:39:10Z",
        "updated_at": "2023-09-11T17:03:56Z",
        "closed_at": "2023-09-11T17:03:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Getting Broken Words or not getting words in proper format when using generator \r\n\r\nUsing this below code to stream the result but getting broken words \r\nfor example \r\nSuppose as su ppose \r\nPostman as POST MAN\r\nVelocity as Velo city\r\n\r\ndef generate_response():\r\n        for text in response_stream.response_gen:\r\n                yield f\"data: {text}\\n\\n\"\r\n                print(text)\r\n    return Response(stream_with_context(generate_response()), mimetype='text/event-stream')\r\n    \r\n    \r\nPlease Help for this\r\n\r\nAs I want response in HTML format it's giving response like\r\n\r\n<p\r\n>\r\nSmart\r\nsearch\r\n is\r\n a\r\n search\r\n functionality\r\n implemented\r\n using\r\n pre\r\n-trained\r\n B\r\nERT\r\n (\r\nBid\r\nirectional\r\n Encoder\r\n Represent\r\nations\r\n from\r\n Transformers\r\n)\r\n\r\n\r\nSpaces within the word ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3783/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3783/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3780",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3780/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3780/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3780/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3780",
        "id": 1721244016,
        "node_id": "I_kwDOIWuq585mmBlw",
        "number": 3780,
        "title": "when is the embedding generated by llama-index for the input text",
        "user": {
            "login": "suraj-gade",
            "id": 112926867,
            "node_id": "U_kgDOBrsgkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/112926867?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suraj-gade",
            "html_url": "https://github.com/suraj-gade",
            "followers_url": "https://api.github.com/users/suraj-gade/followers",
            "following_url": "https://api.github.com/users/suraj-gade/following{/other_user}",
            "gists_url": "https://api.github.com/users/suraj-gade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suraj-gade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suraj-gade/subscriptions",
            "organizations_url": "https://api.github.com/users/suraj-gade/orgs",
            "repos_url": "https://api.github.com/users/suraj-gade/repos",
            "events_url": "https://api.github.com/users/suraj-gade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suraj-gade/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-23T05:51:32Z",
        "updated_at": "2023-07-22T02:36:54Z",
        "closed_at": "2023-07-22T02:36:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\n\r\nBelow is the code that I am using to do inference on Fastchat LLM.\r\n```\r\nfrom llama_index import GPTListIndex, SimpleDirectoryReader, GPTVectorStoreIndex, PromptHelper, LLMPredictor\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index import LangchainEmbedding, ServiceContext\r\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\r\n\r\nmodel_name = 'lmsys/fastchat-t5-3b-v1.0'\r\ntokenizer = T5Tokenizer.from_pretrained(model_name)\r\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\r\n\r\nfrom transformers import pipeline\r\n\r\npipe = pipeline(\r\n    \"text2text-generation\", model=model, tokenizer=tokenizer,\r\n    max_length=1024, temperature=0, top_p = 1,no_repeat_ngram_size=4, early_stopping=True\r\n)\r\n\r\nfrom langchain.llms import HuggingFacePipeline\r\nllm = HuggingFacePipeline(pipeline=pipe)\r\n\r\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings())\r\n\r\n# set maximum input size\r\nmax_input_size = 2048\r\n# set number of output tokens\r\nnum_outputs = 512\r\n# set maximum chunk overlap\r\nmax_chunk_overlap = 20\r\n# set chunk size limit\r\nchunk_size_limit = 512\r\nprompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap)\r\n\r\nservice_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=LLMPredictor(llm), prompt_helper=prompt_helper, chunk_size_limit=chunk_size_limit)\r\n\r\n# build index\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\n\r\nnew_index = GPTListIndex.from_documents(documents, service_context=service_context)\r\n\r\n# query with embed_model specified\r\nquery_engine = new_index.as_query_engine(\r\n    retriever_mode=\"embedding\", \r\n    verbose=True,\r\n    #streaming=True,\r\n    similarity_top_k=1\r\n    #service_context=service_context\r\n)\r\n\r\nresponse = query_engine.query(\"sample query question?\")\r\n```\r\n\r\nHere the \"data\" folder has my full input text in pdf format, and am using the llama_index and langchain pipeline to build the index on that and fetch the relevant chunk to generate the prompt with context and query the FastChat model as shown in the code.\r\n\r\nI want to understand when does llama_index generate the embeddings for the input text from the \"data\" folder. \r\nis it at the time of indexing `new_index = GPTListIndex.from_documents(documents, service_context=service_context)` the embeddings are generated for all the nodes/chunks in the input text of document \r\nor\r\nat the time of query `query_engine.query(\"sample query question?\")`  when the relevant chunk/node is to be fetched with similar embeddings as that of input prompt.\r\n\r\nPlease help me understand at what point does llama_index generate the embeddings.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3780/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3780/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3779",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3779/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3779/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3779/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3779",
        "id": 1721230412,
        "node_id": "I_kwDOIWuq585ml-RM",
        "number": 3779,
        "title": "using llama index to query/inference a LLM using GPU",
        "user": {
            "login": "suraj-gade",
            "id": 112926867,
            "node_id": "U_kgDOBrsgkw",
            "avatar_url": "https://avatars.githubusercontent.com/u/112926867?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suraj-gade",
            "html_url": "https://github.com/suraj-gade",
            "followers_url": "https://api.github.com/users/suraj-gade/followers",
            "following_url": "https://api.github.com/users/suraj-gade/following{/other_user}",
            "gists_url": "https://api.github.com/users/suraj-gade/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suraj-gade/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suraj-gade/subscriptions",
            "organizations_url": "https://api.github.com/users/suraj-gade/orgs",
            "repos_url": "https://api.github.com/users/suraj-gade/repos",
            "events_url": "https://api.github.com/users/suraj-gade/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suraj-gade/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-05-23T05:40:58Z",
        "updated_at": "2023-11-14T04:56:05Z",
        "closed_at": "2023-07-22T02:34:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\n\r\nI am building a chatbot using LLM like fastchat-t5-3b-v1.0  and want to reduce my inference time. \r\n\r\nBelow is the code that I am using to do inference on Fastchat LLM. \r\n```\r\nfrom llama_index import GPTListIndex, SimpleDirectoryReader, GPTVectorStoreIndex, PromptHelper, LLMPredictor\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom llama_index import LangchainEmbedding, ServiceContext\r\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\r\n\r\nmodel_name = 'lmsys/fastchat-t5-3b-v1.0'\r\ntokenizer = T5Tokenizer.from_pretrained(model_name)\r\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\r\n\r\nfrom transformers import pipeline\r\n\r\npipe = pipeline(\r\n    \"text2text-generation\", model=model, tokenizer=tokenizer,\r\n    max_length=1024, temperature=0, top_p = 1,no_repeat_ngram_size=4, early_stopping=True\r\n)\r\n\r\nfrom langchain.llms import HuggingFacePipeline\r\nllm = HuggingFacePipeline(pipeline=pipe)\r\n\r\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings())\r\n\r\n# set maximum input size\r\nmax_input_size = 2048\r\n# set number of output tokens\r\nnum_outputs = 512\r\n# set maximum chunk overlap\r\nmax_chunk_overlap = 20\r\n# set chunk size limit\r\nchunk_size_limit = 512\r\nprompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap)\r\n\r\nservice_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=LLMPredictor(llm), prompt_helper=prompt_helper, chunk_size_limit=chunk_size_limit)\r\n\r\n# build index\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\n\r\nnew_index = GPTListIndex.from_documents(documents, service_context=service_context)\r\n\r\n# query with embed_model specified\r\nquery_engine = new_index.as_query_engine(\r\n    retriever_mode=\"embedding\", \r\n    verbose=True,\r\n    #streaming=True,\r\n    similarity_top_k=1\r\n    #service_context=service_context\r\n)\r\n\r\nresponse = query_engine.query(\"sample query question?\")\r\n```\r\nHere the \"data\" folder has my full input text in pdf format, and am using the llama_index and langchain pipeline to build the index on that and fetch the relevant chunk to generate the prompt with context and query the FastChat model as shown in the code.\r\n\r\nThis takes around 2 mins on average to get a response for a query. I want to bring down this inference time.\r\n\r\nis there any way to introduce GPU for the inference with llama_index and langchain/huggingface pipeline steps above? Also if there is any way to optimize these steps to get better response time?\r\nPlease let me know your thoughts on this.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3779/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3779/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3778",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3778/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3778/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3778/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3778",
        "id": 1721229357,
        "node_id": "PR_kwDOIWuq585RGf1V",
        "number": 3778,
        "title": "Persist Bug fix - do not modify path with custom fs",
        "user": {
            "login": "yoeldk",
            "id": 12507451,
            "node_id": "MDQ6VXNlcjEyNTA3NDUx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12507451?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yoeldk",
            "html_url": "https://github.com/yoeldk",
            "followers_url": "https://api.github.com/users/yoeldk/followers",
            "following_url": "https://api.github.com/users/yoeldk/following{/other_user}",
            "gists_url": "https://api.github.com/users/yoeldk/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yoeldk/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yoeldk/subscriptions",
            "organizations_url": "https://api.github.com/users/yoeldk/orgs",
            "repos_url": "https://api.github.com/users/yoeldk/repos",
            "events_url": "https://api.github.com/users/yoeldk/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yoeldk/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-23T05:39:59Z",
        "updated_at": "2023-06-15T18:44:58Z",
        "closed_at": "2023-06-15T18:44:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3778",
            "html_url": "https://github.com/run-llama/llama_index/pull/3778",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3778.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3778.patch",
            "merged_at": "2023-06-15T18:44:57Z"
        },
        "body": "When fs points to S3, Path will replace slashes with backslashes which causes an error when saving files to S3. My fix is to not manipulate a custom fs path with Path() and let the user full control over it.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3778/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3778/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3777",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3777/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3777/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3777/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3777",
        "id": 1721193048,
        "node_id": "I_kwDOIWuq585ml1JY",
        "number": 3777,
        "title": "Google reader and Notion reader are not working",
        "user": {
            "login": "Ashish5869",
            "id": 131770947,
            "node_id": "U_kgDOB9qqQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/131770947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ashish5869",
            "html_url": "https://github.com/Ashish5869",
            "followers_url": "https://api.github.com/users/Ashish5869/followers",
            "following_url": "https://api.github.com/users/Ashish5869/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ashish5869/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ashish5869/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ashish5869/subscriptions",
            "organizations_url": "https://api.github.com/users/Ashish5869/orgs",
            "repos_url": "https://api.github.com/users/Ashish5869/repos",
            "events_url": "https://api.github.com/users/Ashish5869/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ashish5869/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-05-23T05:11:08Z",
        "updated_at": "2023-12-01T02:40:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Google docs is working but google drive reader is not working \r\n\r\n```\r\nfrom llama_index import download_loader\r\n\r\nGoogleDriveReader = download_loader('GoogleDriveReader')\r\n\r\nloader = GoogleDriveReader()\r\ndocuments = loader.load_data(file_ids=['file_id'])\r\n\r\nOUTPUT:\r\nTypeError: GoogleDriveReader._load_from_file_ids() takes 2 positional arguments but 3 were given\r\n```\r\n\r\n\r\nNotion reader is also giving an error.\r\n\r\n```\r\nfrom llama_index import GPTListIndex, NotionPageReader\r\nfrom IPython.display import Markdown, display\r\nimport os\r\nintegration_token = 'notion_integration_token'\r\npage_ids = [\"page_id\"]\r\nnotion_reader = NotionPageReader(integration_token=integration_token)\r\ndocuments = notion_reader.read_page(page_id=page_ids)\r\n\r\nOUTPUT:\r\n~/.local/lib/python3.10/site-packages/llama_index/readers/notion.py in _read_block(self, block_id, num_tabs)\r\n     58             data = res.json()\r\n     59 \r\n---> 60             for result in data[\"results\"]:\r\n     61                 result_type = result[\"type\"]\r\n     62                 result_obj = result[result_type]\r\n\r\nKeyError: 'results'\r\n```\r\nHow to resolve this error?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3777/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 1,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3777/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3771",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3771/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3771/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3771/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3771",
        "id": 1720636226,
        "node_id": "PR_kwDOIWuq585REZ5y",
        "number": 3771,
        "title": "Update to use BaseLLMPredictor rather than LLMPredictor",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-22T21:54:35Z",
        "updated_at": "2023-05-23T00:18:58Z",
        "closed_at": "2023-05-23T00:18:57Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3771",
            "html_url": "https://github.com/run-llama/llama_index/pull/3771",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3771.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3771.patch",
            "merged_at": "2023-05-23T00:18:57Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3771/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3771/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3765",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3765/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3765/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3765/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3765",
        "id": 1720347588,
        "node_id": "PR_kwDOIWuq585RDYZ5",
        "number": 3765,
        "title": "Add DynamoDB Store",
        "user": {
            "login": "sinofseven",
            "id": 13509891,
            "node_id": "MDQ6VXNlcjEzNTA5ODkx",
            "avatar_url": "https://avatars.githubusercontent.com/u/13509891?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sinofseven",
            "html_url": "https://github.com/sinofseven",
            "followers_url": "https://api.github.com/users/sinofseven/followers",
            "following_url": "https://api.github.com/users/sinofseven/following{/other_user}",
            "gists_url": "https://api.github.com/users/sinofseven/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sinofseven/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sinofseven/subscriptions",
            "organizations_url": "https://api.github.com/users/sinofseven/orgs",
            "repos_url": "https://api.github.com/users/sinofseven/repos",
            "events_url": "https://api.github.com/users/sinofseven/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sinofseven/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-22T19:33:49Z",
        "updated_at": "2023-05-26T07:45:39Z",
        "closed_at": "2023-05-25T06:18:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3765",
            "html_url": "https://github.com/run-llama/llama_index/pull/3765",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3765.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3765.patch",
            "merged_at": "2023-05-25T06:18:33Z"
        },
        "body": "Implementation of a DynamoDB-backed KV store, Document Store, Index Store, and Vector Store. Since DynamoDB is a commonly used and easy-to-setup data storage layer, I thought this may be a useful addition the project.\r\n\r\nI used boto3 for the DynamoDB interactions & am using moto to mock those interactions in unit tests. Vector store testing was not implemented because there were not many samples.\r\n\r\nThe storage scheme stores all KV pairs within a specified DynamoDB Table.\r\n\r\nThe KV pair data is separated in partitions by collection name where each hash key is the collection name. If the value contains a float, it is converted to Decimal before being put into the table.\r\n\r\nThe Vector Store was implemented using DynamoDBKVStore, based on the SimpleVectorStore implementation.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3765/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3765/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3756",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3756/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3756/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3756/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3756",
        "id": 1720089169,
        "node_id": "PR_kwDOIWuq585RCexK",
        "number": 3756,
        "title": "docs: Add CoFounder to App Showcase gallary",
        "user": {
            "login": "seawatts",
            "id": 2148546,
            "node_id": "MDQ6VXNlcjIxNDg1NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2148546?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seawatts",
            "html_url": "https://github.com/seawatts",
            "followers_url": "https://api.github.com/users/seawatts/followers",
            "following_url": "https://api.github.com/users/seawatts/following{/other_user}",
            "gists_url": "https://api.github.com/users/seawatts/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seawatts/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seawatts/subscriptions",
            "organizations_url": "https://api.github.com/users/seawatts/orgs",
            "repos_url": "https://api.github.com/users/seawatts/repos",
            "events_url": "https://api.github.com/users/seawatts/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seawatts/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-22T17:08:19Z",
        "updated_at": "2023-06-13T17:44:25Z",
        "closed_at": "2023-05-24T01:10:05Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3756",
            "html_url": "https://github.com/run-llama/llama_index/pull/3756",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3756.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3756.patch",
            "merged_at": "2023-05-24T01:10:05Z"
        },
        "body": "[CoFounder](https://co-founder.ai?utm_source=llama-index&utm_medium=github&utm_campaign=alpha) is a platform to revolutionize the start-up ecosystem by providing founders with unparalleled tools, resources, and support. We are changing how founders build their companies from 0-1\u2014productizing the accelerator/incubator programs using AI.\r\n\r\nWe are starting with the following features:\r\n\r\n* AI Investor Matching and Introduction and Tracking\r\n* AI Pitch Deck creation\r\n* Real-time Pitch Deck practice/feedback\r\n* Automatic Competitive Analysis / Watchlist\r\n\r\nIt uses LlamaIndex to create a context for each company on the platform. Our algorithms then use it to create recommendations for the founders and investors.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3756/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3756/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3755",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3755/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3755/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3755/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3755",
        "id": 1719522482,
        "node_id": "I_kwDOIWuq585mfdSy",
        "number": 3755,
        "title": "GPU Llama Index under native-windows not works",
        "user": {
            "login": "AngelTs",
            "id": 6697530,
            "node_id": "MDQ6VXNlcjY2OTc1MzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6697530?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AngelTs",
            "html_url": "https://github.com/AngelTs",
            "followers_url": "https://api.github.com/users/AngelTs/followers",
            "following_url": "https://api.github.com/users/AngelTs/following{/other_user}",
            "gists_url": "https://api.github.com/users/AngelTs/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AngelTs/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AngelTs/subscriptions",
            "organizations_url": "https://api.github.com/users/AngelTs/orgs",
            "repos_url": "https://api.github.com/users/AngelTs/repos",
            "events_url": "https://api.github.com/users/AngelTs/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AngelTs/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-22T11:48:06Z",
        "updated_at": "2023-07-22T02:43:39Z",
        "closed_at": "2023-07-22T02:43:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 4: invalid continuation byte\r\nOSError: It looks like the config file at './models/ggml-gpt4all-j-v1.3-groovy.bin' is not a valid JSON file.\r\n--------------------------------------------------------------------------------------------------------------------------------------\r\nThe script:\r\n--------------------------------------------------------------------------------------------------------------------------------------\r\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\r\nfrom langchain.llms import GPT4All\r\nfrom llama_index.node_parser.simple import SimpleNodeParser\r\nfrom llama_index.langchain_helpers.text_splitter import TokenTextSplitter\r\nfrom llama_index import (\r\nGPTVectorStoreIndex,\r\nLangchainEmbedding,\r\nLLMPredictor,\r\nServiceContext,\r\nStorageContext,\r\ndownload_loader,\r\nPromptHelper\r\n)\r\nPyMuPDFReader = download_loader(\"PyMuPDFReader\")\r\n\r\nfrom llama_index.prompts.prompts import SimpleInputPrompt\r\n\r\nquery_wrapper_prompt = SimpleInputPrompt(\r\n\"Below is an instruction that describes a task. \"\r\n\"Write a response that appropriately completes the request.\\n\\n\"\r\n\"### Instruction:\\n{query_str}\\n\\n### Response:\"\r\n)\r\n\r\nimport torch\r\nfrom llama_index.llm_predictor import HuggingFaceLLMPredictor\r\n\r\nhf_predictor = HuggingFaceLLMPredictor(\r\nmax_input_size=2048,\r\nmax_new_tokens=256,\r\ntemperature=0.25,\r\ndo_sample=False,\r\nquery_wrapper_prompt=query_wrapper_prompt,\r\ntokenizer_name=\"./models/ggml-gpt4all-j-v1.3-groovy.bin\",\r\nmodel_name=\"./models/ggml-gpt4all-j-v1.3-groovy.bin\",\r\ndevice_map=\"auto\",\r\ntokenizer_kwargs={\"max_length\": 2048},\r\nmodel_kwargs={\"torch_dtype\": torch.bfloat16}\r\n)\r\n\r\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\r\n\r\nservice_context = ServiceContext.from_defaults(chunk_size_limit=512, llm_predictor=hf_predictor, embed_model=embed_model)\r\n\r\nindex = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\r\nindex.storage_context.persist(persist_dir=\"./source_documents\")\r\n\r\nquery_engine = index.as_query_engine(streaming=True, similarity_top_k=3, service_context=service_context)\r\nresponse_stream = query_engine.query(\"What are the main climate risks to our Oceans?\")\r\nresponse_stream.print_response_stream()\r\n\r\n------------------------------------------------------------------------------------------------------------------------------------------------\r\nDetailed errors:\r\n\r\n File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py\", line 658, in _get_config_dict\r\n    config_dict = cls._dict_from_json_file(resolved_config_file)\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py\", line 745, in _dict_from_json_file\r\n    text = reader.read()\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 4: invalid continuation byte\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\privateGPT-main\\embeddings2-GPU.py\", line 35, in <module>\r\n    hf_predictor = HuggingFaceLLMPredictor(\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llama_index\\llm_predictor\\huggingface.py\", line 64, in __init__\r\n    self.model = model or AutoModelForCausalLM.from_pretrained(\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 441, in from_pretrained\r\n    config, kwargs = AutoConfig.from_pretrained(\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\", line 916, in from_pretrained\r\n    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py\", line 573, in get_config_dict\r\n    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n  File \"C:\\Users\\Angel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py\", line 661, in _get_config_dict\r\n    raise EnvironmentError(\r\nOSError: It looks like the config file at './models/ggml-gpt4all-j-v1.3-groovy.bin' is not a valid JSON file.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3755/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3755/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3754",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3754/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3754/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3754/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3754",
        "id": 1719495119,
        "node_id": "PR_kwDOIWuq585RAdMg",
        "number": 3754,
        "title": "Add Qdrant Usage back to the example",
        "user": {
            "login": "NirantK",
            "id": 3250749,
            "node_id": "MDQ6VXNlcjMyNTA3NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3250749?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NirantK",
            "html_url": "https://github.com/NirantK",
            "followers_url": "https://api.github.com/users/NirantK/followers",
            "following_url": "https://api.github.com/users/NirantK/following{/other_user}",
            "gists_url": "https://api.github.com/users/NirantK/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NirantK/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NirantK/subscriptions",
            "organizations_url": "https://api.github.com/users/NirantK/orgs",
            "repos_url": "https://api.github.com/users/NirantK/repos",
            "events_url": "https://api.github.com/users/NirantK/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NirantK/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-22T11:31:38Z",
        "updated_at": "2023-05-22T16:36:57Z",
        "closed_at": "2023-05-22T16:36:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3754",
            "html_url": "https://github.com/run-llama/llama_index/pull/3754",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3754.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3754.patch",
            "merged_at": "2023-05-22T16:36:57Z"
        },
        "body": "Hello, \r\n\r\nThe previous example was outdated and no longer used `Qdrant`. The client was created but not passed to the `StorageContext`\r\n\r\n\r\nI've verified that the notebook runs without errors from start to end",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3754/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3754/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3750",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3750/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3750/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3750/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3750",
        "id": 1718666846,
        "node_id": "I_kwDOIWuq585mcMZe",
        "number": 3750,
        "title": "No parameter named \"graph_configs\" in LlamaToolkit ",
        "user": {
            "login": "ttu-nguyen",
            "id": 95226838,
            "node_id": "U_kgDOBa0L1g",
            "avatar_url": "https://avatars.githubusercontent.com/u/95226838?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ttu-nguyen",
            "html_url": "https://github.com/ttu-nguyen",
            "followers_url": "https://api.github.com/users/ttu-nguyen/followers",
            "following_url": "https://api.github.com/users/ttu-nguyen/following{/other_user}",
            "gists_url": "https://api.github.com/users/ttu-nguyen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ttu-nguyen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ttu-nguyen/subscriptions",
            "organizations_url": "https://api.github.com/users/ttu-nguyen/orgs",
            "repos_url": "https://api.github.com/users/ttu-nguyen/repos",
            "events_url": "https://api.github.com/users/ttu-nguyen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ttu-nguyen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-21T22:50:38Z",
        "updated_at": "2023-09-14T16:13:04Z",
        "closed_at": "2023-09-14T16:13:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello, I followed the example [here](https://github.com/jerryjliu/llama_index/blob/main/examples/chatbot/Chatbot_SEC.ipynb), but currently we don't have any attribute `graph_configs` in `LlamaToolkit` class. This class only support `index_configs`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3750/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3750/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3749",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3749/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3749/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3749/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3749",
        "id": 1718600947,
        "node_id": "I_kwDOIWuq585mb8Tz",
        "number": 3749,
        "title": "Google LLM",
        "user": {
            "login": "chadbr",
            "id": 3179452,
            "node_id": "MDQ6VXNlcjMxNzk0NTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3179452?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chadbr",
            "html_url": "https://github.com/chadbr",
            "followers_url": "https://api.github.com/users/chadbr/followers",
            "following_url": "https://api.github.com/users/chadbr/following{/other_user}",
            "gists_url": "https://api.github.com/users/chadbr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chadbr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chadbr/subscriptions",
            "organizations_url": "https://api.github.com/users/chadbr/orgs",
            "repos_url": "https://api.github.com/users/chadbr/repos",
            "events_url": "https://api.github.com/users/chadbr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chadbr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-21T18:42:41Z",
        "updated_at": "2023-07-22T02:42:18Z",
        "closed_at": "2023-07-22T02:42:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Are there any plans to support the Google LLM's as a backend model?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3749/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3749/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3747",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3747/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3747/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3747/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3747",
        "id": 1718582501,
        "node_id": "PR_kwDOIWuq585Q9bSN",
        "number": 3747,
        "title": "update docs language",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-21T17:41:11Z",
        "updated_at": "2023-05-21T18:07:03Z",
        "closed_at": "2023-05-21T18:07:02Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3747",
            "html_url": "https://github.com/run-llama/llama_index/pull/3747",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3747.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3747.patch",
            "merged_at": "2023-05-21T18:07:02Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3747/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3747/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3746",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3746/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3746/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3746/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3746",
        "id": 1718575162,
        "node_id": "PR_kwDOIWuq585Q9Z5u",
        "number": 3746,
        "title": "Doc reference for metadata",
        "user": {
            "login": "anoopshrma",
            "id": 26565263,
            "node_id": "MDQ6VXNlcjI2NTY1MjYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/26565263?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anoopshrma",
            "html_url": "https://github.com/anoopshrma",
            "followers_url": "https://api.github.com/users/anoopshrma/followers",
            "following_url": "https://api.github.com/users/anoopshrma/following{/other_user}",
            "gists_url": "https://api.github.com/users/anoopshrma/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anoopshrma/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anoopshrma/subscriptions",
            "organizations_url": "https://api.github.com/users/anoopshrma/orgs",
            "repos_url": "https://api.github.com/users/anoopshrma/repos",
            "events_url": "https://api.github.com/users/anoopshrma/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anoopshrma/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-21T17:14:40Z",
        "updated_at": "2023-05-23T22:43:57Z",
        "closed_at": "2023-05-23T22:43:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3746",
            "html_url": "https://github.com/run-llama/llama_index/pull/3746",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3746.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3746.patch",
            "merged_at": "2023-05-23T22:43:56Z"
        },
        "body": "In Case of loading multiple Docs at once, We can use the file_name reference to specify user about the source file from which data is being extracted. \r\n\r\nUse Case: Provide Mendable like feature to provide the exact file from which response is generated. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3746/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3746/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3744",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3744/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3744/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3744/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3744",
        "id": 1718510839,
        "node_id": "PR_kwDOIWuq585Q9NTZ",
        "number": 3744,
        "title": "typo  in output_parsing.md",
        "user": {
            "login": "helmanofer",
            "id": 6523193,
            "node_id": "MDQ6VXNlcjY1MjMxOTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6523193?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/helmanofer",
            "html_url": "https://github.com/helmanofer",
            "followers_url": "https://api.github.com/users/helmanofer/followers",
            "following_url": "https://api.github.com/users/helmanofer/following{/other_user}",
            "gists_url": "https://api.github.com/users/helmanofer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/helmanofer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/helmanofer/subscriptions",
            "organizations_url": "https://api.github.com/users/helmanofer/orgs",
            "repos_url": "https://api.github.com/users/helmanofer/repos",
            "events_url": "https://api.github.com/users/helmanofer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/helmanofer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-21T13:48:41Z",
        "updated_at": "2023-05-22T07:53:54Z",
        "closed_at": "2023-05-21T22:01:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3744",
            "html_url": "https://github.com/run-llama/llama_index/pull/3744",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3744.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3744.patch",
            "merged_at": "2023-05-21T22:01:57Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3744/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3744/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3737",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3737/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3737/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3737/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3737",
        "id": 1718240541,
        "node_id": "PR_kwDOIWuq585Q8Zk7",
        "number": 3737,
        "title": "update multistep docs ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-20T17:51:22Z",
        "updated_at": "2023-05-21T01:00:56Z",
        "closed_at": "2023-05-21T01:00:56Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3737",
            "html_url": "https://github.com/run-llama/llama_index/pull/3737",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3737.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3737.patch",
            "merged_at": "2023-05-21T01:00:56Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3737/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3737/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3736",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3736/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3736/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3736/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3736",
        "id": 1718239767,
        "node_id": "I_kwDOIWuq585makIX",
        "number": 3736,
        "title": "LLama Toolkit integration seems to be broken for Vector index.",
        "user": {
            "login": "akhiljain",
            "id": 832242,
            "node_id": "MDQ6VXNlcjgzMjI0Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/832242?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/akhiljain",
            "html_url": "https://github.com/akhiljain",
            "followers_url": "https://api.github.com/users/akhiljain/followers",
            "following_url": "https://api.github.com/users/akhiljain/following{/other_user}",
            "gists_url": "https://api.github.com/users/akhiljain/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/akhiljain/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/akhiljain/subscriptions",
            "organizations_url": "https://api.github.com/users/akhiljain/orgs",
            "repos_url": "https://api.github.com/users/akhiljain/repos",
            "events_url": "https://api.github.com/users/akhiljain/events{/privacy}",
            "received_events_url": "https://api.github.com/users/akhiljain/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-20T17:48:08Z",
        "updated_at": "2023-07-22T02:40:50Z",
        "closed_at": "2023-07-22T02:40:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": " when building a toolkit and creating llama chat agent (llam_index v0.6.9 and langchain v0.0.175), it doesn't work against the data in vector store and instead creates a generic chat agent. Any pointers on whats missing here?\r\n\r\n    from langchain.agents import Tool\r\n    from langchain.chains.conversation.memory import ConversationBufferMemory\r\n    from langchain.chat_models import ChatOpenAI\r\n    from llama_index.langchain_helpers.agents import LlamaToolkit, create_llama_chat_agent, IndexToolConfig\r\n    \r\n    query_engine = index.as_query_engine(verbose=True,text_qa_template=QA_PROMPT,streaming=True)    \r\n    index_configs = []\r\n    tool_config = IndexToolConfig(\r\n        query_engine=query_engine, \r\n        name=f\"Vector Index\",\r\n        description=f\"Vector index\",\r\n        tool_kwargs={\"return_direct\": True, \"return_sources\": True},\r\n    )\r\n    index_configs.append(tool_config)\r\n    toolkit = LlamaToolkit(\r\n        index_configs=index_configs\r\n    )\r\n    memory = ConversationBufferMemory(memory_key=\"chat_history\")\r\n    llm = ChatOpenAI(temperature=TEMPERATURE, model_name=OPENAI_MODEL_ID)\r\n    agent_chain = create_llama_chat_agent(\r\n        toolkit,\r\n        llm,\r\n        memory=memory,\r\n        verbose=True\r\n    )\r\n     response = agent.run(query)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3736/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3736/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3735",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3735/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3735/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3735/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3735",
        "id": 1718235321,
        "node_id": "I_kwDOIWuq585majC5",
        "number": 3735,
        "title": "In version 0.6.8 and and 0.6.9, PDFReader dependency has changed to pypdf instead of PyPDF2",
        "user": {
            "login": "akhiljain",
            "id": 832242,
            "node_id": "MDQ6VXNlcjgzMjI0Mg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/832242?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/akhiljain",
            "html_url": "https://github.com/akhiljain",
            "followers_url": "https://api.github.com/users/akhiljain/followers",
            "following_url": "https://api.github.com/users/akhiljain/following{/other_user}",
            "gists_url": "https://api.github.com/users/akhiljain/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/akhiljain/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/akhiljain/subscriptions",
            "organizations_url": "https://api.github.com/users/akhiljain/orgs",
            "repos_url": "https://api.github.com/users/akhiljain/repos",
            "events_url": "https://api.github.com/users/akhiljain/events{/privacy}",
            "received_events_url": "https://api.github.com/users/akhiljain/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-20T17:29:34Z",
        "updated_at": "2023-07-22T02:45:47Z",
        "closed_at": "2023-07-22T02:45:47Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "In version 0.6.8 and and 0.6.9, PDFReader dependency has changed to pypdf instead of PyPDF2. pypdf is not the up to date and doesn't read the pdf properly. please revert it back to PyPDF2",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3735/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3735/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3734",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3734/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3734/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3734/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3734",
        "id": 1718187853,
        "node_id": "I_kwDOIWuq585maXdN",
        "number": 3734,
        "title": "StorageContext can't init with persist_dir",
        "user": {
            "login": "madawei2699",
            "id": 2446612,
            "node_id": "MDQ6VXNlcjI0NDY2MTI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2446612?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/madawei2699",
            "html_url": "https://github.com/madawei2699",
            "followers_url": "https://api.github.com/users/madawei2699/followers",
            "following_url": "https://api.github.com/users/madawei2699/following{/other_user}",
            "gists_url": "https://api.github.com/users/madawei2699/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/madawei2699/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/madawei2699/subscriptions",
            "organizations_url": "https://api.github.com/users/madawei2699/orgs",
            "repos_url": "https://api.github.com/users/madawei2699/repos",
            "events_url": "https://api.github.com/users/madawei2699/events{/privacy}",
            "received_events_url": "https://api.github.com/users/madawei2699/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-20T14:25:39Z",
        "updated_at": "2023-12-11T14:18:51Z",
        "closed_at": "2023-09-10T16:58:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "This is my code:\r\n\r\n```python\r\nfrom llama_index import StorageContext, load_index_from_storage\r\n\r\nindex_cache_web_dir = Path('/tmp/cache_web/')\r\n\r\nif not index_cache_web_dir.is_dir():\r\n    index_cache_web_dir.mkdir(parents=True, exist_ok=True)\r\n\r\nweb_storage_context = StorageContext.from_defaults(persist_dir=str(index_cache_web_dir))\r\n```\r\n\r\nThen it will raise a error, the error log is:\r\n\r\n```text\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/storage/storage_context.py\", line 61, in from_defaults\r\n    docstore = docstore or SimpleDocumentStore.from_persist_dir(\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/storage/docstore/simple_docstore.py\", line 51, in from_persist_dir\r\n    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/storage/docstore/simple_docstore.py\", line 69, in from_persist_path\r\n    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/storage/kvstore/simple_kvstore.py\", line 75, in from_persist_path\r\n    with fs.open(persist_path, \"rb\") as f:\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/spec.py\", line 1199, in open\r\n    f = self._open(\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/implementations/local.py\", line 183, in _open\r\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/implementations/local.py\", line 314, in __init__\r\n    self._open()\r\n  File \"/opt/miniconda3/envs/py310/lib/python3.10/site-packages/fsspec/implementations/local.py\", line 319, in _open\r\n    self.f = open(self.path, mode=self.mode)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/cache_web/docstore.json'\r\n```\r\n\r\nThe Python version is 3.10, the `llama-index` is 0.6.9, and the `langchain` is 0.0.154.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3734/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3734/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3733",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3733/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3733/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3733/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3733",
        "id": 1718178706,
        "node_id": "I_kwDOIWuq585maVOS",
        "number": 3733,
        "title": "Is there a way to control the number of responses from the query engine?",
        "user": {
            "login": "kanodiaayush",
            "id": 1688433,
            "node_id": "MDQ6VXNlcjE2ODg0MzM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1688433?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kanodiaayush",
            "html_url": "https://github.com/kanodiaayush",
            "followers_url": "https://api.github.com/users/kanodiaayush/followers",
            "following_url": "https://api.github.com/users/kanodiaayush/following{/other_user}",
            "gists_url": "https://api.github.com/users/kanodiaayush/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kanodiaayush/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kanodiaayush/subscriptions",
            "organizations_url": "https://api.github.com/users/kanodiaayush/orgs",
            "repos_url": "https://api.github.com/users/kanodiaayush/repos",
            "events_url": "https://api.github.com/users/kanodiaayush/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kanodiaayush/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-20T13:53:30Z",
        "updated_at": "2023-09-06T23:38:47Z",
        "closed_at": "2023-05-23T06:00:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "In the following code\r\n\r\n```\r\ndef load_index():\r\n    # index if dir 'storage' does not exist\r\n    if not os.path.exists('storage'):\r\n        print('Building index...')\r\n        build_index()\r\n    storage_context = StorageContext.from_defaults(persist_dir='./storage')\r\n    # doc_hash_to_filename = json.load(open('doc_hash_to_filename.json', 'r'))\r\n    return load_index_from_storage(storage_context)\r\n\r\ndef ask_question(index, query):\r\n    query_engine = index.as_query_engine()\r\n    response = query_engine.query(query)\r\n    return response\r\n\r\n```\r\n\r\nI always get 2 responses right now, for any query. How can I get more? is there a parameter I can change?\r\n\r\nI also posted this on [Stack Overflow](https://stackoverflow.com/questions/76295530/in-llamaindex-gptindex-how-do-i-control-number-of-responses-to-a-query)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3733/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3733/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3732",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3732/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3732/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3732/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3732",
        "id": 1718110143,
        "node_id": "I_kwDOIWuq585maEe_",
        "number": 3732,
        "title": "response truncated",
        "user": {
            "login": "mccoysc",
            "id": 18025276,
            "node_id": "MDQ6VXNlcjE4MDI1Mjc2",
            "avatar_url": "https://avatars.githubusercontent.com/u/18025276?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mccoysc",
            "html_url": "https://github.com/mccoysc",
            "followers_url": "https://api.github.com/users/mccoysc/followers",
            "following_url": "https://api.github.com/users/mccoysc/following{/other_user}",
            "gists_url": "https://api.github.com/users/mccoysc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mccoysc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mccoysc/subscriptions",
            "organizations_url": "https://api.github.com/users/mccoysc/orgs",
            "repos_url": "https://api.github.com/users/mccoysc/repos",
            "events_url": "https://api.github.com/users/mccoysc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mccoysc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-20T09:11:00Z",
        "updated_at": "2023-07-22T02:45:14Z",
        "closed_at": "2023-07-22T02:44:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When using index.as_query_engine().query(), sometimes the responses returned may be truncated and incomplete,how i can get the complete response?\n@jerryjliu ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3732/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3732/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3728",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3728/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3728/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3728/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3728",
        "id": 1717985546,
        "node_id": "PR_kwDOIWuq585Q7ntu",
        "number": 3728,
        "title": "Nitpick docs updates",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-20T02:00:56Z",
        "updated_at": "2023-08-28T17:10:01Z",
        "closed_at": "2023-05-20T06:23:38Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3728",
            "html_url": "https://github.com/run-llama/llama_index/pull/3728",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3728.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3728.patch",
            "merged_at": "2023-05-20T06:23:38Z"
        },
        "body": "Some minor updates to docs, just to modify some glaring errors and missing information",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3728/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3728/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3726",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3726/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3726/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3726/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3726",
        "id": 1717936310,
        "node_id": "PR_kwDOIWuq585Q7dxa",
        "number": 3726,
        "title": "Vellum <-> LlamaIndex Integration",
        "user": {
            "login": "noanflaherty",
            "id": 14092604,
            "node_id": "MDQ6VXNlcjE0MDkyNjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/14092604?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noanflaherty",
            "html_url": "https://github.com/noanflaherty",
            "followers_url": "https://api.github.com/users/noanflaherty/followers",
            "following_url": "https://api.github.com/users/noanflaherty/following{/other_user}",
            "gists_url": "https://api.github.com/users/noanflaherty/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noanflaherty/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noanflaherty/subscriptions",
            "organizations_url": "https://api.github.com/users/noanflaherty/orgs",
            "repos_url": "https://api.github.com/users/noanflaherty/repos",
            "events_url": "https://api.github.com/users/noanflaherty/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noanflaherty/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-05-19T23:30:06Z",
        "updated_at": "2023-05-25T16:22:41Z",
        "closed_at": "2023-05-25T16:22:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3726",
            "html_url": "https://github.com/run-llama/llama_index/pull/3726",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3726.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3726.patch",
            "merged_at": "2023-05-25T16:22:41Z"
        },
        "body": "This PR represents a proof-of-concept for what an integration between Vellum and LlamaIndex might look like. It is not yet ready to be merged, but is at a good point to collect feedback.\r\n\r\n## Intent\r\nThe intent of this integration is to make it easy for LlamaIndex users to:\r\n1. Register prompts within Vellum\r\n2. Once registered, use Vellum's UI to easily experiment with changes to the prompt template, underlying model, provider, and more\r\n3. Track requests made to the prompt and monitor once in production\r\n4. Allow for technical and non-technical users to experiment and update the prompt, without requiring code changed\r\n\r\n## Assumptions\r\nWith this integration, I'm making a few core assumptions that I welcome to be challenged.\r\n1. We should minimize the number of changes needed to the rest of LlamaIndex's interfaces\r\n2. The `Prompt.prompt_kwargs` property is a fair-game way to pass extra metadata for a prompt along to Vellum\r\n3. OpenAI's `text-davinci-003` continues to be the default model most people should use with LlamaIndex's default prompts (easy to change if not)\r\n\r\n## Usage\r\nCase 1) The user specifies a Vellum deployment id (or name) along with the prompt\r\n<img width=\"877\" alt=\"2023-05-19_19-24-05\" src=\"https://github.com/jerryjliu/llama_index/assets/14092604/995ac6af-fb52-44ef-8119-522a03727330\">\r\n\r\nCase 2) No deployment id/name is provided. In this case, we'll call Vellum's APIs to lazily registry one. This code is stubbed out for now.\r\n\r\n## Representation in Vellum\r\nIf a prompt is automaitcally registered (currently just stubbed out), then we will:\r\n### Create a Vellum Sandbox\r\nThis is where users (potentially non-technical) can experiment with different prompt template wording, different models, providers, temperature, etc.\r\n\r\n<img width=\"1680\" alt=\"2023-05-19_19-24-59\" src=\"https://github.com/jerryjliu/llama_index/assets/14092604/60aac873-48b5-4746-aed9-d7ad23072c97\">\r\n\r\n\r\n### Create a Vellum Deployment\r\nThis is where users can see historical requests, view monitoring dashboards, etc. A deployment could be updated from an edited prompt in a Sandbox and the new prompt/model will be live, no code changes required.\r\n\r\n<img width=\"1680\" alt=\"2023-05-19_19-27-25\" src=\"https://github.com/jerryjliu/llama_index/assets/14092604/6c233c16-5ff2-4d84-bdb1-c971f6baf600\">\r\n\r\n<img width=\"1680\" alt=\"2023-05-19_19-28-23\" src=\"https://github.com/jerryjliu/llama_index/assets/14092604/1ce7c986-9657-4fbf-9889-e75f6d7d4cb8\">\r\n\r\n\r\n## Next Steps\r\n1. Get feedback on the overall direction/approach. If all looks good;\r\n2. Proceed to create two new endpoints:\r\n    * Register prompt (this'll be a shortcut for creating a Sandbox and Deployment)\r\n    * Retrieve compiled prompt (unclear how critical this is. Only seems used for counting tokens)\r\n3. Clean up: add documentations, examples, and tests",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3726/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 2,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3726/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3706",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3706/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3706/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3706/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3706",
        "id": 1717503766,
        "node_id": "I_kwDOIWuq585mXwcW",
        "number": 3706,
        "title": "Llama Index knows only the knowledge from the Index, nothing else.",
        "user": {
            "login": "IvanPigarev",
            "id": 97641648,
            "node_id": "U_kgDOBdHksA",
            "avatar_url": "https://avatars.githubusercontent.com/u/97641648?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IvanPigarev",
            "html_url": "https://github.com/IvanPigarev",
            "followers_url": "https://api.github.com/users/IvanPigarev/followers",
            "following_url": "https://api.github.com/users/IvanPigarev/following{/other_user}",
            "gists_url": "https://api.github.com/users/IvanPigarev/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IvanPigarev/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IvanPigarev/subscriptions",
            "organizations_url": "https://api.github.com/users/IvanPigarev/orgs",
            "repos_url": "https://api.github.com/users/IvanPigarev/repos",
            "events_url": "https://api.github.com/users/IvanPigarev/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IvanPigarev/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-19T16:17:52Z",
        "updated_at": "2023-07-22T18:56:56Z",
        "closed_at": "2023-07-22T18:56:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "LlamaIndex already calls openai under the hood, the second part of your code is not necessary.\r\n\r\n_Originally posted by @Disiok in https://github.com/jerryjliu/llama_index/issues/3376#issuecomment-1548324665_\r\n\r\n-------\r\n\r\nI was sure of that too, but the result was a query only on knowledge from the index. And most of the questions were answered \u2014 I don't know, it's not in the data. And I needed it to be able to answer questions more broadly than just by index! Is there such a possibility inside LlamaIndex? Unfortunately, I couldn't find it :( And in this implementation it answers very well, using both global knowledge and hint (first answer LlamaIndex: prompt = 'Context: '+ response.response + query). Please help me to solve this problem correctly!\r\n\r\nThe answers with the second query are radically different in quality! And where do you configure the language model, temperature, and other parameters for the query within llamaIndex? I didn't find such parameters, although it seems logical to have them.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3706/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3706/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3696",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3696/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3696/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3696/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3696",
        "id": 1717451549,
        "node_id": "PR_kwDOIWuq585Q50JB",
        "number": 3696,
        "title": "Fixed Broken Link to Cost Analysis Howto",
        "user": {
            "login": "JSv4",
            "id": 5049984,
            "node_id": "MDQ6VXNlcjUwNDk5ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5049984?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JSv4",
            "html_url": "https://github.com/JSv4",
            "followers_url": "https://api.github.com/users/JSv4/followers",
            "following_url": "https://api.github.com/users/JSv4/following{/other_user}",
            "gists_url": "https://api.github.com/users/JSv4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JSv4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JSv4/subscriptions",
            "organizations_url": "https://api.github.com/users/JSv4/orgs",
            "repos_url": "https://api.github.com/users/JSv4/repos",
            "events_url": "https://api.github.com/users/JSv4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JSv4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-19T15:41:42Z",
        "updated_at": "2023-05-19T17:14:04Z",
        "closed_at": "2023-05-19T17:14:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3696",
            "html_url": "https://github.com/run-llama/llama_index/pull/3696",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3696.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3696.patch",
            "merged_at": "2023-05-19T17:14:04Z"
        },
        "body": "The link in the usage_patterns primer was missing `/docs...`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3696/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3696/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3695",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3695/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3695/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3695/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3695",
        "id": 1717429086,
        "node_id": "PR_kwDOIWuq585Q5vRj",
        "number": 3695,
        "title": "Constrain search of simple vector index",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-19T15:23:12Z",
        "updated_at": "2023-08-28T17:10:52Z",
        "closed_at": "2023-05-19T22:50:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3695",
            "html_url": "https://github.com/run-llama/llama_index/pull/3695",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3695.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3695.patch",
            "merged_at": "2023-05-19T22:50:17Z"
        },
        "body": "This PR fixes saving multiple SimpleVectorStore objects to the same index.\r\n\r\nThis solves two use cases:\r\n1. Saving/loading graphs with multiple vector indexes\r\n2. Persisting multiple vector indexes to the same directory\r\n\r\nHaving a dependency between the vector store and index struct is not great, but this was the cleanest implementation I've had so far. The index struct already keeps of the \"namespace\" of each simple vector index, so we can leverage that here.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3695/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3695/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3694",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3694/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3694/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3694/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3694",
        "id": 1717405364,
        "node_id": "PR_kwDOIWuq585Q5qBv",
        "number": 3694,
        "title": "Updated Azure OpenAI Example",
        "user": {
            "login": "JSv4",
            "id": 5049984,
            "node_id": "MDQ6VXNlcjUwNDk5ODQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5049984?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JSv4",
            "html_url": "https://github.com/JSv4",
            "followers_url": "https://api.github.com/users/JSv4/followers",
            "following_url": "https://api.github.com/users/JSv4/following{/other_user}",
            "gists_url": "https://api.github.com/users/JSv4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JSv4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JSv4/subscriptions",
            "organizations_url": "https://api.github.com/users/JSv4/orgs",
            "repos_url": "https://api.github.com/users/JSv4/repos",
            "events_url": "https://api.github.com/users/JSv4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JSv4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-19T15:06:34Z",
        "updated_at": "2023-05-20T20:56:45Z",
        "closed_at": "2023-05-20T20:56:45Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3694",
            "html_url": "https://github.com/run-llama/llama_index/pull/3694",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3694.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3694.patch",
            "merged_at": "2023-05-20T20:56:45Z"
        },
        "body": "I was unable to get the Azure OpenAI example in the your [example notebook](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/customization/llms/AzureOpenAI.ipynb) to work. Perhaps I'm missing a way to use the public OpenAI encoder instead of a private instance of it, but, two observations:\r\n\r\n1) I think you *have* to deploy your own and then reference the deployment when you create the OpenAIEmbeddings instance (see my changes). \r\n2) Even if you it's possible to use the public embedding with a private model instance, I'd suggest we at least modify the docs to show someone how to call their own embeddings model. \r\n\r\nI've updated the example to show how to use an Azure-hosted embeddings deployment. FWIW, this is the same solution [suggested in the langchain repo](https://github.com/hwchase17/langchain/issues/1560#issuecomment-1541703342).\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3694/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3694/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3651",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3651/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3651/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3651/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3651",
        "id": 1716973060,
        "node_id": "I_kwDOIWuq585mVu4E",
        "number": 3651,
        "title": "Add weaviate 's filter function",
        "user": {
            "login": "weishu27",
            "id": 129355431,
            "node_id": "U_kgDOB7XOpw",
            "avatar_url": "https://avatars.githubusercontent.com/u/129355431?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weishu27",
            "html_url": "https://github.com/weishu27",
            "followers_url": "https://api.github.com/users/weishu27/followers",
            "following_url": "https://api.github.com/users/weishu27/following{/other_user}",
            "gists_url": "https://api.github.com/users/weishu27/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weishu27/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weishu27/subscriptions",
            "organizations_url": "https://api.github.com/users/weishu27/orgs",
            "repos_url": "https://api.github.com/users/weishu27/repos",
            "events_url": "https://api.github.com/users/weishu27/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weishu27/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-19T09:58:02Z",
        "updated_at": "2023-09-12T16:20:47Z",
        "closed_at": "2023-09-12T16:20:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "This project is awesome! It finished a lot of things I want to do and greatly reduces my workload. \r\nBut in actual scenarios, the filtering function of the vectorsore is very much needed. I wonder if the developers have considered adding this function in the future? Thank you so much",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3651/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3651/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3638",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3638/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3638/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3638/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3638",
        "id": 1716892652,
        "node_id": "I_kwDOIWuq585mVbPs",
        "number": 3638,
        "title": "load graph from disk",
        "user": {
            "login": "rucieryi369",
            "id": 73628939,
            "node_id": "MDQ6VXNlcjczNjI4OTM5",
            "avatar_url": "https://avatars.githubusercontent.com/u/73628939?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rucieryi369",
            "html_url": "https://github.com/rucieryi369",
            "followers_url": "https://api.github.com/users/rucieryi369/followers",
            "following_url": "https://api.github.com/users/rucieryi369/following{/other_user}",
            "gists_url": "https://api.github.com/users/rucieryi369/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rucieryi369/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rucieryi369/subscriptions",
            "organizations_url": "https://api.github.com/users/rucieryi369/orgs",
            "repos_url": "https://api.github.com/users/rucieryi369/repos",
            "events_url": "https://api.github.com/users/rucieryi369/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rucieryi369/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-19T08:58:24Z",
        "updated_at": "2023-07-12T16:51:15Z",
        "closed_at": "2023-06-05T01:56:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "new_storage_context = StorageContext.from_defaults(persist_dir=f'./storage/root')\r\n\r\n# load index\r\nnew_graph = load_graph_from_storage(\r\n    new_storage_context, root_id=graph.root_id, service_context=service_context\r\n)\r\n\r\nnew_query_engine = new_graph.as_query_engine()\r\nnew_response = new_query_engine.query(\"test query\")\r\n\r\nWhen I want to load graph, get 'KeyError:' . It look like can't find the graph doc  ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3638/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3638/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3611",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3611/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3611/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3611/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3611",
        "id": 1716568513,
        "node_id": "PR_kwDOIWuq585Q2zuQ",
        "number": 3611,
        "title": "[version] bump version to 0.6.9",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-19T03:59:54Z",
        "updated_at": "2023-05-19T04:06:30Z",
        "closed_at": "2023-05-19T04:06:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3611",
            "html_url": "https://github.com/run-llama/llama_index/pull/3611",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3611.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3611.patch",
            "merged_at": "2023-05-19T04:06:29Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3611/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3611/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3610",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3610/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3610/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3610/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3610",
        "id": 1716546392,
        "node_id": "I_kwDOIWuq585mUGtY",
        "number": 3610,
        "title": "When I run \"Ingest Unstructured Data\" step in Chatbot_SEC, I got the error \"BadZipFile: File is not a zip file\".Any  one know about it?",
        "user": {
            "login": "dongxu",
            "id": 289812,
            "node_id": "MDQ6VXNlcjI4OTgxMg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/289812?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dongxu",
            "html_url": "https://github.com/dongxu",
            "followers_url": "https://api.github.com/users/dongxu/followers",
            "following_url": "https://api.github.com/users/dongxu/following{/other_user}",
            "gists_url": "https://api.github.com/users/dongxu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dongxu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dongxu/subscriptions",
            "organizations_url": "https://api.github.com/users/dongxu/orgs",
            "repos_url": "https://api.github.com/users/dongxu/repos",
            "events_url": "https://api.github.com/users/dongxu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dongxu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-19T03:20:17Z",
        "updated_at": "2023-09-10T16:58:33Z",
        "closed_at": "2023-09-10T16:58:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I run \"Ingest Unstructured Data\" step in Chatbot_SEC, I got the error \"BadZipFile: File is not a zip file\".Any  one know about it?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3610/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3610/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3607",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3607/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3607/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3607/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3607",
        "id": 1716540161,
        "node_id": "PR_kwDOIWuq585Q2txb",
        "number": 3607,
        "title": "Minor docs update",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-19T03:08:51Z",
        "updated_at": "2023-05-19T03:09:02Z",
        "closed_at": "2023-05-19T03:09:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3607",
            "html_url": "https://github.com/run-llama/llama_index/pull/3607",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3607.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3607.patch",
            "merged_at": "2023-05-19T03:09:01Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3607/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3607/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3606",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3606/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3606/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3606/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3606",
        "id": 1716519669,
        "node_id": "PR_kwDOIWuq585Q2peG",
        "number": 3606,
        "title": "Flush output to make streaming appear in REPL",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-19T02:36:07Z",
        "updated_at": "2023-05-19T02:41:59Z",
        "closed_at": "2023-05-19T02:41:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3606",
            "html_url": "https://github.com/run-llama/llama_index/pull/3606",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3606.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3606.patch",
            "merged_at": "2023-05-19T02:41:58Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3606/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3606/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3586",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3586/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3586/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3586/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3586",
        "id": 1716493021,
        "node_id": "I_kwDOIWuq585mT5rd",
        "number": 3586,
        "title": "Errors occur when reading special strings such as spaces in repository readers.",
        "user": {
            "login": "takanomizuki",
            "id": 111120131,
            "node_id": "U_kgDOBp-PAw",
            "avatar_url": "https://avatars.githubusercontent.com/u/111120131?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/takanomizuki",
            "html_url": "https://github.com/takanomizuki",
            "followers_url": "https://api.github.com/users/takanomizuki/followers",
            "following_url": "https://api.github.com/users/takanomizuki/following{/other_user}",
            "gists_url": "https://api.github.com/users/takanomizuki/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/takanomizuki/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/takanomizuki/subscriptions",
            "organizations_url": "https://api.github.com/users/takanomizuki/orgs",
            "repos_url": "https://api.github.com/users/takanomizuki/repos",
            "events_url": "https://api.github.com/users/takanomizuki/events{/privacy}",
            "received_events_url": "https://api.github.com/users/takanomizuki/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-19T01:53:20Z",
        "updated_at": "2023-09-10T16:58:39Z",
        "closed_at": "2023-09-10T16:58:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Exception occurred: ValueError\r\nEncountered text corresponding to disallowed special token '<|endoftext|>'.\r\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...} `.\r\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<| endoftext|>'})`.\r\nTo disable this check for all special tokens, pass `disallowed_special=()`.\r\n  File \"/Users/takanomizuki/george/keywords/vectorstore-create-repository-folder-English.py\", line 208, in create_index_from_pdf\r\n    index = GPTVectorStoreIndex.from_documents(\r\n  File \"/Users/takanomizuki/george/keywords/vectorstore-create-repository-folder-English.py\", line 224, in <module\r\n    create_index_from_pdf(use_model_path)\r\nValueError: Encountered text corresponding to disallowed special token '<|endoftext|>'.\r\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...} `.\r\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<| endoftext|>'})`.\r\nTo disable this check for all special tokens, pass `disallowed_special=()`.\r\n\r\n\u2193Error line\r\n\r\n# Create a GPTVectorStoreIndex instance with the specified USEMultilingualEmbedding instance and custom service context\r\n    index = GPTVectorStoreIndex.from_documents(\r\n        documents=documents, service_context=service_context\r\n        service_context=service_context,.\r\n    )",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3586/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3586/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3560",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3560/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3560/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3560/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3560",
        "id": 1716315969,
        "node_id": "PR_kwDOIWuq585Q1-SI",
        "number": 3560,
        "title": "[feature] Added compact accumulator response builder and unit test",
        "user": {
            "login": "pocketcolin",
            "id": 47982430,
            "node_id": "MDQ6VXNlcjQ3OTgyNDMw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47982430?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pocketcolin",
            "html_url": "https://github.com/pocketcolin",
            "followers_url": "https://api.github.com/users/pocketcolin/followers",
            "following_url": "https://api.github.com/users/pocketcolin/following{/other_user}",
            "gists_url": "https://api.github.com/users/pocketcolin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pocketcolin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pocketcolin/subscriptions",
            "organizations_url": "https://api.github.com/users/pocketcolin/orgs",
            "repos_url": "https://api.github.com/users/pocketcolin/repos",
            "events_url": "https://api.github.com/users/pocketcolin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pocketcolin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-18T21:54:16Z",
        "updated_at": "2023-05-25T19:21:49Z",
        "closed_at": "2023-05-25T19:21:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3560",
            "html_url": "https://github.com/run-llama/llama_index/pull/3560",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3560.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3560.patch",
            "merged_at": "2023-05-25T19:21:49Z"
        },
        "body": "I added a accumulator response builder in the last PR and now I'm adding onto that with a new compact accumulator. It does the same compacting that Compact and Refine does, but then runs the Accumulator afterwards.\r\n\r\nExample:\r\n```\r\nquery_engine = RetrieverQueryEngine.from_args(\r\n    retriever=retriever,\r\n    service_context=service_context,\r\n    node_postprocessors=[\r\n        SimilarityPostprocessor(similarity_cutoff=0.7)\r\n    ],\r\n    text_qa_template=QA_PROMPT,\r\n    response_mode='compact_accumulate'\r\n)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3560/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3560/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3552",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3552/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3552/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3552/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3552",
        "id": 1716211864,
        "node_id": "PR_kwDOIWuq585Q1nWs",
        "number": 3552,
        "title": "Reorganize response builder",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-18T20:20:20Z",
        "updated_at": "2023-05-18T20:48:40Z",
        "closed_at": "2023-05-18T20:48:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3552",
            "html_url": "https://github.com/run-llama/llama_index/pull/3552",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3552.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3552.patch",
            "merged_at": "2023-05-18T20:48:39Z"
        },
        "body": "### Summary\r\n* Break `response_builder.py` into smaller files\r\n* Add better docs for response modes. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3552/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3552/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3547",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3547/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3547/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3547/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3547",
        "id": 1716037721,
        "node_id": "PR_kwDOIWuq585Q1BCg",
        "number": 3547,
        "title": "Fixing a couple broken links in the docs",
        "user": {
            "login": "dorkitude",
            "id": 157717,
            "node_id": "MDQ6VXNlcjE1NzcxNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/157717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dorkitude",
            "html_url": "https://github.com/dorkitude",
            "followers_url": "https://api.github.com/users/dorkitude/followers",
            "following_url": "https://api.github.com/users/dorkitude/following{/other_user}",
            "gists_url": "https://api.github.com/users/dorkitude/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dorkitude/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dorkitude/subscriptions",
            "organizations_url": "https://api.github.com/users/dorkitude/orgs",
            "repos_url": "https://api.github.com/users/dorkitude/repos",
            "events_url": "https://api.github.com/users/dorkitude/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dorkitude/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-18T17:58:43Z",
        "updated_at": "2023-05-22T19:08:39Z",
        "closed_at": "2023-05-22T19:08:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3547",
            "html_url": "https://github.com/run-llama/llama_index/pull/3547",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3547.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3547.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3547/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3547/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3539",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3539/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3539/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3539/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3539",
        "id": 1715784110,
        "node_id": "I_kwDOIWuq585mRMmu",
        "number": 3539,
        "title": "how can I stop the LLM response from being cached?",
        "user": {
            "login": "maspotts",
            "id": 4096446,
            "node_id": "MDQ6VXNlcjQwOTY0NDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4096446?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/maspotts",
            "html_url": "https://github.com/maspotts",
            "followers_url": "https://api.github.com/users/maspotts/followers",
            "following_url": "https://api.github.com/users/maspotts/following{/other_user}",
            "gists_url": "https://api.github.com/users/maspotts/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/maspotts/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/maspotts/subscriptions",
            "organizations_url": "https://api.github.com/users/maspotts/orgs",
            "repos_url": "https://api.github.com/users/maspotts/repos",
            "events_url": "https://api.github.com/users/maspotts/events{/privacy}",
            "received_events_url": "https://api.github.com/users/maspotts/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-18T14:55:44Z",
        "updated_at": "2023-09-10T16:58:44Z",
        "closed_at": "2023-09-10T16:58:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi: I've noticed that if I issue the same query string multiple times (against the same index), then although the first query takes a long time, subsequent queries return instantly: making me believe that the query response is being cached (although I'm not passing a `cache` argument to `LLMPredictor()`).  (Also: I've noticed that changing the llm (on subsequent queries) seems to have no effect, which I assume also to be due to caching?). But I can't see any evidence of a cache being updated under my home directory, or in /tmp.  Is there a way to prevent caching, so each query is executed via the API, even if it's a duplicate of a previous query?  And where is the cache file?!  Many tnanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3539/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3539/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3529",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3529/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3529/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3529/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3529",
        "id": 1715562162,
        "node_id": "I_kwDOIWuq585mQWay",
        "number": 3529,
        "title": "GPTCache doesn't seem to work with LlamaIndex",
        "user": {
            "login": "ashwinr1980",
            "id": 49855811,
            "node_id": "MDQ6VXNlcjQ5ODU1ODEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/49855811?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ashwinr1980",
            "html_url": "https://github.com/ashwinr1980",
            "followers_url": "https://api.github.com/users/ashwinr1980/followers",
            "following_url": "https://api.github.com/users/ashwinr1980/following{/other_user}",
            "gists_url": "https://api.github.com/users/ashwinr1980/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ashwinr1980/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ashwinr1980/subscriptions",
            "organizations_url": "https://api.github.com/users/ashwinr1980/orgs",
            "repos_url": "https://api.github.com/users/ashwinr1980/repos",
            "events_url": "https://api.github.com/users/ashwinr1980/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ashwinr1980/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-18T12:35:37Z",
        "updated_at": "2023-09-10T16:58:49Z",
        "closed_at": "2023-09-10T16:58:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "So I've been trying to get GPTCache to work with LlamaIndex. While Langchain has a documented integration with GPTCache - https://python.langchain.com/en/latest/modules/models/llms/examples/llm_caching.html#gptcache , when I try to use it in my own code which uses `GPTSimpleVectorIndex`, it is unable to persist the question/answer pair in the cache. \r\n\r\nHere's my code. \r\n\r\n```\r\nimport langchain\r\nfrom flask import Flask, render_template, request, Response, jsonify\r\nimport os\r\nimport logging\r\nimport sys\r\nimport time\r\n\r\nfrom llama_index import GPTSimpleVectorIndex, QuestionAnswerPrompt\r\nfrom langchain import PromptTemplate, LLMChain\r\nfrom langchain.llms import OpenAI\r\nfrom gptcache import Cache\r\nfrom gptcache.adapter.api import init_similar_cache\r\nfrom langchain.cache import GPTCache\r\n\r\nlogging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\napp = Flask(__name__)\r\n# run_with_ngrok(app)\r\nos.environ['OPENAI_API_KEY'] = \"MY OPENAPI KEY\"\r\n\r\n\r\ndef init_gptcache(cache_obj: Cache):\r\n    init_similar_cache(cache_obj=cache_obj, data_dir=f\"similar_cache_ikgpt\")\r\n\r\n\r\nlangchain.llm_cache = GPTCache(init_gptcache)\r\n\r\nclass ChatGPTService:\r\n    __instance = None\r\n    index = None\r\n\r\n    @staticmethod\r\n    def get_instance():\r\n        \"\"\"Static method to fetch the current instance of the class.\"\"\"\r\n        if ChatGPTService.__instance is None:\r\n            ChatGPTService()\r\n        return ChatGPTService.__instance\r\n\r\n    def __init__(self):\r\n        \"\"\"Virtually private constructor.\"\"\"\r\n        if ChatGPTService.__instance is not None:\r\n            raise Exception(\"This class is a singleton!\")\r\n        else:\r\n            ChatGPTService.__instance = self\r\n\r\n    def load_index(self):\r\n        if self.index is None:\r\n            start_time = time.time()\r\n            self.index = GPTSimpleVectorIndex.load_from_disk(\"static/latest_index.json\")\r\n            end_time = time.time()\r\n            print(\"Time taken to load index: \", end_time - start_time)\r\n\r\n        return self.index\r\n\r\n    def generate_response(self, prompt):\r\n        index = self.__instance.load_index()\r\n\r\n        QA_PROMPT_TMPL = (\r\n            \"Context:\\n\"\r\n            \"---------------------\\n\"\r\n            \"{context_str}\"\r\n            \"\\n---------------------\\n\"\r\n            \"Question:\\n\"\r\n            \"{query_str}\"\r\n            \"\\n---------------------\\n\"\r\n            \"Instructions:\\n\"\r\n            \"Please provide an answer to the question that is truthful and directly related to the information presented in the context above.\"\r\n            \"If the answer is not in the context, please respond with \\\"I don't know\\\".\\n\"\r\n        )\r\n\r\n        QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\r\n\r\n        start_time = time.time()\r\n        # index is a GPTSimpleVectorIndex object provided by LlamaIndex\r\n        response = index.query(prompt,\r\n                               text_qa_template=QA_PROMPT,\r\n                               )\r\n        end_time = time.time()\r\n\r\n        print(\"Time taken to generate response: \", end_time - start_time)\r\n        return str(response)\r\n```\r\n\r\n\r\nThe error (which is a warning) in the logs looks like this \r\n\r\n```\r\nWARNING:root:failed to save the data to cache, error: GPTCache._update_cache_callback() got an unexpected keyword argument 'prompt'\r\nfailed to save the data to cache, error: GPTCache._update_cache_callback() got an unexpected keyword argument 'prompt'\r\n```\r\n\r\nLooks like when we do `index.query` it seems to be sending an additional args 'prompt' to GPTCache. Am I missing something obvious or is there something specific we need to do to support GPTCache (considering langchain supports it).",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3529/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3529/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3526",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3526/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3526/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3526/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3526",
        "id": 1715491956,
        "node_id": "I_kwDOIWuq585mQFR0",
        "number": 3526,
        "title": "How to change \"vector_store.json\" file name to \"vector_store.index\" for Faiss index?",
        "user": {
            "login": "zeonn",
            "id": 786821,
            "node_id": "MDQ6VXNlcjc4NjgyMQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/786821?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeonn",
            "html_url": "https://github.com/zeonn",
            "followers_url": "https://api.github.com/users/zeonn/followers",
            "following_url": "https://api.github.com/users/zeonn/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeonn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeonn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeonn/subscriptions",
            "organizations_url": "https://api.github.com/users/zeonn/orgs",
            "repos_url": "https://api.github.com/users/zeonn/repos",
            "events_url": "https://api.github.com/users/zeonn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeonn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-18T11:42:21Z",
        "updated_at": "2023-06-11T07:00:16Z",
        "closed_at": "2023-06-11T07:00:16Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I use the Faiss index, the binary data file is named \"vector_store.json\" instead of \"vector_store.index\". It's a bit wrong bacause actrually it's not a JSON.\r\n\r\nHow can I specify the name of this file explicitly? Or perhaps you could make the required changes so that the file automatically gets the correct name.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3526/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3526/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3516",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3516/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3516/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3516/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3516",
        "id": 1715394250,
        "node_id": "I_kwDOIWuq585mPtbK",
        "number": 3516,
        "title": "Large indexes",
        "user": {
            "login": "jimmarshall87",
            "id": 3678081,
            "node_id": "MDQ6VXNlcjM2NzgwODE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3678081?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jimmarshall87",
            "html_url": "https://github.com/jimmarshall87",
            "followers_url": "https://api.github.com/users/jimmarshall87/followers",
            "following_url": "https://api.github.com/users/jimmarshall87/following{/other_user}",
            "gists_url": "https://api.github.com/users/jimmarshall87/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jimmarshall87/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jimmarshall87/subscriptions",
            "organizations_url": "https://api.github.com/users/jimmarshall87/orgs",
            "repos_url": "https://api.github.com/users/jimmarshall87/repos",
            "events_url": "https://api.github.com/users/jimmarshall87/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jimmarshall87/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-18T10:27:59Z",
        "updated_at": "2023-05-19T06:14:03Z",
        "closed_at": "2023-05-19T06:14:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "We are using the `GPTVectorStoreIndex` and begin to hit some practical limits of using it since it is all stored in memory. E.g. loading a 7000 article index in our case needs 3GB RAM.\r\n\r\nIf we use a Pinecone (or similar) backend with LlamaIndex on top, will this avoid the issue by never loading the full index into memory and just dynamically querying what it needs from the vector database, or does LlamaIndex still attempt to load the whole index into memory?\r\n\r\nIf the latter any recommendations on how to keep the memory footprint down?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3516/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3516/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3511",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3511/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3511/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3511/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3511",
        "id": 1715337715,
        "node_id": "I_kwDOIWuq585mPfnz",
        "number": 3511,
        "title": "\"No index in storage context...\" error when loading Faiss based index from a file.",
        "user": {
            "login": "zeonn",
            "id": 786821,
            "node_id": "MDQ6VXNlcjc4NjgyMQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/786821?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zeonn",
            "html_url": "https://github.com/zeonn",
            "followers_url": "https://api.github.com/users/zeonn/followers",
            "following_url": "https://api.github.com/users/zeonn/following{/other_user}",
            "gists_url": "https://api.github.com/users/zeonn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zeonn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zeonn/subscriptions",
            "organizations_url": "https://api.github.com/users/zeonn/orgs",
            "repos_url": "https://api.github.com/users/zeonn/repos",
            "events_url": "https://api.github.com/users/zeonn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zeonn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-18T09:46:58Z",
        "updated_at": "2023-06-06T03:46:00Z",
        "closed_at": "2023-06-01T15:42:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "My code is:\r\n\r\n```python\r\n# Create Faiss based index\r\nd = 1536 \r\nfaiss_index = faiss.IndexFlatL2(d)\r\nvector_store = FaissVectorStore(faiss_index=faiss_index)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context)\r\n\r\n# save the index to the disk\r\nindex.storage_context.persist()\r\n\r\n# Load the index from the disk\r\nvector_store = FaissVectorStore.from_persist_dir('./storage')\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\nindex = load_index_from_storage(storage_context=storage_context)\r\n```\r\n\r\nAfter that the \"load_index_from_storage\" function causes an error:\r\n\r\n```\r\n      2 vector_store = FaissVectorStore.from_persist_dir('./storage')\r\n      3 storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n----> 4 index = load_index_from_storage(storage_context=storage_context)\r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/loading.py] in load_index_from_storage(storage_context, index_id, **kwargs)\r\n     34 \r\n     35     if len(indices) == 0:\r\n---> 36         raise ValueError(\r\n     37             \"No index in storage context, check if you specified the right persist_dir.\"\r\n     38         )\r\n\r\nValueError: No index in storage context, check if you specified the right persist_dir.\r\n```\r\n\r\n- llama-index==0.6.8\r\n- faiss-cpu==1.7.4\r\n- python3.10",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3511/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3511/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3509",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3509/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3509/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3509/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3509",
        "id": 1715242928,
        "node_id": "PR_kwDOIWuq585QySwC",
        "number": 3509,
        "title": "Added optional num parameter for dataset generation",
        "user": {
            "login": "sahil-springworks",
            "id": 102500694,
            "node_id": "U_kgDOBhwJVg",
            "avatar_url": "https://avatars.githubusercontent.com/u/102500694?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sahil-springworks",
            "html_url": "https://github.com/sahil-springworks",
            "followers_url": "https://api.github.com/users/sahil-springworks/followers",
            "following_url": "https://api.github.com/users/sahil-springworks/following{/other_user}",
            "gists_url": "https://api.github.com/users/sahil-springworks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sahil-springworks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sahil-springworks/subscriptions",
            "organizations_url": "https://api.github.com/users/sahil-springworks/orgs",
            "repos_url": "https://api.github.com/users/sahil-springworks/repos",
            "events_url": "https://api.github.com/users/sahil-springworks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sahil-springworks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-18T08:35:23Z",
        "updated_at": "2023-05-26T03:30:00Z",
        "closed_at": "2023-05-26T03:30:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3509",
            "html_url": "https://github.com/run-llama/llama_index/pull/3509",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3509.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3509.patch",
            "merged_at": "2023-05-26T03:30:00Z"
        },
        "body": "### Summary\r\n\r\nAdded a new optional `num` parameter to the dataset `generate_questions_from_nodes` function allowing users to fetch only \"num\" number of questions from the given nodes.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3509/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3509/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3506",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3506/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3506/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3506/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3506",
        "id": 1715143984,
        "node_id": "I_kwDOIWuq585mOwUw",
        "number": 3506,
        "title": "Does Llamaindex avaialble as nuget package for C# Developers ",
        "user": {
            "login": "laharicharan",
            "id": 15885795,
            "node_id": "MDQ6VXNlcjE1ODg1Nzk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/15885795?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/laharicharan",
            "html_url": "https://github.com/laharicharan",
            "followers_url": "https://api.github.com/users/laharicharan/followers",
            "following_url": "https://api.github.com/users/laharicharan/following{/other_user}",
            "gists_url": "https://api.github.com/users/laharicharan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/laharicharan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/laharicharan/subscriptions",
            "organizations_url": "https://api.github.com/users/laharicharan/orgs",
            "repos_url": "https://api.github.com/users/laharicharan/repos",
            "events_url": "https://api.github.com/users/laharicharan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/laharicharan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-18T07:14:31Z",
        "updated_at": "2023-05-19T02:50:19Z",
        "closed_at": "2023-05-19T02:50:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi Team,\r\n\r\nI would like to understand whether Llamaindex is available as Nuget package for C# developers? so that we utilize this package in C# Apps \r\n\r\nAnd also i would like to understand whether Llamaindex is compactable to the Microsoft sematic kernel? \r\n\r\nThanks,\r\n-Charan",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3506/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3506/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3502",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3502/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3502/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3502/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3502",
        "id": 1715116128,
        "node_id": "I_kwDOIWuq585mOphg",
        "number": 3502,
        "title": "How to send streamed response from terminal to frontend ",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-18T06:51:58Z",
        "updated_at": "2023-09-10T16:58:55Z",
        "closed_at": "2023-09-10T16:58:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "def query():\r\n    query_engine = index.as_query_engine(similarity_top_k=3, streaming=True)\r\n    prompt = request.form['prompt']\r\n    prompt += \" Give in html format\"\r\n    print('prompt given issss:',prompt)\r\n    response_stream = query_engine.query(prompt) \r\n    response_stream.print_response_stream()\r\n    \r\n  using this code getting streamed response on terminal how I can I give this as an api call to frontend \r\n  \r\n  I have already used genrator  \r\nresponse.response_gen to get a generator, which you can iterate over to get text one token at a time to get answer but how to do this  \r\n  \r\n  Need complete code for this",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3502/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3502/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3501",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3501/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3501/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3501/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3501",
        "id": 1715091900,
        "node_id": "I_kwDOIWuq585mOjm8",
        "number": 3501,
        "title": "ValueError: The following `model_kwargs` are not used by the model: ['token_type_ids'] ",
        "user": {
            "login": "ZERO-A-ONE",
            "id": 18625356,
            "node_id": "MDQ6VXNlcjE4NjI1MzU2",
            "avatar_url": "https://avatars.githubusercontent.com/u/18625356?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ZERO-A-ONE",
            "html_url": "https://github.com/ZERO-A-ONE",
            "followers_url": "https://api.github.com/users/ZERO-A-ONE/followers",
            "following_url": "https://api.github.com/users/ZERO-A-ONE/following{/other_user}",
            "gists_url": "https://api.github.com/users/ZERO-A-ONE/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ZERO-A-ONE/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ZERO-A-ONE/subscriptions",
            "organizations_url": "https://api.github.com/users/ZERO-A-ONE/orgs",
            "repos_url": "https://api.github.com/users/ZERO-A-ONE/repos",
            "events_url": "https://api.github.com/users/ZERO-A-ONE/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ZERO-A-ONE/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-18T06:34:42Z",
        "updated_at": "2023-09-25T16:01:41Z",
        "closed_at": "2023-09-25T16:01:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I try to use the vicuna-13b-1.1 model, the following problem occurs\r\n```\r\nimport torch\r\nquery_wrapper_prompt = SimpleInputPrompt(\r\n    \"Below is an instruction that describes a task. \"\r\n    \"Write a response that appropriately completes the request.\\n\\n\"\r\n    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\r\n)\r\nhf_predictor = HuggingFaceLLMPredictor(\r\n    max_input_size=2048, \r\n    max_new_tokens=512,\r\n    temperature=0.25,\r\n    do_sample=False,\r\n    query_wrapper_prompt=query_wrapper_prompt,\r\n    tokenizer_name=\"eachadea/vicuna-13b-1.1\",\r\n    model_name=\"eachadea/vicuna-13b-1.1\",\r\n    device_map=\"auto\",\r\n    tokenizer_kwargs={\"max_length\": 2048},\r\n    # uncomment this if using CUDA to reduce memory usage\r\n    model_kwargs={\"torch_dtype\": torch.float16}\r\n)\r\nprompt_helper = PromptHelper(max_input_size=2048, num_output=512, max_chunk_overlap=50)\r\nembed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\r\nservice_context = ServiceContext.from_defaults(chunk_size_limit=512, llm_predictor=hf_predictor, embed_model=embed_model, prompt_helper=prompt_helper)\r\nindex = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\r\nindex.storage_context.persist(persist_dir=\"./storage\")\r\nquery_engine = index.as_query_engine(streaming=True, similarity_top_k=4, service_context=service_context)\r\n```\r\n```\r\nException in thread Thread-14 (generate):\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File \"/usr/lib/python3.10/threading.py\", line 953, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1267, in generate\r\n    self._validate_model_kwargs(model_kwargs.copy())\r\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1140, in _validate_model_kwargs\r\n    raise ValueError(\r\nValueError: The following `model_kwargs` are not used by the model: ['token_type_ids'] (note: typos in the generate arguments will also show up in this list)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3501/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3501/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3494",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3494/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3494/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3494/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3494",
        "id": 1715024123,
        "node_id": "I_kwDOIWuq585mOTD7",
        "number": 3494,
        "title": "Example for reading and writing simple index to cloud storage",
        "user": {
            "login": "SikandAlex",
            "id": 12959962,
            "node_id": "MDQ6VXNlcjEyOTU5OTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/12959962?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SikandAlex",
            "html_url": "https://github.com/SikandAlex",
            "followers_url": "https://api.github.com/users/SikandAlex/followers",
            "following_url": "https://api.github.com/users/SikandAlex/following{/other_user}",
            "gists_url": "https://api.github.com/users/SikandAlex/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SikandAlex/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SikandAlex/subscriptions",
            "organizations_url": "https://api.github.com/users/SikandAlex/orgs",
            "repos_url": "https://api.github.com/users/SikandAlex/repos",
            "events_url": "https://api.github.com/users/SikandAlex/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SikandAlex/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-18T05:48:13Z",
        "updated_at": "2023-09-11T06:01:11Z",
        "closed_at": "2023-09-10T16:58:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I see examples for loading data from cloud storage and I've also seen the use of external cloud vector stores.\r\n\r\nHow can I read and write a simple index to cloud storage (one perhaps constructed on a few web pages)? Do I need to create a custom `StorageContext`? How can I save the index to cloud storage and then reload it from within a serverless function when a user makes an API request to a serverless cloud function?\r\n\r\nMy background is in computer vision so please excuse any naiive questions. I really appreciate this open-source tool and community. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3494/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3494/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3493",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3493/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3493/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3493/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3493",
        "id": 1715019410,
        "node_id": "I_kwDOIWuq585mOR6S",
        "number": 3493,
        "title": "How to read PDF present in google drive folder  ",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-18T05:43:22Z",
        "updated_at": "2023-09-14T16:13:08Z",
        "closed_at": "2023-09-14T16:13:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Using this code for authorization \r\ndef authorize_gdocs():\r\n    google_oauth2_scopes = [\r\n        \"https://www.googleapis.com/auth/drive.readonly\",\r\n        \"https://www.googleapis.com/auth/documents.readonly\"\r\n    ]\r\n    cred = None\r\n    if os.path.exists(\"token.pickle\"):\r\n        with open(\"token.pickle\", 'rb') as token:\r\n            cred = pickle.load(token)\r\n    if not cred or not cred.valid:\r\n        if cred and cred.expired and cred.refresh_token:\r\n            cred.refresh(Request())\r\n        else:\r\n            flow = InstalledAppFlow.from_client_secrets_file(\"client_secrets.json\", google_oauth2_scopes)\r\n            cred = flow.run_local_server(port=0)\r\n        with open(\"token.pickle\", 'wb') as token:\r\n            pickle.dump(cred, token)\r\n\r\nauthorize_gdocs()\r\n\r\n\r\nNow how to create index and query index for files available on google drive\r\n\r\nGoogleDriveReader = download_loader('GoogleDriveReader')\r\nfolder_id = '1chfbc-eA0kVGSLl0l7UX8zbW-sT9aNN6'\r\nloader = GoogleDriveReader()\r\n###### PDFReader = download_loader(\"PDFReader\")\r\n###### loader = PDFReader()\r\ndocuments = loader.load_data(folder_id=folder_id)\r\n\r\n\r\nHow to handle this please guide ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3493/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3493/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3443",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3443/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3443/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3443/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3443",
        "id": 1714489715,
        "node_id": "I_kwDOIWuq585mMQlz",
        "number": 3443,
        "title": " ValueError: invalid literal for int() with base 10: '$640'",
        "user": {
            "login": "nazkhan-8451",
            "id": 108809950,
            "node_id": "U_kgDOBnxO3g",
            "avatar_url": "https://avatars.githubusercontent.com/u/108809950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nazkhan-8451",
            "html_url": "https://github.com/nazkhan-8451",
            "followers_url": "https://api.github.com/users/nazkhan-8451/followers",
            "following_url": "https://api.github.com/users/nazkhan-8451/following{/other_user}",
            "gists_url": "https://api.github.com/users/nazkhan-8451/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nazkhan-8451/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nazkhan-8451/subscriptions",
            "organizations_url": "https://api.github.com/users/nazkhan-8451/orgs",
            "repos_url": "https://api.github.com/users/nazkhan-8451/repos",
            "events_url": "https://api.github.com/users/nazkhan-8451/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nazkhan-8451/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-17T18:58:12Z",
        "updated_at": "2023-10-05T16:03:23Z",
        "closed_at": "2023-10-05T16:03:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "From: https://github.com/jerryjliu/llama_index/blob/main/docs/examples/node_postprocessor/LLMReranker-Gatsby.ipynb\r\n\r\n**Code**\r\n\r\n```\r\nnew_nodes = get_retrieved_nodes(\r\n    custom_query, vector_top_k=3, with_reranker=False\r\n)\r\n\r\nvisualize_retrieved_nodes(new_nodes)\r\n```\r\n\r\n**Error**\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<command-3433144466079443> in <module>\r\n----> 1 new_nodes = get_retrieved_nodes(\r\n      2     custom_query, vector_top_k=10, reranker_top_n=3, with_reranker=True\r\n      3 )\r\n      4 print(new_nodes)\r\n\r\n<command-3433144466078678> in get_retrieved_nodes(query_str, vector_top_k, reranker_top_n, with_reranker)\r\n     23         # configure reranker\r\n     24         reranker = LLMRerank(choice_batch_size=5, top_n=reranker_top_n, service_context=service_context)\r\n---> 25         retrieved_nodes = reranker.postprocess_nodes(retrieved_nodes, query_bundle)\r\n     26 \r\n     27     return retrieved_nodes\r\n\r\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-10da9aab-5927-4007-895d-ab2a25ffe5bd/lib/python3.8/site-packages/llama_index/indices/postprocessor/llm_rerank.py in postprocess_nodes(self, nodes, query_bundle)\r\n     61             )\r\n     62 \r\n---> 63             raw_choices, relevances = self._parse_choice_select_answer_fn(\r\n     64                 raw_response, len(nodes_batch)\r\n     65             )\r\n\r\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-10da9aab-5927-4007-895d-ab2a25ffe5bd/lib/python3.8/site-packages/llama_index/indices/utils.py in default_parse_choice_select_answer_fn(answer, num_choices, raise_error)\r\n     98                     \"answer_num: <int>, answer_relevance: <float>\"\r\n     99                 )\r\n--> 100         answer_num = int(line_tokens[0].split(\":\")[1].strip())\r\n    101         if answer_num > num_choices:\r\n    102             continue\r\n\r\nValueError: invalid literal for int() with base 10: '$60'\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3443/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3443/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3440",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3440/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3440/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3440/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3440",
        "id": 1714290956,
        "node_id": "I_kwDOIWuq585mLgEM",
        "number": 3440,
        "title": "Performance degradation in AzureOpenAI with version 0.6.x compared to 0.5.8",
        "user": {
            "login": "nazkhan-8451",
            "id": 108809950,
            "node_id": "U_kgDOBnxO3g",
            "avatar_url": "https://avatars.githubusercontent.com/u/108809950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nazkhan-8451",
            "html_url": "https://github.com/nazkhan-8451",
            "followers_url": "https://api.github.com/users/nazkhan-8451/followers",
            "following_url": "https://api.github.com/users/nazkhan-8451/following{/other_user}",
            "gists_url": "https://api.github.com/users/nazkhan-8451/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nazkhan-8451/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nazkhan-8451/subscriptions",
            "organizations_url": "https://api.github.com/users/nazkhan-8451/orgs",
            "repos_url": "https://api.github.com/users/nazkhan-8451/repos",
            "events_url": "https://api.github.com/users/nazkhan-8451/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nazkhan-8451/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-17T16:50:53Z",
        "updated_at": "2023-09-10T16:59:09Z",
        "closed_at": "2023-09-10T16:59:08Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I was testing `pdf_page_finder`: https://github.com/jerryjliu/llama_index/blob/main/docs/examples/citation/pdf_page_reference.ipynb. For semantic search, I am getting reasonable output for my query from version 0.5.8. But 0.6.x version gives garbage output but shows page number.\r\n\r\n`pip freeze`:\r\n\r\n```\r\nabsl-py==1.4.0\r\naiohttp==3.8.4\r\naiosignal==1.3.1\r\nantlr4-python3-runtime==4.9.3\r\nanyio==3.6.2\r\nappdirs==1.4.4\r\nargilla==1.7.0\r\nargon2-cffi==20.1.0\r\nastunparse==1.6.3\r\nasync-generator==1.10\r\nasync-timeout==4.0.2\r\nattrs==20.3.0\r\nazure-core==1.26.4\r\nazure-identity==1.13.0\r\nazure-storage-blob==12.16.0\r\nazure-storage-file-datalake==12.11.0\r\nbackcall==0.2.0\r\nbackoff==2.2.1\r\nbidict==0.21.4\r\nbleach==3.3.0\r\nboto3==1.16.7\r\nbotocore==1.19.7\r\nbump2version==1.0.1\r\nbumpversion==0.6.0\r\ncachetools==5.3.0\r\ncertifi==2023.5.7\r\ncffi==1.14.5\r\nchardet==4.0.0\r\ncharset-normalizer==3.1.0\r\nclick==8.1.3\r\ncmake==3.26.3\r\ncoloredlogs==15.0.1\r\ncommonmark==0.9.1\r\ncomponent-logger==1.11.1.post0\r\ncryptography==40.0.2\r\ncycler==0.10.0\r\nCython==0.29.23\r\ndataclasses-json==0.5.7\r\ndatarobot==3.1.1\r\ndbus-python==1.2.16\r\ndecorator==5.0.6\r\ndefusedxml==0.7.1\r\nDeprecated==1.2.13\r\ndistlib==0.3.4\r\ndistro==1.4.0\r\ndistro-info===0.23ubuntu1\r\ndocopt==0.6.2\r\neffdet==0.3.0\r\neffo411==0.3.0\r\neffodata==2.5.4\r\nentrypoints==0.3\r\net-xmlfile==1.1.0\r\nfacets-overview==1.0.0\r\nfastapi==0.95.2\r\nfilelock==3.6.0\r\nflatbuffers==23.5.9\r\nflowcate==1.0.2.post1\r\nfrozenlist==1.3.3\r\nfsspec==2023.5.0\r\ngast==0.4.0\r\ngoogle-api-core==2.11.0\r\ngoogle-auth==2.18.0\r\ngoogle-auth-oauthlib==1.0.0\r\ngoogle-cloud-appengine-logging==1.3.0\r\ngoogle-cloud-audit-log==0.2.5\r\ngoogle-cloud-core==2.3.2\r\ngoogle-cloud-logging==3.5.0\r\ngoogle-cloud-storage==2.9.0\r\ngoogle-crc32c==1.5.0\r\ngoogle-pasta==0.2.0\r\ngoogle-resumable-media==2.5.0\r\ngoogleapis-common-protos==1.59.0\r\ngreenlet==2.0.2\r\ngrpc-google-iam-v1==0.12.6\r\ngrpcio==1.54.2\r\ngrpcio-status==1.54.2\r\nh11==0.14.0\r\nh5py==3.8.0\r\nhttpcore==0.16.3\r\nhttpx==0.23.3\r\nhuggingface-hub==0.14.1\r\nhumanfriendly==10.0\r\nidna==2.10\r\nimportlib-metadata==6.6.0\r\niopath==0.1.10\r\nipykernel==5.3.4\r\nipython==7.22.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.6.3\r\nisodate==0.6.1\r\njax==0.4.10\r\njedi==0.17.2\r\nJinja2==2.11.3\r\njmespath==0.10.0\r\njoblib==1.0.1\r\njsonschema==3.2.0\r\njupyter-client==6.1.12\r\njupyter-core==4.7.1\r\njupyterlab-pygments==0.1.2\r\njupyterlab-widgets==1.0.0\r\nkayday==2.1.1\r\nkeras==2.12.0\r\nkiwisolver==1.3.1\r\nkoalas==1.8.2\r\nkpi-metrics==1.3.7\r\nlangchain==0.0.172\r\nlayoutparser==0.3.4\r\nlibclang==16.0.0\r\nlit==16.0.5\r\nllama-index==0.6.8\r\nlxml==4.9.2\r\nMarkdown==3.4.3\r\nMarkupSafe==2.1.2\r\nmarshmallow==3.19.0\r\nmarshmallow-enum==1.5.1\r\nmatplotlib==3.4.2\r\nmistune==0.8.4\r\nml-dtypes==0.1.0\r\nmonotonic==1.6\r\nmpmath==1.3.0\r\nmsal==1.22.0\r\nmsal-extensions==1.0.0\r\nmsg-parser==1.2.0\r\nmultidict==6.0.4\r\nmypy-extensions==1.0.0\r\nnbclient==0.5.3\r\nnbconvert==6.0.7\r\nnbformat==5.1.3\r\nnest-asyncio==1.5.1\r\nnetworkx==3.1\r\nnltk==3.8.1\r\nnotebook==6.3.0\r\nnum2words==0.5.12\r\nnumber-parser==0.3.0\r\nnumexpr==2.8.4\r\nnumpy==1.22.4\r\nnvidia-cublas-cu11==11.10.3.66\r\nnvidia-cuda-cupti-cu11==11.7.101\r\nnvidia-cuda-nvrtc-cu11==11.7.99\r\nnvidia-cuda-runtime-cu11==11.7.99\r\nnvidia-cudnn-cu11==8.5.0.96\r\nnvidia-cufft-cu11==10.9.0.58\r\nnvidia-curand-cu11==10.2.10.91\r\nnvidia-cusolver-cu11==11.4.0.1\r\nnvidia-cusparse-cu11==11.7.4.91\r\nnvidia-nccl-cu11==2.14.3\r\nnvidia-nvtx-cu11==11.7.91\r\noauthlib==3.2.2\r\nolefile==0.46\r\nomegaconf==2.3.0\r\nonnxruntime==1.14.1\r\nopenai==0.27.6\r\nopenapi-schema-pydantic==1.2.4\r\nopencv-python==4.7.0.72\r\nopenpyxl==3.1.2\r\nopt-einsum==3.3.0\r\npackaging==23.1\r\npandas==1.2.4\r\npandocfilters==1.4.3\r\nparso==0.7.0\r\npatsy==0.5.1\r\npdf2image==1.16.3\r\npdfminer.six==20221105\r\npdfplumber==0.9.0\r\npexpect==4.8.0\r\npickleshare==0.7.5\r\nPillow==9.5.0\r\nplotly==5.5.0\r\npoirot==2.6.4\r\nportalocker==2.7.0\r\nprometheus-client==0.10.1\r\nprompt-toolkit==3.0.17\r\nproto-plus==1.22.2\r\nprotobuf==4.23.0\r\npsycopg2==2.8.5\r\nptyprocess==0.7.0\r\npy4j==0.10.9.7\r\npyarrow==4.0.0\r\npyasn1==0.5.0\r\npyasn1-modules==0.3.0\r\npycocotools==2.0.6\r\npycparser==2.20\r\npydantic==1.10.7\r\nPygments==2.8.1\r\nPyGObject==3.36.0\r\nPyJWT==2.7.0\r\npyluach==2.2.0\r\npypandoc==1.11\r\npyparsing==2.4.7\r\npypdf==3.8.1\r\npypdf2==3.0.1\r\npyrsistent==0.17.3\r\npyspark==3.4.0\r\npyspark-shared-libs-8451==1.0.79\r\npytesseract==0.3.10\r\npython-apt==2.0.1+ubuntu0.20.4.1\r\npython-dateutil==2.8.1\r\npython-docx==0.8.11\r\npython-engineio==4.3.0\r\npython-magic==0.4.15\r\npython-multipart==0.0.6\r\npython-pptx==0.6.21\r\npython-socketio==5.4.1\r\npytz==2020.5\r\nPyYAML==6.0\r\npyzmq==20.0.0\r\nregex==2023.5.5\r\nrequests==2.29.0\r\nrequests-oauthlib==1.3.1\r\nrequests-toolbelt==1.0.0\r\nrequests-unixsocket==0.2.0\r\nrfc3986==1.5.0\r\nrich==13.0.1\r\nrsa==4.9\r\ns3transfer==0.3.7\r\nsafetensors==0.3.1\r\nscikit-learn==0.24.1\r\nscipy==1.10.1\r\nseaborn==0.11.1\r\nseg==1.8.2.post1\r\nSend2Trash==1.5.0\r\nsix==1.15.0\r\nsniffio==1.3.0\r\nSQLAlchemy==2.0.13\r\nsqlparse==0.4.4\r\nssh-import-id==5.10\r\nstarlette==0.27.0\r\nstatsmodels==0.12.2\r\nsympy==1.12\r\ntenacity==8.2.2\r\ntensorboard==2.12.3\r\ntensorboard-data-server==0.7.0\r\ntensorflow==2.12.0\r\ntensorflow-estimator==2.12.0\r\ntensorflow-io-gcs-filesystem==0.32.0\r\ntermcolor==2.3.0\r\nterminado==0.9.4\r\ntestpath==0.4.4\r\nthreadpoolctl==2.1.0\r\ntiktoken==0.4.0\r\ntimm==0.9.2\r\ntokenizers==0.13.3\r\ntorch==2.0.1\r\ntorchvision==0.15.2\r\ntornado==6.1\r\ntqdm==4.65.0\r\ntrafaret==2.1.1\r\ntraitlets==5.0.5\r\ntransformers==4.29.2\r\ntriton==2.0.0\r\ntyper==0.9.0\r\ntyping-extensions==4.5.0\r\ntyping-inspect==0.8.0\r\ntzlocal==2.1\r\nunattended-upgrades==0.1\r\nunstructured==0.6.6\r\nunstructured-inference==0.4.4\r\nupc-input==2.2.1.post1\r\nurllib3==1.25.11\r\nuvicorn==0.22.0\r\nvirtualenv==20.4.1\r\nWand==0.6.11\r\nwcwidth==0.2.5\r\nwebencodings==0.5.1\r\nWerkzeug==2.3.4\r\nwidgetsnbextension==3.5.1\r\nwrapt==1.14.1\r\nXlsxWriter==3.1.0\r\nyarl==1.9.2\r\nzipp==3.15.0\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3440/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3440/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3435",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3435/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3435/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3435/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3435",
        "id": 1713965353,
        "node_id": "PR_kwDOIWuq585Qt9x_",
        "number": 3435,
        "title": "Improve retrieval performance of retriever",
        "user": {
            "login": "IANTHEREAL",
            "id": 10701973,
            "node_id": "MDQ6VXNlcjEwNzAxOTcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10701973?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IANTHEREAL",
            "html_url": "https://github.com/IANTHEREAL",
            "followers_url": "https://api.github.com/users/IANTHEREAL/followers",
            "following_url": "https://api.github.com/users/IANTHEREAL/following{/other_user}",
            "gists_url": "https://api.github.com/users/IANTHEREAL/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IANTHEREAL/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IANTHEREAL/subscriptions",
            "organizations_url": "https://api.github.com/users/IANTHEREAL/orgs",
            "repos_url": "https://api.github.com/users/IANTHEREAL/repos",
            "events_url": "https://api.github.com/users/IANTHEREAL/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IANTHEREAL/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-05-17T13:50:02Z",
        "updated_at": "2023-05-30T00:19:59Z",
        "closed_at": "2023-05-29T22:15:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3435",
            "html_url": "https://github.com/run-llama/llama_index/pull/3435",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3435.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3435.patch",
            "merged_at": "2023-05-29T22:15:43Z"
        },
        "body": "The retriever will always query the node from docstore when retrieving nodes, even if the vector also saves the data.  So I want to add a line code to make retriever query data from docstore only if the vector does not savethe data or it is an image/index node\r\n\r\nI test it manully, the result is as following:\r\n\r\nwithout this pr\r\n```\r\nTime to get nodes from doc store:  3.6941089630126953 (second)\r\n```\r\nwith this pr\r\n```\r\nTime to get nodes from doc store:  1.6927719116210938e-05 (second)\r\n```\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3435/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3435/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3429",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3429/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3429/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3429/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3429",
        "id": 1713661044,
        "node_id": "I_kwDOIWuq585mJGR0",
        "number": 3429,
        "title": "Unable to read and use service_context  when loading an index with the load_index_from_storage function",
        "user": {
            "login": "paolosalvatori",
            "id": 1658419,
            "node_id": "MDQ6VXNlcjE2NTg0MTk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1658419?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/paolosalvatori",
            "html_url": "https://github.com/paolosalvatori",
            "followers_url": "https://api.github.com/users/paolosalvatori/followers",
            "following_url": "https://api.github.com/users/paolosalvatori/following{/other_user}",
            "gists_url": "https://api.github.com/users/paolosalvatori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/paolosalvatori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/paolosalvatori/subscriptions",
            "organizations_url": "https://api.github.com/users/paolosalvatori/orgs",
            "repos_url": "https://api.github.com/users/paolosalvatori/repos",
            "events_url": "https://api.github.com/users/paolosalvatori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/paolosalvatori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-17T11:11:29Z",
        "updated_at": "2023-09-07T00:05:13Z",
        "closed_at": "2023-05-17T13:30:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I created the following sample that works as follows:\r\n\r\n1. The first time you run it, it loads a list of documents, creates and index, then stores it locally. Then it runs the query using AzureOpenAI as LLM engine\r\n2. The second time the code loads the index from the local store and runs the query\r\n\r\n```python\r\n# For more information, see: \r\n# https://gpt-index.readthedocs.io/en/latest/getting_started/starter_example.html\r\n# https://gist.github.com/csiebler/e287b791333011183792c08bad1dc140\r\n\r\n# Load modules\r\nimport os\r\nimport openai\r\nfrom dotenv import load_dotenv\r\nfrom llama_index import (\r\n    GPTVectorStoreIndex, \r\n    SimpleDirectoryReader, \r\n    PromptHelper, \r\n    LangchainEmbedding, \r\n    ServiceContext, \r\n    StorageContext, \r\n    load_index_from_storage)\r\nfrom llama_index.storage.index_store.types import DEFAULT_PERSIST_DIR\r\nfrom langchain.chat_models import AzureChatOpenAI\r\nfrom langchain.embeddings import OpenAIEmbeddings\r\nfrom llama_index.llm_predictor.chatgpt import ChatGPTLLMPredictor\r\n\r\n# Load environment variables (set OPENAI_API_KEY and OPENAI_API_BASE in .env)\r\nload_dotenv(override=True)\r\n\r\n# Initialize LLM and Embeddings model\r\nllm = AzureChatOpenAI(\r\n  temperature=0.9, \r\n  deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \r\n  openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\r\n  openai_api_base=os.getenv(\"AZURE_OPENAI_BASE\"),\r\n  openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"))\r\n\r\nllm_predictor = ChatGPTLLMPredictor(llm=llm, retry_on_throttling=False)\r\n\r\nopen_ai_embeddings = OpenAIEmbeddings(\r\n  deployment = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\"), \r\n  openai_api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\r\n  openai_api_base = os.getenv(\"AZURE_OPENAI_BASE\"),\r\n  openai_api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\r\n  openai_api_type = \"azure\",\r\n  chunk_size = 1)\r\n\r\nembeddings = LangchainEmbedding(open_ai_embeddings)\r\n\r\n# Define prompt helper\r\nmax_input_size = 3000\r\nnum_output = 256\r\nchunk_size_limit = 1000\r\nmax_chunk_overlap = 20\r\nprompt_helper = PromptHelper(\r\n  max_input_size = max_input_size, \r\n  num_output = num_output, \r\n  max_chunk_overlap = max_chunk_overlap, \r\n  chunk_size_limit = chunk_size_limit)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n  llm_predictor = llm_predictor, \r\n  embed_model = embeddings, \r\n  prompt_helper = prompt_helper)\r\n\r\n# Check if storage directory exists\r\npersist_dir = DEFAULT_PERSIST_DIR\r\ninput_files = ['/mnt/d/Paolos/books/Building_Microservices.pdf']\r\n\r\nif not os.path.isdir(persist_dir):\r\n  # Load documents\r\n  print(\"Loading documents:\")\r\n  for input_file in input_files:\r\n    print(f\" -  {input_file}\")\r\n\r\n  # Create the simple directory reader\r\n  print(\"Creating directory reader...\")\r\n  documents = SimpleDirectoryReader(\r\n    input_files=input_files, \r\n    required_exts=['.pdf']).load_data()\r\n\r\n  # Create index\r\n  print(\"Creating index...\")\r\n  index = GPTVectorStoreIndex.from_documents(\r\n    documents = documents, \r\n    service_context = service_context, \r\n    prompt_helper = prompt_helper)\r\n\r\n  # Save index\r\n  print(\"Saving index...\")\r\n  index.storage_context.persist(persist_dir = persist_dir)\r\nelse:\r\n  # Rebuild storage context\r\n  storage_context = StorageContext.from_defaults(persist_dir = persist_dir)\r\n\r\n  # Load index\r\n  print(f\"Loading index from {persist_dir}...\")\r\n  index = load_index_from_storage(storage_context)\r\n\r\n# Query index\r\nprint(\"Creating query engine from index...\")\r\nquery_engine = index.as_query_engine(service_context = service_context, verbose = True, engine = llm)\r\n\r\n# Run query\r\nquery = \"What is a microservice? Summarize and provide main characteristics in a bullet point list.\"\r\nprint(\"Running query...\")\r\nanswer = query_engine.query(query)\r\n\r\n# Print results\r\nprint(f\"Query: {query}\")\r\nprint(f\"Answer: {answer}\")\r\nprint(f\"Sources: {answer.get_formatted_sources()}\")\r\n```\r\nThe application behaves as follows:\r\n\r\n1. The first time the app works as expected, the index is created locally, and the query returns an answer as expected.\r\n2. The second time the `answer = query_engine.query(query)` call throws the following exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/tenacity/__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/embeddings/openai.py\", line 105, in get_embedding\r\n    return openai.Embedding.create(input=[text], model=engine, **kwargs)[\"data\"][0][\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/openai/api_resources/embedding.py\", line 33, in create\r\n    response = super().create(*args, **kwargs)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 149, in create\r\n    ) = cls.__prepare_create_request(\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 83, in __prepare_create_request\r\n    raise error.InvalidRequestError(\r\nopenai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py\", line 39, in <module>\r\n    cli.main()\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py\", line 430, in main\r\n    run()\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py\", line 284, in run_file\r\n    runpy.run_path(target, run_name=\"__main__\")\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 321, in run_path\r\n    return _run_module_code(code, init_globals, run_name,\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 135, in _run_module_code\r\n    _run_code(code, mod_globals, init_globals,\r\n  File \"/home/paolos/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py\", line 124, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/paolos/python/llama_index/quickstart/storage.py\", line 126, in <module>\r\n    answer = query_engine.query(query)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/indices/query/base.py\", line 20, in query\r\n    return self._query(str_or_query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/query_engine/retriever_query_engine.py\", line 139, in _query\r\n    nodes = self._retriever.retrieve(query_bundle)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/indices/base_retriever.py\", line 21, in retrieve\r\n    return self._retrieve(str_or_query_bundle)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/token_counter/token_counter.py\", line 78, in wrapped_llm_predict\r\n    f_return_val = f(_self, *args, **kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/indices/vector_store/retrievers/retriever.py\", line 70, in _retrieve\r\n    self._service_context.embed_model.get_agg_embedding_from_queries(\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/embeddings/base.py\", line 91, in get_agg_embedding_from_queries\r\n    query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/embeddings/base.py\", line 91, in <listcomp>\r\n    query_embeddings = [self.get_query_embedding(query) for query in queries]\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/embeddings/base.py\", line 77, in get_query_embedding\r\n    query_embedding = self._get_query_embedding(query)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/llama_index/embeddings/openai.py\", line 230, in _get_query_embedding\r\n    return get_embedding(\r\n           ^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/tenacity/__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/paolos/python/llama_index/quickstart/.venv/lib/python3.11/site-packages/tenacity/__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x7f56be227410 state=finished raised InvalidRequestError>]\r\n```\r\n\r\nAfter some investigation and debugging, I found that the `VectorIndexRetriever` gets the `service_context` from the index. When creating the index using the `load_index_from_storage`, there is no possibility of passing the `service_context` as a parameter. The `service_context` property of the `BaseGPTIndex` has no setter, so I changed the following code:\r\n\r\n```python\r\n  ...\r\n  # Load index\r\n  print(f\"Loading index from {persist_dir}...\")\r\n  index = load_index_from_storage(storage_context)\r\n  ...\r\n```\r\n\r\ninto: \r\n\r\n```python\r\n  ...\r\n  # Load index\r\n  print(f\"Loading index from {persist_dir}...\")\r\n  index = load_index_from_storage(storage_context)\r\n  index._service_context = service_context\r\n  ...\r\n```\r\n\r\nNow the retriever can retrieve the `service_context` from the index, and the  `answer = query_engine.query(query)` call returns an answer as expected. Maybe the `load_index_from_storage` function should be extended with the `service_context` parameter, or maybe there is another way to pass the service_context to an index loaded from storage. Thoughts?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3429/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3429/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3426",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3426/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3426/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3426/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3426",
        "id": 1713461067,
        "node_id": "I_kwDOIWuq585mIVdL",
        "number": 3426,
        "title": "AttributeError: 'str' object has no attribute 'get_index_struct' when loading index from load_index_from_storage ",
        "user": {
            "login": "vrubashr",
            "id": 88377240,
            "node_id": "MDQ6VXNlcjg4Mzc3MjQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/88377240?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vrubashr",
            "html_url": "https://github.com/vrubashr",
            "followers_url": "https://api.github.com/users/vrubashr/followers",
            "following_url": "https://api.github.com/users/vrubashr/following{/other_user}",
            "gists_url": "https://api.github.com/users/vrubashr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vrubashr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vrubashr/subscriptions",
            "organizations_url": "https://api.github.com/users/vrubashr/orgs",
            "repos_url": "https://api.github.com/users/vrubashr/repos",
            "events_url": "https://api.github.com/users/vrubashr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vrubashr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-17T09:06:43Z",
        "updated_at": "2023-11-07T00:32:09Z",
        "closed_at": "2023-06-11T07:10:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "In reference to #3425 \r\n\r\n`  # Load the storage context\r\n    docstore = 'storage/docstore.json'\r\n    index_store = 'storage/index_store.json'\r\n    vector_store = 'storage/vector_store.json'\r\n    \r\n    # Load the index from storage\r\n    storage_context = StorageContext.from_defaults(\r\n        docstore=docstore,\r\n        index_store=index_store,\r\n        vector_store=vector_store)\r\n    index = load_index_from_storage(storage_context)`\r\n`doc = Document(doc_id=data_file, text=text)\r\n    max_input_size = 4096\r\n    num_output = 256\r\n    max_chunk_overlap = 20\r\n    chunk_size_limit = 600\r\n    \r\n    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\",max_tokens=num_output))\r\n    prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap,chunk_size_limit=chunk_size_limit)\r\n    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\r\n    index = GPTVectorStoreIndex.from_documents([doc], service_context=service_context)\r\n    index.storage_context.persist(index_path)`\r\n    \r\n![image](https://github.com/jerryjliu/llama_index/assets/88377240/f7c61390-bd6a-4a5f-9b9c-3e3883fee8a2)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3426/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3426/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3425",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3425/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3425/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3425/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3425",
        "id": 1713443277,
        "node_id": "I_kwDOIWuq585mIRHN",
        "number": 3425,
        "title": "AttributeError: 'str' object has no attribute 'get_index_struct' when loading index from load_index_from_storage",
        "user": {
            "login": "vrubashr",
            "id": 88377240,
            "node_id": "MDQ6VXNlcjg4Mzc3MjQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/88377240?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vrubashr",
            "html_url": "https://github.com/vrubashr",
            "followers_url": "https://api.github.com/users/vrubashr/followers",
            "following_url": "https://api.github.com/users/vrubashr/following{/other_user}",
            "gists_url": "https://api.github.com/users/vrubashr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vrubashr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vrubashr/subscriptions",
            "organizations_url": "https://api.github.com/users/vrubashr/orgs",
            "repos_url": "https://api.github.com/users/vrubashr/repos",
            "events_url": "https://api.github.com/users/vrubashr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vrubashr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-17T08:56:39Z",
        "updated_at": "2023-05-17T09:01:53Z",
        "closed_at": "2023-05-17T09:00:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Passed the path of the index files(docstore.json, index_store.json and vector_store.json) properly but facing error when loading it. Facing error on the line \"index = load_index_from_storage(storage_context,index_id='vector_index')\".\r\n![image](https://github.com/jerryjliu/llama_index/assets/88377240/385b661d-f6a4-4e02-adca-859efed4627f)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3425/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3425/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3424",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3424/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3424/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3424/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3424",
        "id": 1713382892,
        "node_id": "I_kwDOIWuq585mICXs",
        "number": 3424,
        "title": "How to store embedding vector when using a custom embedding model?",
        "user": {
            "login": "DZ9",
            "id": 6756880,
            "node_id": "MDQ6VXNlcjY3NTY4ODA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6756880?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DZ9",
            "html_url": "https://github.com/DZ9",
            "followers_url": "https://api.github.com/users/DZ9/followers",
            "following_url": "https://api.github.com/users/DZ9/following{/other_user}",
            "gists_url": "https://api.github.com/users/DZ9/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DZ9/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DZ9/subscriptions",
            "organizations_url": "https://api.github.com/users/DZ9/orgs",
            "repos_url": "https://api.github.com/users/DZ9/repos",
            "events_url": "https://api.github.com/users/DZ9/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DZ9/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-17T08:18:37Z",
        "updated_at": "2023-06-11T06:54:43Z",
        "closed_at": "2023-06-11T06:54:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I used a custom embedding model from langchain, it is configed as follows:\r\n\r\n`embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=embedding_path))`\r\n\r\n`service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper, embed_model=embed_model)`\r\n\r\nIt is configed in the service_context, which will not be stroed when I call `index.storage_context.persist`\r\n\r\nand when I load the saved index, I need to reconfig the service_context and pass it to the index:\r\n`index = load_index_from_storage(storage_context, service_context=service_context)`\r\n\r\nSo I found that, the persisted `vector_store.json` was empty, and the embedding vector will regenerate every time I run the code.\r\n\r\nIs there any way to solve this problem?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3424/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3424/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3423",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3423/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3423/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3423/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3423",
        "id": 1713357096,
        "node_id": "I_kwDOIWuq585mH8Eo",
        "number": 3423,
        "title": "Mongo collection name contains invalid character",
        "user": {
            "login": "richardeee",
            "id": 5335164,
            "node_id": "MDQ6VXNlcjUzMzUxNjQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5335164?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/richardeee",
            "html_url": "https://github.com/richardeee",
            "followers_url": "https://api.github.com/users/richardeee/followers",
            "following_url": "https://api.github.com/users/richardeee/following{/other_user}",
            "gists_url": "https://api.github.com/users/richardeee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/richardeee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/richardeee/subscriptions",
            "organizations_url": "https://api.github.com/users/richardeee/orgs",
            "repos_url": "https://api.github.com/users/richardeee/repos",
            "events_url": "https://api.github.com/users/richardeee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/richardeee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-17T08:02:51Z",
        "updated_at": "2023-07-31T19:59:01Z",
        "closed_at": "2023-05-18T01:03:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\n\r\nI used Azure CosmosDB for Mongo as Doc Store and Index Store, after initialized storage context, when I try to build new index, I got the error:\r\n`OperationFailure: Collection name contains invalid character., full error: {'ok': 0.0, 'errmsg': 'Collection name contains invalid character.', 'code': 73, 'codeName': 'InvalidNamespace'}`\r\n\r\nHere is my code:\r\n```python\r\nconnection_string=\"mongodb://xx\"\r\nindex_store = MongoIndexStore.from_uri(uri=str(connection_string), db_name=\"kg_index\")\r\ndoc_store = MongoDocumentStore.from_uri(uri=str(connection_string), db_name= \"doc_store\")\r\nstorage_context = StorageContext.from_defaults(\r\n            docstore=doc_store,\r\n            index_store=index_store)\r\n```\r\n```python\r\nnew_index = GPTKnowledgeGraphIndex.from_documents(\r\n    docs, \r\n    max_triplets_per_chunk=5,\r\n    service_context=service_context,\r\n    storage_context=storage_context\r\n)\r\n```\r\n\r\nIt seems the collection name f\"{namespace}/data\" is not supported, is it possible if I can use no namespace at all? Thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3423/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3423/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3422",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3422/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3422/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3422/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3422",
        "id": 1713230086,
        "node_id": "I_kwDOIWuq585mHdEG",
        "number": 3422,
        "title": "Typo in QUERY_RESPONSE_REFINE_PROMPT causing incorrect refine prompt",
        "user": {
            "login": "jameshknowles",
            "id": 89317105,
            "node_id": "MDQ6VXNlcjg5MzE3MTA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/89317105?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jameshknowles",
            "html_url": "https://github.com/jameshknowles",
            "followers_url": "https://api.github.com/users/jameshknowles/followers",
            "following_url": "https://api.github.com/users/jameshknowles/following{/other_user}",
            "gists_url": "https://api.github.com/users/jameshknowles/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jameshknowles/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jameshknowles/subscriptions",
            "organizations_url": "https://api.github.com/users/jameshknowles/orgs",
            "repos_url": "https://api.github.com/users/jameshknowles/repos",
            "events_url": "https://api.github.com/users/jameshknowles/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jameshknowles/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-17T06:40:53Z",
        "updated_at": "2023-06-06T05:41:40Z",
        "closed_at": "2023-06-06T05:41:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When asking the LLM to evaluate a response the following improper prompt is passed:\r\n\r\n\"We want to understand if the following query and response isin line with the context information\"\r\n\r\nWith the assumed intent being:\r\n\r\n\"We want to understand if the following query and response is in line with the context information\"\r\n\r\nThe base.py file has a missing character in the definition of QUERY_RESPONSE_REFINE_PROMPT.  A space was left off the first line so the \"is\" and \"in\" become \"isin\"\r\n\r\nQUERY_RESPONSE_REFINE_PROMPT = (\r\n    \"We want to understand if the following query and response is\"\r\n    \"in line with the context information: \\n {query_str}\\n\"\r\n    \"We have provided an existing YES/NO answer: \\n {existing_answer}\\n\"\r\n    \"We have the opportunity to refine the existing answer \"\r\n    \"(only if needed) with some more context below.\\n\"\r\n    \"------------\\n\"\r\n    \"{context_msg}\\n\"\r\n    \"------------\\n\"\r\n    \"If the existing answer was already YES, still answer YES. \"\r\n    \"If the information is present in the new context, answer YES. \"\r\n    \"Otherwise answer NO.\\n\"\r\n)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3422/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3422/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3420",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3420/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3420/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3420/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3420",
        "id": 1713204828,
        "node_id": "PR_kwDOIWuq585QrXeg",
        "number": 3420,
        "title": "fix gatsby notebook, add 10k notebook",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-17T06:21:02Z",
        "updated_at": "2023-05-17T06:28:40Z",
        "closed_at": "2023-05-17T06:28:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3420",
            "html_url": "https://github.com/run-llama/llama_index/pull/3420",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3420.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3420.patch",
            "merged_at": "2023-05-17T06:28:39Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3420/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3420/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3419",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3419/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3419/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3419/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3419",
        "id": 1713155109,
        "node_id": "PR_kwDOIWuq585QrMx_",
        "number": 3419,
        "title": "Sub question query engine",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-17T05:34:15Z",
        "updated_at": "2023-05-18T19:53:44Z",
        "closed_at": "2023-05-18T19:53:43Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3419",
            "html_url": "https://github.com/run-llama/llama_index/pull/3419",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3419.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3419.patch",
            "merged_at": "2023-05-18T19:53:43Z"
        },
        "body": "### Summary\r\n* New \"sub question\" query engine, that takes in K query engine tools, and generate M sub questions.\r\n* Sub questions are passed to query engines to execute, and all intermediate responses are gathered and sent to response synthesizer for final response. \r\n* Add notebooks, docs, etc ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3419/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3419/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3418",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3418/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3418/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3418/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3418",
        "id": 1713047360,
        "node_id": "PR_kwDOIWuq585Qq1Y5",
        "number": 3418,
        "title": "Fix EmbeddingRecencyPostProcessor Docstring",
        "user": {
            "login": "NirantK",
            "id": 3250749,
            "node_id": "MDQ6VXNlcjMyNTA3NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3250749?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NirantK",
            "html_url": "https://github.com/NirantK",
            "followers_url": "https://api.github.com/users/NirantK/followers",
            "following_url": "https://api.github.com/users/NirantK/following{/other_user}",
            "gists_url": "https://api.github.com/users/NirantK/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NirantK/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NirantK/subscriptions",
            "organizations_url": "https://api.github.com/users/NirantK/orgs",
            "repos_url": "https://api.github.com/users/NirantK/repos",
            "events_url": "https://api.github.com/users/NirantK/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NirantK/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-17T03:42:00Z",
        "updated_at": "2023-05-17T04:03:59Z",
        "closed_at": "2023-05-17T04:03:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3418",
            "html_url": "https://github.com/run-llama/llama_index/pull/3418",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3418.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3418.patch",
            "merged_at": "2023-05-17T04:03:58Z"
        },
        "body": "Added the relevant description reasoning to the PostProcessor",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3418/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3418/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3417",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3417/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3417/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3417/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3417",
        "id": 1712997060,
        "node_id": "PR_kwDOIWuq585QqrCf",
        "number": 3417,
        "title": "[WIP] Fix persisting multiple indexes",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-17T02:34:05Z",
        "updated_at": "2023-08-28T17:11:01Z",
        "closed_at": "2023-05-18T01:26:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": true,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3417",
            "html_url": "https://github.com/run-llama/llama_index/pull/3417",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3417.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3417.patch",
            "merged_at": null
        },
        "body": "This is an initial attempt to fix persisting graphs (and also persisting multiple indexes with the same storage context!)\r\n\r\nCurrently, there's no checking for duplicate documents in an index, so persisting multiple indexes to the same directory causes issues. However, this is exactly how a graph saves itself.\r\n\r\nThis PR uses the doc_hash as the doc_id. This way, duplicate documents are automatically not allowed, while also fixing how documents and vectors are shared between indexes.\r\n\r\nTODO:\r\n- [x] Initial POC\r\n- [ ] confirm this is the best approach\r\n- [ ] add fix to all vector stores?\r\n- [ ] fix tests\r\n- [ ] validate all indexes ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3417/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3417/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3393",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3393/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3393/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3393/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3393",
        "id": 1712667705,
        "node_id": "I_kwDOIWuq585mFTw5",
        "number": 3393,
        "title": "how to control the sequance length of the query_engine and make more than 256 ",
        "user": {
            "login": "rabeeqasem",
            "id": 44259257,
            "node_id": "MDQ6VXNlcjQ0MjU5MjU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/44259257?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rabeeqasem",
            "html_url": "https://github.com/rabeeqasem",
            "followers_url": "https://api.github.com/users/rabeeqasem/followers",
            "following_url": "https://api.github.com/users/rabeeqasem/following{/other_user}",
            "gists_url": "https://api.github.com/users/rabeeqasem/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rabeeqasem/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rabeeqasem/subscriptions",
            "organizations_url": "https://api.github.com/users/rabeeqasem/orgs",
            "repos_url": "https://api.github.com/users/rabeeqasem/repos",
            "events_url": "https://api.github.com/users/rabeeqasem/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rabeeqasem/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-16T20:05:02Z",
        "updated_at": "2023-05-18T03:34:33Z",
        "closed_at": "2023-05-18T03:34:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm currently trying the llama_index for the first time, and I'm using the following code. It works fine, but when I print the `print('length of it',len(answer.response))`, it always shows 256 or less. I would like to increase it. I tried changing the num_output and max_token values, but it didn't make any difference. How can I increase the response length?\r\n\r\n\r\n\r\n```python\r\ndef create_index(path):\r\n    max_input = 4096\r\n    num_output = 1000\r\n    chunk_size = 600  # for LLM, we need to define chunk size\r\n    max_chunk_overlap = 20\r\n\r\n    # define prompt\r\n    promptHelper = PromptHelper(max_input, num_output=num_output, max_chunk_overlap=max_chunk_overlap, chunk_size_limit=chunk_size)\r\n\r\n    # define LLM \u2014 there could be many models we can use, but in this example, let\u2019s go with OpenAI model\r\n    # llmPredictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-ada-001\",max_tokens=tokens))\r\n    llmPredictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_output))\r\n\r\n    # load data \u2014 it will take all the .txtx files, if there are more than 1\r\n    docs = SimpleDirectoryReader(path).load_data()\r\n\r\n    # create vector index\r\n    service_context = ServiceContext.from_defaults(llm_predictor=llmPredictor, prompt_helper=promptHelper)\r\n\r\n    vectorIndex = GPTVectorStoreIndex.from_documents(documents=docs, service_context=service_context)\r\n    vectorIndex.storage_context.persist(persist_dir='Store')\r\n\r\ncreate_index('text_files')\r\n\r\ndef answerMe(question):\r\n    storage_context = StorageContext.from_defaults(persist_dir='Store')\r\n    index = load_index_from_storage(storage_context)\r\n    query_engine = index.as_query_engine()\r\n    # response = query_engine.query(question)\r\n    response = query_engine.query(question)  # increase the length of the prompt\r\n\r\n    return response\r\n\r\npromt=\"some text\"\r\nact=\"some text\"\r\npromt=promt+act\r\nanswer=answerMe(promt)\r\n\r\nprint(promt)\r\nprint(answer.response)\r\nprint('length of it',len(answer.response))\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3393/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3393/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3392",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3392/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3392/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3392/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3392",
        "id": 1712636492,
        "node_id": "PR_kwDOIWuq585QpfDI",
        "number": 3392,
        "title": "[feature] Accumulator response builder",
        "user": {
            "login": "pocketcolin",
            "id": 47982430,
            "node_id": "MDQ6VXNlcjQ3OTgyNDMw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47982430?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pocketcolin",
            "html_url": "https://github.com/pocketcolin",
            "followers_url": "https://api.github.com/users/pocketcolin/followers",
            "following_url": "https://api.github.com/users/pocketcolin/following{/other_user}",
            "gists_url": "https://api.github.com/users/pocketcolin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pocketcolin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pocketcolin/subscriptions",
            "organizations_url": "https://api.github.com/users/pocketcolin/orgs",
            "repos_url": "https://api.github.com/users/pocketcolin/repos",
            "events_url": "https://api.github.com/users/pocketcolin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pocketcolin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-16T19:40:18Z",
        "updated_at": "2023-05-18T19:57:51Z",
        "closed_at": "2023-05-18T19:57:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3392",
            "html_url": "https://github.com/run-llama/llama_index/pull/3392",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3392.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3392.patch",
            "merged_at": "2023-05-18T19:57:51Z"
        },
        "body": "The current response builders don't offer a way to accumulate new responses from each chunk of text. Refine, for example, is meant for iterating over chunks and modifying the answer with each iteration until you end up with 1 answer. Being able to accumulate responses allows people (like me) to use a prompt like \"Summarize this text\" and generate multiple summaries, 1 for each chunk.\r\n\r\nExample:\r\n```\r\nquery_engine = RetrieverQueryEngine.from_args(\r\n    retriever=retriever,\r\n    service_context=service_context,\r\n    node_postprocessors=[\r\n        SimilarityPostprocessor(similarity_cutoff=0.7)\r\n    ],\r\n    text_qa_template=QA_PROMPT,\r\n    response_mode='accumulate'\r\n)\r\n```\r\n\r\n**NOTE:** This response builder does not work for streaming (and will fail with an error saying so if you try). In order to get streaming working, I think we'd have to make it possible for `get_response` to return an array of generators which would probably break other consumers? Happy to discuss solutions though.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3392/reactions",
            "total_count": 3,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 3,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3392/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3391",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3391/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3391/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3391/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3391",
        "id": 1712516824,
        "node_id": "I_kwDOIWuq585mEu7Y",
        "number": 3391,
        "title": "Repeating semantic search answer",
        "user": {
            "login": "nazkhan-8451",
            "id": 108809950,
            "node_id": "U_kgDOBnxO3g",
            "avatar_url": "https://avatars.githubusercontent.com/u/108809950?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nazkhan-8451",
            "html_url": "https://github.com/nazkhan-8451",
            "followers_url": "https://api.github.com/users/nazkhan-8451/followers",
            "following_url": "https://api.github.com/users/nazkhan-8451/following{/other_user}",
            "gists_url": "https://api.github.com/users/nazkhan-8451/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nazkhan-8451/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nazkhan-8451/subscriptions",
            "organizations_url": "https://api.github.com/users/nazkhan-8451/orgs",
            "repos_url": "https://api.github.com/users/nazkhan-8451/repos",
            "events_url": "https://api.github.com/users/nazkhan-8451/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nazkhan-8451/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-16T18:22:21Z",
        "updated_at": "2023-06-06T05:02:54Z",
        "closed_at": "2023-06-06T05:02:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Using text-ada-002 to embed a document. Then using text-davinci-003 to query the document. If i ask a question like `list 5 properties of iron from the document`, each time I get different properties. How can I fix the answer (or repeat the same answer) on every query?\r\n\r\nIs there any `args` that I can pass somewhere or use some prompt engineering?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3391/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3391/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3390",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3390/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3390/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3390/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3390",
        "id": 1712461379,
        "node_id": "I_kwDOIWuq585mEhZD",
        "number": 3390,
        "title": "Got a larger chunk overlap ({chunk_overlap}) than chunk size ({chunk_size}), should be smaller.",
        "user": {
            "login": "aerickson-clt",
            "id": 32244272,
            "node_id": "MDQ6VXNlcjMyMjQ0Mjcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/32244272?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aerickson-clt",
            "html_url": "https://github.com/aerickson-clt",
            "followers_url": "https://api.github.com/users/aerickson-clt/followers",
            "following_url": "https://api.github.com/users/aerickson-clt/following{/other_user}",
            "gists_url": "https://api.github.com/users/aerickson-clt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aerickson-clt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aerickson-clt/subscriptions",
            "organizations_url": "https://api.github.com/users/aerickson-clt/orgs",
            "repos_url": "https://api.github.com/users/aerickson-clt/repos",
            "events_url": "https://api.github.com/users/aerickson-clt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aerickson-clt/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-16T17:43:57Z",
        "updated_at": "2023-06-06T00:58:16Z",
        "closed_at": "2023-06-06T00:58:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "https://github.com/jerryjliu/llama_index/blob/a873f7dc467990c25b8676511888441bc4c339d7/llama_index/langchain_helpers/text_splitter.py#L39-L43\r\n\r\n~~This validation raises errors for short documents.~~  I'm still investigating why this comes up.  It seems to relate to splitting and compacting a prompt.\r\n\r\nThis seems to originate from Langchain's code.\r\n\r\n```\r\nFile C:...\\llama_index\\indices\\query\\base.py:20, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n18 if isinstance(str_or_query_bundle, str):\r\n19     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 20 return self._query(str_or_query_bundle)\r\n\r\n\r\nFile C:...\\llama_index\\query_engine\\retriever_query_engine.py:145, in RetrieverQueryEngine._query(self, query_bundle)\r\n140 self.callback_manager.on_event_end(\r\n141     CBEventType.RETRIEVE, payload={\"nodes\": nodes}, event_id=retrieve_id\r\n142 )\r\n144 synth_id = self.callback_manager.on_event_start(CBEventType.SYNTHESIZE)\r\n--> 145 response = self._response_synthesizer.synthesize(\r\n146     query_bundle=query_bundle,\r\n147     nodes=nodes,\r\n148 )\r\n149 self.callback_manager.on_event_end(\r\n150     CBEventType.SYNTHESIZE, payload={\"response\": response}, event_id=synth_id\r\n151 )\r\n153 self.callback_manager.on_event_end(CBEventType.QUERY, event_id=query_id)\r\n\r\n\r\nFile C:...\\llama_index\\indices\\query\\response_synthesis.py:163, in ResponseSynthesizer.synthesize(self, query_bundle, nodes, additional_source_nodes)\r\n161 if self._response_mode != ResponseMode.NO_TEXT:\r\n162     assert self._response_builder is not None\r\n--> 163     response_str = self._response_builder.get_response(\r\n164         query_str=query_bundle.query_str,\r\n165         text_chunks=text_chunks,\r\n166         **self._response_kwargs,\r\n167     )\r\n168 else:\r\n169     response_str = None\r\n\r\n\r\nFile C:...\\llama_index\\indices\\response\\response_builder.py:295, in CompactAndRefine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n289 with temp_set_attrs(\r\n290     self._service_context.prompt_helper, use_chunk_size_limit=False\r\n291 ):\r\n292     new_texts = self._service_context.prompt_helper.compact_text_chunks(\r\n293         max_prompt, text_chunks\r\n294     )\r\n--> 295     response = super().get_response(\r\n296         query_str=query_str, text_chunks=new_texts, prev_response=prev_response\r\n297     )\r\n298 return response\r\n\r\nFile C:...\\llama_index\\token_counter\\token_counter.py:78, in llm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict(_self, *args, **kwargs)\r\n76 def wrapped_llm_predict(_self: Any, *args: Any, **kwargs: Any) -> Any:\r\n77     with wrapper_logic(_self):\r\n---> 78         f_return_val = f(_self, *args, **kwargs)\r\n80     return f_return_val\r\n\r\n\r\nFile C:...\\llama_index\\indices\\response\\response_builder.py:139, in Refine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n134         response = self._give_response_single(\r\n135             query_str,\r\n136             text_chunk,\r\n137         )\r\n138     else:\r\n--> 139         response = self._refine_response_single(\r\n140             prev_response_obj, query_str, text_chunk\r\n141         )\r\n142     prev_response_obj = response\r\n143 if isinstance(response, str):\r\n\r\n\r\nFile C:...\\llama_index\\indices\\response\\response_builder.py:217, in Refine._refine_response_single(self, response, query_str, text_chunk, **response_kwargs)\r\n212 # NOTE: partial format refine template with query_str and existing_answer here\r\n213 refine_template = self._refine_template.partial_format(\r\n214     query_str=query_str, existing_answer=response\r\n215 )\r\n216 refine_text_splitter = (\r\n--> 217     self._service_context.prompt_helper.get_text_splitter_given_prompt(\r\n218         refine_template, 1\r\n219     )\r\n220 )\r\n222 text_chunks = refine_text_splitter.split_text(text_chunk)\r\n224 for cur_text_chunk in text_chunks:\r\n\r\n\r\nFile C:...\\llama_index\\indices\\prompt_helper.py:162, in PromptHelper.get_text_splitter_given_prompt(self, prompt, num_chunks, padding)\r\n158 empty_prompt_txt = self._get_empty_prompt_txt(prompt)\r\n159 chunk_size = self.get_chunk_size_given_prompt(\r\n160     empty_prompt_txt, num_chunks, padding=padding\r\n161 )\r\n--> 162 text_splitter = TokenTextSplitter(\r\n163     separator=self._separator,\r\n164     chunk_size=chunk_size,\r\n165     chunk_overlap=self.max_chunk_overlap // num_chunks,\r\n166     tokenizer=self._tokenizer,\r\n167 )\r\n168 return text_splitter\r\n\r\n\r\nFile C:...\\llama_index\\langchain_helpers\\text_splitter.py:40, in TokenTextSplitter.init(self, separator, chunk_size, chunk_overlap, tokenizer, backup_separators, callback_manager)\r\n38 \"\"\"Initialize with parameters.\"\"\"\r\n39 if chunk_overlap > chunk_size:\r\n---> 40     raise ValueError(\r\n41         f\"Got a larger chunk overlap ({chunk_overlap}) than chunk size \"\r\n42         f\"({chunk_size}), should be smaller.\"\r\n43     )\r\n44 self._separator = separator\r\n45 self._chunk_size = chunk_size\r\n\r\n\r\nValueError: Got a larger chunk overlap (20) than chunk size (16), should be smaller.\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3390/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3390/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3389",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3389/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3389/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3389/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3389",
        "id": 1712362929,
        "node_id": "I_kwDOIWuq585mEJWx",
        "number": 3389,
        "title": "Passing service context results in broken responses",
        "user": {
            "login": "rishi-dhar",
            "id": 23067036,
            "node_id": "MDQ6VXNlcjIzMDY3MDM2",
            "avatar_url": "https://avatars.githubusercontent.com/u/23067036?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rishi-dhar",
            "html_url": "https://github.com/rishi-dhar",
            "followers_url": "https://api.github.com/users/rishi-dhar/followers",
            "following_url": "https://api.github.com/users/rishi-dhar/following{/other_user}",
            "gists_url": "https://api.github.com/users/rishi-dhar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rishi-dhar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rishi-dhar/subscriptions",
            "organizations_url": "https://api.github.com/users/rishi-dhar/orgs",
            "repos_url": "https://api.github.com/users/rishi-dhar/repos",
            "events_url": "https://api.github.com/users/rishi-dhar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rishi-dhar/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-16T16:36:20Z",
        "updated_at": "2023-09-10T16:59:14Z",
        "closed_at": "2023-09-10T16:59:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Running across an interesting issue, passing service context during storage context initialization or during index.as_query_engine() calls results in query responses being broken. Getting a large string as a response with `answer answer answer answer` (see screenshot).\r\n\r\nRemoving the service context fixes the answer but then we are not able to predict the # of tokens used for each query.\r\n\r\n![image](https://github.com/jerryjliu/llama_index/assets/23067036/46e52a3a-665d-43fa-8819-79e4f8bfd3ed)\r\n\r\nCode for context\r\n```\r\nmax_input_size, num_output, max_chunk_overlap = 1024, 256, 20\r\nprompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\r\nllm_predictor = MockLLMPredictor(\r\n            llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\r\n        )\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm_predictor=llm_predictor,\r\n    prompt_helper=prompt_helper,\r\n    chunk_size_limit=1024,\r\n)\r\n\r\n# build storage context\r\nstorage_context = StorageContext.from_defaults()\r\ntry:\r\n    # Attempt to read index from local storage (in storage directory)\r\n    index = load_index_from_storage(\r\n        storage_context, service_context=service_context\r\n    )\r\n    print(\"Loaded index from disk\")\r\nexcept ValueError:\r\n    # If read from local storage fails - read from `data` folder\r\n    documents = self.load_files()\r\n    index = GPTVectorStoreIndex.from_documents(\r\n        documents, service_context=service_context\r\n    )\r\n    index.storage_context.persist()\r\n\r\nreturn llm_predictor, index.as_query_engine(service_context=service_context)\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3389/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3389/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3388",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3388/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3388/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3388/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3388",
        "id": 1711776873,
        "node_id": "I_kwDOIWuq585mB6Rp",
        "number": 3388,
        "title": "How to get streamed response from Llama_index on Flask Based Html Page like chatgpt streamed response ",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-16T10:57:50Z",
        "updated_at": "2023-05-17T03:03:06Z",
        "closed_at": "2023-05-16T14:26:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\n# Flask App Code\r\napp = Flask(__name__)\r\n\r\n@app.route('/')\r\ndef home():\r\n    return render_template('index.html')\r\n\r\n@app.route('/query', methods=['POST'])\r\ndef query():\r\n    query_engine = index.as_query_engine(similarity_top_k=3, streaming=True)\r\n    prompt = request.form['prompt']\r\n    prompt += \" Give in html format\"\r\n    print('prompt given issss:',prompt)\r\n    response_stream = query_engine.query(prompt)\r\n    response = response_stream.print_response_stream()\r\n    \r\n    return render_template('index.html', prompt=prompt,response = response_stream)\r\n    \r\n    \r\n    Here is the code for index.html \r\n    \r\n    <body>\r\n    <div class=\"container\">\r\n        <h1><Center>Documents Based QA Bot</Center></h1>\r\n        <form id=\"queryForm\" action=\"/query\" method=\"post\">\r\n            <label for=\"prompt\" >Enter a prompt:</label>\r\n            <input type=\"text\" id=\"prompt\" name=\"prompt\">\r\n            <input type=\"submit\" value=\"Submit\">\r\n        </form>\r\n        <div id=\"result\">\r\n            {% if prompt %}\r\n            <h2>Recent Prompt:</h2>\r\n            <p>{{ prompt }}</p>\r\n            {% endif %}\r\n            {% if response %}\r\n            <h2>Response:</h2>\r\n            <p>{{ response|safe }}</p>\r\n            {% endif %}\r\n        </div>\r\n    </div>\r\n    <div class=\"loader\" id=\"loader\"></div>\r\n\r\n    <script>\r\n        const form = document.getElementById('queryForm');\r\n        const loader = document.getElementById('loader');\r\n        const resultDiv = document.getElementById('result');\r\n\r\n        form.addEventListener('submit', function() {\r\n            loader.style.display = 'block';\r\n            resultDiv.style.display = 'none';\r\n        });\r\n\r\n        // If there's a response, hide the loader\r\n        // {% if response %}\r\n        // loader.style.display = 'none';\r\n        // {% endif %}\r\n    </script>\r\n</body>\r\n</html>\r\n    ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3388/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3388/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3387",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3387/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3387/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3387/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3387",
        "id": 1711721857,
        "node_id": "I_kwDOIWuq585mBs2B",
        "number": 3387,
        "title": "HuggingFaceLLMPredictor not found ",
        "user": {
            "login": "DSOBoy",
            "id": 133762639,
            "node_id": "U_kgDOB_kOTw",
            "avatar_url": "https://avatars.githubusercontent.com/u/133762639?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DSOBoy",
            "html_url": "https://github.com/DSOBoy",
            "followers_url": "https://api.github.com/users/DSOBoy/followers",
            "following_url": "https://api.github.com/users/DSOBoy/following{/other_user}",
            "gists_url": "https://api.github.com/users/DSOBoy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DSOBoy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DSOBoy/subscriptions",
            "organizations_url": "https://api.github.com/users/DSOBoy/orgs",
            "repos_url": "https://api.github.com/users/DSOBoy/repos",
            "events_url": "https://api.github.com/users/DSOBoy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DSOBoy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-16T10:23:41Z",
        "updated_at": "2023-07-18T13:24:09Z",
        "closed_at": "2023-05-17T08:56:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello,\r\n\r\nI am attempting to use the StableLM model through hugging face as a custom LLM model but have been unable to import the module 'from llama_index.llm_predictor import HuggingFaceLLMPredictor'. \r\n\r\nThe error message is below. I have updated the package and the HuggingFaceLLMPredictor is not in the files.\r\n\r\nImportError: cannot import name 'HuggingFaceLLMPredictor' from 'llama_index.llm_predictor' (C:\\Users\\DSOBoy\\AppData\\Local\\anaconda3\\lib\\site-packages\\llama_index\\llm_predictor\\__init__.py)\r\n\r\nAny help finding a work around for this would be greatly appreciated. Thank you.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3387/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3387/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3384",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3384/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3384/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3384/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3384",
        "id": 1711553778,
        "node_id": "I_kwDOIWuq585mBDzy",
        "number": 3384,
        "title": "How to improve the server request response speed of azure openai?",
        "user": {
            "login": "Bruce337f",
            "id": 127927670,
            "node_id": "U_kgDOB6AFdg",
            "avatar_url": "https://avatars.githubusercontent.com/u/127927670?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Bruce337f",
            "html_url": "https://github.com/Bruce337f",
            "followers_url": "https://api.github.com/users/Bruce337f/followers",
            "following_url": "https://api.github.com/users/Bruce337f/following{/other_user}",
            "gists_url": "https://api.github.com/users/Bruce337f/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Bruce337f/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Bruce337f/subscriptions",
            "organizations_url": "https://api.github.com/users/Bruce337f/orgs",
            "repos_url": "https://api.github.com/users/Bruce337f/repos",
            "events_url": "https://api.github.com/users/Bruce337f/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Bruce337f/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-05-16T08:47:54Z",
        "updated_at": "2023-09-10T16:59:20Z",
        "closed_at": "2023-09-10T16:59:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "How to improve the server request response speed of azure openai, the average access time is more than 1 minute each time, even if chunk_szie=256 is set, the speed is relatively slow?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3384/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3384/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3383",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3383/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3383/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3383/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3383",
        "id": 1711394490,
        "node_id": "I_kwDOIWuq585mAc66",
        "number": 3383,
        "title": "Performance issues with indexing between 0.5 and 0.6",
        "user": {
            "login": "DaytimeAH",
            "id": 12272195,
            "node_id": "MDQ6VXNlcjEyMjcyMTk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12272195?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DaytimeAH",
            "html_url": "https://github.com/DaytimeAH",
            "followers_url": "https://api.github.com/users/DaytimeAH/followers",
            "following_url": "https://api.github.com/users/DaytimeAH/following{/other_user}",
            "gists_url": "https://api.github.com/users/DaytimeAH/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DaytimeAH/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DaytimeAH/subscriptions",
            "organizations_url": "https://api.github.com/users/DaytimeAH/orgs",
            "repos_url": "https://api.github.com/users/DaytimeAH/repos",
            "events_url": "https://api.github.com/users/DaytimeAH/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DaytimeAH/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-16T07:10:41Z",
        "updated_at": "2023-07-22T02:48:28Z",
        "closed_at": "2023-07-22T02:48:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi,\r\nI use the same service_context and documents (~5MB json files) for indexing. It took about 5 minutes on version 0.5, but it took an hour on version 0.6. I'm migrating my code from 0.5 to 0.6 and very confused. Any advice is greatly appreciated. \r\n0.5.26\r\nindex = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\r\n0.6.8\r\nindex = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3383/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3383/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3382",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3382/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3382/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3382/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3382",
        "id": 1711239646,
        "node_id": "PR_kwDOIWuq585QkwAT",
        "number": 3382,
        "title": "Save index summary",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-16T05:02:34Z",
        "updated_at": "2023-08-28T17:10:38Z",
        "closed_at": "2023-05-16T16:07:27Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3382",
            "html_url": "https://github.com/run-llama/llama_index/pull/3382",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3382.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3382.patch",
            "merged_at": "2023-05-16T16:07:27Z"
        },
        "body": "The summary of the index struct was not being properly persisted. People had been using this to store various things (tool descriptions, graph summaries, etc.)\r\n\r\nThis PR fixes that py adding a dedicated property for the summary ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3382/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3382/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3381",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3381/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3381/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3381/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3381",
        "id": 1711204325,
        "node_id": "PR_kwDOIWuq585QkoeN",
        "number": 3381,
        "title": "[version] bump version to 0.6.8",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-16T04:12:43Z",
        "updated_at": "2023-05-16T04:16:04Z",
        "closed_at": "2023-05-16T04:16:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3381",
            "html_url": "https://github.com/run-llama/llama_index/pull/3381",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3381.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3381.patch",
            "merged_at": "2023-05-16T04:16:03Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3381/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3381/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3380",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3380/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3380/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3380/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3380",
        "id": 1711064080,
        "node_id": "I_kwDOIWuq585l_MQQ",
        "number": 3380,
        "title": "KeyError: \"Unknown task Context information is below.",
        "user": {
            "login": "vuvskp7",
            "id": 107998993,
            "node_id": "U_kgDOBm_vEQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/107998993?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vuvskp7",
            "html_url": "https://github.com/vuvskp7",
            "followers_url": "https://api.github.com/users/vuvskp7/followers",
            "following_url": "https://api.github.com/users/vuvskp7/following{/other_user}",
            "gists_url": "https://api.github.com/users/vuvskp7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vuvskp7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vuvskp7/subscriptions",
            "organizations_url": "https://api.github.com/users/vuvskp7/orgs",
            "repos_url": "https://api.github.com/users/vuvskp7/repos",
            "events_url": "https://api.github.com/users/vuvskp7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vuvskp7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-16T01:28:08Z",
        "updated_at": "2023-10-07T10:03:50Z",
        "closed_at": "2023-07-22T18:58:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "query_engine = new_index.as_query_engine()\r\nresponse = query_engine.query(\"What did the author do in 9th grade?\")\r\n\r\nprint(response)\r\n\r\n\r\n\u2502 /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1184 in check_task        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   1181 \u2502   \u2502   \u2502   \u2502   return task, targeted_task, (tokens[1], tokens[3])                        \u2502\r\n\u2502   1182 \u2502   \u2502   \u2502   raise KeyError(f\"Invalid translation task {task}, use 'translation_XX_to_YY'  \u2502\r\n\u2502   1183 \u2502   \u2502                                                                                     \u2502\r\n\u2502 \u2771 1184 \u2502   \u2502   raise KeyError(                                                                   \u2502\r\n\u2502   1185 \u2502   \u2502   \u2502   f\"Unknown task {task}, available tasks are {self.get_supported_tasks() + ['t  \u2502\r\n\u2502   1186 \u2502   \u2502   )                                                                                 \u2502\r\n\u2502   1187             ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3380/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3380/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3379",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3379/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3379/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3379/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3379",
        "id": 1710978988,
        "node_id": "PR_kwDOIWuq585Qj4xh",
        "number": 3379,
        "title": "Add S3 KV store",
        "user": {
            "login": "sourabhdesai",
            "id": 3005241,
            "node_id": "MDQ6VXNlcjMwMDUyNDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3005241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sourabhdesai",
            "html_url": "https://github.com/sourabhdesai",
            "followers_url": "https://api.github.com/users/sourabhdesai/followers",
            "following_url": "https://api.github.com/users/sourabhdesai/following{/other_user}",
            "gists_url": "https://api.github.com/users/sourabhdesai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sourabhdesai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sourabhdesai/subscriptions",
            "organizations_url": "https://api.github.com/users/sourabhdesai/orgs",
            "repos_url": "https://api.github.com/users/sourabhdesai/repos",
            "events_url": "https://api.github.com/users/sourabhdesai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sourabhdesai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-15T23:21:47Z",
        "updated_at": "2023-05-18T00:28:50Z",
        "closed_at": "2023-05-17T19:37:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3379",
            "html_url": "https://github.com/run-llama/llama_index/pull/3379",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3379.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3379.patch",
            "merged_at": "2023-05-17T19:37:30Z"
        },
        "body": "Implementation of a S3-backed KV store for document/index persistence. Since S3 is a commonly used and easy-to-setup data storage layer, I thought this may be a useful addition the project.\r\n\r\nI used [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) for the S3 interactions & am using [moto](https://docs.getmoto.org/en/latest/index.html) to mock those interactions in unit tests.\r\n\r\nThe current storage scheme is geared towards optimizing for `get()` of an individual key-value pair rather than `get_all()` for retrieving all key-value pairs within a collection.\r\n\r\nThe storage scheme stores all KV pairs within a specified S3 bucket and an optionally supplied subdirectory path within that bucket.\r\n\r\nThe KV pair data is separated into subfolders by `collection` name where each subfolder's name is the `collection` name.\r\nWithin a given `collection`s subfolder, you would find one JSON file for each individual KV pair. The `key` is stored as JSON files filename i.e. `{key}.json`. The contents of the JSON file is the serialized value dict.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3379/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3379/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3378",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3378/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3378/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3378/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3378",
        "id": 1710893236,
        "node_id": "PR_kwDOIWuq585Qjmr7",
        "number": 3378,
        "title": "Milvus load and guide fix",
        "user": {
            "login": "filip-halt",
            "id": 81822489,
            "node_id": "MDQ6VXNlcjgxODIyNDg5",
            "avatar_url": "https://avatars.githubusercontent.com/u/81822489?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/filip-halt",
            "html_url": "https://github.com/filip-halt",
            "followers_url": "https://api.github.com/users/filip-halt/followers",
            "following_url": "https://api.github.com/users/filip-halt/following{/other_user}",
            "gists_url": "https://api.github.com/users/filip-halt/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/filip-halt/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/filip-halt/subscriptions",
            "organizations_url": "https://api.github.com/users/filip-halt/orgs",
            "repos_url": "https://api.github.com/users/filip-halt/repos",
            "events_url": "https://api.github.com/users/filip-halt/events{/privacy}",
            "received_events_url": "https://api.github.com/users/filip-halt/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-15T21:52:46Z",
        "updated_at": "2023-05-15T23:14:49Z",
        "closed_at": "2023-05-15T23:14:49Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3378",
            "html_url": "https://github.com/run-llama/llama_index/pull/3378",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3378.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3378.patch",
            "merged_at": "2023-05-15T23:14:49Z"
        },
        "body": "Fixing up the Milvus loading steps and the guide for using GPTVectorStoreIndex.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3378/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3378/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3377",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3377/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3377/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3377/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3377",
        "id": 1710772438,
        "node_id": "PR_kwDOIWuq585QjMo7",
        "number": 3377,
        "title": "[feature] Add W&B Instrumentation",
        "user": {
            "login": "ayulockin",
            "id": 31141479,
            "node_id": "MDQ6VXNlcjMxMTQxNDc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/31141479?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ayulockin",
            "html_url": "https://github.com/ayulockin",
            "followers_url": "https://api.github.com/users/ayulockin/followers",
            "following_url": "https://api.github.com/users/ayulockin/following{/other_user}",
            "gists_url": "https://api.github.com/users/ayulockin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ayulockin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ayulockin/subscriptions",
            "organizations_url": "https://api.github.com/users/ayulockin/orgs",
            "repos_url": "https://api.github.com/users/ayulockin/repos",
            "events_url": "https://api.github.com/users/ayulockin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ayulockin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-05-15T20:23:10Z",
        "updated_at": "2023-06-07T07:42:35Z",
        "closed_at": "2023-06-07T07:42:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3377",
            "html_url": "https://github.com/run-llama/llama_index/pull/3377",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3377.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3377.patch",
            "merged_at": "2023-06-07T07:42:35Z"
        },
        "body": "This PR leverages a newly added callback tracer #3835 by @logan-markewich and  [Weights and Biases Prompts](https://docs.wandb.ai/guides/prompts) to try and build a powerful visualization/tracker for LlamaIndex \"event\" like Query, Retrieval, Node Parsing, etc.\r\n\r\nHere's a minimal usage of the callback:\r\n\r\n```\r\nllama_debug = LlamaDebugHandler(print_trace_on_end=True)\r\n\r\n# wandb.init args\r\nrun_args = dict(\r\n    project=\"llamaindex-demo\",\r\n)\r\n\r\nwandb_callback = WandbCallbackHandler(run_args=run_args)\r\n\r\ncallback_manager = CallbackManager([llama_debug, wandb_callback])\r\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager, llm_predictor=llm_predictor)\r\n```\r\n\r\nYou can check out the added `docs/examples/callbacks/WandbCallbackHandler.ipynb` for an example demo.\r\n\r\nThe trace timeline will be logged to the created W&B url. (Check out the example [run page](https://wandb.ai/ayut/llamaindex-demo/runs/an4z3ut9?workspace=user-ayut))\r\n\r\n<img width=\"1613\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/31141479/70e952c8-9d13-4898-bd77-e394741196e0\">\r\n\r\n### TODOs\r\n\r\n- [x] ~add token count logging~\r\n- [x] LLM span minor improvement \r\n- [x] add this PR here #3367 \r\n- [x] allow user to control the artifact storage dir\r\n- [x] remove a debugging variable artifact_dir\r\n- [x] rename `download_index` to `load_storage_context`\r\n- [x] Parse `response` from `Response/StreamingResponse` (P0)\r\n- [x] Try to parse prompt template (P1)\r\n- [x] Fix builds (P0)\r\n- [x] Add docstings (P1)\r\n- [x] Add explanatory text to the demo notebook (P1)\r\n- [ ] ~Fix index construction trace logging (I think I have a solution now) (P0)~ will be fixed in a separate PR",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3377/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 2,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3377/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3376",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3376/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3376/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3376/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3376",
        "id": 1710543830,
        "node_id": "I_kwDOIWuq585l9NPW",
        "number": 3376,
        "title": "Do I understand correctly how embedding tips for chat works?",
        "user": {
            "login": "IvanPigarev",
            "id": 97641648,
            "node_id": "U_kgDOBdHksA",
            "avatar_url": "https://avatars.githubusercontent.com/u/97641648?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IvanPigarev",
            "html_url": "https://github.com/IvanPigarev",
            "followers_url": "https://api.github.com/users/IvanPigarev/followers",
            "following_url": "https://api.github.com/users/IvanPigarev/following{/other_user}",
            "gists_url": "https://api.github.com/users/IvanPigarev/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IvanPigarev/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IvanPigarev/subscriptions",
            "organizations_url": "https://api.github.com/users/IvanPigarev/orgs",
            "repos_url": "https://api.github.com/users/IvanPigarev/repos",
            "events_url": "https://api.github.com/users/IvanPigarev/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IvanPigarev/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-15T17:50:27Z",
        "updated_at": "2023-05-15T19:44:24Z",
        "closed_at": "2023-05-15T18:08:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I need to build an index on the basis of a pdf document (and it worked) and then make a query to the index and after getting the necessary context from it, make a query to OpenAI...\r\n\r\nIt turns out that first there is a query through Llama Index, and then another query through OpenAI? Can't this be done in one query through Llama Index?\r\n\r\nimport openai\r\nimport os\r\n\r\nos.environ[\"OPENAI_API_KEY\"] = \"my_openai_api_key\"\r\nos.environ[\"INDEX_DIR\"] = \"tmp\"\r\n\r\nfrom llama_index import StorageContext, GPTVectorStoreIndex, SimpleDirectoryReader, load_index_from_storage\r\n\r\nstorage_context = StorageContext.from_defaults(persist_dir=os.environ[\"INDEX_DIR\"])\r\nindex = load_index_from_storage(storage_context)\r\n\r\nquery_engine = index.as_query_engine()\r\nquery = \"My query?\"\r\nresponse = query_engine.query(query)\r\n\r\nopenai.api_key = \"my_openai_api_key\"\r\n\r\nprompt = 'Context: '+response.response+query\r\n\r\nresponse = openai.Completion.create(\r\n    engine=\"text-davinci-003\", \r\n    prompt=prompt,\r\n    max_tokens=1500, \r\n    n=1, \r\n    stop=None,\r\n    temperature=0.1,\r\n    top_p=1,\r\n    frequency_penalty=0,\r\n    presence_penalty=0,\r\n)\r\n\r\nanswer = response.choices[0].text.strip()\r\nprint('Answer: '+answer)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3376/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3376/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3375",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3375/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3375/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3375/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3375",
        "id": 1710518697,
        "node_id": "PR_kwDOIWuq585QiVUj",
        "number": 3375,
        "title": "Query Index with SVM causes value error when similarity_top_k > 1",
        "user": {
            "login": "davidkelly",
            "id": 1072532,
            "node_id": "MDQ6VXNlcjEwNzI1MzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1072532?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/davidkelly",
            "html_url": "https://github.com/davidkelly",
            "followers_url": "https://api.github.com/users/davidkelly/followers",
            "following_url": "https://api.github.com/users/davidkelly/following{/other_user}",
            "gists_url": "https://api.github.com/users/davidkelly/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/davidkelly/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/davidkelly/subscriptions",
            "organizations_url": "https://api.github.com/users/davidkelly/orgs",
            "repos_url": "https://api.github.com/users/davidkelly/repos",
            "events_url": "https://api.github.com/users/davidkelly/events{/privacy}",
            "received_events_url": "https://api.github.com/users/davidkelly/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-15T17:31:00Z",
        "updated_at": "2023-05-15T19:19:44Z",
        "closed_at": "2023-05-15T19:19:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3375",
            "html_url": "https://github.com/run-llama/llama_index/pull/3375",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3375.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3375.patch",
            "merged_at": "2023-05-15T19:19:44Z"
        },
        "body": "Since the similarities is a numpy array when using svm, rather than an Optional[list(float)], we need to be a bit more careful when looking at whether or not we have similarities in the result.\r\n\r\nThis attempts to address #1288 - in the simplest way I could.  \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3375/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3375/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3374",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3374/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3374/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3374/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3374",
        "id": 1710426042,
        "node_id": "I_kwDOIWuq585l8we6",
        "number": 3374,
        "title": "Newer versions throw error \"TypeError: 'method' object is not iterable\" on query_engine.query()",
        "user": {
            "login": "rajphaniraj",
            "id": 23645020,
            "node_id": "MDQ6VXNlcjIzNjQ1MDIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/23645020?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rajphaniraj",
            "html_url": "https://github.com/rajphaniraj",
            "followers_url": "https://api.github.com/users/rajphaniraj/followers",
            "following_url": "https://api.github.com/users/rajphaniraj/following{/other_user}",
            "gists_url": "https://api.github.com/users/rajphaniraj/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rajphaniraj/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rajphaniraj/subscriptions",
            "organizations_url": "https://api.github.com/users/rajphaniraj/orgs",
            "repos_url": "https://api.github.com/users/rajphaniraj/repos",
            "events_url": "https://api.github.com/users/rajphaniraj/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rajphaniraj/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 13,
        "created_at": "2023-05-15T16:24:24Z",
        "updated_at": "2023-07-30T05:46:50Z",
        "closed_at": "2023-06-05T12:53:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm using a custom LLM with code based on\r\nhttps://github.com/amrrs/LLM-QA-Bot/blob/main/LLM_Q%26A_with_Open_Source_Hugging_Face_Models.ipynb\r\n\r\nWith older versions of llama_index and langchain  (0.5.27 and  0.0.142) the code works correctly, as in the line\r\nresponse = index.query( \"What's the cost of Whisper model?\")  in cell 13\r\n\r\nWith newer versions of llama_index and langchain (0.6.7 and  0.0.169), and the code changed to use the newer syntax\r\n\r\nquery_engine = index.as_query_engine(service_context=service_context)\r\nresponse = query_engine.query( \"What's the cost of Whisper model?\") \r\n\r\nI get the error TypeError: 'method' object is not iterable, on line 145 of RetrieverQueryEngine, which is listed below\r\n\r\nresponse = self._response_synthesizer.synthesize(\r\n    query_bundle=query_bundle,\r\n    nodes=nodes,)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3374/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3374/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3373",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3373/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3373/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3373/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3373",
        "id": 1710266359,
        "node_id": "PR_kwDOIWuq585QheXU",
        "number": 3373,
        "title": "update tutorials with local models ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-05-15T14:52:08Z",
        "updated_at": "2023-05-15T14:57:54Z",
        "closed_at": "2023-05-15T14:57:53Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3373",
            "html_url": "https://github.com/run-llama/llama_index/pull/3373",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3373.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3373.patch",
            "merged_at": "2023-05-15T14:57:53Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3373/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3373/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3372",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3372/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3372/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3372/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3372",
        "id": 1710244712,
        "node_id": "I_kwDOIWuq585l8ENo",
        "number": 3372,
        "title": "Must provide engine or deployment_id Azure and v0.6.5",
        "user": {
            "login": "GuillaumeTurcotte",
            "id": 78774,
            "node_id": "MDQ6VXNlcjc4Nzc0",
            "avatar_url": "https://avatars.githubusercontent.com/u/78774?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GuillaumeTurcotte",
            "html_url": "https://github.com/GuillaumeTurcotte",
            "followers_url": "https://api.github.com/users/GuillaumeTurcotte/followers",
            "following_url": "https://api.github.com/users/GuillaumeTurcotte/following{/other_user}",
            "gists_url": "https://api.github.com/users/GuillaumeTurcotte/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GuillaumeTurcotte/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GuillaumeTurcotte/subscriptions",
            "organizations_url": "https://api.github.com/users/GuillaumeTurcotte/orgs",
            "repos_url": "https://api.github.com/users/GuillaumeTurcotte/repos",
            "events_url": "https://api.github.com/users/GuillaumeTurcotte/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GuillaumeTurcotte/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-05-15T14:39:23Z",
        "updated_at": "2023-05-19T13:21:20Z",
        "closed_at": "2023-05-19T13:21:20Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Similar to [this issue](https://github.com/jerryjliu/llama_index/issues/3264) however none of the solutions seem to work for me.\r\n\r\nI am using these versions:\r\n\r\n```txt\r\nopenai==0.27.6\r\nlangchain==0.0.169\r\nllama-index==0.6.5\r\n```\r\n\r\nI am getting a `openai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>` error while performing a search, this code is working fine if I roll back to `v0.6.0` of `llama_index`. Nothing else seems to affect it otherwise. \r\n\r\n```python\r\nopenai.api_type    = os.environ[\"OPENAI_API_TYPE\"]    = 'azure'\r\nopenai.api_base    = os.environ[\"OPENAI_API_BASE\"]    = azure_openai_uri\r\nopenai.api_key     = os.environ[\"OPENAI_API_KEY\"]     = client.get_secret(\"AzureOpenAIKey\").value\r\nopenai.api_version = os.environ[\"OPENAI_API_VERSION\"] = openai_api_version\r\n\r\ndef _get_service_context(temperature: float = 0.7) -> \"ServiceContext\":\r\n    # Define prompt helper\r\n    max_input_size = 4096\r\n    num_output = 256 #hard limit\r\n    chunk_size_limit = 1000 # token window size per document\r\n    max_chunk_overlap = 20 # overlap for each token fragment\r\n\r\n    # using same dep as model name because of an older bug in langchains lib (now fixed I believe)\r\n    llm = AzureChatOpenAI(deployment_name=deployment_name, \r\n                            temperature=temperature,)\r\n    llm_predictor = LLMPredictor(llm=llm,)\r\n\r\n    prompt_helper = PromptHelper(max_input_size=max_input_size, num_output=num_output, max_chunk_overlap=max_chunk_overlap, chunk_size_limit=chunk_size_limit)\r\n\r\n    # limit is chunk size 1 atm\r\n    embedding_llm = LangchainEmbedding(\r\n        OpenAIEmbeddings(\r\n            deployment=\"text-embedding-ada-002\", \r\n            chunk_size=1, \r\n            openai_api_key= openai.api_key,\r\n            openai_api_base=openai.api_base,\r\n            openai_api_type=openai.api_type,\r\n            openai_api_version=\"2022-12-01\",\r\n            ), \r\n        embed_batch_size=1)\r\n\r\n    llama_logger = LlamaLogger()\r\n\r\n    return ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper, embed_model=embedding_llm, llama_logger=llama_logger)\r\n```\r\n\r\nI tried playing with the `OpenAIEmbeddings` params (`model`, `deployment` and `openai_api_version`) to no avail. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3372/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3372/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3371",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3371/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3371/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3371/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3371",
        "id": 1710131411,
        "node_id": "I_kwDOIWuq585l7ojT",
        "number": 3371,
        "title": "Purpose of doc_id and ref_doc_id ",
        "user": {
            "login": "sudarshansivakumar",
            "id": 63507238,
            "node_id": "MDQ6VXNlcjYzNTA3MjM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/63507238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sudarshansivakumar",
            "html_url": "https://github.com/sudarshansivakumar",
            "followers_url": "https://api.github.com/users/sudarshansivakumar/followers",
            "following_url": "https://api.github.com/users/sudarshansivakumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/sudarshansivakumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sudarshansivakumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sudarshansivakumar/subscriptions",
            "organizations_url": "https://api.github.com/users/sudarshansivakumar/orgs",
            "repos_url": "https://api.github.com/users/sudarshansivakumar/repos",
            "events_url": "https://api.github.com/users/sudarshansivakumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sudarshansivakumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-15T13:41:52Z",
        "updated_at": "2023-06-11T06:42:04Z",
        "closed_at": "2023-06-11T06:42:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm not sure if there is a support forum where I can ask about this. But I am confused about why there is a separate doc_id and ref_doc_id property in Weaviate vector stores. Here's what I did  : \r\n* Created a list of Documents (List[Document]) which each have a doc_id property, generated through Python's uuid library. I assumed that this doc_id would be stored as the doc_id that every Weaviate data object is supposed to have. However, what I'm seeing is that the Weaviate doc_id property is generated through a separate process (reading the code it seems like it's using the UUID library too). The doc_id that is passed by the user is instead used in ref_doc_id. Is there a reason for this behaviour. \r\n\r\nBecause of this separation I'm not sure how exactly to maintain a mapping between each chunk and its doc_id. For instance after inserting 40 documents into a particular weaviate class I tried to insert another document which had a repeated ref_doc_id. This insert was allowed because Weaviate only checks for the doc_id being unique, and not the ref_doc_id too. \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3371/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3371/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3370",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3370/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3370/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3370/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3370",
        "id": 1710022428,
        "node_id": "I_kwDOIWuq585l7N8c",
        "number": 3370,
        "title": "Custom properties in Weaviate insert",
        "user": {
            "login": "sudarshansivakumar",
            "id": 63507238,
            "node_id": "MDQ6VXNlcjYzNTA3MjM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/63507238?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sudarshansivakumar",
            "html_url": "https://github.com/sudarshansivakumar",
            "followers_url": "https://api.github.com/users/sudarshansivakumar/followers",
            "following_url": "https://api.github.com/users/sudarshansivakumar/following{/other_user}",
            "gists_url": "https://api.github.com/users/sudarshansivakumar/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sudarshansivakumar/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sudarshansivakumar/subscriptions",
            "organizations_url": "https://api.github.com/users/sudarshansivakumar/orgs",
            "repos_url": "https://api.github.com/users/sudarshansivakumar/repos",
            "events_url": "https://api.github.com/users/sudarshansivakumar/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sudarshansivakumar/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-15T12:43:56Z",
        "updated_at": "2023-06-11T06:44:05Z",
        "closed_at": "2023-06-11T06:44:05Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi I'm relatively new to using Llama Index, and just started playing around with it to perform inserts into a Weaviate vector store.  I really like the simple functionality of index.insert, index.refresh, etc. that allows me to update the vector store based on changes in the source document!\r\nWhile reading the documentation I understand that the Weaviate Node schema contains properties _doc_id, ref_doc_id,text,node_info,relationships_ \r\nHowever for my use case I would also like to insert some additional properties like \r\n* document_URL \r\n* document_title \r\n* chunk_number\r\n* last_updated_date\r\n.. etc.\r\nI do not see anything in the documentation that suggests this is possible, so I'm wondering if I'm missing something or if this is currently not supported ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3370/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3370/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3369",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3369/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3369/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3369/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3369",
        "id": 1709983483,
        "node_id": "I_kwDOIWuq585l7Eb7",
        "number": 3369,
        "title": "error in StorageContext methods 'from_dict' and 'to_dict' ",
        "user": {
            "login": "Ashish5869",
            "id": 131770947,
            "node_id": "U_kgDOB9qqQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/131770947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ashish5869",
            "html_url": "https://github.com/Ashish5869",
            "followers_url": "https://api.github.com/users/Ashish5869/followers",
            "following_url": "https://api.github.com/users/Ashish5869/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ashish5869/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ashish5869/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ashish5869/subscriptions",
            "organizations_url": "https://api.github.com/users/Ashish5869/orgs",
            "repos_url": "https://api.github.com/users/Ashish5869/repos",
            "events_url": "https://api.github.com/users/Ashish5869/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ashish5869/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-15T12:18:30Z",
        "updated_at": "2023-06-11T07:05:17Z",
        "closed_at": "2023-06-11T07:05:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "```\r\nfrom llama_index import StorageContextload_index_from_storage\r\nfrom llama_index.readers import WeaviateReader\r\nfrom llama_index.vector_stores import WeaviateVectorStore\r\n\r\ndocuments = SimpleDirectoryReader('test_doc').load_data()\r\n\r\nstorage_context = StorageContext.from_dict()\r\n```\r\nTypeError: StorageContext.from_dict() missing 1 required positional argument: 'save_dict'\r\n\r\n\r\ni want to use weaviate vector store.\r\n\r\n```\r\nstorage_context = StorageContext.from_dict(\r\n     vector_store=WeaviateVectorStore(weaviate_client=weaviate_client),\r\n)\r\n```\r\nThen i got an error \r\n`TypeError: StorageContext.from_dict() got an unexpected keyword argument 'vector_store'`\r\n\r\nIf i use 'from_defaults' instead of 'from_dict' and weaviate vector store and trying to save in dict by using to_dict(). Then  got value error\r\n\r\n```\r\nstorage_context = StorageContext.from_defaults(\r\n     vector_store=WeaviateVectorStore(weaviate_client=weaviate_client),\r\n)\r\n\r\nindex = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context,service_context=service_context)\r\nindex.storage_context.to_dict()\r\n\r\nValueError: to_dict only available when using simple doc/index/vector stores\r\n```\r\n\r\n**### In previous versions of llama_index, we have save_to_disk, save_to_dict and save_to_string and similarly load from methods. Do we have save and load indices methods except load index persist in new version?**\r\n\r\n\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3369/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3369/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3368",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3368/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3368/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3368/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3368",
        "id": 1709874176,
        "node_id": "I_kwDOIWuq585l6pwA",
        "number": 3368,
        "title": "LLM must support streaming and set streaming=True",
        "user": {
            "login": "vishalp-simplecrm",
            "id": 115548851,
            "node_id": "U_kgDOBuMisw",
            "avatar_url": "https://avatars.githubusercontent.com/u/115548851?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vishalp-simplecrm",
            "html_url": "https://github.com/vishalp-simplecrm",
            "followers_url": "https://api.github.com/users/vishalp-simplecrm/followers",
            "following_url": "https://api.github.com/users/vishalp-simplecrm/following{/other_user}",
            "gists_url": "https://api.github.com/users/vishalp-simplecrm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vishalp-simplecrm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vishalp-simplecrm/subscriptions",
            "organizations_url": "https://api.github.com/users/vishalp-simplecrm/orgs",
            "repos_url": "https://api.github.com/users/vishalp-simplecrm/repos",
            "events_url": "https://api.github.com/users/vishalp-simplecrm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vishalp-simplecrm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-05-15T11:15:49Z",
        "updated_at": "2023-06-16T04:57:06Z",
        "closed_at": "2023-06-06T05:46:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "# This is my code\r\n\r\nllm = ChatOpenAI(\r\n  temperature=0, \r\n  model_name=\"gpt-3.5-turbo\",\r\n  frequency_penalty = 0.5,\r\n  max_tokens=500,\r\n  streaming=True,\r\n)\r\nllm_predictor = LLMPredictor(llm=llm)\r\n\r\nprompt_helper = PromptHelper(\r\n    max_input_size = 3500, \r\n    num_output = 500, \r\n    max_chunk_overlap = 20, \r\n    chunk_size_limit = 700\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\r\n\r\ndocuments = SimpleDirectoryReader('./demoDoc/').load_data()\r\n\r\nindex = GPTVectorStoreIndex.from_documents(\r\n    documents, service_context=service_context )\r\n\r\nquery_engine = index.as_query_engine(similarity_top_k=3, streaming=True)\r\nprompt=input(\"ask here:\")\r\nresponse_stream = query_engine.query(prompt)\r\nresponse_stream.print_response_stream()\r\n\r\n# For the above code I am getting streamed output result as expected \r\n# but when I use to save the index and load it and  then pass the query It is showing error as \"LLM must support streaming and set streaming=True\"\r\n\r\ncode for storing the index and then loading the index and querying on the loaded index\r\n#persisting index\r\nindex.storage_context.persist('./storage/')\r\n\r\n### rebuild storage context\r\nstorage_context = StorageContext.from_defaults(persist_dir='./storage/')\r\n\r\n### load index\r\nindex = load_index_from_storage(storage_context)\r\n\r\n# Please help thanks in advance \r\n\r\n ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3368/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3368/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3367",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3367/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3367/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3367/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/3367",
        "id": 1709869561,
        "node_id": "PR_kwDOIWuq585QgHqy",
        "number": 3367,
        "title": "[feature] Expand `StorageContext`'s `persist` method to save the \"stores\" as W&B Artifact",
        "user": {
            "login": "ayulockin",
            "id": 31141479,
            "node_id": "MDQ6VXNlcjMxMTQxNDc5",
            "avatar_url": "https://avatars.githubusercontent.com/u/31141479?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ayulockin",
            "html_url": "https://github.com/ayulockin",
            "followers_url": "https://api.github.com/users/ayulockin/followers",
            "following_url": "https://api.github.com/users/ayulockin/following{/other_user}",
            "gists_url": "https://api.github.com/users/ayulockin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ayulockin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ayulockin/subscriptions",
            "organizations_url": "https://api.github.com/users/ayulockin/orgs",
            "repos_url": "https://api.github.com/users/ayulockin/repos",
            "events_url": "https://api.github.com/users/ayulockin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ayulockin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-15T11:12:50Z",
        "updated_at": "2023-06-02T10:47:41Z",
        "closed_at": "2023-06-02T10:47:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/3367",
            "html_url": "https://github.com/run-llama/llama_index/pull/3367",
            "diff_url": "https://github.com/run-llama/llama_index/pull/3367.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/3367.patch",
            "merged_at": null
        },
        "body": "The storage context's `persist` method can save the docstore, indexstore and vector store on disk. This however is not versioned properly and is hard to share with team members/community, etc.\r\n\r\nThis PR is an attempt to make it easy to version control the stores by using Weights and Biases [Artifacts](https://docs.wandb.ai/guides/artifacts).\r\n\r\nThe following code snippet can upload the stores to W&B:\r\n\r\n```\r\nimport wandb\r\nfrom llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\r\n\r\ndocuments = SimpleDirectoryReader(\"examples/paul_graham_essay/data\").load_data()\r\nindex = GPTVectorStoreIndex.from_documents(documents)\r\n\r\nrun = wandb.init(project=\"store_demo\")\r\nindex.storage_context.persist(log_to_wandb=True)\r\nwandb.finish()\r\n```\r\n<img width=\"1723\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/31141479/2f5bf988-0098-4f83-a4b8-018df7711467\">\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3367/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3367/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3366",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3366/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3366/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3366/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3366",
        "id": 1709864003,
        "node_id": "I_kwDOIWuq585l6nRD",
        "number": 3366,
        "title": "load_index_from_storage: response has no attribute print_response_stream  or response_gen",
        "user": {
            "login": "Ashish5869",
            "id": 131770947,
            "node_id": "U_kgDOB9qqQw",
            "avatar_url": "https://avatars.githubusercontent.com/u/131770947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ashish5869",
            "html_url": "https://github.com/Ashish5869",
            "followers_url": "https://api.github.com/users/Ashish5869/followers",
            "following_url": "https://api.github.com/users/Ashish5869/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ashish5869/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ashish5869/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ashish5869/subscriptions",
            "organizations_url": "https://api.github.com/users/Ashish5869/orgs",
            "repos_url": "https://api.github.com/users/Ashish5869/repos",
            "events_url": "https://api.github.com/users/Ashish5869/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ashish5869/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-05-15T11:09:21Z",
        "updated_at": "2023-06-02T08:28:37Z",
        "closed_at": "2023-05-17T04:47:27Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "After loading the indexed data from the storage it is not printing the streaming response. There is no attribute print_response_stream and response_gen.\r\n\r\n```\r\nllm_predictor = LLMPredictor(\r\n    llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", openai_api_key='openai_api_key', streaming=True))\r\nservice_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, llama_logger=llama_logger)\r\n\r\nvector_store = WeaviateVectorStore(weaviate_client=weaviate_client, class_prefix= 'Indexing')\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\nindex =GPTVectorStoreIndex.from_documents(documents,storage_context=storage_context,service_context=service_context)\r\nindex.storage_context.persist(persist_dir='index_test')\r\n\r\nstorage_context=StorageContext.from_defaults(vector_store=WeaviateVectorStore(weaviate_client=weaviate_client),persist_dir=\"index_test\")\r\nindex = load_index_from_storage(storage_context, service_context=service_context)\r\nquery_engine = index.as_query_engine( streaming=True)\r\nresponse = query_engine.query(\"query)\r\nprint(dir(response))\r\n```\r\n\r\nOUTPUT:\r\n`['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'extra_info', 'get_formatted_sources', 'response', 'source_nodes']`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3366/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3366/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/3365",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/3365/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/3365/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/3365/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/3365",
        "id": 1709818076,
        "node_id": "I_kwDOIWuq585l6cDc",
        "number": 3365,
        "title": "embedding generate cost every time that initialized app",
        "user": {
            "login": "NaelsonAccountDrive",
            "id": 122898249,
            "node_id": "U_kgDOB1NHSQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/122898249?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NaelsonAccountDrive",
            "html_url": "https://github.com/NaelsonAccountDrive",
            "followers_url": "https://api.github.com/users/NaelsonAccountDrive/followers",
            "following_url": "https://api.github.com/users/NaelsonAccountDrive/following{/other_user}",
            "gists_url": "https://api.github.com/users/NaelsonAccountDrive/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NaelsonAccountDrive/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NaelsonAccountDrive/subscriptions",
            "organizations_url": "https://api.github.com/users/NaelsonAccountDrive/orgs",
            "repos_url": "https://api.github.com/users/NaelsonAccountDrive/repos",
            "events_url": "https://api.github.com/users/NaelsonAccountDrive/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NaelsonAccountDrive/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5274485211,
                "node_id": "LA_kwDOIWuq588AAAABOmJB2w",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/discord",
                "name": "discord",
                "color": "E2208D",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-05-15T10:41:59Z",
        "updated_at": "2023-05-15T18:14:00Z",
        "closed_at": "2023-05-15T18:13:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\"Total embedding token usage: 15591 tokens\"\r\nit already was bought, how can i reduce it cost? create programmer logic? Anyone have some snippets code to me? Please!!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/3365/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/3365/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    }
]