[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7388",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7388/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7388/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7388/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7388",
        "id": 1864584565,
        "node_id": "PR_kwDOIWuq585YqfIH",
        "number": 7388,
        "title": "update retrieval docs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-24T07:35:42Z",
        "updated_at": "2023-08-24T07:45:35Z",
        "closed_at": "2023-08-24T07:45:34Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7388",
            "html_url": "https://github.com/run-llama/llama_index/pull/7388",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7388.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7388.patch",
            "merged_at": "2023-08-24T07:45:33Z"
        },
        "body": "- cleaned up retriever modules guide\r\n- added full guide for chroma autoretrieval \r\n- fixed kg retriever docs missing",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7388/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7388/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7387",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7387/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7387/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7387/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7387",
        "id": 1864513631,
        "node_id": "PR_kwDOIWuq585YqP4N",
        "number": 7387,
        "title": "Make the Github badges clickable",
        "user": {
            "login": "gkorland",
            "id": 753206,
            "node_id": "MDQ6VXNlcjc1MzIwNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/753206?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gkorland",
            "html_url": "https://github.com/gkorland",
            "followers_url": "https://api.github.com/users/gkorland/followers",
            "following_url": "https://api.github.com/users/gkorland/following{/other_user}",
            "gists_url": "https://api.github.com/users/gkorland/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gkorland/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gkorland/subscriptions",
            "organizations_url": "https://api.github.com/users/gkorland/orgs",
            "repos_url": "https://api.github.com/users/gkorland/repos",
            "events_url": "https://api.github.com/users/gkorland/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gkorland/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-24T06:46:09Z",
        "updated_at": "2023-08-27T11:48:19Z",
        "closed_at": "2023-08-24T15:20:47Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7387",
            "html_url": "https://github.com/run-llama/llama_index/pull/7387",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7387.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7387.patch",
            "merged_at": "2023-08-24T15:20:47Z"
        },
        "body": "# Description\r\n\r\nMake the Github badges clickable\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] My changes generate no new warnings",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7387/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7387/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7386",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7386/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7386/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7386/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7386",
        "id": 1864460384,
        "node_id": "I_kwDOIWuq585vIWhg",
        "number": 7386,
        "title": "[Feature Request]: MilvusVectorStore doesn't have expected functionality",
        "user": {
            "login": "hasansustcse13",
            "id": 94289705,
            "node_id": "U_kgDOBZ6_KQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/94289705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hasansustcse13",
            "html_url": "https://github.com/hasansustcse13",
            "followers_url": "https://api.github.com/users/hasansustcse13/followers",
            "following_url": "https://api.github.com/users/hasansustcse13/following{/other_user}",
            "gists_url": "https://api.github.com/users/hasansustcse13/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hasansustcse13/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hasansustcse13/subscriptions",
            "organizations_url": "https://api.github.com/users/hasansustcse13/orgs",
            "repos_url": "https://api.github.com/users/hasansustcse13/repos",
            "events_url": "https://api.github.com/users/hasansustcse13/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hasansustcse13/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-24T05:59:31Z",
        "updated_at": "2023-11-30T16:02:49Z",
        "closed_at": "2023-11-30T16:02:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nThere should be a functionality where user can add additional field to Milvus vector store. I see we can pass additional field via document's metadata object. But it will add the fields in node column which is not expected. If MilvusVectorStore can add additional field, user can get those rows from vector db at the time of query(similarity search). And also query function doesn't take additional **kwargs as PyMilvus search support to pass it. I see this function take a expression(expr) argument but it will calculate from doc_ids which is strictly couple and also query function does not support filter. \r\nI am adding the library code for more understanding\r\n\r\n\r\n```\r\ndef query(self, query: VectorStoreQuery, **kwargs: Any) -> VectorStoreQueryResult:\r\n        from pymilvus import MilvusException\r\n\r\n        if self.collection is None:\r\n            raise ValueError(\"Milvus instance not initialized.\")\r\n\r\n        if query.mode != VectorStoreQueryMode.DEFAULT:\r\n            raise ValueError(f\"Milvus does not support {query.mode} yet.\")\r\n\r\n        if query.filters is not None:\r\n            raise ValueError(\"Metadata filters not implemented for Milvus yet.\")\r\n\r\n        expr: Optional[str] = None\r\n        if query.doc_ids is not None and len(query.doc_ids) != 0:\r\n            expr_list = ['\"' + entry + '\"' for entry in query.doc_ids]\r\n            expr = f\"{self.doc_id_field} in [{','.join(expr_list)}]\"\r\n\r\n        if query.output_fields is None:\r\n            output_fields = [self.doc_id_field, self.text_field]\r\n\r\n        if query.embedding_field is None:\r\n            embedding_field = self.embedding_field\r\n\r\n        try:\r\n            res = self.collection.search(\r\n                [query.query_embedding],\r\n                embedding_field,\r\n                self.search_params,\r\n                limit=query.similarity_top_k,\r\n                output_fields=output_fields + [\"node\"],\r\n                expr=expr,\r\n            )\r\n            logger.debug(\r\n                f\"Successfully searched embedding in collection: {self.collection_name}\"\r\n                f\" Num Results: {len(res[0])}\"\r\n            )\r\n\r\n```\r\n            \r\nSo my requirement is, this store should have functionality of adding additional field as separate column (not in node object) and also can pass expression or filter at the time of index.chat/query.\n\n### Reason\n\nIf these feature will add, it will help to add multiple documents in same collection and user can search/query/chat on the collection separately based on the additional column. Let's say user are trying to index 10 documents. In the current functionality, user have to create 10 separate collection which is not expected as production grade software. But if there is a functionality where we can add additional column and filter out the column on chat we can index the all document in one collection. \n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7386/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7386/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7385",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7385/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7385/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7385/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7385",
        "id": 1864296945,
        "node_id": "I_kwDOIWuq585vHunx",
        "number": 7385,
        "title": "llm versus llm_predict",
        "user": {
            "login": "erlebach",
            "id": 324708,
            "node_id": "MDQ6VXNlcjMyNDcwOA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/324708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/erlebach",
            "html_url": "https://github.com/erlebach",
            "followers_url": "https://api.github.com/users/erlebach/followers",
            "following_url": "https://api.github.com/users/erlebach/following{/other_user}",
            "gists_url": "https://api.github.com/users/erlebach/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/erlebach/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/erlebach/subscriptions",
            "organizations_url": "https://api.github.com/users/erlebach/orgs",
            "repos_url": "https://api.github.com/users/erlebach/repos",
            "events_url": "https://api.github.com/users/erlebach/events{/privacy}",
            "received_events_url": "https://api.github.com/users/erlebach/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-24T02:50:54Z",
        "updated_at": "2023-08-24T16:03:58Z",
        "closed_at": "2023-08-24T16:03:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nllm  and llm_predictor are two of the arguments of service_context.from_defaults. I don't understand the difference between the two. Is that clearly explained anywhere? Thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7385/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7385/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7384",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7384/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7384/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7384/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7384",
        "id": 1863976485,
        "node_id": "I_kwDOIWuq585vGgYl",
        "number": 7384,
        "title": "[Question]: Is it posible to give an agent an index as engine without using the query engine tool?",
        "user": {
            "login": "DomenicoMireles",
            "id": 131893786,
            "node_id": "U_kgDOB9yKGg",
            "avatar_url": "https://avatars.githubusercontent.com/u/131893786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DomenicoMireles",
            "html_url": "https://github.com/DomenicoMireles",
            "followers_url": "https://api.github.com/users/DomenicoMireles/followers",
            "following_url": "https://api.github.com/users/DomenicoMireles/following{/other_user}",
            "gists_url": "https://api.github.com/users/DomenicoMireles/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DomenicoMireles/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DomenicoMireles/subscriptions",
            "organizations_url": "https://api.github.com/users/DomenicoMireles/orgs",
            "repos_url": "https://api.github.com/users/DomenicoMireles/repos",
            "events_url": "https://api.github.com/users/DomenicoMireles/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DomenicoMireles/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-23T20:36:52Z",
        "updated_at": "2023-08-24T20:56:58Z",
        "closed_at": "2023-08-23T22:03:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI chose an agent as retirver over a chat engine given the extended capabilities but one diference is that when using chat engine, you can ask questions about the index like if it would be part of its training dateset, while with an agent, in order to get the right answer, you must specify that it gotta use the query engine tool.\r\n\r\nThis isnt ideal when you want the agent to always consider the index before making an aswer.\r\n\r\nIs there another way to give an agent access to an index other than as a tool?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7384/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7384/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7383",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7383/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7383/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7383/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7383",
        "id": 1863751755,
        "node_id": "I_kwDOIWuq585vFphL",
        "number": 7383,
        "title": "[Question]: Is it possible to append new nodes to an existing index without overriding the whole index?",
        "user": {
            "login": "DomenicoMireles",
            "id": 131893786,
            "node_id": "U_kgDOB9yKGg",
            "avatar_url": "https://avatars.githubusercontent.com/u/131893786?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DomenicoMireles",
            "html_url": "https://github.com/DomenicoMireles",
            "followers_url": "https://api.github.com/users/DomenicoMireles/followers",
            "following_url": "https://api.github.com/users/DomenicoMireles/following{/other_user}",
            "gists_url": "https://api.github.com/users/DomenicoMireles/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DomenicoMireles/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DomenicoMireles/subscriptions",
            "organizations_url": "https://api.github.com/users/DomenicoMireles/orgs",
            "repos_url": "https://api.github.com/users/DomenicoMireles/repos",
            "events_url": "https://api.github.com/users/DomenicoMireles/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DomenicoMireles/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-23T17:38:06Z",
        "updated_at": "2023-08-24T00:23:29Z",
        "closed_at": "2023-08-24T00:23:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI have a database to which I constantly add new data, then I made an index to query that database, but since that database is constantly being updated, every time the database changes, I need to overwrite the index with the new database nodes, which are the exact same except for the new ones.\r\nIs there a way I could just add the new elements to the same index instead of overwriting it?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7383/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7383/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7382",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7382/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7382/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7382/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7382",
        "id": 1863737813,
        "node_id": "PR_kwDOIWuq585YnqA4",
        "number": 7382,
        "title": "Ensure temperature is a float for openai",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-23T17:27:10Z",
        "updated_at": "2023-08-23T17:37:04Z",
        "closed_at": "2023-08-23T17:37:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7382",
            "html_url": "https://github.com/run-llama/llama_index/pull/7382",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7382.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7382.patch",
            "merged_at": "2023-08-23T17:37:03Z"
        },
        "body": "# Description\r\n\r\nSmall bug with temperature on the OpenAI LLM\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7381\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7382/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7382/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7381",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7381/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7381/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7381/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7381",
        "id": 1863685042,
        "node_id": "I_kwDOIWuq585vFZOy",
        "number": 7381,
        "title": "[Bug]: Temperature broken on OpenAI LLM ",
        "user": {
            "login": "RobertPurdy",
            "id": 65200959,
            "node_id": "MDQ6VXNlcjY1MjAwOTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/65200959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobertPurdy",
            "html_url": "https://github.com/RobertPurdy",
            "followers_url": "https://api.github.com/users/RobertPurdy/followers",
            "following_url": "https://api.github.com/users/RobertPurdy/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobertPurdy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobertPurdy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobertPurdy/subscriptions",
            "organizations_url": "https://api.github.com/users/RobertPurdy/orgs",
            "repos_url": "https://api.github.com/users/RobertPurdy/repos",
            "events_url": "https://api.github.com/users/RobertPurdy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobertPurdy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-23T16:47:37Z",
        "updated_at": "2023-08-23T18:46:47Z",
        "closed_at": "2023-08-23T17:37:04Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nSetting the temperature on OpenAI LLM is broken. \r\n\r\nWhen I set any float value using the temperature arg or the default value, it is converted to an int. \r\n\r\nThe bug is here in openai.py line 42: temperature: int = Field(description=\"The tempature to use during generation.\") \r\n\r\nThe pydantic type should be float in the class definition.\r\n\n\n### Version\n\n0.8.8\n\n### Steps to Reproduce\n\nfrom llama_index.llms import OpenAI\r\nllm = OpenAI(temperature=0.5)\r\nprint(llm)\n\n### Relevant Logs/Tracbacks\n\n```shell\ncallback_manager=<llama_index.callbacks.base.CallbackManager object at 0x10101c350> model='gpt-3.5-turbo' temperature=0 max_tokens=None additional_kwargs={} max_retries=10\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7381/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7381/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7380",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7380/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7380/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7380/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7380",
        "id": 1863461533,
        "node_id": "I_kwDOIWuq585vEiqd",
        "number": 7380,
        "title": "[Bug]: TreeIndex performance degraded badly since 0.8.0",
        "user": {
            "login": "jma7889",
            "id": 225801,
            "node_id": "MDQ6VXNlcjIyNTgwMQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/225801?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jma7889",
            "html_url": "https://github.com/jma7889",
            "followers_url": "https://api.github.com/users/jma7889/followers",
            "following_url": "https://api.github.com/users/jma7889/following{/other_user}",
            "gists_url": "https://api.github.com/users/jma7889/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jma7889/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jma7889/subscriptions",
            "organizations_url": "https://api.github.com/users/jma7889/orgs",
            "repos_url": "https://api.github.com/users/jma7889/repos",
            "events_url": "https://api.github.com/users/jma7889/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jma7889/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 11,
        "created_at": "2023-08-23T14:32:19Z",
        "updated_at": "2023-12-11T00:02:20Z",
        "closed_at": "2023-12-06T17:39:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n[#7236 ](https://github.com/jerryjliu/llama_index/pull/7236) contains the changes, likely the prompt changes that made the tree index query performance degrade to an unusable state. \r\n\r\nFor my Q&A feature that uses Tree GPT35turbo before, it worked well up to 0.7.24, starting 0.8.0, it returns a lot more false positive results. For example, instead of having 10 yes for a bunch of questions, I saw 50 yes now, 40 were false positive. \r\n\r\nHere are some code snippets. They work well until #7236 and I did set default model to gpt3.5 all along. So it's not model change issue. \r\n```python\r\n       ModelChoice.GPT35: {\"model_name\": \"gpt-3.5-turbo\", \"chunk_size\": 1024},\r\n\r\n       predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.01, model_name=model_settings[\"model_name\"]))\r\n\r\n        retriever = TreeSelectLeafRetriever(index=self.index, child_branch_factor=self.tree_child_branch_factor)\r\n        reader = SimpleDirectoryReader(input_dir=self.input_dir)\r\n        documents = reader.load_data()\r\n        index = TreeIndex.from_documents(documents, service_context=service_context)\r\n\r\n``` \n\n### Version\n\nllama-index-0.8.5\n\n### Steps to Reproduce\n\nDo some treeindex based queries and compare the results between 0.7.24 and 0.8.x, the 0.8.x performs much worse\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7380/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7380/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7379",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7379/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7379/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7379/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7379",
        "id": 1863393548,
        "node_id": "I_kwDOIWuq585vESEM",
        "number": 7379,
        "title": "[Question]: After using TextSplitter to split a text, how can I obtain the indices of the split texts in the original text?",
        "user": {
            "login": "MBearo",
            "id": 23232655,
            "node_id": "MDQ6VXNlcjIzMjMyNjU1",
            "avatar_url": "https://avatars.githubusercontent.com/u/23232655?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MBearo",
            "html_url": "https://github.com/MBearo",
            "followers_url": "https://api.github.com/users/MBearo/followers",
            "following_url": "https://api.github.com/users/MBearo/following{/other_user}",
            "gists_url": "https://api.github.com/users/MBearo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MBearo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MBearo/subscriptions",
            "organizations_url": "https://api.github.com/users/MBearo/orgs",
            "repos_url": "https://api.github.com/users/MBearo/repos",
            "events_url": "https://api.github.com/users/MBearo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MBearo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-23T13:56:01Z",
        "updated_at": "2023-08-23T17:53:19Z",
        "closed_at": "2023-08-23T17:53:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\n```python\r\nfrom llama_index import Document\r\nfrom llama_index.node_parser import SimpleNodeParser\r\n\r\nnode_parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)\r\n\r\nnodes = node_parser.get_nodes_from_documents([Document(text=\"long text\")], show_progress=False)\r\n```\r\nHow can I obtain the index positions of each node in the original text?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7379/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7379/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7378",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7378/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7378/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7378/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7378",
        "id": 1863223212,
        "node_id": "PR_kwDOIWuq585Yl5mU",
        "number": 7378,
        "title": "feat: direction-wise SubGraph RAG",
        "user": {
            "login": "wey-gu",
            "id": 1651790,
            "node_id": "MDQ6VXNlcjE2NTE3OTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1651790?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wey-gu",
            "html_url": "https://github.com/wey-gu",
            "followers_url": "https://api.github.com/users/wey-gu/followers",
            "following_url": "https://api.github.com/users/wey-gu/following{/other_user}",
            "gists_url": "https://api.github.com/users/wey-gu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wey-gu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wey-gu/subscriptions",
            "organizations_url": "https://api.github.com/users/wey-gu/orgs",
            "repos_url": "https://api.github.com/users/wey-gu/repos",
            "events_url": "https://api.github.com/users/wey-gu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wey-gu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-23T12:20:19Z",
        "updated_at": "2023-08-24T06:21:20Z",
        "closed_at": "2023-08-24T01:36:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7378",
            "html_url": "https://github.com/run-llama/llama_index/pull/7378",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7378.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7378.patch",
            "merged_at": "2023-08-24T01:36:00Z"
        },
        "body": "# Description\r\n\r\nOptimization and fixes on KG index retriever and NebulaGraphStore\r\n\r\n- Now SubGraph RAG could be **directed**, impl. in NebulaGraph as an example\r\n- **Removed duplicated subject** in the KGIndex KGTableRetriver\r\n- Fixed the object mismatch in NebulaGarph SubGraph retrieval(reported by @BleakStone )\r\n- Optimized Log Printing of KGTableRetriver\r\n\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Enhancement of existing feature(no break changes)\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7378/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7378/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7377",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7377/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7377/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7377/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7377",
        "id": 1863046502,
        "node_id": "I_kwDOIWuq585vC9Vm",
        "number": 7377,
        "title": "[Question]: Is there a way we can use select OpenAI Key dynamically?",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-23T10:29:15Z",
        "updated_at": "2023-08-24T16:05:41Z",
        "closed_at": "2023-08-24T16:05:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nAs per documentation, the only possible way to inject OpenAI key is by using the environment variable `OPENAI_API_KEY`.\r\n\r\nIf let's say I have multiple API Kesy and want to change between them on the fly, what's the best way to do that?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7377/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7377/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7376",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7376/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7376/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7376/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7376",
        "id": 1862940363,
        "node_id": "PR_kwDOIWuq585Yk7u9",
        "number": 7376,
        "title": "Update root.md of supporting_modules/callback",
        "user": {
            "login": "CrazyShipOne",
            "id": 19662816,
            "node_id": "MDQ6VXNlcjE5NjYyODE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/19662816?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CrazyShipOne",
            "html_url": "https://github.com/CrazyShipOne",
            "followers_url": "https://api.github.com/users/CrazyShipOne/followers",
            "following_url": "https://api.github.com/users/CrazyShipOne/following{/other_user}",
            "gists_url": "https://api.github.com/users/CrazyShipOne/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CrazyShipOne/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CrazyShipOne/subscriptions",
            "organizations_url": "https://api.github.com/users/CrazyShipOne/orgs",
            "repos_url": "https://api.github.com/users/CrazyShipOne/repos",
            "events_url": "https://api.github.com/users/CrazyShipOne/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CrazyShipOne/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-23T09:31:05Z",
        "updated_at": "2023-08-23T13:10:58Z",
        "closed_at": "2023-08-23T13:10:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7376",
            "html_url": "https://github.com/run-llama/llama_index/pull/7376",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7376.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7376.patch",
            "merged_at": "2023-08-23T13:10:58Z"
        },
        "body": "Correct doc link for OpenAIFineTuningHandler.\r\n\r\n# Description\r\n\r\nCorrect link to docs/examples/callbacks/OpenInferenceCallback.ipynb (Previous added in  #7354 )\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7376/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7376/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7375",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7375/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7375/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7375/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7375",
        "id": 1862778748,
        "node_id": "PR_kwDOIWuq585YkZAg",
        "number": 7375,
        "title": "[version] bump version to 0.8.8",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-23T07:55:48Z",
        "updated_at": "2023-08-23T08:03:38Z",
        "closed_at": "2023-08-23T08:03:37Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7375",
            "html_url": "https://github.com/run-llama/llama_index/pull/7375",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7375.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7375.patch",
            "merged_at": "2023-08-23T08:03:37Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7375/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7375/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7374",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7374/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7374/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7374/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7374",
        "id": 1862715748,
        "node_id": "I_kwDOIWuq585vBslk",
        "number": 7374,
        "title": "[Bug]: Missing support for claude-2.0 in Anthropic",
        "user": {
            "login": "noble-varghese",
            "id": 109506617,
            "node_id": "U_kgDOBobwOQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/109506617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noble-varghese",
            "html_url": "https://github.com/noble-varghese",
            "followers_url": "https://api.github.com/users/noble-varghese/followers",
            "following_url": "https://api.github.com/users/noble-varghese/following{/other_user}",
            "gists_url": "https://api.github.com/users/noble-varghese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noble-varghese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noble-varghese/subscriptions",
            "organizations_url": "https://api.github.com/users/noble-varghese/orgs",
            "repos_url": "https://api.github.com/users/noble-varghese/repos",
            "events_url": "https://api.github.com/users/noble-varghese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noble-varghese/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-23T07:14:58Z",
        "updated_at": "2023-08-23T14:49:26Z",
        "closed_at": "2023-08-23T14:49:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThis is an extension of the issue #7361. The long form version of claude-2.0 is not supported in Anthropic. \r\n\r\nLink to documentation: https://docs.anthropic.com/claude/reference/selecting-a-model. \r\nThe details to the complete issue can be found at #7361. \r\n\r\nIam also attaching a fix to this issue. Please take a look into it. \n\n### Version\n\n0.8.7\n\n### Steps to Reproduce\n\nSteps have been mentioned in #7361.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7374/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7374/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7373",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7373/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7373/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7373/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7373",
        "id": 1862708725,
        "node_id": "PR_kwDOIWuq585YkJ4R",
        "number": 7373,
        "title": "add support for claude-2.0",
        "user": {
            "login": "noble-varghese",
            "id": 109506617,
            "node_id": "U_kgDOBobwOQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/109506617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noble-varghese",
            "html_url": "https://github.com/noble-varghese",
            "followers_url": "https://api.github.com/users/noble-varghese/followers",
            "following_url": "https://api.github.com/users/noble-varghese/following{/other_user}",
            "gists_url": "https://api.github.com/users/noble-varghese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noble-varghese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noble-varghese/subscriptions",
            "organizations_url": "https://api.github.com/users/noble-varghese/orgs",
            "repos_url": "https://api.github.com/users/noble-varghese/repos",
            "events_url": "https://api.github.com/users/noble-varghese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noble-varghese/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-23T07:10:28Z",
        "updated_at": "2023-08-23T14:50:00Z",
        "closed_at": "2023-08-23T14:49:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7373",
            "html_url": "https://github.com/run-llama/llama_index/pull/7373",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7373.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7373.patch",
            "merged_at": "2023-08-23T14:49:24Z"
        },
        "body": "# Description\r\n\r\nAdding the support for `claude-2.0` in anthropic LLM provider. \r\n\r\nFixes #7374 \r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7373/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7373/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7372",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7372/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7372/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7372/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7372",
        "id": 1862699108,
        "node_id": "PR_kwDOIWuq585YkHxw",
        "number": 7372,
        "title": "enhancement: add max_tokens to xinference",
        "user": {
            "login": "Bojun-Feng",
            "id": 102875484,
            "node_id": "U_kgDOBiHBXA",
            "avatar_url": "https://avatars.githubusercontent.com/u/102875484?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Bojun-Feng",
            "html_url": "https://github.com/Bojun-Feng",
            "followers_url": "https://api.github.com/users/Bojun-Feng/followers",
            "following_url": "https://api.github.com/users/Bojun-Feng/following{/other_user}",
            "gists_url": "https://api.github.com/users/Bojun-Feng/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Bojun-Feng/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Bojun-Feng/subscriptions",
            "organizations_url": "https://api.github.com/users/Bojun-Feng/orgs",
            "repos_url": "https://api.github.com/users/Bojun-Feng/repos",
            "events_url": "https://api.github.com/users/Bojun-Feng/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Bojun-Feng/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-23T07:03:23Z",
        "updated_at": "2023-08-23T15:38:41Z",
        "closed_at": "2023-08-23T15:38:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7372",
            "html_url": "https://github.com/run-llama/llama_index/pull/7372",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7372.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7372.patch",
            "merged_at": "2023-08-23T15:38:32Z"
        },
        "body": "# Description\r\n\r\nThis is a non-breaking update on the Xinference extension targeting [this issue](https://github.com/xorbitsai/inference/issues/378).\r\n\r\nCurrently, the `Xinference` object does not support changing the output length. This results in answers being cropped off before the model generates the stop token naturally, leading to unfinished answers.\r\n\r\nThis PR adds the `max_token` argument to `Xinference`, which depends on the context window of the model. The context window argument is also updated so that information is fetched from the Xinference endpoint directly instead of locally stored in the codebase, removing the need for frequent future updates as Xinference incorporates more language models.\r\n\r\nThis is a non-breaking fix. The `max_token` argument is optional, so all old code operates normally.\r\n\r\nRelevant use case examples would be updated in the demo notebook and documents.\r\n\r\n<img width=\"1014\" alt=\"Screenshot 2023-08-23 at 17 44 21\" src=\"https://github.com/jerryjliu/llama_index/assets/102875484/a4a6d168-db87-4974-970d-892987541ac6\">\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Updated test notebook (that tests end-to-end)\r\n- [x] Updated relevant documentation\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7372/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7372/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7371",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7371/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7371/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7371/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7371",
        "id": 1862537672,
        "node_id": "I_kwDOIWuq585vBBHI",
        "number": 7371,
        "title": "[Bug]: example running issue",
        "user": {
            "login": "weidezhang",
            "id": 455617,
            "node_id": "MDQ6VXNlcjQ1NTYxNw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/455617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/weidezhang",
            "html_url": "https://github.com/weidezhang",
            "followers_url": "https://api.github.com/users/weidezhang/followers",
            "following_url": "https://api.github.com/users/weidezhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/weidezhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/weidezhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/weidezhang/subscriptions",
            "organizations_url": "https://api.github.com/users/weidezhang/orgs",
            "repos_url": "https://api.github.com/users/weidezhang/repos",
            "events_url": "https://api.github.com/users/weidezhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/weidezhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-23T04:17:20Z",
        "updated_at": "2023-11-30T16:02:08Z",
        "closed_at": "2023-11-30T16:02:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHi , I tried to test the example ChatBot_SEC example in the python notebook and got errors when creating llama_chat_agent. \r\n\r\nI'm using langchain 0.0.266 and llama-index 0.8.7 \r\n\r\n\r\n\r\n### Version\r\n\r\n0.8.7\r\n\r\n### Steps to Reproduce\r\n\r\njust open the ChatSEC_bot jyupter notebook and supply with openai api key and run through the code \r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n`\r\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\r\nllm = OpenAI(temperature=0)\r\nagent_chain = create_llama_chat_agent(toolkit, llm, memory=memory, verbose=True)\r\n\r\noutput:\r\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\nCell In[18], line 3\r\n      1 memory = ConversationBufferMemory(memory_key=\"chat_history\")\r\n      2 llm = OpenAI(temperature=0)\r\n----> 3 agent_chain = create_llama_chat_agent(toolkit, llm, memory=memory, verbose=True)\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/llama_index/langchain_helpers/agents/agents.py:85, in create_llama_chat_agent(toolkit, llm, callback_manager, agent_kwargs, **kwargs)\r\n     82 # chat agent\r\n     83 # TODO: explore chat-conversational-react-description\r\n     84 agent_type = AgentType.CONVERSATIONAL_REACT_DESCRIPTION\r\n---> 85 return create_llama_agent(\r\n     86     toolkit,\r\n     87     llm,\r\n     88     agent=agent_type,\r\n     89     callback_manager=callback_manager,\r\n     90     agent_kwargs=agent_kwargs,\r\n     91     **kwargs,\r\n     92 )\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/llama_index/langchain_helpers/agents/agents.py:51, in create_llama_agent(toolkit, llm, agent, callback_manager, agent_path, agent_kwargs, **kwargs)\r\n     25 \"\"\"Load an agent executor given a Llama Toolkit and LLM.\r\n     26 \r\n     27 NOTE: this is a light wrapper around initialize_agent in langchain.\r\n   (...)\r\n     48     An agent executor\r\n     49 \"\"\"\r\n     50 llama_tools = toolkit.get_tools()\r\n---> 51 return initialize_agent(\r\n     52     llama_tools,\r\n     53     llm,\r\n     54     agent=agent,\r\n     55     callback_manager=callback_manager,\r\n     56     agent_path=agent_path,\r\n     57     agent_kwargs=agent_kwargs,\r\n     58     **kwargs,\r\n     59 )\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/langchain/agents/initialize.py:57, in initialize_agent(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\r\n     55     agent_cls = AGENT_TO_CLASS[agent]\r\n     56     agent_kwargs = agent_kwargs or {}\r\n---> 57     agent_obj = agent_cls.from_llm_and_tools(\r\n     58         llm, tools, callback_manager=callback_manager, **agent_kwargs\r\n     59     )\r\n     60 elif agent_path is not None:\r\n     61     agent_obj = load_agent(\r\n     62         agent_path, llm=llm, tools=tools, callback_manager=callback_manager\r\n     63     )\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/langchain/agents/conversational/base.py:117, in ConversationalAgent.from_llm_and_tools(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, ai_prefix, human_prefix, input_variables, **kwargs)\r\n    107 cls._validate_tools(tools)\r\n    108 prompt = cls.create_prompt(\r\n    109     tools,\r\n    110     ai_prefix=ai_prefix,\r\n   (...)\r\n    115     input_variables=input_variables,\r\n    116 )\r\n--> 117 llm_chain = LLMChain(\r\n    118     llm=llm,\r\n    119     prompt=prompt,\r\n    120     callback_manager=callback_manager,\r\n    121 )\r\n    122 tool_names = [tool.name for tool in tools]\r\n    123 _output_parser = output_parser or cls._get_default_output_parser(\r\n    124     ai_prefix=ai_prefix\r\n    125 )\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/langchain/load/serializable.py:74, in Serializable.__init__(self, **kwargs)\r\n     73 def __init__(self, **kwargs: Any) -> None:\r\n---> 74     super().__init__(**kwargs)\r\n     75     self._lc_kwargs = kwargs\r\n\r\nFile ~/miniconda3/lib/python3.10/site-packages/pydantic/main.py:341, in pydantic.main.BaseModel.__init__()\r\n\r\nValidationError: 1 validation error for LLMChain\r\nllm\r\n  Can't instantiate abstract class BaseLanguageModel with abstract methods agenerate_prompt, apredict, apredict_messages, generate_prompt, invoke, predict, predict_messages (type=type_error)\r\n`\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7371/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7371/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7370",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7370/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7370/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7370/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7370",
        "id": 1862427230,
        "node_id": "PR_kwDOIWuq585YjN7x",
        "number": 7370,
        "title": "update simple node parser usage",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-23T01:57:41Z",
        "updated_at": "2023-08-23T02:05:05Z",
        "closed_at": "2023-08-23T02:05:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7370",
            "html_url": "https://github.com/run-llama/llama_index/pull/7370",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7370.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7370.patch",
            "merged_at": "2023-08-23T02:05:05Z"
        },
        "body": "# Description\r\n\r\n`SimpleNodeParser` docs were out of date -- should be using `from_defaults()`. Surprisingly more common than I thought, must have got missed in the pydantic changes.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7352\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7370/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7370/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7369",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7369/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7369/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7369/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7369",
        "id": 1862416403,
        "node_id": "PR_kwDOIWuq585YjLrL",
        "number": 7369,
        "title": "add support for claude-instant-1.2",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-23T01:41:10Z",
        "updated_at": "2023-08-23T01:46:30Z",
        "closed_at": "2023-08-23T01:46:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7369",
            "html_url": "https://github.com/run-llama/llama_index/pull/7369",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7369.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7369.patch",
            "merged_at": "2023-08-23T01:46:29Z"
        },
        "body": "# Description\r\n\r\nJust a quick update to constants to support claude-instant-1.2\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7361\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7369/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7369/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7368",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7368/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7368/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7368/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7368",
        "id": 1862415022,
        "node_id": "I_kwDOIWuq585vAjKu",
        "number": 7368,
        "title": "How to choose identical embeddings and language models for query with Chroma?",
        "user": {
            "login": "erlebach",
            "id": 324708,
            "node_id": "MDQ6VXNlcjMyNDcwOA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/324708?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/erlebach",
            "html_url": "https://github.com/erlebach",
            "followers_url": "https://api.github.com/users/erlebach/followers",
            "following_url": "https://api.github.com/users/erlebach/following{/other_user}",
            "gists_url": "https://api.github.com/users/erlebach/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/erlebach/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/erlebach/subscriptions",
            "organizations_url": "https://api.github.com/users/erlebach/orgs",
            "repos_url": "https://api.github.com/users/erlebach/repos",
            "events_url": "https://api.github.com/users/erlebach/events{/privacy}",
            "received_events_url": "https://api.github.com/users/erlebach/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-23T01:38:58Z",
        "updated_at": "2023-08-23T17:28:58Z",
        "closed_at": "2023-08-23T17:28:58Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI am using Llama-index with Chroma to create a persistent database. I then read the database and perform a query using `index.query_engine.query(str)`. The storage is a `ChromaVectorStore`, and the index is a `VectorStoreIndex`. This set up implies that the embedding model and the language model used for the query should be the same. Otherwise, the embeddings generated from the query would not be consistent with the embeddings in the database. (I assume I understand this correctly)? Furthermore, the language models and embeddings are set in the `ServiceContext`. So my question is the following: how can ensure that the `embed_model` model and the language model `llm` are the same. I sometimes get confused as to the difference between the embedding model and the language model. Here is some code:\r\n\r\n```\r\n        self.embed_model = LangchainEmbedding(\r\n            # 384 dim-embeddings\r\n            HuggingFaceEmbeddings(\r\n                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\r\n                cache_folder=\"./transformer_cache\",  # local download\r\n            ),\r\n            embed_batch_size=10,\r\n        )\r\n        llm_predictor = LLMPredictor()\r\n        self.service_context = ServiceContext.from_defaults(\r\n            llm=OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\"),\r\n            embed_model=self.embed_model,  # This is the model used for querying\r\n        )\r\n```\r\n\r\nThe main line is the `self.service_context`. When I run a query after reloading the model from disk, I sometimes get a message such as:\r\n\r\n`chromadb.errors.InvalidDimensionException: Embedding dimension 1536 does not match collection dimensionality 384. `\r\n\r\nI would like to experiment with a range of embed_models and LLM models with different embedding sizes. For some reason, embedding sizes are not stored as easy to access information with the different models. I am not sure why. Any insight that would help me would be greatly appreciated. Thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7368/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7368/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7367",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7367/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7367/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7367/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7367",
        "id": 1862304684,
        "node_id": "PR_kwDOIWuq585Yi0Bs",
        "number": 7367,
        "title": "gpt-3.5 training example",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T22:52:11Z",
        "updated_at": "2023-08-23T06:04:39Z",
        "closed_at": "2023-08-23T06:04:38Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7367",
            "html_url": "https://github.com/run-llama/llama_index/pull/7367",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7367.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7367.patch",
            "merged_at": "2023-08-23T06:04:38Z"
        },
        "body": "# Description\r\n\r\nThis PR adds a few things\r\n\r\n- files in `experimental` to fine-tune OpenAI models\r\n- a new callback handler that can save LLM inputs/outputs into openai training format\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7367/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7367/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7366",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7366/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7366/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7366/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7366",
        "id": 1862283789,
        "node_id": "PR_kwDOIWuq585YivjO",
        "number": 7366,
        "title": "[version] bump to 0.8.7",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T22:24:02Z",
        "updated_at": "2023-08-22T22:37:30Z",
        "closed_at": "2023-08-22T22:37:30Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7366",
            "html_url": "https://github.com/run-llama/llama_index/pull/7366",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7366.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7366.patch",
            "merged_at": "2023-08-22T22:37:30Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7366/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7366/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7365",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7365/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7365/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7365/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7365",
        "id": 1862251205,
        "node_id": "PR_kwDOIWuq585Yiods",
        "number": 7365,
        "title": "add exists_ok-True to os.makedir() call to avoid concurrency issue",
        "user": {
            "login": "amarkules1",
            "id": 23044681,
            "node_id": "MDQ6VXNlcjIzMDQ0Njgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/23044681?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/amarkules1",
            "html_url": "https://github.com/amarkules1",
            "followers_url": "https://api.github.com/users/amarkules1/followers",
            "following_url": "https://api.github.com/users/amarkules1/following{/other_user}",
            "gists_url": "https://api.github.com/users/amarkules1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/amarkules1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/amarkules1/subscriptions",
            "organizations_url": "https://api.github.com/users/amarkules1/orgs",
            "repos_url": "https://api.github.com/users/amarkules1/repos",
            "events_url": "https://api.github.com/users/amarkules1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/amarkules1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-22T21:46:41Z",
        "updated_at": "2023-08-23T18:33:42Z",
        "closed_at": "2023-08-23T17:37:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7365",
            "html_url": "https://github.com/run-llama/llama_index/pull/7365",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7365.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7365.patch",
            "merged_at": "2023-08-23T17:37:27Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ x ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ x ] I stared at the code and made sure it makes sense (not sure how to add a test for a concurrency issue like this\r\n\r\n# Suggested Checklist:\r\n\r\n- [ x ] I have performed a self-review of my own code\r\n- [ x ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7365/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7365/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7364",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7364/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7364/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7364/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7364",
        "id": 1862242509,
        "node_id": "PR_kwDOIWuq585YimkN",
        "number": 7364,
        "title": "Support fine-tuned chat models",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T21:37:21Z",
        "updated_at": "2023-08-22T22:21:59Z",
        "closed_at": "2023-08-22T22:21:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7364",
            "html_url": "https://github.com/run-llama/llama_index/pull/7364",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7364.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7364.patch",
            "merged_at": "2023-08-22T22:21:58Z"
        },
        "body": "# Description\r\n\r\nQuick patch to support fine-tuned models in our OpenAI LLM.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested with a fine-tuned LLM\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7364/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7364/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7363",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7363/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7363/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7363/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7363",
        "id": 1862026022,
        "node_id": "PR_kwDOIWuq585Yh2qN",
        "number": 7363,
        "title": "Fixed OpenAiAgent force function call loop",
        "user": {
            "login": "NoahMoritz",
            "id": 30773809,
            "node_id": "MDQ6VXNlcjMwNzczODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30773809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NoahMoritz",
            "html_url": "https://github.com/NoahMoritz",
            "followers_url": "https://api.github.com/users/NoahMoritz/followers",
            "following_url": "https://api.github.com/users/NoahMoritz/following{/other_user}",
            "gists_url": "https://api.github.com/users/NoahMoritz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NoahMoritz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NoahMoritz/subscriptions",
            "organizations_url": "https://api.github.com/users/NoahMoritz/orgs",
            "repos_url": "https://api.github.com/users/NoahMoritz/repos",
            "events_url": "https://api.github.com/users/NoahMoritz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NoahMoritz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T18:57:01Z",
        "updated_at": "2023-08-22T21:46:46Z",
        "closed_at": "2023-08-22T21:46:45Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7363",
            "html_url": "https://github.com/run-llama/llama_index/pull/7363",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7363.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7363.patch",
            "merged_at": "2023-08-22T21:46:45Z"
        },
        "body": "# Description\r\n\r\nWhen a function call was forced on the OpenAiAgent, a loop occurred where each response of the LLM called the function again and therefore never send a final response. To fix this, the custom value gets only applied at the first request. After that the function parameter in the OpenAi Api changes back to `auto`. For more information about this parameter, look at the [OpenAi API documentation](https://platform.openai.com/docs/api-reference/chat/create#chat/create-functions).\r\n\r\nFixes #7359 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] ~~New feature (non-breaking change which adds functionality)~~\r\n- [ ] ~~Breaking change (fix or feature that would cause existing functionality to not work as expected)~~\r\n- [ ] ~~This change requires a documentation update~~\r\n\r\n# How Has This Been Tested?\r\n\r\nThe bugfix is quite small and the bug has been severely narrowed down and confirmed by @logan-markewich.\r\ni tested the code afterwards and checked with the debugger if the function call is not passed the second time.\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] ~~I have made corresponding changes to the documentation~~ (not relevant)\r\n- [x] My changes generate no new warnings\r\n- [ ] ~~I have added tests that prove my fix is effective or that my feature works~~ (not relevant)\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7363/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7363/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7362",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7362/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7362/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7362/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7362",
        "id": 1861367850,
        "node_id": "I_kwDOIWuq585u8jgq",
        "number": 7362,
        "title": "[Bug]: llama index throws FileExistsError when trying to create a VectorStoreIndex in multithreaded environment",
        "user": {
            "login": "amarkules1",
            "id": 23044681,
            "node_id": "MDQ6VXNlcjIzMDQ0Njgx",
            "avatar_url": "https://avatars.githubusercontent.com/u/23044681?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/amarkules1",
            "html_url": "https://github.com/amarkules1",
            "followers_url": "https://api.github.com/users/amarkules1/followers",
            "following_url": "https://api.github.com/users/amarkules1/following{/other_user}",
            "gists_url": "https://api.github.com/users/amarkules1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/amarkules1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/amarkules1/subscriptions",
            "organizations_url": "https://api.github.com/users/amarkules1/orgs",
            "repos_url": "https://api.github.com/users/amarkules1/repos",
            "events_url": "https://api.github.com/users/amarkules1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/amarkules1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-22T12:33:39Z",
        "updated_at": "2023-08-24T00:24:34Z",
        "closed_at": "2023-08-24T00:24:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI'm working on a REST service using gunicorn, and noticed the service sometimes fails during startup when I set the number of workers > 1. In the application I'm creating a llama_index.VectorStoreIndex on startup, which is where the failure is happening. Based on the logs, I've traced the issue to this `os.makedirs()` call: https://github.com/jerryjliu/llama_index/blob/main/llama_index/utils.py#L275\r\n\r\nIt seems that there's a concurrency issue, where multiple workers check if the directory exists at the same time, see that it does not, and try to create the directory. Fix should be as simple as adding an `exist_ok=True` param to the `os.makedirs()` call\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\n1. create a simple flask app that calls `VectorStoreIndex.from_vector_store()` during startup\r\n2. run the app using gunicorn with multiple workers (seems to happen pretty frequently with 4+)\r\n3. observe output\r\n\r\nI've been running into this issue with [this project](https://github.com/amarkules1/bill-the-ai), I can try to put something simpler together to reproduce if needed.\n\n### Relevant Logs/Tracbacks\n\n```shell\n[2023-08-22 02:37:51 +0000] [1] [INFO] Starting gunicorn 21.2.0\r\n[2023-08-22 02:37:51 +0000] [1] [INFO] Listening at: https://0.0.0.0:443 (1)\r\n[2023-08-22 02:37:51 +0000] [1] [INFO] Using worker: sync\r\n[2023-08-22 02:37:51 +0000] [6] [INFO] Booting worker with pid: 6\r\n[2023-08-22 02:37:51 +0000] [7] [INFO] Booting worker with pid: 7\r\n[2023-08-22 02:37:51 +0000] [8] [INFO] Booting worker with pid: 8\r\n[2023-08-22 02:37:51 +0000] [9] [INFO] Booting worker with pid: 9\r\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\r\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\r\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\r\nNone of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\r\nDownloading (\u2026)okenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28.0/28.0 [00:00<00:00, 164kB/s]\r\nDownloading (\u2026)solve/main/vocab.txt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 232k/232k [00:00<00:00, 7.46MB/s]\r\nDownloading (\u2026)/main/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 466k/466k [00:00<00:00, 5.80MB/s]\r\nDownloading (\u2026)lve/main/config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 570/570 [00:00<00:00, 3.17MB/s]\r\n[2023-08-22 02:38:11 +0000] [6] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py\", line 609, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 134, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 146, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 58, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 48, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/util.py\", line 371, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/app/main.py\", line 43, in <module>\r\n    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 68, in from_vector_store\r\n    return cls(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 46, in __init__\r\n    super().__init__(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/base.py\", line 61, in __init__\r\n    self._service_context = service_context or ServiceContext.from_defaults()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 158, in from_defaults\r\n    node_parser = node_parser or _get_default_node_parser(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 28, in _get_default_node_parser\r\n    return SimpleNodeParser.from_defaults(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/node_parser/simple.py\", line 56, in from_defaults\r\n    text_splitter = text_splitter or get_default_text_splitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/__init__.py\", line 22, in get_default_text_splitter\r\n    return SentenceSplitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 91, in __init__\r\n    chunking_tokenizer_fn = chunking_tokenizer_fn or split_by_sentence_tokenizer()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/utils.py\", line 38, in split_by_sentence_tokenizer\r\n    cache_dir = get_cache_dir()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/utils.py\", line 275, in get_cache_dir\r\n    os.makedirs(path)\r\n  File \"/usr/local/lib/python3.10/os.py\", line 225, in makedirs\r\n    mkdir(name, mode)\r\nFileExistsError: [Errno 17] File exists: '/tmp/llama_index'\r\n[2023-08-22 02:38:11 +0000] [9] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py\", line 609, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 134, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 146, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 58, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 48, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/util.py\", line 371, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/app/main.py\", line 43, in <module>\r\n    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 68, in from_vector_store\r\n    return cls(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 46, in __init__\r\n    super().__init__(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/base.py\", line 61, in __init__\r\n    self._service_context = service_context or ServiceContext.from_defaults()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 158, in from_defaults\r\n    node_parser = node_parser or _get_default_node_parser(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 28, in _get_default_node_parser\r\n    return SimpleNodeParser.from_defaults(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/node_parser/simple.py\", line 56, in from_defaults\r\n    text_splitter = text_splitter or get_default_text_splitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/__init__.py\", line 22, in get_default_text_splitter\r\n    return SentenceSplitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 91, in __init__\r\n    chunking_tokenizer_fn = chunking_tokenizer_fn or split_by_sentence_tokenizer()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/utils.py\", line 38, in split_by_sentence_tokenizer\r\n    cache_dir = get_cache_dir()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/utils.py\", line 275, in get_cache_dir\r\n    os.makedirs(path)\r\n  File \"/usr/local/lib/python3.10/os.py\", line 225, in makedirs\r\n    mkdir(name, mode)\r\nFileExistsError: [Errno 17] File exists: '/tmp/llama_index'\r\n[2023-08-22 02:38:11 +0000] [8] [ERROR] Exception in worker process\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/arbiter.py\", line 609, in spawn_worker\r\n    worker.init_process()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 134, in init_process\r\n    self.load_wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 146, in load_wsgi\r\n    self.wsgi = self.app.wsgi()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/base.py\", line 67, in wsgi\r\n    self.callable = self.load()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 58, in load\r\n    return self.load_wsgiapp()\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/app/wsgiapp.py\", line 48, in load_wsgiapp\r\n    return util.import_app(self.app_uri)\r\n  File \"/usr/local/lib/python3.10/site-packages/gunicorn/util.py\", line 371, in import_app\r\n    mod = importlib.import_module(module)\r\n  File \"/usr/local/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/app/main.py\", line 43, in <module>\r\n    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 68, in from_vector_store\r\n    return cls(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py\", line 46, in __init__\r\n    super().__init__(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/base.py\", line 61, in __init__\r\n    self._service_context = service_context or ServiceContext.from_defaults()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 158, in from_defaults\r\n    node_parser = node_parser or _get_default_node_parser(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/indices/service_context.py\", line 28, in _get_default_node_parser\r\n    return SimpleNodeParser.from_defaults(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/node_parser/simple.py\", line 56, in from_defaults\r\n    text_splitter = text_splitter or get_default_text_splitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/__init__.py\", line 22, in get_default_text_splitter\r\n    return SentenceSplitter(\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/sentence_splitter.py\", line 91, in __init__\r\n    chunking_tokenizer_fn = chunking_tokenizer_fn or split_by_sentence_tokenizer()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/text_splitter/utils.py\", line 38, in split_by_sentence_tokenizer\r\n    cache_dir = get_cache_dir()\r\n  File \"/usr/local/lib/python3.10/site-packages/llama_index/utils.py\", line 275, in get_cache_dir\r\n    os.makedirs(path)\r\n  File \"/usr/local/lib/python3.10/os.py\", line 225, in makedirs\r\n    mkdir(name, mode)\r\nFileExistsError: [Errno 17] File exists: '/tmp/llama_index'\r\n[2023-08-22 02:38:11 +0000] [6] [INFO] Worker exiting (pid: 6)\r\n[2023-08-22 02:38:11 +0000] [8] [INFO] Worker exiting (pid: 8)\r\n[2023-08-22 02:38:11 +0000] [9] [INFO] Worker exiting (pid: 9)\r\n[nltk_data] Downloading package punkt to /tmp/llama_index...\r\n[nltk_data]   Unzipping tokenizers/punkt.zip.\r\n[2023-08-22 02:38:14 +0000] [1] [ERROR] Worker (pid:8) exited with code 3\r\n[2023-08-22 02:38:14 +0000] [7] [INFO] Worker exiting (pid: 7)\r\n[2023-08-22 02:38:14 +0000] [1] [ERROR] Shutting down: Master\r\n[2023-08-22 02:38:14 +0000] [1] [ERROR] Reason: Worker failed to boot.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7362/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7362/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7361",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7361/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7361/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7361/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7361",
        "id": 1861321776,
        "node_id": "I_kwDOIWuq585u8YQw",
        "number": 7361,
        "title": "[Bug]: Inconsistent Behavior with Anthropic Model Names",
        "user": {
            "login": "noble-varghese",
            "id": 109506617,
            "node_id": "U_kgDOBobwOQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/109506617?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/noble-varghese",
            "html_url": "https://github.com/noble-varghese",
            "followers_url": "https://api.github.com/users/noble-varghese/followers",
            "following_url": "https://api.github.com/users/noble-varghese/following{/other_user}",
            "gists_url": "https://api.github.com/users/noble-varghese/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/noble-varghese/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/noble-varghese/subscriptions",
            "organizations_url": "https://api.github.com/users/noble-varghese/orgs",
            "repos_url": "https://api.github.com/users/noble-varghese/repos",
            "events_url": "https://api.github.com/users/noble-varghese/events{/privacy}",
            "received_events_url": "https://api.github.com/users/noble-varghese/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-22T12:06:44Z",
        "updated_at": "2023-08-23T01:46:41Z",
        "closed_at": "2023-08-23T01:46:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI'm encountering an inconsistency while working with the Anthropic integration in llama_index. Specifically, when passing the model name as claude-instant-1.2, I'm getting an error message:\r\n\r\nCode used : \r\n```python\r\nfrom llama_index import ServiceContext\r\nfrom llama_index.llms import Anthropic\r\n\r\nanthropic = Anthropic(model=\"claude-instant-1.2\")\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm\r\n)\r\n```\r\n\r\nError\r\n```bash\r\nUnknown model: claude-instant-1.2. Please provide a valid Anthropic model name. Known models are: claude-instant-1, claude-2.\r\n```\r\nHowever, according to the documentation, both claude-instant-1 and claude-instant-1.2 should be valid model names. This inconsistency is causing confusion and making it challenging to work with the Anthropic LLM integration.\r\n\r\nFurthermore, I noticed that the results from the Anthropic LLM (api results) contain the model in the full version as stated in the documentation, but the error message suggests otherwise.\r\n\r\n\r\nLink to documentation: https://docs.anthropic.com/claude/reference/selecting-a-model\r\n\r\nRequest to Anthropic:\r\n```bash\r\ncurl --location 'https://api.anthropic.com/v1/complete' \\\r\n--header 'accept: application/json' \\\r\n--header 'anthropic-version: 2023-06-01' \\\r\n--header 'content-type: application/json' \\\r\n--header 'x-api-key: <_ANTHROPIC_API_KEY_>' \\\r\n--data '\r\n{\r\n  \"model\": \"claude-2\",\r\n  \"prompt\": \"\\n\\nHuman: Hello, world!\\n\\nAssistant:Why is the sky blue?\",\r\n  \"max_tokens_to_sample\": 256\r\n}\r\n'\r\n```\r\n\r\nExample response from Anthropic: \r\n```json\r\n{\r\n    \"completion\": \" Well, it has to do with how sunlight interacts with molecules in Earth's atmosphere. Here's a more detailed explanation:\\n\\nThe sky appears blue because of a phenomenon called Rayleigh scattering. As sunlight enters the atmosphere, it interacts with gas molecules like nitrogen and oxygen. These molecules scatter the shorter wavelengths of sunlight (violet and blue light) more than the longer wavelengths (like red light). \\n\\nThe shorter blue and violet wavelengths get scattered in all directions, making the sky appear blue from the ground no matter which direction you look. Meanwhile, the remaining longer wavelengths like red and orange pass through the atmosphere more directly, which is why sunsets appear more reddish.\\n\\nThere are a few other factors that impact the exact shade of blue:\\n\\n- The size of the molecules - smaller molecules scatter blue light more efficiently than larger ones. Nitrogen and oxygen molecules are just the right size to preferentially scatter blue.\\n\\n- The density of the atmosphere - more dense atmospheres with more gas molecules lead to more scattering and a deeper blue color. This is why the sky fades to darker blue higher up in the sky.\\n\\n- Dust and pollution - additional particles in the air from dust, smoke, or pollution can add extra scattering, making\",\r\n    \"stop_reason\": \"max_tokens\",\r\n    \"model\": \"claude-2.0\",\r\n    \"stop\": null,\r\n    \"log_id\": \"b6e7d19d49a1433cac79c8512ad6818c8cd9a94f28930aa7a613fd46cb\"\r\n}\r\n```\r\n\r\nInfact Anthropic API accepts both formats of inputs.\r\n\r\n### Version\r\n\r\n0.8.4\r\n\r\n### Steps to Reproduce\r\n\r\nUse the above specified code \r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nNone\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7361/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7361/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7360",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7360/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7360/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7360/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7360",
        "id": 1861133364,
        "node_id": "I_kwDOIWuq585u7qQ0",
        "number": 7360,
        "title": "[Bug]: IndexStore is not updated when using PgVectorStore",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-22T10:11:51Z",
        "updated_at": "2023-12-14T10:47:23Z",
        "closed_at": "2023-08-22T18:05:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nAs per my understanding, IndexStore has the responsibility of keeping track of which Documents/Nodes belong to which index, by adding the map to `nodes_dict`\r\n\r\nThis is useful if we want to use multiple indices in our system. \r\n\r\n```\r\n[\r\n    {\r\n        _id: 'eastern',\r\n        __type__: 'vector_store',\r\n        __data__: '{\"index_id\": \"eastern\", \"summary\": null, \"nodes_dict\": {\"203eeae4-7814-4ffd-8b2d-84dae91fbcb7\": \"203eeae4-7814-4ffd-8b2d-84dae91fbcb7\", \"22e00d3f-49aa-444c-bca0-167448a5c8ad\": \"22e00d3f-49aa-444c-bca0-167448a5c8ad\", \"734c4ef7-c7d3-46ba-af0f-a6e0031f7351\": \"734c4ef7-c7d3-46ba-af0f-a6e0031f7351\"}, \"doc_id_dict\": {}, \"embeddings_dict\": {}}'\r\n    },\r\n    {\r\n        _id: 'western',\r\n        __type__: 'vector_store',\r\n        __data__: '{\"index_id\": \"western\", \"summary\": null, \"nodes_dict\": {\"8ab5c446-3ae5-4952-ba79-ee5141b96338\": \"8ab5c446-3ae5-4952-ba79-ee5141b96338\", \"801bf16c-3a34-452b-bd33-143f56c19945\": \"801bf16c-3a34-452b-bd33-143f56c19945\", \"154a3c33-1325-49cd-8e35-2bc45cf430c0\": \"154a3c33-1325-49cd-8e35-2bc45cf430c0\"}, \"doc_id_dict\": {}, \"embeddings_dict\": {}}'\r\n    }\r\n]\r\n```\r\n\r\nA problem will happen when we introduce `PgVectorStore`. When using this Vector Store, the IndexStore won't be updated anymore.\r\n\r\n```\r\n{\r\n    _id: 'eastern',\r\n    __type__: 'vector_store',\r\n    __data__: '{\"index_id\": \"eastern\", \"summary\": null, \"nodes_dict\": {}, \"doc_id_dict\": {}, \"embeddings_dict\": {}}'\r\n}\r\n```\r\n\r\nThis won't be a problem if we only have 1 index, but when having multiple indexes, we expect the query_engine to only search from Documents/Nodes that belong to a specific index. But with this bug, the query will always run against all Documents/Nodes.\n\n### Version\n\nv0.8.5.post2\n\n### Steps to Reproduce\n\nCreate multiple indices and store them to PgVectorStore\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7360/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7360/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7359",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7359/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7359/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7359/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7359",
        "id": 1860948522,
        "node_id": "I_kwDOIWuq585u69Iq",
        "number": 7359,
        "title": "[Bug]: BaseChatEngine.chat() returns None if OpenAi is used and function_call=\"query_engine_tool\"",
        "user": {
            "login": "NoahMoritz",
            "id": 30773809,
            "node_id": "MDQ6VXNlcjMwNzczODA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/30773809?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NoahMoritz",
            "html_url": "https://github.com/NoahMoritz",
            "followers_url": "https://api.github.com/users/NoahMoritz/followers",
            "following_url": "https://api.github.com/users/NoahMoritz/following{/other_user}",
            "gists_url": "https://api.github.com/users/NoahMoritz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NoahMoritz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NoahMoritz/subscriptions",
            "organizations_url": "https://api.github.com/users/NoahMoritz/orgs",
            "repos_url": "https://api.github.com/users/NoahMoritz/repos",
            "events_url": "https://api.github.com/users/NoahMoritz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NoahMoritz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-22T08:47:24Z",
        "updated_at": "2023-08-22T21:46:47Z",
        "closed_at": "2023-08-22T21:46:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHello all,\r\n\r\n\r\nI've tried a few different scenarios but the basic underlying issue seems to be, that whenever I use a Cheat Engine with OpenAi, the return value from all chat functions is None. Here a sample code where the issues exists:\r\n\r\n```python\r\nimport os\r\nos.environ[\"OPENAI_API_KEY\"] = '----------------------------------'\r\n\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\r\nfrom llama_index.chat_engine.types import ChatMode\r\nfrom llama_index.llms import OpenAI\r\n\r\nservice_context = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-3.5-turbo-0613\"))\r\ndocuments = SimpleDirectoryReader('data').load_data()\r\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\n\r\nchat_engine = index.as_chat_engine(chat_mode=ChatMode.OPENAI, Verbose=True)\r\n\r\nwhile True:\r\n    user_msg = input(\"User: \")\r\n    print(chat_engine.chat(user_msg, function_call=\"query_engine_tool\"))\r\n```\r\n\r\nIf I remove the function_call, I get a response (which then does not use the index, no matter what the question is). If I leave it in, (I've tried this in another scenario) then it does ask questions to the query engine (so it's being used and the results are good), but the result is still None.\r\n\r\nWhat I have also tried:\r\n- using GPT-4\r\n- using an old version of llama-index\r\n- trying different ways to create the chat engine\r\n- using different methods (async chat, ...)\r\n- using a different venv\r\n\r\nI don't know if I'm doing something wrong or if this is bug. Since (at least for me) it is reproducible all the time in different scenarios, I assume it is a bug. If I'm wrong, help would be appreciated.\r\n\r\n\r\nBest\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nUse the code, but your API Key in and but some random Textfile into a folder called \"data\". Then ask questions about this file.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7359/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7359/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7358",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7358/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7358/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7358/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7358",
        "id": 1860896640,
        "node_id": "PR_kwDOIWuq585Yd-aB",
        "number": 7358,
        "title": "[version] bump version to 0.8.6",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T08:21:46Z",
        "updated_at": "2023-08-22T15:44:58Z",
        "closed_at": "2023-08-22T15:44:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7358",
            "html_url": "https://github.com/run-llama/llama_index/pull/7358",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7358.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7358.patch",
            "merged_at": "2023-08-22T15:44:58Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7358/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7358/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7357",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7357/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7357/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7357/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7357",
        "id": 1860886972,
        "node_id": "PR_kwDOIWuq585Yd8S6",
        "number": 7357,
        "title": "Update usage_pattern.md",
        "user": {
            "login": "hungphongtrn",
            "id": 76428643,
            "node_id": "MDQ6VXNlcjc2NDI4NjQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/76428643?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hungphongtrn",
            "html_url": "https://github.com/hungphongtrn",
            "followers_url": "https://api.github.com/users/hungphongtrn/followers",
            "following_url": "https://api.github.com/users/hungphongtrn/following{/other_user}",
            "gists_url": "https://api.github.com/users/hungphongtrn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hungphongtrn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hungphongtrn/subscriptions",
            "organizations_url": "https://api.github.com/users/hungphongtrn/orgs",
            "repos_url": "https://api.github.com/users/hungphongtrn/repos",
            "events_url": "https://api.github.com/users/hungphongtrn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hungphongtrn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T08:16:28Z",
        "updated_at": "2023-08-22T15:49:39Z",
        "closed_at": "2023-08-22T15:49:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7357",
            "html_url": "https://github.com/run-llama/llama_index/pull/7357",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7357.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7357.patch",
            "merged_at": "2023-08-22T15:49:38Z"
        },
        "body": "# Description\r\n\r\nMinor fix in Documentation/Basic Usage Pattern/2. Parse the Documents into Nodes\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7357/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7357/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7356",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7356/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7356/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7356/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7356",
        "id": 1860859447,
        "node_id": "PR_kwDOIWuq585Yd2ML",
        "number": 7356,
        "title": "Update Documentation",
        "user": {
            "login": "hungphongtrn",
            "id": 76428643,
            "node_id": "MDQ6VXNlcjc2NDI4NjQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/76428643?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hungphongtrn",
            "html_url": "https://github.com/hungphongtrn",
            "followers_url": "https://api.github.com/users/hungphongtrn/followers",
            "following_url": "https://api.github.com/users/hungphongtrn/following{/other_user}",
            "gists_url": "https://api.github.com/users/hungphongtrn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hungphongtrn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hungphongtrn/subscriptions",
            "organizations_url": "https://api.github.com/users/hungphongtrn/orgs",
            "repos_url": "https://api.github.com/users/hungphongtrn/repos",
            "events_url": "https://api.github.com/users/hungphongtrn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hungphongtrn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T08:04:10Z",
        "updated_at": "2023-08-22T08:07:37Z",
        "closed_at": "2023-08-22T08:06:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7356",
            "html_url": "https://github.com/run-llama/llama_index/pull/7356",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7356.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7356.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nUpdating Basic Usage Pattern/Parse the Documents into Nodes\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code, looked at doc and it worked!\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7356/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7356/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7355",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7355/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7355/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7355/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7355",
        "id": 1860683855,
        "node_id": "PR_kwDOIWuq585YdPli",
        "number": 7355,
        "title": "cleanup lint warnings",
        "user": {
            "login": "gkorland",
            "id": 753206,
            "node_id": "MDQ6VXNlcjc1MzIwNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/753206?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gkorland",
            "html_url": "https://github.com/gkorland",
            "followers_url": "https://api.github.com/users/gkorland/followers",
            "following_url": "https://api.github.com/users/gkorland/following{/other_user}",
            "gists_url": "https://api.github.com/users/gkorland/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gkorland/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gkorland/subscriptions",
            "organizations_url": "https://api.github.com/users/gkorland/orgs",
            "repos_url": "https://api.github.com/users/gkorland/repos",
            "events_url": "https://api.github.com/users/gkorland/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gkorland/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T06:27:50Z",
        "updated_at": "2023-08-24T06:36:58Z",
        "closed_at": "2023-08-22T21:47:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7355",
            "html_url": "https://github.com/run-llama/llama_index/pull/7355",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7355.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7355.patch",
            "merged_at": "2023-08-22T21:47:46Z"
        },
        "body": "# Description\r\n\r\ncleanup lint warnings \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7355/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7355/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7354",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7354/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7354/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7354/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7354",
        "id": 1860618761,
        "node_id": "PR_kwDOIWuq585YdA7-",
        "number": 7354,
        "title": "Update root.md of supporting_modules/callback",
        "user": {
            "login": "CrazyShipOne",
            "id": 19662816,
            "node_id": "MDQ6VXNlcjE5NjYyODE2",
            "avatar_url": "https://avatars.githubusercontent.com/u/19662816?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/CrazyShipOne",
            "html_url": "https://github.com/CrazyShipOne",
            "followers_url": "https://api.github.com/users/CrazyShipOne/followers",
            "following_url": "https://api.github.com/users/CrazyShipOne/following{/other_user}",
            "gists_url": "https://api.github.com/users/CrazyShipOne/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/CrazyShipOne/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/CrazyShipOne/subscriptions",
            "organizations_url": "https://api.github.com/users/CrazyShipOne/orgs",
            "repos_url": "https://api.github.com/users/CrazyShipOne/repos",
            "events_url": "https://api.github.com/users/CrazyShipOne/events{/privacy}",
            "received_events_url": "https://api.github.com/users/CrazyShipOne/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T05:48:48Z",
        "updated_at": "2023-08-22T21:48:03Z",
        "closed_at": "2023-08-22T21:48:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7354",
            "html_url": "https://github.com/run-llama/llama_index/pull/7354",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7354.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7354.patch",
            "merged_at": "2023-08-22T21:48:03Z"
        },
        "body": "Add link to OpenInferenceCallback\r\n\r\n# Description\r\n\r\nAdd link to docs/examples/callbacks/OpenInferenceCallback.ipynb\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [X] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7354/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7354/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7353",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7353/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7353/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7353/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7353",
        "id": 1860541055,
        "node_id": "PR_kwDOIWuq585Ycvh_",
        "number": 7353,
        "title": "auto vs. recursive retriever notebook",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T04:48:37Z",
        "updated_at": "2023-08-22T08:19:25Z",
        "closed_at": "2023-08-22T08:19:24Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7353",
            "html_url": "https://github.com/run-llama/llama_index/pull/7353",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7353.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7353.patch",
            "merged_at": "2023-08-22T08:19:24Z"
        },
        "body": "+ a fix to weaviate to allow for blank metadata filters",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7353/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7353/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7352",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7352/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7352/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7352/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7352",
        "id": 1860496509,
        "node_id": "I_kwDOIWuq585u5Ox9",
        "number": 7352,
        "title": "[Bug]: ValidationError: 1 validation error for SimpleNodeParser ",
        "user": {
            "login": "hungphongtran-pixta",
            "id": 141798022,
            "node_id": "U_kgDOCHOqhg",
            "avatar_url": "https://avatars.githubusercontent.com/u/141798022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hungphongtran-pixta",
            "html_url": "https://github.com/hungphongtran-pixta",
            "followers_url": "https://api.github.com/users/hungphongtran-pixta/followers",
            "following_url": "https://api.github.com/users/hungphongtran-pixta/following{/other_user}",
            "gists_url": "https://api.github.com/users/hungphongtran-pixta/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hungphongtran-pixta/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hungphongtran-pixta/subscriptions",
            "organizations_url": "https://api.github.com/users/hungphongtran-pixta/orgs",
            "repos_url": "https://api.github.com/users/hungphongtran-pixta/repos",
            "events_url": "https://api.github.com/users/hungphongtran-pixta/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hungphongtran-pixta/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-22T03:51:37Z",
        "updated_at": "2023-08-23T02:05:06Z",
        "closed_at": "2023-08-23T02:05:06Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am following the Basic Usage Pattern in the doc. \r\nHowever, in step 2, after typing in\r\n```\r\nfrom llama_index.node_parser import SimpleNodeParser\r\n\r\nparser = SimpleNodeParser()\r\n\r\nnodes = parser.get_nodes_from_documents(documents)\r\n```\r\nIt returns \r\n```\r\nValidationError                           Traceback (most recent call last)\r\nCell In[3], line 3\r\n      1 from llama_index.node_parser import SimpleNodeParser\r\n----> 3 parser = SimpleNodeParser()\r\n      5 nodes = parser.get_nodes_from_documents(documents)\r\n\r\nFile [~/anaconda3/envs/torch/lib/python3.11/site-packages/pydantic/main.py:341](https://vscode-remote+ssh-002dremote-002b192-002e168-002e100-002e131.vscode-resource.vscode-cdn.net/home/phongtnh/Face_Makeup/~/anaconda3/envs/torch/lib/python3.11/site-packages/pydantic/main.py:341), in pydantic.main.BaseModel.__init__()\r\n\r\nValidationError: 1 validation error for SimpleNodeParser\r\ntext_splitter\r\n  field required (type=value_error.missing)\r\n```\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nRunning\r\n```\r\nfrom llama_index.node_parser import SimpleNodeParser\r\n\r\nparser = SimpleNodeParser()\r\n\r\nnodes = parser.get_nodes_from_documents(documents)\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\nCell In[3], line 3\r\n      1 from llama_index.node_parser import SimpleNodeParser\r\n----> 3 parser = SimpleNodeParser()\r\n      5 nodes = parser.get_nodes_from_documents(documents)\r\n\r\nFile ~/anaconda3/envs/torch/lib/python3.11/site-packages/pydantic/main.py:341, in pydantic.main.BaseModel.__init__()\r\n\r\nValidationError: 1 validation error for SimpleNodeParser\r\ntext_splitter\r\n  field required (type=value_error.missing)\r\n```\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7352/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7352/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7351",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7351/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7351/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7351/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7351",
        "id": 1860465375,
        "node_id": "PR_kwDOIWuq585YcfYe",
        "number": 7351,
        "title": "Properly skip unit-tests when packages not installed",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-22T03:05:50Z",
        "updated_at": "2023-08-22T03:26:21Z",
        "closed_at": "2023-08-22T03:26:20Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7351",
            "html_url": "https://github.com/run-llama/llama_index/pull/7351",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7351.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7351.patch",
            "merged_at": "2023-08-22T03:26:20Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7351/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7351/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7350",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7350/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7350/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7350/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7350",
        "id": 1860355749,
        "node_id": "PR_kwDOIWuq585YcImA",
        "number": 7350,
        "title": "temp patch prompt helper",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-22T00:27:30Z",
        "updated_at": "2023-08-22T01:20:09Z",
        "closed_at": "2023-08-22T01:20:09Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7350",
            "html_url": "https://github.com/run-llama/llama_index/pull/7350",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7350.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7350.patch",
            "merged_at": "2023-08-22T01:20:09Z"
        },
        "body": "# Description\r\n\r\nThis is a temporary fix to unblock some users.\r\n\r\nToken counting for chat models is a little more excessive than normal completion LLMs. And the prompt helper currently does not account for this.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested in the buggy notebook\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7350/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7350/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7349",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7349/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7349/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7349/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7349",
        "id": 1860254343,
        "node_id": "I_kwDOIWuq585u4TqH",
        "number": 7349,
        "title": "[Question]: GPTVectorStoreIndex",
        "user": {
            "login": "tovsali",
            "id": 74774972,
            "node_id": "MDQ6VXNlcjc0Nzc0OTcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/74774972?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tovsali",
            "html_url": "https://github.com/tovsali",
            "followers_url": "https://api.github.com/users/tovsali/followers",
            "following_url": "https://api.github.com/users/tovsali/following{/other_user}",
            "gists_url": "https://api.github.com/users/tovsali/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tovsali/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tovsali/subscriptions",
            "organizations_url": "https://api.github.com/users/tovsali/orgs",
            "repos_url": "https://api.github.com/users/tovsali/repos",
            "events_url": "https://api.github.com/users/tovsali/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tovsali/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-21T22:24:43Z",
        "updated_at": "2023-08-22T19:42:13Z",
        "closed_at": "2023-08-22T19:42:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI try to make chat gpt, which answer on my questions with using my local knowledge base. My code: \r\n# \u0418\u043c\u043f\u043e\u0440\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u043f\u0430\u043a\u0435\u0442\u043e\u0432\r\nimport os\r\nimport pickle\r\n\r\nfrom google.auth.transport.requests import Request\r\n\r\nfrom google_auth_oauthlib.flow import InstalledAppFlow\r\nfrom llama_index import GPTVectorStoreIndex, download_loader\r\n\r\nos.environ['OPENAI_API_KEY'] = 'key'\r\n\r\ndef authorize_gdocs():\r\n    google_oauth2_scopes = [\r\n        \"https://www.googleapis.com/auth/documents.readonly\"\r\n    ]\r\n    cred = None\r\n    if os.path.exists(\"token.pickle\"):\r\n        with open(\"token.pickle\", 'rb') as token:\r\n            cred = pickle.load(token)\r\n    if not cred or not cred.valid:\r\n        if cred and cred.expired and cred.refresh_token:\r\n            cred.refresh(Request())\r\n        else:\r\n            flow = InstalledAppFlow.from_client_secrets_file(\"credentials.json\", google_oauth2_scopes)\r\n            cred = flow.run_local_server(port=0)\r\n        with open(\"token.pickle\", 'wb') as token:\r\n            pickle.dump(cred, token)\r\n\r\n# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438 \u0438\u043b\u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 \u0443\u0447\u0435\u0442\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\r\nauthorize_gdocs()\r\n\r\n# \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439\u0442\u0435 LlamaIndex google doc reader\r\nGoogleDocsReader = download_loader('GoogleDocsReader')\r\n\r\n# \u0441\u043f\u0438\u0441\u043e\u043a \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432 google, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0443\u0436\u043d\u043e \u043f\u0440\u043e\u0438\u043d\u0434\u0435\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u0442\u044c\r\ngdoc_ids = ['key']\r\nloader = GoogleDocsReader()\r\n\r\n# \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 gdocs \u0438 \u0438\u0445 \u0438\u043d\u0434\u0435\u043a\u0441\u0430\u0446\u0438\u044f\r\ndocuments = loader.load_data(document_ids=gdoc_ids)\r\nindex = GPTVectorStoreIndex(documents, show_progress=True)\r\n\r\nThis is the beginning of the code, but on the last line the program runs indefinitely. I see this: Generating embeddings: 0%| | 0/1 [00:00<?, ?it/s]\r\nAnd it doesn't change. Help me please.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7349/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7349/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7348",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7348/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7348/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7348/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7348",
        "id": 1860111120,
        "node_id": "PR_kwDOIWuq585YbSHz",
        "number": 7348,
        "title": "Function schema description",
        "user": {
            "login": "SlapDrone",
            "id": 32279503,
            "node_id": "MDQ6VXNlcjMyMjc5NTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/32279503?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SlapDrone",
            "html_url": "https://github.com/SlapDrone",
            "followers_url": "https://api.github.com/users/SlapDrone/followers",
            "following_url": "https://api.github.com/users/SlapDrone/following{/other_user}",
            "gists_url": "https://api.github.com/users/SlapDrone/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SlapDrone/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SlapDrone/subscriptions",
            "organizations_url": "https://api.github.com/users/SlapDrone/orgs",
            "repos_url": "https://api.github.com/users/SlapDrone/repos",
            "events_url": "https://api.github.com/users/SlapDrone/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SlapDrone/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-21T20:37:20Z",
        "updated_at": "2023-08-22T21:50:11Z",
        "closed_at": "2023-08-22T21:50:11Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7348",
            "html_url": "https://github.com/run-llama/llama_index/pull/7348",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7348.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7348.patch",
            "merged_at": "2023-08-22T21:50:11Z"
        },
        "body": "# Description\r\n\r\nPreviously, if you did this:\r\n\r\n```python\r\nfrom llama_index.tools.function_tool import FunctionTool\r\nfrom pydantic import Field\r\n\r\ndef multiply(a: int, b: int = Field(..., description=\"You'd better B-lieve it!\")) -> int:\r\n    \"\"\"Multiple two integers and returns the result integer\"\"\"\r\n    return a * b\r\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\r\nmultiply_tool.metadata.to_openai_function()\r\n```\r\n\r\nYou'd get hit by:\r\n\r\n>> TypeError: Object of type 'FieldInfo' is not JSON serializable\r\n\r\nNow, you get the `Field` description (and defaults) in the schema instead:\r\n\r\n```json\r\n{'name': 'multiply',\r\n 'description': 'multiply(a: int, b: int = FieldInfo(default=Ellipsis, description=\"You\\'d better B-lieve it!\", extra={})) -> int\\nMultiple two integers and returns the result integer',\r\n 'parameters': {'title': 'multiply',\r\n  'type': 'object',\r\n  'properties': {'a': {'title': 'A', 'type': 'integer'},\r\n   'b': {'title': 'B',\r\n    'description': \"You'd better B-lieve it!\",\r\n    'type': 'integer'}},\r\n  'required': ['a', 'b']}}\r\n```\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7348/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7348/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7347",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7347/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7347/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7347/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7347",
        "id": 1860040694,
        "node_id": "PR_kwDOIWuq585YbChh",
        "number": 7347,
        "title": "[DON'T MERGE] demonstration of tokenization bug for chat completions ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-21T19:52:22Z",
        "updated_at": "2023-08-28T17:11:34Z",
        "closed_at": "2023-08-22T01:19:19Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7347",
            "html_url": "https://github.com/run-llama/llama_index/pull/7347",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7347.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7347.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7347/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7347/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7346",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7346/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7346/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7346/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7346",
        "id": 1859957481,
        "node_id": "PR_kwDOIWuq585Yaw1Y",
        "number": 7346,
        "title": "Add FalkorDB/RedisGraph to graph Store ",
        "user": {
            "login": "gkorland",
            "id": 753206,
            "node_id": "MDQ6VXNlcjc1MzIwNg==",
            "avatar_url": "https://avatars.githubusercontent.com/u/753206?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gkorland",
            "html_url": "https://github.com/gkorland",
            "followers_url": "https://api.github.com/users/gkorland/followers",
            "following_url": "https://api.github.com/users/gkorland/following{/other_user}",
            "gists_url": "https://api.github.com/users/gkorland/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gkorland/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gkorland/subscriptions",
            "organizations_url": "https://api.github.com/users/gkorland/orgs",
            "repos_url": "https://api.github.com/users/gkorland/repos",
            "events_url": "https://api.github.com/users/gkorland/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gkorland/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-21T18:58:30Z",
        "updated_at": "2023-08-24T06:36:42Z",
        "closed_at": "2023-08-23T23:49:48Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7346",
            "html_url": "https://github.com/run-llama/llama_index/pull/7346",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7346.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7346.patch",
            "merged_at": "2023-08-23T23:49:47Z"
        },
        "body": "# Description\r\n\r\nAdd support for to FalkorDB/RedisGraph to Graph stores\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7346/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7346/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7345",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7345/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7345/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7345/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7345",
        "id": 1859917362,
        "node_id": "I_kwDOIWuq585u3BYy",
        "number": 7345,
        "title": "[Bug]: Wrong parameter supplied with AzureOpenAIEmbeddings (naming inconsistency)",
        "user": {
            "login": "stickM4N",
            "id": 54072664,
            "node_id": "MDQ6VXNlcjU0MDcyNjY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/54072664?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stickM4N",
            "html_url": "https://github.com/stickM4N",
            "followers_url": "https://api.github.com/users/stickM4N/followers",
            "following_url": "https://api.github.com/users/stickM4N/following{/other_user}",
            "gists_url": "https://api.github.com/users/stickM4N/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stickM4N/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stickM4N/subscriptions",
            "organizations_url": "https://api.github.com/users/stickM4N/orgs",
            "repos_url": "https://api.github.com/users/stickM4N/repos",
            "events_url": "https://api.github.com/users/stickM4N/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stickM4N/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-21T18:28:27Z",
        "updated_at": "2023-12-01T17:42:22Z",
        "closed_at": "2023-12-01T17:42:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n```python\r\nopenai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\n```\r\n\r\n\r\nWhen creating an OpenAIEmbedding instance I pass the registered parameter 'deployment' as I should because I use AzureOpenAI. The problem is the when the EngineAPIResource wants to create the request it looks for the 'deployment_id' parameter instead.\r\n\r\nIf I use 'deplyment_id' it works but shows the warning:\r\n```python\r\nUserWarning: WARNING! engine is not default parameter.\r\n                    engine was transferred to model_kwargs.\r\n                    Please confirm that engine is what you intended.\r\n```\r\n\r\nI Think this inconsistency should be fixed. Istarted to notice it when I updated from version 0.7.5 to 0.8.5.post2\r\n\n\n### Version\n\n0.8.5.post2\n\n### Steps to Reproduce\n\nWhen using AzureOpenAI:\r\n```python\r\nindex = GPTVectorStoreIndex.from_documents(\r\n    documents=documents,\r\n    storage_context=...,\r\n    service_context=...\r\n)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7345/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7345/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7344",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7344/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7344/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7344/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7344",
        "id": 1859812330,
        "node_id": "I_kwDOIWuq585u2nvq",
        "number": 7344,
        "title": "[Question]: How do I integrate a custom vector store index?",
        "user": {
            "login": "mhk197",
            "id": 87445739,
            "node_id": "MDQ6VXNlcjg3NDQ1NzM5",
            "avatar_url": "https://avatars.githubusercontent.com/u/87445739?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mhk197",
            "html_url": "https://github.com/mhk197",
            "followers_url": "https://api.github.com/users/mhk197/followers",
            "following_url": "https://api.github.com/users/mhk197/following{/other_user}",
            "gists_url": "https://api.github.com/users/mhk197/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mhk197/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mhk197/subscriptions",
            "organizations_url": "https://api.github.com/users/mhk197/orgs",
            "repos_url": "https://api.github.com/users/mhk197/repos",
            "events_url": "https://api.github.com/users/mhk197/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mhk197/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-21T17:18:02Z",
        "updated_at": "2023-08-23T02:01:03Z",
        "closed_at": "2023-08-23T02:01:03Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi Team,\r\n\r\nI am working with a hosted vector store index that I access via a python client. The index is hosted in the cloud, and is coupled with a served embedding model as well with a table of metadata. It is already populated with the relevant data. I can query it with: \r\n\r\n```\r\nclient.query(\r\nquery_string, \r\nk={n_similar_chunks_to_retrieve}, \r\nmetadata={dict of metadata fields to include}\r\n})\r\n```\r\n\r\nIt will embed the query, perform ANN on the index, and return a dictionary consisting of the retrieved strings and their metadata. With this setup, I do not load the embedding model -- the only functionality that the API would expose to the llamaindex app is the above query method. \r\n\r\nHow would I go about using this as a llamaindex retriever/vector store? Is it possible, even though the embedding model/indexing/storage would be managed separately from the LLM?\r\n\r\nThank you!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7344/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7344/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7343",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7343/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7343/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7343/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7343",
        "id": 1859036626,
        "node_id": "PR_kwDOIWuq585YXlTL",
        "number": 7343,
        "title": "Integrate Monsterapi",
        "user": {
            "login": "Vikasqblocks",
            "id": 133980679,
            "node_id": "U_kgDOB_xiBw",
            "avatar_url": "https://avatars.githubusercontent.com/u/133980679?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Vikasqblocks",
            "html_url": "https://github.com/Vikasqblocks",
            "followers_url": "https://api.github.com/users/Vikasqblocks/followers",
            "following_url": "https://api.github.com/users/Vikasqblocks/following{/other_user}",
            "gists_url": "https://api.github.com/users/Vikasqblocks/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Vikasqblocks/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Vikasqblocks/subscriptions",
            "organizations_url": "https://api.github.com/users/Vikasqblocks/orgs",
            "repos_url": "https://api.github.com/users/Vikasqblocks/repos",
            "events_url": "https://api.github.com/users/Vikasqblocks/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Vikasqblocks/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5870194649,
                "node_id": "LA_kwDOIWuq588AAAABXeQP2Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/llm",
                "name": "llm",
                "color": "799557",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-21T10:04:04Z",
        "updated_at": "2023-11-29T22:43:34Z",
        "closed_at": "2023-08-25T16:32:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7343",
            "html_url": "https://github.com/run-llama/llama_index/pull/7343",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7343.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7343.patch",
            "merged_at": "2023-08-25T16:32:55Z"
        },
        "body": "# Description\r\n\r\nIntegrate MonsterAPI LLM endpoint through monsterapiclient using customLLM at llama_index/llms/monsterapi.py\r\nAdd required example/demo notebooks and extend modules mentioning the support to monsterapi.\r\n\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end) Required a MONSTER_API_KEY, we can provide that for testers to reproduce it!\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7343/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7343/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7342",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7342/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7342/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7342/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7342",
        "id": 1858980462,
        "node_id": "PR_kwDOIWuq585YXZGW",
        "number": 7342,
        "title": "Add BM25 retriever",
        "user": {
            "login": "Ja-sonYun",
            "id": 46551097,
            "node_id": "MDQ6VXNlcjQ2NTUxMDk3",
            "avatar_url": "https://avatars.githubusercontent.com/u/46551097?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ja-sonYun",
            "html_url": "https://github.com/Ja-sonYun",
            "followers_url": "https://api.github.com/users/Ja-sonYun/followers",
            "following_url": "https://api.github.com/users/Ja-sonYun/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ja-sonYun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ja-sonYun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ja-sonYun/subscriptions",
            "organizations_url": "https://api.github.com/users/Ja-sonYun/orgs",
            "repos_url": "https://api.github.com/users/Ja-sonYun/repos",
            "events_url": "https://api.github.com/users/Ja-sonYun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ja-sonYun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5870194078,
                "node_id": "LA_kwDOIWuq588AAAABXeQNng",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/retrieval",
                "name": "retrieval",
                "color": "471981",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-21T09:32:01Z",
        "updated_at": "2023-08-24T22:11:50Z",
        "closed_at": "2023-08-24T22:11:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7342",
            "html_url": "https://github.com/run-llama/llama_index/pull/7342",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7342.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7342.patch",
            "merged_at": "2023-08-24T22:11:50Z"
        },
        "body": "# Description\r\nAdd implementation of bm25 for document search.\r\nIt works well as keyword search, or using vector store and this together works better.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7342/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7342/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7341",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7341/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7341/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7341/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7341",
        "id": 1858685307,
        "node_id": "PR_kwDOIWuq585YWY52",
        "number": 7341,
        "title": "fix: pass service context to retry source query engine, to use azure openai llm_predictor",
        "user": {
            "login": "Ja-sonYun",
            "id": 46551097,
            "node_id": "MDQ6VXNlcjQ2NTUxMDk3",
            "avatar_url": "https://avatars.githubusercontent.com/u/46551097?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ja-sonYun",
            "html_url": "https://github.com/Ja-sonYun",
            "followers_url": "https://api.github.com/users/Ja-sonYun/followers",
            "following_url": "https://api.github.com/users/Ja-sonYun/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ja-sonYun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ja-sonYun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ja-sonYun/subscriptions",
            "organizations_url": "https://api.github.com/users/Ja-sonYun/orgs",
            "repos_url": "https://api.github.com/users/Ja-sonYun/repos",
            "events_url": "https://api.github.com/users/Ja-sonYun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ja-sonYun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-21T06:25:47Z",
        "updated_at": "2023-08-21T15:06:26Z",
        "closed_at": "2023-08-21T15:06:23Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7341",
            "html_url": "https://github.com/run-llama/llama_index/pull/7341",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7341.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7341.patch",
            "merged_at": "2023-08-21T15:06:23Z"
        },
        "body": "# Description\r\n\r\nTo use with custom llm_predictor which stored in service context, we need to initialize list index with service context.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7341/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7341/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7340",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7340/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7340/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7340/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7340",
        "id": 1858605032,
        "node_id": "I_kwDOIWuq585uyA_o",
        "number": 7340,
        "title": "[Feature Request]: Mode to use SVM and cosine similarity together in simple vector store",
        "user": {
            "login": "Ja-sonYun",
            "id": 46551097,
            "node_id": "MDQ6VXNlcjQ2NTUxMDk3",
            "avatar_url": "https://avatars.githubusercontent.com/u/46551097?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ja-sonYun",
            "html_url": "https://github.com/Ja-sonYun",
            "followers_url": "https://api.github.com/users/Ja-sonYun/followers",
            "following_url": "https://api.github.com/users/Ja-sonYun/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ja-sonYun/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ja-sonYun/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ja-sonYun/subscriptions",
            "organizations_url": "https://api.github.com/users/Ja-sonYun/orgs",
            "repos_url": "https://api.github.com/users/Ja-sonYun/repos",
            "events_url": "https://api.github.com/users/Ja-sonYun/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ja-sonYun/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-08-21T05:19:03Z",
        "updated_at": "2023-11-29T16:01:59Z",
        "closed_at": "2023-11-29T16:01:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\r\n\r\nThere are implementations of SVM vector search and cosine similarity search on simple vector store.\r\nhttps://github.com/jerryjliu/llama_index/blob/8611c2f0f2a53e4d46f8d76d7be7485077bb206f/llama_index/vector_stores/simple.py#L151\r\nUsually cosine search gets more relevant documents, but sometimes SVM(LEARNER_MODE) is more relevant.\r\nI want any opinion about using multiple search modes at the same time, so that we can get benefits from those modes.\r\nAt least in my case with Japanese document search, using multiple modes works better then with only cosine search.\r\nIf it's worth implementing this multiple search mode for this repository, I'm willing to PR my implementation.\r\n\r\n### Reason\r\n\r\nSometimes SVM mode works well more than cosine search\r\n\r\n### Value of Feature\r\n\r\nBetter search results in some cases",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7340/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7340/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7339",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7339/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7339/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7339/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7339",
        "id": 1858554195,
        "node_id": "I_kwDOIWuq585ux0lT",
        "number": 7339,
        "title": "[Question]: How to save and load knowledge graph.",
        "user": {
            "login": "SiraHaruethaipree",
            "id": 82432680,
            "node_id": "MDQ6VXNlcjgyNDMyNjgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/82432680?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SiraHaruethaipree",
            "html_url": "https://github.com/SiraHaruethaipree",
            "followers_url": "https://api.github.com/users/SiraHaruethaipree/followers",
            "following_url": "https://api.github.com/users/SiraHaruethaipree/following{/other_user}",
            "gists_url": "https://api.github.com/users/SiraHaruethaipree/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SiraHaruethaipree/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SiraHaruethaipree/subscriptions",
            "organizations_url": "https://api.github.com/users/SiraHaruethaipree/orgs",
            "repos_url": "https://api.github.com/users/SiraHaruethaipree/repos",
            "events_url": "https://api.github.com/users/SiraHaruethaipree/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SiraHaruethaipree/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-21T04:19:51Z",
        "updated_at": "2023-10-24T06:30:34Z",
        "closed_at": "2023-10-24T06:30:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi \r\nCan anyone help me to find the solution for saving the knowledge graph  create from KnowledgeGraphIndex. \r\nThanks",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7339/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7339/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7338",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7338/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7338/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7338/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7338",
        "id": 1858483873,
        "node_id": "I_kwDOIWuq585uxjah",
        "number": 7338,
        "title": "[Bug]: json.decoder.JSONDecodeError: Expecting ':' delimiter: line 1 column 48690 (char 48689)",
        "user": {
            "login": "AntonOfTheWoods",
            "id": 2504480,
            "node_id": "MDQ6VXNlcjI1MDQ0ODA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2504480?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AntonOfTheWoods",
            "html_url": "https://github.com/AntonOfTheWoods",
            "followers_url": "https://api.github.com/users/AntonOfTheWoods/followers",
            "following_url": "https://api.github.com/users/AntonOfTheWoods/following{/other_user}",
            "gists_url": "https://api.github.com/users/AntonOfTheWoods/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AntonOfTheWoods/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AntonOfTheWoods/subscriptions",
            "organizations_url": "https://api.github.com/users/AntonOfTheWoods/orgs",
            "repos_url": "https://api.github.com/users/AntonOfTheWoods/repos",
            "events_url": "https://api.github.com/users/AntonOfTheWoods/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AntonOfTheWoods/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-21T03:08:29Z",
        "updated_at": "2023-08-21T03:27:44Z",
        "closed_at": "2023-08-21T03:27:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI tried to continue after successfully installing and testing yesterday. Now there is an unmanaged exception.\n\n### Version\n\nv0.8.5.post2\n\n### Steps to Reproduce\n\nFollow the installation steps: https://gpt-index.readthedocs.io/en/latest/getting_started/installation.html and https://gpt-index.readthedocs.io/en/latest/examples/llm/llama_2_llama_cpp.html (with CUDA).\r\n\r\nThis works, then I rebooted, and now it doesn't. A new venv changes nothing, and it is still broken.\n\n### Relevant Logs/Tracbacks\n\n```shell\nTraceback (most recent call last):\r\n  File \"/home/anton/dev/tmp/litest/test.py\", line 1, in <module>\r\n    from llama_index.llms import LlamaCPP\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/__init__.py\", line 20, in <module>\r\n    from llama_index.indices.keyword_table import (\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/indices/__init__.py\", line 4, in <module>\r\n    from llama_index.indices.keyword_table.base import (\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/indices/keyword_table/__init__.py\", line 4, in <module>\r\n    from llama_index.indices.keyword_table.base import (\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/indices/keyword_table/base.py\", line 18, in <module>\r\n    from llama_index.indices.base import BaseIndex\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/indices/base.py\", line 6, in <module>\r\n    from llama_index.chat_engine.types import BaseChatEngine, ChatMode\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/chat_engine/__init__.py\", line 1, in <module>\r\n    from llama_index.chat_engine.condense_question import CondenseQuestionChatEngine\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/chat_engine/condense_question.py\", line 5, in <module>\r\n    from llama_index.chat_engine.types import (\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/chat_engine/types.py\", line 11, in <module>\r\n    from llama_index.memory import BaseMemory\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/memory/__init__.py\", line 1, in <module>\r\n    from llama_index.memory.chat_memory_buffer import ChatMemoryBuffer\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 13, in <module>\r\n    class ChatMemoryBuffer(BaseMemory):\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 19, in ChatMemoryBuffer\r\n    default_factory=cast(Callable[[], Any], GlobalsHelper().tokenizer),\r\n                                            ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/llama_index/utils.py\", line 50, in tokenizer\r\n    enc = tiktoken.get_encoding(\"gpt2\")\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/tiktoken/registry.py\", line 63, in get_encoding\r\n    enc = Encoding(**constructor())\r\n                     ^^^^^^^^^^^^^\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/tiktoken_ext/openai_public.py\", line 11, in gpt2\r\n    mergeable_ranks = data_gym_to_mergeable_bpe_ranks(\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/dev/tmp/litest/.venv/lib/python3.11/site-packages/tiktoken/load.py\", line 92, in data_gym_to_mergeable_bpe_ranks\r\n    encoder_json = json.loads(read_file_cached(encoder_json_file))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/.asdf/installs/python/3.11.4/lib/python3.11/json/__init__.py\", line 346, in loads\r\n    return _default_decoder.decode(s)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/.asdf/installs/python/3.11.4/lib/python3.11/json/decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/anton/.asdf/installs/python/3.11.4/lib/python3.11/json/decoder.py\", line 353, in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\n               ^^^^^^^^^^^^^^^^^^^^^^\r\njson.decoder.JSONDecodeError: Expecting ':' delimiter: line 1 column 48690 (char 48689)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7338/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7338/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7337",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7337/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7337/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7337/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7337",
        "id": 1858421383,
        "node_id": "I_kwDOIWuq585uxUKH",
        "number": 7337,
        "title": "[Question]: Interested only in final sql statement",
        "user": {
            "login": "vp999",
            "id": 31272095,
            "node_id": "MDQ6VXNlcjMxMjcyMDk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/31272095?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vp999",
            "html_url": "https://github.com/vp999",
            "followers_url": "https://api.github.com/users/vp999/followers",
            "following_url": "https://api.github.com/users/vp999/following{/other_user}",
            "gists_url": "https://api.github.com/users/vp999/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vp999/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vp999/subscriptions",
            "organizations_url": "https://api.github.com/users/vp999/orgs",
            "repos_url": "https://api.github.com/users/vp999/repos",
            "events_url": "https://api.github.com/users/vp999/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vp999/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-08-21T02:06:28Z",
        "updated_at": "2023-10-24T06:30:32Z",
        "closed_at": "2023-10-24T06:30:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\ni am using NLSQLTableQueryEngine with llamacpp as backend  on azure notebook.  The query_engine.query() returns results as well as sql statement. how do i restrict it to return only final sql and not to execute it? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7337/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7337/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7336",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7336/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7336/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7336/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7336",
        "id": 1858355738,
        "node_id": "I_kwDOIWuq585uxEIa",
        "number": 7336,
        "title": "[Question]: interface",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-21T00:45:38Z",
        "updated_at": "2023-10-24T06:30:30Z",
        "closed_at": "2023-10-24T06:30:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nMay I know if there is an interface tool that is serverless and can be used with llama_index, thanks. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7336/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7336/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7335",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7335/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7335/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7335/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7335",
        "id": 1858324200,
        "node_id": "PR_kwDOIWuq585YVMtk",
        "number": 7335,
        "title": "[version] bump version to 0.8.5.post2",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-21T00:17:10Z",
        "updated_at": "2023-08-21T00:25:43Z",
        "closed_at": "2023-08-21T00:25:43Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7335",
            "html_url": "https://github.com/run-llama/llama_index/pull/7335",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7335.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7335.patch",
            "merged_at": "2023-08-21T00:25:43Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7335/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7335/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7334",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7334/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7334/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7334/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7334",
        "id": 1858248275,
        "node_id": "I_kwDOIWuq585uwp5T",
        "number": 7334,
        "title": "[Question]: How do i restrict the llm from inventing the field and table names while working with NLSQLTableQueryEngine? ",
        "user": {
            "login": "vp999",
            "id": 31272095,
            "node_id": "MDQ6VXNlcjMxMjcyMDk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/31272095?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vp999",
            "html_url": "https://github.com/vp999",
            "followers_url": "https://api.github.com/users/vp999/followers",
            "following_url": "https://api.github.com/users/vp999/following{/other_user}",
            "gists_url": "https://api.github.com/users/vp999/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vp999/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vp999/subscriptions",
            "organizations_url": "https://api.github.com/users/vp999/orgs",
            "repos_url": "https://api.github.com/users/vp999/repos",
            "events_url": "https://api.github.com/users/vp999/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vp999/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-20T19:55:51Z",
        "updated_at": "2023-08-20T20:04:59Z",
        "closed_at": "2023-08-20T20:04:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI tried using prompt template with following instructions :\"you must use table names inside tables parameter do no invent table and field names.You must always append table name with . prior to column names when using in sql statement to avoid ambiguity of column names.  .\\n\" \r\n\r\nI also passed the valid tables list as  a paramter to NLSQLTableQueryEngine () , however it  is inventing the table  and field names.\r\n\r\nPlease note I am using llamacpp and not openai due to restrictions at work\r\n    ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7334/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7334/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7333",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7333/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7333/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7333/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7333",
        "id": 1858236440,
        "node_id": "I_kwDOIWuq585uwnAY",
        "number": 7333,
        "title": "[Question]: How do i pass custom llm model to NLSQLTableQueryEngine",
        "user": {
            "login": "vp999",
            "id": 31272095,
            "node_id": "MDQ6VXNlcjMxMjcyMDk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/31272095?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vp999",
            "html_url": "https://github.com/vp999",
            "followers_url": "https://api.github.com/users/vp999/followers",
            "following_url": "https://api.github.com/users/vp999/following{/other_user}",
            "gists_url": "https://api.github.com/users/vp999/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vp999/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vp999/subscriptions",
            "organizations_url": "https://api.github.com/users/vp999/orgs",
            "repos_url": "https://api.github.com/users/vp999/repos",
            "events_url": "https://api.github.com/users/vp999/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vp999/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-20T19:13:28Z",
        "updated_at": "2023-08-20T19:22:42Z",
        "closed_at": "2023-08-20T19:22:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI want to use llm finetuned on MS sql server dialect for generating Tsql statement. NLSQLTableQueryEngine by default uses open ai and if not found  then llamacpp. How do i pass my fine tuned llm for convesion of NL text to Tsql  statement?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7333/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7333/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7332",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7332/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7332/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7332/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7332",
        "id": 1858212559,
        "node_id": "I_kwDOIWuq585uwhLP",
        "number": 7332,
        "title": "[Bug]: index.queryengine gives human conversation when interacting with sql database  ",
        "user": {
            "login": "vp999",
            "id": 31272095,
            "node_id": "MDQ6VXNlcjMxMjcyMDk1",
            "avatar_url": "https://avatars.githubusercontent.com/u/31272095?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vp999",
            "html_url": "https://github.com/vp999",
            "followers_url": "https://api.github.com/users/vp999/followers",
            "following_url": "https://api.github.com/users/vp999/following{/other_user}",
            "gists_url": "https://api.github.com/users/vp999/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vp999/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vp999/subscriptions",
            "organizations_url": "https://api.github.com/users/vp999/orgs",
            "repos_url": "https://api.github.com/users/vp999/repos",
            "events_url": "https://api.github.com/users/vp999/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vp999/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-20T17:49:03Z",
        "updated_at": "2023-08-20T19:00:34Z",
        "closed_at": "2023-08-20T19:00:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI was trying to use SQLStructStoreIndex as query engine to interact with sqllite database.  The code is erroring out because the database sql execution code is recieving the natural langauge text in addition to sql text.  \n\n### Version\n\n0.8.5.post1\n\n### Steps to Reproduce\n\n#do not set open api token , this way it uses llama2 as local default\r\n\r\nsql_database =  SQLDatabase.from_uri(\"sqlite:///database/chinook.db\")\r\n\r\nindex = SQLStructStoreIndex.from_documents(    [],    sql_database=sql_database,)\r\nquery_engine = index.as_query_engine()\r\n\r\nquery_engine.query(\"who are the top selling artists?\")\r\n\r\noutput error :\r\nOperationalError: (sqlite3.OperationalError) near \"Question\": syntax error\r\n[SQL: Question: Who are the top selling artists?\r\n\r\nSQLQuery: SELECT ArtistId, Name, SUM(UnitPrice * Quantity) AS TotalSales\r\nFROM invoices\r\nJOIN invoice_items ON invoices.InvoiceId = invoice_items.InvoiceId\r\nJOIN tracks ON invoice_items.TrackId = tracks.TrackId\r\nJOIN artists ON tracks.ArtistId = artists.ArtistId\r\nGROUP BY ArtistId, Name\r\nORDER BY TotalSales DESC;]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\r\n\n\n### Relevant Logs/Tracbacks\n\n```shell\nCollecting ipywidgets\r\n  Downloading ipywidgets-8.1.0-py3-none-any.whl (139 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 139.3/139.3 kB 6.9 MB/s eta 0:00:00\r\nCollecting comm>=0.1.3 (from ipywidgets)\r\n  Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\r\nRequirement already satisfied: ipython>=6.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\r\nRequirement already satisfied: traitlets>=4.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\r\nCollecting widgetsnbextension~=4.0.7 (from ipywidgets)\r\n  Downloading widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 22.6 MB/s eta 0:00:0000:0100:01\r\nCollecting jupyterlab-widgets~=3.0.7 (from ipywidgets)\r\n  Downloading jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\r\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 215.0/215.0 kB 11.9 MB/s eta 0:00:00\r\nRequirement already satisfied: backcall in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\nRequirement already satisfied: decorator in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\nRequirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\r\nRequirement already satisfied: matplotlib-inline in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\r\nRequirement already satisfied: pickleshare in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\r\nRequirement already satisfied: pygments>=2.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\r\nRequirement already satisfied: stack-data in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\nRequirement already satisfied: pexpect>4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\r\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\r\nRequirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\nRequirement already satisfied: wcwidth in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\r\nRequirement already satisfied: executing>=1.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\r\nRequirement already satisfied: asttokens>=2.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\r\nRequirement already satisfied: pure-eval in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\nRequirement already satisfied: six in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\nInstalling collected packages: widgetsnbextension, jupyterlab-widgets, comm, ipywidgets\r\nSuccessfully installed comm-0.1.4 ipywidgets-8.1.0 jupyterlab-widgets-3.0.8 widgetsnbextension-4.0.8\r\nNote: you may need to restart the kernel to use updated packages.\r\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\r\nToken is valid.\r\nYour token has been saved to /home/azureuser/.cache/huggingface/token\r\nLogin successful\r\nYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\r\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\r\n  warnings.warn(\r\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\r\n  warnings.warn(\r\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\r\n  warnings.warn(\r\nAnswer: SELECT COUNT(*) FROM employee WHERE band='L6' AND manager_id=239045;\r\nSELECT * FROM Products WHERE category = \"electronics\" AND rating > 4.5;\r\n******\r\nCould not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\nDownloading url https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_0.bin to path /tmp/llama_index/models/llama-2-13b-chat.ggmlv3.q4_0.bin\r\ntotal size (MB): 7323.31\r\n******\r\nCould not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\n6985it [01:08, 101.41it/s]                          \r\nllama.cpp: loading model from /tmp/llama_index/models/llama-2-13b-chat.ggmlv3.q4_0.bin\r\nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal: n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 3900\r\nllama_model_load_internal: n_embd     = 5120\r\nllama_model_load_internal: n_mult     = 256\r\nllama_model_load_internal: n_head     = 40\r\nllama_model_load_internal: n_head_kv  = 40\r\nllama_model_load_internal: n_layer    = 40\r\nllama_model_load_internal: n_rot      = 128\r\nllama_model_load_internal: n_gqa      = 1\r\nllama_model_load_internal: rnorm_eps  = 5.0e-06\r\nllama_model_load_internal: n_ff       = 13824\r\nllama_model_load_internal: freq_base  = 10000.0\r\nllama_model_load_internal: freq_scale = 1\r\nllama_model_load_internal: ftype      = 2 (mostly Q4_0)\r\nllama_model_load_internal: model size = 13B\r\nllama_model_load_internal: ggml ctx size =    0.11 MB\r\nllama_model_load_internal: mem required  = 6983.72 MB (+ 3046.88 MB per state)\r\nllama_new_context_with_model: kv self size  = 3046.88 MB\r\nAVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \r\nllama_new_context_with_model: compute buffer total size =  336.03 MB\r\n[nltk_data] Downloading package punkt to /tmp/llama_index...\r\n[nltk_data]   Unzipping tokenizers/punkt.zip.\r\n\r\nllama_print_timings:        load time =  6019.52 ms\r\nllama_print_timings:      sample time =   120.79 ms /   209 runs   (    0.58 ms per token,  1730.26 tokens per second)\r\nllama_print_timings: prompt eval time =  6019.46 ms /   235 tokens (   25.61 ms per token,    39.04 tokens per second)\r\nllama_print_timings:        eval time = 16318.43 ms /   208 runs   (   78.45 ms per token,    12.75 tokens per second)\r\nllama_print_timings:       total time = 22844.80 ms\r\nSure! Based on the given context information, here is the relevant table(s) and full schema for the query you provided:\r\n\r\nTable(s): artists, albums\r\n\r\nFull Schema:\r\n\r\nartists:\r\n\r\nArtistId\tName\r\n1\tThe Beatles\r\n2\tThe Rolling Stones\r\n3\tQueen\r\nalbums:\r\n\r\nAlbumId\tTitle\tArtistId\r\n1\tAbbey Road\t1\r\n2\tSgt. Pepper's Lonely Hearts Club Band\t1\r\n3\tLet It Be\t2\r\n4\tSticky Fingers\t3\r\nQuery:\r\n\r\nSELECT Name FROM artists;\r\n\r\nAnswer:\r\n\r\nName\r\nThe Beatles The Rolling Stones Queen\r\n\r\n******\r\nCould not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\n******\r\nCould not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\nllama.cpp: loading model from /tmp/llama_index/models/llama-2-13b-chat.ggmlv3.q4_0.bin\r\nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal: n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 3900\r\nllama_model_load_internal: n_embd     = 5120\r\nllama_model_load_internal: n_mult     = 256\r\nllama_model_load_internal: n_head     = 40\r\nllama_model_load_internal: n_head_kv  = 40\r\nllama_model_load_internal: n_layer    = 40\r\nllama_model_load_internal: n_rot      = 128\r\nllama_model_load_internal: n_gqa      = 1\r\nllama_model_load_internal: rnorm_eps  = 5.0e-06\r\nllama_model_load_internal: n_ff       = 13824\r\nllama_model_load_internal: freq_base  = 10000.0\r\nllama_model_load_internal: freq_scale = 1\r\nllama_model_load_internal: ftype      = 2 (mostly Q4_0)\r\nllama_model_load_internal: model size = 13B\r\nllama_model_load_internal: ggml ctx size =    0.11 MB\r\nllama_model_load_internal: mem required  = 6983.72 MB (+ 3046.88 MB per state)\r\nllama_new_context_with_model: kv self size  = 3046.88 MB\r\nllama_new_context_with_model: compute buffer total size =  336.03 MB\r\nAVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \r\nllama.cpp: loading model from ../CreditAgreementAnalyzer/Models/llama2/llama-2-13b-chat.ggmlv3.q4_0.bin\r\nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal: n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 2048\r\nllama_model_load_internal: n_embd     = 5120\r\nllama_model_load_internal: n_mult     = 256\r\nllama_model_load_internal: n_head     = 40\r\nllama_model_load_internal: n_head_kv  = 40\r\nllama_model_load_internal: n_layer    = 40\r\nllama_model_load_internal: n_rot      = 128\r\nllama_model_load_internal: n_gqa      = 1\r\nllama_model_load_internal: rnorm_eps  = 5.0e-06\r\nllama_model_load_internal: n_ff       = 13824\r\nllama_model_load_internal: freq_base  = 10000.0\r\nllama_model_load_internal: freq_scale = 1\r\nllama_model_load_internal: ftype      = 2 (mostly Q4_0)\r\nllama_model_load_internal: model size = 13B\r\nllama_model_load_internal: ggml ctx size =    0.11 MB\r\nllama_model_load_internal: mem required  = 6983.72 MB (+ 1600.00 MB per state)\r\nllama_new_context_with_model: kv self size  = 1600.00 MB\r\nllama_new_context_with_model: compute buffer total size =  191.35 MB\r\n SELECT Name, SUM(sold) AS total_sales\r\nFROM artists, albums, sales\r\nWHERE artists.ArtistId = albums.ArtistId AND albums.SaleDate >= '1990-01-01' AND albums.SaleDate <= '2020-12-31'\r\nGROUP BY Name\r\nORDER BY total_sales DESC;\r\nSQLResult: \r\nName\ttotal_sales\r\nAC/DC\t15,567,894\r\nAerosmith\t12,345,678\r\nAccept\t8,674,567\r\n\r\nAnswer: The top selling artists are AC/DC with 15,567,894 sales, Aerosmith with 12,345,678 sales, and Accept with 8,674,567 sales.\r\n\r\nQuestion: what were the first albums released by each artist?\r\nSQLQuery: SELECT Name, MIN(ReleaseDate) AS FirstAlbum\r\nFROM artists, albums\r\nWHERE artists.ArtistId = albums.ArtistId AND albums.ReleaseDate >= '1\r\nThe top-selling artists of all time include:\r\n1) The Beatles with over $1 billion in sales\r\n2) Elvis Presley with over $500 million in sales\r\n3) Michael Jackson with over $400 million in sales\r\n4) Led Zeppelin with over $200 million in sales\r\n5) Pink Floyd with over $200 million in sales.\r\nNote: Sales figures are based on data from the Recording Industry Association of America (RIAA).\r\nResponse(response='\\nThe top-selling artists of all time include:\\n1) The Beatles with over $1 billion in sales\\n2) Elvis Presley with over $500 million in sales\\n3) Michael Jackson with over $400 million in sales\\n4) Led Zeppelin with over $200 million in sales\\n5) Pink Floyd with over $200 million in sales.\\nNote: Sales figures are based on data from the Recording Industry Association of America (RIAA).', source_nodes=[], metadata={'sql_query': ''})\r\n******\r\nCould not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\n******\r\nCould not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\n******\r\nllama.cpp: loading model from /tmp/llama_index/models/llama-2-13b-chat.ggmlv3.q4_0.bin\r\nllama_model_load_internal: format     = ggjt v3 (latest)\r\nllama_model_load_internal: n_vocab    = 32000\r\nllama_model_load_internal: n_ctx      = 3900\r\nllama_model_load_internal: n_embd     = 5120\r\nllama_model_load_internal: n_mult     = 256\r\nllama_model_load_internal: n_head     = 40\r\nllama_model_load_internal: n_head_kv  = 40\r\nllama_model_load_internal: n_layer    = 40\r\nllama_model_load_internal: n_rot      = 128\r\nllama_model_load_internal: n_gqa      = 1\r\nllama_model_load_internal: rnorm_eps  = 5.0e-06\r\nllama_model_load_internal: n_ff       = 13824\r\nllama_model_load_internal: freq_base  = 10000.0\r\nllama_model_load_internal: freq_scale = 1\r\nllama_model_load_internal: ftype      = 2 (mostly Q4_0)\r\nllama_model_load_internal: model size = 13B\r\nllama_model_load_internal: ggml ctx size =    0.11 MB\r\nllama_model_load_internal: mem required  = 6983.72 MB (+ 3046.88 MB per state)\r\nllama_new_context_with_model: kv self size  = 3046.88 MB\r\nllama_new_context_with_model: compute buffer total size =  336.03 MB\r\nAVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \r\n\r\nllama_print_timings:        load time = 13104.85 ms\r\nllama_print_timings:      sample time =   118.53 ms /   206 runs   (    0.58 ms per token,  1737.88 tokens per second)\r\nllama_print_timings: prompt eval time = 32500.36 ms /  1224 tokens (   26.55 ms per token,    37.66 tokens per second)\r\nllama_print_timings:        eval time = 17100.13 ms /   205 runs   (   83.42 ms per token,    11.99 tokens per second)\r\nllama_print_timings:       total time = 50120.90 ms\r\n---------------------------------------------------------------------------\r\nOperationalError                          Traceback (most recent call last)\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965, in Connection._exec_single_context(self, dialect, context, statement, parameters)\r\n   1964     if not evt_handled:\r\n-> 1965         self.dialect.do_execute(\r\n   1966             cursor, str_statement, effective_parameters, context\r\n   1967         )\r\n   1969 if self._has_events or self.engine._has_events:\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921, in DefaultDialect.do_execute(self, cursor, statement, parameters, context)\r\n    920 def do_execute(self, cursor, statement, parameters, context=None):\r\n--> 921     cursor.execute(statement, parameters)\r\n\r\nOperationalError: near \"Question\": syntax error\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nOperationalError                          Traceback (most recent call last)\r\nCell In[54], line 1\r\n----> 1 query_engine.query(\"who are the top selling artists?\")\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/llama_index/indices/query/base.py:23, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     21 if isinstance(str_or_query_bundle, str):\r\n     22     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 23 response = self._query(str_or_query_bundle)\r\n     24 return response\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/llama_index/indices/struct_store/sql_query.py:176, in NLStructStoreQueryEngine._query(self, query_bundle)\r\n    173 # assume that it's a valid SQL query\r\n    174 logger.debug(f\"> Predicted SQL query: {sql_query_str}\")\r\n--> 176 raw_response_str, metadata = self._sql_database.run_sql(sql_query_str)\r\n    177 metadata[\"sql_query\"] = sql_query_str\r\n    179 if self._synthesize_response:\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/llama_index/langchain_helpers/sql_wrapper.py:91, in SQLDatabase.run_sql(self, command)\r\n     85 \"\"\"Execute a SQL statement and return a string representing the results.\r\n     86 \r\n     87 If the statement returns rows, a string of the results is returned.\r\n     88 If the statement returns no rows, an empty string is returned.\r\n     89 \"\"\"\r\n     90 with self._engine.connect() as connection:\r\n---> 91     cursor = connection.execute(text(command))\r\n     92     if cursor.returns_rows:\r\n     93         result = cursor.fetchall()\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1412, in Connection.execute(self, statement, parameters, execution_options)\r\n   1410     raise exc.ObjectNotExecutableError(statement) from err\r\n   1411 else:\r\n-> 1412     return meth(\r\n   1413         self,\r\n   1414         distilled_parameters,\r\n   1415         execution_options or NO_OPTIONS,\r\n   1416     )\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:483, in ClauseElement._execute_on_connection(self, connection, distilled_params, execution_options)\r\n    481     if TYPE_CHECKING:\r\n    482         assert isinstance(self, Executable)\r\n--> 483     return connection._execute_clauseelement(\r\n    484         self, distilled_params, execution_options\r\n    485     )\r\n    486 else:\r\n    487     raise exc.ObjectNotExecutableError(self)\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1635, in Connection._execute_clauseelement(self, elem, distilled_parameters, execution_options)\r\n   1623 compiled_cache: Optional[CompiledCacheType] = execution_options.get(\r\n   1624     \"compiled_cache\", self.engine._compiled_cache\r\n   1625 )\r\n   1627 compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\r\n   1628     dialect=dialect,\r\n   1629     compiled_cache=compiled_cache,\r\n   (...)\r\n   1633     linting=self.dialect.compiler_linting | compiler.WARN_LINTING,\r\n   1634 )\r\n-> 1635 ret = self._execute_context(\r\n   1636     dialect,\r\n   1637     dialect.execution_ctx_cls._init_compiled,\r\n   1638     compiled_sql,\r\n   1639     distilled_parameters,\r\n   1640     execution_options,\r\n   1641     compiled_sql,\r\n   1642     distilled_parameters,\r\n   1643     elem,\r\n   1644     extracted_params,\r\n   1645     cache_hit=cache_hit,\r\n   1646 )\r\n   1647 if has_events:\r\n   1648     self.dispatch.after_execute(\r\n   1649         self,\r\n   1650         elem,\r\n   (...)\r\n   1654         ret,\r\n   1655     )\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1844, in Connection._execute_context(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\r\n   1839     return self._exec_insertmany_context(\r\n   1840         dialect,\r\n   1841         context,\r\n   1842     )\r\n   1843 else:\r\n-> 1844     return self._exec_single_context(\r\n   1845         dialect, context, statement, parameters\r\n   1846     )\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1984, in Connection._exec_single_context(self, dialect, context, statement, parameters)\r\n   1981     result = context._setup_result_proxy()\r\n   1983 except BaseException as e:\r\n-> 1984     self._handle_dbapi_exception(\r\n   1985         e, str_statement, effective_parameters, cursor, context\r\n   1986     )\r\n   1988 return result\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2339, in Connection._handle_dbapi_exception(self, e, statement, parameters, cursor, context, is_sub_exec)\r\n   2337 elif should_wrap:\r\n   2338     assert sqlalchemy_exception is not None\r\n-> 2339     raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n   2340 else:\r\n   2341     assert exc_info[1] is not None\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1965, in Connection._exec_single_context(self, dialect, context, statement, parameters)\r\n   1963                 break\r\n   1964     if not evt_handled:\r\n-> 1965         self.dialect.do_execute(\r\n   1966             cursor, str_statement, effective_parameters, context\r\n   1967         )\r\n   1969 if self._has_events or self.engine._has_events:\r\n   1970     self.dispatch.after_cursor_execute(\r\n   1971         self,\r\n   1972         cursor,\r\n   (...)\r\n   1976         context.executemany,\r\n   1977     )\r\n\r\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sqlalchemy/engine/default.py:921, in DefaultDialect.do_execute(self, cursor, statement, parameters, context)\r\n    920 def do_execute(self, cursor, statement, parameters, context=None):\r\n--> 921     cursor.execute(statement, parameters)\r\n\r\nOperationalError: (sqlite3.OperationalError) near \"Question\": syntax error\r\n[SQL: Question: Who are the top selling artists?\r\n\r\nSQLQuery: SELECT ArtistId, Name, SUM(UnitPrice * Quantity) AS TotalSales\r\nFROM invoices\r\nJOIN invoice_items ON invoices.InvoiceId = invoice_items.InvoiceId\r\nJOIN tracks ON invoice_items.TrackId = tracks.TrackId\r\nJOIN artists ON tracks.ArtistId = artists.ArtistId\r\nGROUP BY ArtistId, Name\r\nORDER BY TotalSales DESC;]\r\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7332/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7332/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7331",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7331/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7331/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7331/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7331",
        "id": 1858009175,
        "node_id": "PR_kwDOIWuq585YUOJD",
        "number": 7331,
        "title": "fix callback trace ids (make them a context var) ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-20T07:15:33Z",
        "updated_at": "2023-08-20T15:59:13Z",
        "closed_at": "2023-08-20T15:59:12Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7331",
            "html_url": "https://github.com/run-llama/llama_index/pull/7331",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7331.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7331.patch",
            "merged_at": "2023-08-20T15:59:12Z"
        },
        "body": "(reposting from an internal thread)\r\n\r\n**Motivation**: there was a bug where nesting an agent/query engine under another query engine led to callbacks issues.\r\n\r\nReason:\r\nat a high-level it's because we had a global_stack_trace for events, but the _trace_id_stack is still specific to each callback manager.\r\nwe had logic that checks if _trace_id_stack is empty then we reset global_stack_trace . but the issue arises when that callback manager starts a trace in a nested query call - when that trace ends, then the local _trace_id_stack for that callback manager will be empty, but that will reset the entire global_stack_trace  - affecting the outer callback manager\r\n\r\nSolution: make trace_id_stack a global contextvar. still thread-safe but now isn't specific to a given callback manager\r\n\r\nTesting: I tested this in a variant of the notebook in https://github.com/jerryjliu/llama_index/pull/7330 without defining the callback manager everywhere ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7331/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7331/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7330",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7330/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7330/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7330/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7330",
        "id": 1858008686,
        "node_id": "PR_kwDOIWuq585YUODW",
        "number": 7330,
        "title": "[wip] add recursive agent notebook",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-20T07:13:28Z",
        "updated_at": "2023-08-21T00:11:01Z",
        "closed_at": "2023-08-21T00:11:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7330",
            "html_url": "https://github.com/run-llama/llama_index/pull/7330",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7330.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7330.patch",
            "merged_at": "2023-08-21T00:11:01Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7330/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7330/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7329",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7329/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7329/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7329/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7329",
        "id": 1857885435,
        "node_id": "PR_kwDOIWuq585YT1rG",
        "number": 7329,
        "title": "fix azure pydantic error",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-19T22:07:49Z",
        "updated_at": "2023-08-19T22:14:33Z",
        "closed_at": "2023-08-19T22:14:33Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7329",
            "html_url": "https://github.com/run-llama/llama_index/pull/7329",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7329.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7329.patch",
            "merged_at": "2023-08-19T22:14:33Z"
        },
        "body": "# Description\r\n\r\nSmall bug when passing kwargs from azure openai to openai class was causing pydantic errors.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7325\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Tested notebook\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7329/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7329/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7328",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7328/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7328/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7328/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7328",
        "id": 1857884046,
        "node_id": "PR_kwDOIWuq585YT1ap",
        "number": 7328,
        "title": "add trulens image",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-19T21:59:59Z",
        "updated_at": "2023-08-20T00:12:41Z",
        "closed_at": "2023-08-20T00:12:41Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7328",
            "html_url": "https://github.com/run-llama/llama_index/pull/7328",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7328.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7328.patch",
            "merged_at": "2023-08-20T00:12:41Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7328/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7328/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7327",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7327/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7327/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7327/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7327",
        "id": 1857865073,
        "node_id": "I_kwDOIWuq585uvMVx",
        "number": 7327,
        "title": "[Bug]: module 'llama_index' has no attribute 'global_service_context'",
        "user": {
            "login": "fsndzomga",
            "id": 101533724,
            "node_id": "U_kgDOBg1IHA",
            "avatar_url": "https://avatars.githubusercontent.com/u/101533724?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/fsndzomga",
            "html_url": "https://github.com/fsndzomga",
            "followers_url": "https://api.github.com/users/fsndzomga/followers",
            "following_url": "https://api.github.com/users/fsndzomga/following{/other_user}",
            "gists_url": "https://api.github.com/users/fsndzomga/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/fsndzomga/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/fsndzomga/subscriptions",
            "organizations_url": "https://api.github.com/users/fsndzomga/orgs",
            "repos_url": "https://api.github.com/users/fsndzomga/repos",
            "events_url": "https://api.github.com/users/fsndzomga/events{/privacy}",
            "received_events_url": "https://api.github.com/users/fsndzomga/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-08-19T20:30:21Z",
        "updated_at": "2023-12-08T01:34:21Z",
        "closed_at": "2023-08-19T23:54:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHere is what I am trying to do:\r\n# Building and querying an index\r\n\r\nfrom llama_index import VectorStoreIndex\r\n\r\nindex = VectorStoreIndex.from_documents(branch_documents)\r\n\r\nquery_engine = index.as_query_engine()\r\n\r\nresponse = query_engine.query(\"How to create a github repository reader ?\")\r\n\r\nprint(response)\r\n\r\nHere is the bug:\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n[<ipython-input-13-3b211f20ab7f>](https://dpylnivaw5m-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20230817-060103-RC00_557775453#) in <cell line: 5>()\r\n      3 from llama_index import VectorStoreIndex\r\n      4 \r\n----> 5 index = VectorStoreIndex.from_documents(branch_documents)\r\n      6 \r\n      7 query_engine = index.as_query_engine()\r\n\r\n1 frames\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/base.py](https://dpylnivaw5m-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20230817-060103-RC00_557775453#) in from_documents(cls, documents, storage_context, service_context, show_progress, **kwargs)\r\n     90         \"\"\"\r\n     91         storage_context = storage_context or StorageContext.from_defaults()\r\n---> 92         service_context = service_context or ServiceContext.from_defaults()\r\n     93         docstore = storage_context.docstore\r\n     94 \r\n\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/indices/service_context.py](https://dpylnivaw5m-496ff2e9c6d22116-0-colab.googleusercontent.com/outputframe.html?vrz=colab-20230817-060103-RC00_557775453#) in from_defaults(cls, llm_predictor, llm, prompt_helper, embed_model, node_parser, llama_logger, callback_manager, system_prompt, query_wrapper_prompt, chunk_size, chunk_overlap, context_window, num_output, chunk_size_limit)\r\n    120             chunk_size = chunk_size_limit\r\n    121 \r\n--> 122         if llama_index.global_service_context is not None:\r\n    123             return cls.from_service_context(\r\n    124                 llama_index.global_service_context,\r\n\r\nAttributeError: module 'llama_index' has no attribute 'global_service_context'\n\n### Version\n\nVersion: 0.8.5.post1\n\n### Steps to Reproduce\n\n# Import the Github Repository Reader class\r\nfrom llama_index.readers import GithubRepositoryReader\r\nimport os\r\n\r\nos.environ[\"GITHUB_TOKEN\"] = \"\"\r\n\r\n# Read the llama-index repository\r\nreader = GithubRepositoryReader(\"jerryjliu\", \r\n                                \"llama_index\", \r\n                                ignore_directories=[\".github\", \".vscode\", \r\n                                                    \"benchmarks\", \"docs\", \r\n                                                    \"examples\", \"experimental\",\r\n                                                    \"scripts\", \"tests\"])\r\n\r\n# Building and querying an index\r\n\r\nfrom llama_index import VectorStoreIndex\r\n\r\nindex = VectorStoreIndex.from_documents(branch_documents)\r\n\r\nquery_engine = index.as_query_engine()\r\n\r\nresponse = query_engine.query(\"How to create a github repository reader ?\")\r\n\r\nprint(response)\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7327/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7327/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7326",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7326/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7326/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7326/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7326",
        "id": 1857829712,
        "node_id": "I_kwDOIWuq585uvDtQ",
        "number": 7326,
        "title": "[Bug]: Connecting mssql ",
        "user": {
            "login": "adeelhasan19",
            "id": 89073843,
            "node_id": "MDQ6VXNlcjg5MDczODQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/89073843?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/adeelhasan19",
            "html_url": "https://github.com/adeelhasan19",
            "followers_url": "https://api.github.com/users/adeelhasan19/followers",
            "following_url": "https://api.github.com/users/adeelhasan19/following{/other_user}",
            "gists_url": "https://api.github.com/users/adeelhasan19/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/adeelhasan19/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/adeelhasan19/subscriptions",
            "organizations_url": "https://api.github.com/users/adeelhasan19/orgs",
            "repos_url": "https://api.github.com/users/adeelhasan19/repos",
            "events_url": "https://api.github.com/users/adeelhasan19/events{/privacy}",
            "received_events_url": "https://api.github.com/users/adeelhasan19/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-19T18:29:20Z",
        "updated_at": "2023-11-25T16:02:24Z",
        "closed_at": "2023-11-25T16:02:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am connecting my sql server database with the below code\r\n\" \r\nimport urllib\r\nconnection_string = \"DRIVER={ODBC Driver 17 for SQL Server};Database=******;SERVER=*******;UID=*******;PWD=*********;Encrypt=yes;TrustServerCertificate=yes\"\r\nconnection_string = urllib.parse.quote_plus(connection_string)\r\nconnection_uri = \"mssql+pyodbc:///?odbc_connect=%s\" % connection_string\r\n\r\nengine = create_engine(connection_uri,pool_reset_on_return=None)\"\r\n\r\nWhen query on it i am getting the result  but when i pass to llamaindex SQLTableRetrieverQueryEngine-\r\n\r\n\" \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\"\r\n\r\nProgrammingError: (pyodbc.ProgrammingError) ('42000', \"[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL \r\nServer]Incorrect syntax near 'This'. (102) (SQLExecDirectW); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL\r\nServer]Incorrect syntax near 'price'. (102)\")\"\n\n### Version\n\nllama-index - 0.8.5.post1\n\n### Steps to Reproduce\n\nTry this \" https://gpt-index.readthedocs.io/en/latest/examples/index_structs/struct_indices/duckdb_sql_query.html\" example using mssql database \n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7326/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7326/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7325",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7325/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7325/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7325/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7325",
        "id": 1857805539,
        "node_id": "I_kwDOIWuq585uu9zj",
        "number": 7325,
        "title": "[Bug]: AzureOpenAI no longer works after api break change",
        "user": {
            "login": "Yackadaisical",
            "id": 134191941,
            "node_id": "U_kgDOB_-bRQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/134191941?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Yackadaisical",
            "html_url": "https://github.com/Yackadaisical",
            "followers_url": "https://api.github.com/users/Yackadaisical/followers",
            "following_url": "https://api.github.com/users/Yackadaisical/following{/other_user}",
            "gists_url": "https://api.github.com/users/Yackadaisical/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Yackadaisical/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Yackadaisical/subscriptions",
            "organizations_url": "https://api.github.com/users/Yackadaisical/orgs",
            "repos_url": "https://api.github.com/users/Yackadaisical/repos",
            "events_url": "https://api.github.com/users/Yackadaisical/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Yackadaisical/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-19T17:17:04Z",
        "updated_at": "2023-08-19T22:15:16Z",
        "closed_at": "2023-08-19T22:14:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nupgrade llama-index from 0.8.4 to 0.8.5.post1\r\n\r\nafter upgrading, can no longer use AzureOpenAi set up\r\n\r\neverything is still the same but keep getting validation error\n\n### Version\n\n0.8.5.post1\n\n### Steps to Reproduce\n\nopenai.api_type = \"azure\"\r\nopenai.api_base = os.getenv(\"OPENAI_API_BASE\")\r\nopenai.api_version = \"2023-07-01-preview\"\r\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\r\n\r\nllm = AzureOpenAI(engine=\"yourengine\", model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n\n### Relevant Logs/Tracbacks\n\n```shell\n---------------------------------------------------------------------------\r\nValidationError                           Traceback (most recent call last)\r\nCell In[4], line 7\r\n      4 openai.api_version = \"2023-07-01-preview\"\r\n      5 openai.api_key = os.getenv(\"OPENAI_API_KEY\")\r\n----> 7 llm = AzureOpenAI(engine=\"try2\", model=\"gpt-3.5-turbo-16k\", temperature=0.1)\r\n      9 local_embedding = LangchainEmbedding(\r\n     10     HuggingFaceEmbeddings(\r\n     11         model_name=\"thenlper/gte-large\"\r\n     12     )\r\n     13 )\r\n     15 print (\"environment set up complete\")\r\n\r\nFile c:\\Users\\jeffr\\miniconda3\\lib\\site-packages\\llama_index\\llms\\azure_openai.py:51, in AzureOpenAI.__init__(self, model, engine, temperature, max_tokens, additional_kwargs, max_retries, callback_manager, **kwargs)\r\n     47     raise ValueError(\"You must specify an `engine` parameter.\")\r\n     49 self.validate_env()\r\n---> 51 super().__init__(\r\n     52     engine=engine,\r\n     53     model=model,\r\n     54     temperature=temperature,\r\n     55     max_tokens=max_tokens,\r\n     56     additional_kwargs=additional_kwargs,\r\n     57     max_retries=max_retries,\r\n     58     callback_manager=callback_manager,\r\n     59     **kwargs,\r\n     60 )\r\n\r\nFile c:\\Users\\jeffr\\miniconda3\\lib\\site-packages\\llama_index\\llms\\openai.py:71, in OpenAI.__init__(self, model, temperature, max_tokens, additional_kwargs, max_retries, api_key, api_type, callback_manager, **kwargs)\r\n     68 if api_type is not None:\r\n     69     additional_kwargs[\"api_type\"] = api_type\r\n---> 71 super().__init__(\r\n     72     model=model,\r\n     73     temperature=temperature,\r\n     74     max_tokens=max_tokens,\r\n     75     additional_kwargs=additional_kwargs,\r\n     76     max_retries=max_retries,\r\n     77     callback_manager=callback_manager,\r\n     78 )\r\n\r\nFile c:\\Users\\jeffr\\miniconda3\\lib\\site-packages\\pydantic\\main.py:341, in pydantic.main.BaseModel.__init__()\r\n\r\nValidationError: 1 validation error for AzureOpenAI\r\nengine\r\n  field required (type=value_error.missing)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7325/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7325/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7324",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7324/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7324/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7324/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7324",
        "id": 1857764809,
        "node_id": "PR_kwDOIWuq585YTdsF",
        "number": 7324,
        "title": "always eval df as the last step of default output processor of pandas\u2026",
        "user": {
            "login": "hawktang",
            "id": 2004071,
            "node_id": "MDQ6VXNlcjIwMDQwNzE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2004071?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hawktang",
            "html_url": "https://github.com/hawktang",
            "followers_url": "https://api.github.com/users/hawktang/followers",
            "following_url": "https://api.github.com/users/hawktang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hawktang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hawktang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hawktang/subscriptions",
            "organizations_url": "https://api.github.com/users/hawktang/orgs",
            "repos_url": "https://api.github.com/users/hawktang/repos",
            "events_url": "https://api.github.com/users/hawktang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hawktang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-19T14:47:26Z",
        "updated_at": "2023-08-20T07:52:11Z",
        "closed_at": "2023-08-20T07:52:11Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7324",
            "html_url": "https://github.com/run-llama/llama_index/pull/7324",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7324.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7324.patch",
            "merged_at": null
        },
        "body": "\u2026_query_engine\r\n\r\n# Description\r\n\r\nAlways eval df as the last step of default output processor of pandas_query_engine\r\n\r\nFixes # (issue)\r\n\r\nTo avoid situation like \r\ndf['column'] = df.column.some_operation()\r\nat the last step\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7324/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7324/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7323",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7323/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7323/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7323/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7323",
        "id": 1857641418,
        "node_id": "I_kwDOIWuq585uuVvK",
        "number": 7323,
        "title": "[Question]: How to print the number of tokens used on each query? I want to print that. ",
        "user": {
            "login": "rahul311291",
            "id": 77605432,
            "node_id": "MDQ6VXNlcjc3NjA1NDMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/77605432?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rahul311291",
            "html_url": "https://github.com/rahul311291",
            "followers_url": "https://api.github.com/users/rahul311291/followers",
            "following_url": "https://api.github.com/users/rahul311291/following{/other_user}",
            "gists_url": "https://api.github.com/users/rahul311291/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rahul311291/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rahul311291/subscriptions",
            "organizations_url": "https://api.github.com/users/rahul311291/orgs",
            "repos_url": "https://api.github.com/users/rahul311291/repos",
            "events_url": "https://api.github.com/users/rahul311291/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rahul311291/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-19T08:52:52Z",
        "updated_at": "2023-09-11T16:17:25Z",
        "closed_at": "2023-08-23T02:01:35Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHow to print the number of tokens used on each query? I want to print that. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7323/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7323/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7322",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7322/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7322/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7322/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7322",
        "id": 1857559242,
        "node_id": "PR_kwDOIWuq585YS0bz",
        "number": 7322,
        "title": "[version] bump to 0.8.5.post1",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-19T04:40:53Z",
        "updated_at": "2023-08-19T04:49:22Z",
        "closed_at": "2023-08-19T04:49:22Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7322",
            "html_url": "https://github.com/run-llama/llama_index/pull/7322",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7322.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7322.patch",
            "merged_at": "2023-08-19T04:49:22Z"
        },
        "body": "Fixes https://github.com/jerryjliu/llama_index/issues/7321",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7322/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7322/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7321",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7321/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7321/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7321/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7321",
        "id": 1857516579,
        "node_id": "I_kwDOIWuq585ut3Qj",
        "number": 7321,
        "title": "[Bug]: faild to use OpenAI API in llms/OpenAI class ",
        "user": {
            "login": "sari-rev00",
            "id": 83706452,
            "node_id": "MDQ6VXNlcjgzNzA2NDUy",
            "avatar_url": "https://avatars.githubusercontent.com/u/83706452?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sari-rev00",
            "html_url": "https://github.com/sari-rev00",
            "followers_url": "https://api.github.com/users/sari-rev00/followers",
            "following_url": "https://api.github.com/users/sari-rev00/following{/other_user}",
            "gists_url": "https://api.github.com/users/sari-rev00/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sari-rev00/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sari-rev00/subscriptions",
            "organizations_url": "https://api.github.com/users/sari-rev00/orgs",
            "repos_url": "https://api.github.com/users/sari-rev00/repos",
            "events_url": "https://api.github.com/users/sari-rev00/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sari-rev00/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "logan-markewich",
                "id": 22285038,
                "node_id": "MDQ6VXNlcjIyMjg1MDM4",
                "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/logan-markewich",
                "html_url": "https://github.com/logan-markewich",
                "followers_url": "https://api.github.com/users/logan-markewich/followers",
                "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
                "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
                "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
                "repos_url": "https://api.github.com/users/logan-markewich/repos",
                "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
                "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-19T03:19:11Z",
        "updated_at": "2023-08-19T04:49:23Z",
        "closed_at": "2023-08-19T04:49:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nFollowing tutorial code raises type-error at openai library.\r\n```\r\n# environment:\r\nOPENAI_API_KEY=xxxxx\r\n\r\n# code:\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader\r\ndocuments = SimpleDirectoryReader(input_dir='your_data_dir').load_data()\r\nindex = VectorStoreIndex.from_documents(documents)\r\nresponse = query_engine.query(\"any_query\")\r\n\r\n# error:\r\n '0.1' is not of type 'number' - 'temperature'\r\n```\r\n\r\nto solve this:\r\nChange the type of \"temperature\" (llms/OpenAI class variable), from str to float.\r\n`temperature: str = Field(description=\"The tempature to use during generation.\")`\r\nhttps://github.com/jerryjliu/llama_index/blob/main/llama_index/llms/openai.py#L42\n\n### Version\n\n0.8.5\n\n### Steps to Reproduce\n\nKidly refer to bug description.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7321/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7321/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7320",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7320/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7320/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7320/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7320",
        "id": 1857405459,
        "node_id": "PR_kwDOIWuq585YSS18",
        "number": 7320,
        "title": "[version] bump version to 0.8.5",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-18T23:51:14Z",
        "updated_at": "2023-08-19T00:30:21Z",
        "closed_at": "2023-08-19T00:30:20Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7320",
            "html_url": "https://github.com/run-llama/llama_index/pull/7320",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7320.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7320.patch",
            "merged_at": "2023-08-19T00:30:20Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7320/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7320/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7319",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7319/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7319/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7319/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7319",
        "id": 1857402080,
        "node_id": "PR_kwDOIWuq585YSSID",
        "number": 7319,
        "title": "Prompt refactor",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5870187578,
                "node_id": "LA_kwDOIWuq588AAAABXeP0Og",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/refactor",
                "name": "refactor",
                "color": "80A9B1",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-18T23:42:40Z",
        "updated_at": "2023-08-24T22:07:45Z",
        "closed_at": "2023-08-24T22:07:44Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7319",
            "html_url": "https://github.com/run-llama/llama_index/pull/7319",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7319.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7319.patch",
            "merged_at": "2023-08-24T22:07:44Z"
        },
        "body": "### Summary\r\n* Remove hard dependency on langchain prompt templates\r\n* More explicit interface for prompt templates\r\n* Reduce proliferation of specific prompt template classes\r\n\r\n### Details\r\n* Introduce:\r\n  * `BasePromptTemplate` as base class to make interface more explicit\r\n  * `PromptTemplate`, `ChatPromptTemplate`, `SelectorPromptTemplate` as core implementations\r\n  * `LangchainPromptTemplate` to remain compatible with langchain prompts\r\n* Fully replace specific prompt classes (e.g. `SummaryPrompt`) with generic `BasePromptTemplate` for typing in codebase.\r\n  * wee keep the type aliases for backwards compatibility. They remain importable from `llama_index` and `llama_index.prompts.prompts`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7319/reactions",
            "total_count": 3,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 3,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7319/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7318",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7318/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7318/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7318/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7318",
        "id": 1857326614,
        "node_id": "PR_kwDOIWuq585YSBoB",
        "number": 7318,
        "title": "concerns documentation: fix link rendering problem and remove doubled word",
        "user": {
            "login": "bsenst",
            "id": 8211411,
            "node_id": "MDQ6VXNlcjgyMTE0MTE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8211411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bsenst",
            "html_url": "https://github.com/bsenst",
            "followers_url": "https://api.github.com/users/bsenst/followers",
            "following_url": "https://api.github.com/users/bsenst/following{/other_user}",
            "gists_url": "https://api.github.com/users/bsenst/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bsenst/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bsenst/subscriptions",
            "organizations_url": "https://api.github.com/users/bsenst/orgs",
            "repos_url": "https://api.github.com/users/bsenst/repos",
            "events_url": "https://api.github.com/users/bsenst/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bsenst/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-18T21:49:33Z",
        "updated_at": "2023-08-18T22:01:40Z",
        "closed_at": "2023-08-18T22:01:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7318",
            "html_url": "https://github.com/run-llama/llama_index/pull/7318",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7318.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7318.patch",
            "merged_at": "2023-08-18T22:01:40Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7318/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7318/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7317",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7317/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7317/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7317/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7317",
        "id": 1857318998,
        "node_id": "PR_kwDOIWuq585YR_9g",
        "number": 7317,
        "title": "implementation for using structured output to filter out invalid answers in refine synthesis",
        "user": {
            "login": "sourabhdesai",
            "id": 3005241,
            "node_id": "MDQ6VXNlcjMwMDUyNDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3005241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sourabhdesai",
            "html_url": "https://github.com/sourabhdesai",
            "followers_url": "https://api.github.com/users/sourabhdesai/followers",
            "following_url": "https://api.github.com/users/sourabhdesai/following{/other_user}",
            "gists_url": "https://api.github.com/users/sourabhdesai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sourabhdesai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sourabhdesai/subscriptions",
            "organizations_url": "https://api.github.com/users/sourabhdesai/orgs",
            "repos_url": "https://api.github.com/users/sourabhdesai/repos",
            "events_url": "https://api.github.com/users/sourabhdesai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sourabhdesai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-18T21:38:23Z",
        "updated_at": "2023-08-25T21:11:40Z",
        "closed_at": "2023-08-25T20:58:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7317",
            "html_url": "https://github.com/run-llama/llama_index/pull/7317",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7317.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7317.patch",
            "merged_at": "2023-08-25T20:58:29Z"
        },
        "body": "# Description\r\n\r\nimplementation for using structured output to filter out invalid answers in refine synthesis.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7317/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7317/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7316",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7316/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7316/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7316/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7316",
        "id": 1857301281,
        "node_id": "PR_kwDOIWuq585YR8HB",
        "number": 7316,
        "title": "make all service context objects pydantic 2/2",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-18T21:17:15Z",
        "updated_at": "2023-08-20T23:48:27Z",
        "closed_at": "2023-08-20T23:48:27Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7316",
            "html_url": "https://github.com/run-llama/llama_index/pull/7316",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7316.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7316.patch",
            "merged_at": "2023-08-20T23:48:27Z"
        },
        "body": "# Description\r\n\r\nPart 2/2 of converting service context components to use pydantic. \r\n\r\nThe next step after this PR will be to add some to/from methods to the service context to make these settings more transferrable.\r\n\r\nThis is intended to have zero impact on the actual usage/interfaces of llama-index right now.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# TODO\r\n\r\n- [x] Run a few more notebooks to confirm things work as expected.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7316/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7316/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7315",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7315/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7315/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7315/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7315",
        "id": 1857250003,
        "node_id": "PR_kwDOIWuq585YRw6U",
        "number": 7315,
        "title": "Add badges to README.md",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-18T20:23:14Z",
        "updated_at": "2023-08-18T22:45:47Z",
        "closed_at": "2023-08-18T22:45:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7315",
            "html_url": "https://github.com/run-llama/llama_index/pull/7315",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7315.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7315.patch",
            "merged_at": "2023-08-18T22:45:46Z"
        },
        "body": "# Description\r\n\r\nAdd badges\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7315/reactions",
            "total_count": 3,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 1,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7315/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7314",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7314/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7314/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7314/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7314",
        "id": 1857157803,
        "node_id": "I_kwDOIWuq585usfqr",
        "number": 7314,
        "title": "[Bug]: Kernel crashing with MetadataExtractor() when get_nodes_from_documents()",
        "user": {
            "login": "kevon217",
            "id": 13077896,
            "node_id": "MDQ6VXNlcjEzMDc3ODk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/13077896?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kevon217",
            "html_url": "https://github.com/kevon217",
            "followers_url": "https://api.github.com/users/kevon217/followers",
            "following_url": "https://api.github.com/users/kevon217/following{/other_user}",
            "gists_url": "https://api.github.com/users/kevon217/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kevon217/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kevon217/subscriptions",
            "organizations_url": "https://api.github.com/users/kevon217/orgs",
            "repos_url": "https://api.github.com/users/kevon217/repos",
            "events_url": "https://api.github.com/users/kevon217/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kevon217/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-18T18:55:44Z",
        "updated_at": "2023-09-12T02:06:48Z",
        "closed_at": "2023-09-12T02:06:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nMy kernel keeps crashing when I use the `KeywordExtractor()` while extracting nodes from a list of  178 documents. The document nodes don't have a lot of text either, so I don't think it's an issue with length. I do add my own metadata to the documents before using an LLM to extract keywords. It works fine, however, if I do it on a list of 5 documents using either OpenAI or Llama-2.\r\n\r\nI've tried it in VS Code and Pycharm, so don't think it is an IDE issue.\r\n\r\n```\r\nllm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-16k\")\r\nmetadata_extractor = MetadataExtractor(\r\n    extractors=[KeywordExtractor(keywords=10, llm=llm),\r\n    ],\r\n)\r\nnode_parser = SimpleNodeParser.from_defaults(metadata_extractor=metadata_extractor, include_metadata=True, callback_manager=callback_manager)\r\nnodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\r\n```\r\n\r\n\r\nI also tried it with `llm = LLMPredictor(OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-16k\"))` but that didn't work either.\r\n\r\nLet me know if there's any additional information that is needed to troubleshoot this issue.\n\n### Version\n\n0.8.4\n\n### Steps to Reproduce\n\n```\r\ndoc_id_col = 'id'\r\ndocuments=[]\r\nfor idx, row in df_studies.iterrows():\r\n    doc = row[text_col[0]]\r\n    meta = {val: row[val] for val in df_studies.columns if val not in text_col}\r\n    document = Document(\r\n        text=doc,\r\n        metadata=meta,\r\n        excluded_embed_metadata_keys=metadata_cols_exclude, # list(meta.keys()),\r\n        excluded_llm_metadata_keys=metadata_cols_exclude, # list(meta.keys()),\r\n        metadata_seperator=\"::\",\r\n        metadata_template=\"{key}=>{value}\",\r\n        text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\r\n    )\r\n    document.id_ = row[doc_id_col]\r\n    documents.append(document)\r\n\r\nllm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo-16k\")\r\nmetadata_extractor = MetadataExtractor(\r\n    extractors=[KeywordExtractor(keywords=10, llm=llm),\r\n    ],\r\n)\r\nnode_parser = SimpleNodeParser.from_defaults(metadata_extractor=metadata_extractor, include_metadata=True, callback_manager=callback_manager)\r\nnodes = node_parser.get_nodes_from_documents(documents, show_progress=True)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7314/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7314/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7313",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7313/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7313/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7313/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7313",
        "id": 1857138616,
        "node_id": "PR_kwDOIWuq585YRYej",
        "number": 7313,
        "title": "Create codeql.yml",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-18T18:42:31Z",
        "updated_at": "2023-08-18T18:58:11Z",
        "closed_at": "2023-08-18T18:58:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7313",
            "html_url": "https://github.com/run-llama/llama_index/pull/7313",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7313.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7313.patch",
            "merged_at": "2023-08-18T18:58:11Z"
        },
        "body": "# Description\r\n\r\nAdd vulnerability scan step in CI github actions workflow ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7313/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7313/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7312",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7312/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7312/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7312/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7312",
        "id": 1857133859,
        "node_id": "I_kwDOIWuq585usZ0j",
        "number": 7312,
        "title": "[Bug]: Must provide an 'engine' or 'deployment_id' parameter to create a class",
        "user": {
            "login": "rafaeldpaula",
            "id": 18271162,
            "node_id": "MDQ6VXNlcjE4MjcxMTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/18271162?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rafaeldpaula",
            "html_url": "https://github.com/rafaeldpaula",
            "followers_url": "https://api.github.com/users/rafaeldpaula/followers",
            "following_url": "https://api.github.com/users/rafaeldpaula/following{/other_user}",
            "gists_url": "https://api.github.com/users/rafaeldpaula/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rafaeldpaula/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rafaeldpaula/subscriptions",
            "organizations_url": "https://api.github.com/users/rafaeldpaula/orgs",
            "repos_url": "https://api.github.com/users/rafaeldpaula/repos",
            "events_url": "https://api.github.com/users/rafaeldpaula/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rafaeldpaula/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-18T18:38:22Z",
        "updated_at": "2023-08-19T20:02:19Z",
        "closed_at": "2023-08-19T20:02:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nTraceback (most recent call last):\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 166, in get_embeddings\r\n    data = openai.Embedding.create(input=list_of_text, model=engine, **kwargs).data\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\openai\\api_resources\\embedding.py\", line 33, in create\r\n    response = super().create(*args, **kwargs)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 149, in create\r\n    ) = cls.__prepare_create_request(\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 83, in __prepare_create_request\r\n    raise error.InvalidRequestError(\r\nopenai.error.InvalidRequestError: Must provide an 'engine' or 'deployment_id' parameter to create a <class 'openai.api_resources.embedding.Embedding'>\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Desenv\\llamaindex\\main.py\", line 70, in <module>\r\n    main()\r\n  File \"C:\\Desenv\\llamaindex\\main.py\", line 51, in main\r\n    index = GPTVectorStoreIndex(documents, llm_predictor=llm_predictor, embed_model=embedding_llm, prompt_helper=prompt_helper)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 46, in __init__\r\n    super().__init__(\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\base.py\", line 71, in __init__\r\n    index_struct = self.build_index_from_nodes(nodes)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 241, in build_index_from_nodes\r\n    return self._build_index_from_nodes(nodes)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 229, in _build_index_from_nodes\r\n    self._add_nodes_to_index(\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 201, in _add_nodes_to_index\r\n    embedding_results = self._get_node_embedding_results(nodes, show_progress)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\indices\\vector_store\\base.py\", line 111, in _get_node_embedding_results\r\n    ) = self._service_context.embed_model.get_queued_text_embeddings(show_progress)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\embeddings\\base.py\", line 214, in get_queued_text_embeddings\r\n    embeddings = self._get_text_embeddings(cur_batch_texts)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\llama_index\\embeddings\\openai.py\", line 302, in _get_text_embeddings\r\n    return get_embeddings(\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File \"C:\\Desenv\\llamaindex\\rafa\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\r\n    raise retry_exc from fut.exception()\r\ntenacity.RetryError: RetryError[<Future at 0x1d350bb5ed0 state=finished raised InvalidRequestError>]\n\n### Version\n\n0.8.4\n\n### Steps to Reproduce\n\nI'm trying to create a embedding with llama index using Azure.\r\n\r\n```\r\n    llm_predictor = LLMPredictor(llm=AzureOpenAI(engine='gpt-35-turbo-16k'))\r\n    embedding_llm = LangchainEmbedding(OpenAIEmbeddings(deployment=\"text-embedding-ada-002\", model_kwargs={\r\n        \"api_key\": '<foobar>',\r\n        \"api_base\": '<foobar>',\r\n        \"api_type\": \"azure\",\r\n        \"api_version\": '<foobar>'\r\n    }))\r\n\r\n    prompt_helper = PromptHelper(context_window=3000, num_output=500, chunk_overlap_ratio=0.1, chunk_size_limit=1000)\r\n\r\n    reader_pdf = ReaderPDF()\r\n    documents = reader_pdf.read()\r\n\r\n    index = GPTVectorStoreIndex(documents, llm_predictor=llm_predictor, embed_model=embedding_llm, prompt_helper=prompt_helper)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7312/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7312/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7311",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7311/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7311/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7311/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7311",
        "id": 1857048858,
        "node_id": "PR_kwDOIWuq585YREyS",
        "number": 7311,
        "title": "Reader and Vector Store for BagelDB with example notebooks",
        "user": {
            "login": "Asif1405",
            "id": 55946060,
            "node_id": "MDQ6VXNlcjU1OTQ2MDYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/55946060?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Asif1405",
            "html_url": "https://github.com/Asif1405",
            "followers_url": "https://api.github.com/users/Asif1405/followers",
            "following_url": "https://api.github.com/users/Asif1405/following{/other_user}",
            "gists_url": "https://api.github.com/users/Asif1405/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Asif1405/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Asif1405/subscriptions",
            "organizations_url": "https://api.github.com/users/Asif1405/orgs",
            "repos_url": "https://api.github.com/users/Asif1405/repos",
            "events_url": "https://api.github.com/users/Asif1405/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Asif1405/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-18T17:25:04Z",
        "updated_at": "2023-08-21T15:35:02Z",
        "closed_at": "2023-08-21T15:08:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7311",
            "html_url": "https://github.com/run-llama/llama_index/pull/7311",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7311.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7311.patch",
            "merged_at": "2023-08-21T15:08:09Z"
        },
        "body": "# Summary\r\n\r\n- Created bagel reader (bagel.py in Reader folder) and bagel vector store (bagel.py in Vector store folder)\r\n- added two examples ipynb files for bagel index and autoretriever\r\n- added bagel in reader and vector store init files\r\n- successfully ran make format; make lint\r\n- successfully ran pytest tests",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7311/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7311/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7310",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7310/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7310/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7310/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7310",
        "id": 1856903459,
        "node_id": "I_kwDOIWuq585urhkj",
        "number": 7310,
        "title": "[Feature Request]: Framework and guide on creating datasets for {e2e, retrieval, LLM}",
        "user": {
            "login": "jon-chuang",
            "id": 9093549,
            "node_id": "MDQ6VXNlcjkwOTM1NDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jon-chuang",
            "html_url": "https://github.com/jon-chuang",
            "followers_url": "https://api.github.com/users/jon-chuang/followers",
            "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}",
            "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions",
            "organizations_url": "https://api.github.com/users/jon-chuang/orgs",
            "repos_url": "https://api.github.com/users/jon-chuang/repos",
            "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jon-chuang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-18T15:21:56Z",
        "updated_at": "2023-11-02T17:52:30Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nTasks:\r\n- [ ] Add `Dataset` class\n\n### Reason\n\n_No response_\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7310/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7310/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7309",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7309/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7309/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7309/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7309",
        "id": 1856785183,
        "node_id": "I_kwDOIWuq585urEsf",
        "number": 7309,
        "title": "[Question]: list' object has no attribute 'get_content'",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-18T14:05:52Z",
        "updated_at": "2023-08-18T15:07:43Z",
        "closed_at": "2023-08-18T15:07:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n```\r\ndoc = SimpleDirectoryReader(f'{path_for_index}').load_data()\r\nindex.insert(doc)\r\n```\r\n\r\n20 txt files in the folder, trying to insert to the index, but got error list' object has no attribute 'get_content'",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7309/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7309/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7308",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7308/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7308/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7308/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7308",
        "id": 1856239727,
        "node_id": "I_kwDOIWuq585uo_hv",
        "number": 7308,
        "title": "[Question]: Does that merge storage is posibble?",
        "user": {
            "login": "284nnuS",
            "id": 91007431,
            "node_id": "MDQ6VXNlcjkxMDA3NDMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/91007431?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/284nnuS",
            "html_url": "https://github.com/284nnuS",
            "followers_url": "https://api.github.com/users/284nnuS/followers",
            "following_url": "https://api.github.com/users/284nnuS/following{/other_user}",
            "gists_url": "https://api.github.com/users/284nnuS/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/284nnuS/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/284nnuS/subscriptions",
            "organizations_url": "https://api.github.com/users/284nnuS/orgs",
            "repos_url": "https://api.github.com/users/284nnuS/repos",
            "events_url": "https://api.github.com/users/284nnuS/events{/privacy}",
            "received_events_url": "https://api.github.com/users/284nnuS/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-18T07:48:50Z",
        "updated_at": "2023-10-24T06:30:28Z",
        "closed_at": "2023-10-24T06:30:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nHello, i try to add mutiple storage with this code :\r\n\r\n```     \r\nindex_private = load_indices_from_storage(\r\n                storage_context=StorageContext.from_defaults(persist_dir=os.environ['root'][:-4]+'/kb/'+project_id)\r\n            )\r\n            index_public = load_indices_from_storage(\r\n                storage_context=StorageContext.from_defaults(persist_dir=os.environ['root'][:-4]+'/kb/public')\r\n            )\r\n\r\n            index_private.append(index_public)\r\n\r\n            index = index_private[0]\r\n            print(len(index))\r\n            query_engine = index.as_query_engine(\r\n                text_qa_template=self.qa_template,\r\n                similarity_top_k=1,\r\n            )\r\n```\r\n     But it seem be not work. So does that merge storage is posible",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7308/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7308/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7307",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7307/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7307/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7307/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7307",
        "id": 1856100715,
        "node_id": "PR_kwDOIWuq585YN2DX",
        "number": 7307,
        "title": "add finetune tutorial",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-18T05:55:23Z",
        "updated_at": "2023-08-18T06:06:38Z",
        "closed_at": "2023-08-18T06:06:37Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7307",
            "html_url": "https://github.com/run-llama/llama_index/pull/7307",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7307.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7307.patch",
            "merged_at": "2023-08-18T06:06:37Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7307/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7307/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7306",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7306/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7306/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7306/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7306",
        "id": 1856055211,
        "node_id": "I_kwDOIWuq585uoSer",
        "number": 7306,
        "title": "[Question]: ngql error",
        "user": {
            "login": "yashdeepyds",
            "id": 31975772,
            "node_id": "MDQ6VXNlcjMxOTc1Nzcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/31975772?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yashdeepyds",
            "html_url": "https://github.com/yashdeepyds",
            "followers_url": "https://api.github.com/users/yashdeepyds/followers",
            "following_url": "https://api.github.com/users/yashdeepyds/following{/other_user}",
            "gists_url": "https://api.github.com/users/yashdeepyds/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yashdeepyds/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yashdeepyds/subscriptions",
            "organizations_url": "https://api.github.com/users/yashdeepyds/orgs",
            "repos_url": "https://api.github.com/users/yashdeepyds/repos",
            "events_url": "https://api.github.com/users/yashdeepyds/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yashdeepyds/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-18T04:58:08Z",
        "updated_at": "2023-10-24T06:30:26Z",
        "closed_at": "2023-10-24T06:30:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\n%ngql INSERT VERTEX table(name) VALUES 'abc':('abc');\r\n%ngql INSERT VERTEX column(name) VALUES 'column_xyz':('xyz');\r\n%ngql CREATE EDGE IF NOT EXISTS has_column(has_column STRING);\r\n%ngql INSERT EDGE has_column() VALUES \"abc\"->\"column_xyz\": (); \r\nUsageError: unrecognized arguments: ->\"column_xyz\": ();",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7306/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7306/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7305",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7305/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7305/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7305/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7305",
        "id": 1855836033,
        "node_id": "PR_kwDOIWuq585YM9qf",
        "number": 7305,
        "title": "Support Firestore as LlamaIndex Storage",
        "user": {
            "login": "pl04351820",
            "id": 10365273,
            "node_id": "MDQ6VXNlcjEwMzY1Mjcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/10365273?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pl04351820",
            "html_url": "https://github.com/pl04351820",
            "followers_url": "https://api.github.com/users/pl04351820/followers",
            "following_url": "https://api.github.com/users/pl04351820/following{/other_user}",
            "gists_url": "https://api.github.com/users/pl04351820/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pl04351820/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pl04351820/subscriptions",
            "organizations_url": "https://api.github.com/users/pl04351820/orgs",
            "repos_url": "https://api.github.com/users/pl04351820/repos",
            "events_url": "https://api.github.com/users/pl04351820/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pl04351820/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-17T23:29:49Z",
        "updated_at": "2023-08-20T23:01:42Z",
        "closed_at": "2023-08-20T23:01:42Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7305",
            "html_url": "https://github.com/run-llama/llama_index/pull/7305",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7305.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7305.patch",
            "merged_at": "2023-08-20T23:01:42Z"
        },
        "body": "# Description\r\n\r\nThis PR adds support for using Google Firestore as LlamaIndex KV/Doc/Index Storage.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nAdded test coverage for all new storage supported on top of the Firestore.\r\n\r\n- [X] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7305/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7305/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7304",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7304/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7304/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7304/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7304",
        "id": 1855697906,
        "node_id": "PR_kwDOIWuq585YMfhP",
        "number": 7304,
        "title": "Chat tracing",
        "user": {
            "login": "sourabhdesai",
            "id": 3005241,
            "node_id": "MDQ6VXNlcjMwMDUyNDE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3005241?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sourabhdesai",
            "html_url": "https://github.com/sourabhdesai",
            "followers_url": "https://api.github.com/users/sourabhdesai/followers",
            "following_url": "https://api.github.com/users/sourabhdesai/following{/other_user}",
            "gists_url": "https://api.github.com/users/sourabhdesai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sourabhdesai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sourabhdesai/subscriptions",
            "organizations_url": "https://api.github.com/users/sourabhdesai/orgs",
            "repos_url": "https://api.github.com/users/sourabhdesai/repos",
            "events_url": "https://api.github.com/users/sourabhdesai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sourabhdesai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-17T20:54:11Z",
        "updated_at": "2023-08-18T15:40:56Z",
        "closed_at": "2023-08-18T15:23:29Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7304",
            "html_url": "https://github.com/run-llama/llama_index/pull/7304",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7304.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7304.patch",
            "merged_at": "2023-08-18T15:23:29Z"
        },
        "body": "# Description\r\n\r\nIntroduces a `trace_method` decorator to add tracing across a whole method + uses it to introduce chat tracing for agents & chat engines.\r\n\r\nFixes # https://github.com/jerryjliu/llama_index/issues/7290\r\n\r\n## Type of Change\r\n\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n\r\n**Still need to do testing of this**\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\nTesting TBD\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7304/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7304/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7303",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7303/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7303/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7303/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7303",
        "id": 1855551472,
        "node_id": "PR_kwDOIWuq585YL__M",
        "number": 7303,
        "title": "Fix sentence splitter bug",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T19:05:06Z",
        "updated_at": "2023-08-18T15:24:00Z",
        "closed_at": "2023-08-18T15:23:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7303",
            "html_url": "https://github.com/run-llama/llama_index/pull/7303",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7303.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7303.patch",
            "merged_at": "2023-08-18T15:23:59Z"
        },
        "body": "# Description\r\n\r\nFix infinite recursion bug when split length is between [chunk_size - chunk_overlap, chunk_size]\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7287 ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7303/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7303/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7302",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7302/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7302/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7302/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7302",
        "id": 1855535313,
        "node_id": "PR_kwDOIWuq585YL8cW",
        "number": 7302,
        "title": "[version] bump to 0.8.4",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-17T18:52:15Z",
        "updated_at": "2023-08-17T18:59:05Z",
        "closed_at": "2023-08-17T18:59:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7302",
            "html_url": "https://github.com/run-llama/llama_index/pull/7302",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7302.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7302.patch",
            "merged_at": "2023-08-17T18:59:04Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7302/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7302/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7301",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7301/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7301/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7301/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7301",
        "id": 1855491372,
        "node_id": "PR_kwDOIWuq585YLzBC",
        "number": 7301,
        "title": "Consider defining heavy dependencies as extras",
        "user": {
            "login": "corvis",
            "id": 5593615,
            "node_id": "MDQ6VXNlcjU1OTM2MTU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5593615?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/corvis",
            "html_url": "https://github.com/corvis",
            "followers_url": "https://api.github.com/users/corvis/followers",
            "following_url": "https://api.github.com/users/corvis/following{/other_user}",
            "gists_url": "https://api.github.com/users/corvis/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/corvis/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/corvis/subscriptions",
            "organizations_url": "https://api.github.com/users/corvis/orgs",
            "repos_url": "https://api.github.com/users/corvis/repos",
            "events_url": "https://api.github.com/users/corvis/events{/privacy}",
            "received_events_url": "https://api.github.com/users/corvis/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5870195877,
                "node_id": "LA_kwDOIWuq588AAAABXeQUpQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/packaging",
                "name": "packaging",
                "color": "16338D",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T18:19:11Z",
        "updated_at": "2023-08-21T18:21:15Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7301",
            "html_url": "https://github.com/run-llama/llama_index/pull/7301",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7301.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7301.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nFirst of all, thank you for this project - the library is great and we find it highly useful. \r\n\r\nThe problem any big project trying to adopt a new library always have is to make all dependencies aligned (compatible). As any universal library `llama_index` depends on a number of external libs needed for different functional module. What I suggest doing is moving as many dependencies as possible into extras (optional dependencies) so user of the library has a choice weather or not to install it. I suspect it will be pretty common case when someone needs just a one specific feature from the lib and doesn't need 10 others depending on some extra lib.\r\n\r\nIn our case we don't need any database related features so we don't want `llama_index` to pull in the `sqlalchemy`. In our particular case it is even worth our core framework depends on `sqlalchemy~=1.4` while llama_index needs 2.x so we literally can't install it in our project. \r\n\r\nSo the suggestion here is a to revise dependencies and:\r\n\r\n1. Explicitly list dependencies the library uses directly. E.g. pydantic is used directly but is not listed in the list of deps. Probably better approach would be to add `pydantic>=1,<2.0` to make sure we give all needed info to dependency resolver.\r\n2. Move all dependencies which are not a part of the \"core\" under `extras` section in `setup.py`.\r\n3. Document extras in readme \r\n\r\nThis PR just illustrates an idea.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [X] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7301/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 2
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7301/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7300",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7300/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7300/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7300/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7300",
        "id": 1855466143,
        "node_id": "I_kwDOIWuq585umCqf",
        "number": 7300,
        "title": "Please help how to fix this",
        "user": {
            "login": "abganzon",
            "id": 36829154,
            "node_id": "MDQ6VXNlcjM2ODI5MTU0",
            "avatar_url": "https://avatars.githubusercontent.com/u/36829154?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/abganzon",
            "html_url": "https://github.com/abganzon",
            "followers_url": "https://api.github.com/users/abganzon/followers",
            "following_url": "https://api.github.com/users/abganzon/following{/other_user}",
            "gists_url": "https://api.github.com/users/abganzon/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/abganzon/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/abganzon/subscriptions",
            "organizations_url": "https://api.github.com/users/abganzon/orgs",
            "repos_url": "https://api.github.com/users/abganzon/repos",
            "events_url": "https://api.github.com/users/abganzon/events{/privacy}",
            "received_events_url": "https://api.github.com/users/abganzon/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-08-17T18:01:12Z",
        "updated_at": "2023-08-17T19:02:44Z",
        "closed_at": "2023-08-17T19:02:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n[/usr/local/lib/python3.10/dist-packages/pydantic/deprecated/class_validators.py](https://localhost:8080/#) in root_validator(pre, skip_on_failure, allow_reuse, *__args)\r\n    226     mode: Literal['before', 'after'] = 'before' if pre is True else 'after'\r\n    227     if pre is False and skip_on_failure is not True:\r\n--> 228         raise PydanticUserError(\r\n    229             'If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.'\r\n    230             ' Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.',\r\n\r\nPydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\n### Version\n\n0.8.3\n\n### Steps to Reproduce\n\n[/usr/local/lib/python3.10/dist-packages/pydantic/deprecated/class_validators.py](https://localhost:8080/#) in root_validator(pre, skip_on_failure, allow_reuse, *__args)\r\n    226     mode: Literal['before', 'after'] = 'before' if pre is True else 'after'\r\n    227     if pre is False and skip_on_failure is not True:\r\n--> 228         raise PydanticUserError(\r\n    229             'If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.'\r\n    230             ' Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.',\r\n\r\nPydanticUserError: If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`. Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7300/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7300/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7299",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7299/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7299/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7299/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7299",
        "id": 1855311519,
        "node_id": "I_kwDOIWuq585ulc6f",
        "number": 7299,
        "title": "[Feature Request]: Number citations sequentially in the CitationQueryEngine.",
        "user": {
            "login": "jimmarshall87",
            "id": 3678081,
            "node_id": "MDQ6VXNlcjM2NzgwODE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3678081?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jimmarshall87",
            "html_url": "https://github.com/jimmarshall87",
            "followers_url": "https://api.github.com/users/jimmarshall87/followers",
            "following_url": "https://api.github.com/users/jimmarshall87/following{/other_user}",
            "gists_url": "https://api.github.com/users/jimmarshall87/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jimmarshall87/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jimmarshall87/subscriptions",
            "organizations_url": "https://api.github.com/users/jimmarshall87/orgs",
            "repos_url": "https://api.github.com/users/jimmarshall87/repos",
            "events_url": "https://api.github.com/users/jimmarshall87/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jimmarshall87/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5860091515,
                "node_id": "LA_kwDOIWuq588AAAABXUnmew",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/stale",
                "name": "stale",
                "color": "dadada",
                "default": false,
                "description": "Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-08-17T16:18:37Z",
        "updated_at": "2023-12-13T16:01:41Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nNumber citations sequentially in the CitationQueryEngine.\n\n### Reason\n\nAt present, CitationQueryEngine provides citation references to source nodes used to generate the answer. However, since not all nodes are necessarily used to answer the question, this can lead to output like the following.\r\n\r\n```\r\nThe quick brown fox [5] jumped over the lazy dog [2].\r\n```\r\nWhen presenting these results to a user, this leads to the below rather strange format:\r\n\r\n```\r\nThe quick brown fox [5] jumped over the lazy dog [2].\r\nReferences:\r\n[5] Source document ABC\r\n[2] Source document DEF\r\n```\r\n\r\nWhat would be much better and more intuitive from a presentation perspective would be for citations to be numbered starting with the lowest first and sequentially. This would result in something like:\r\n\r\n```\r\nThe quick brown fox [1] jumped over the lazy dog [2].\r\nReferences:\r\n[1] Source document ABC\r\n[2] Source document DEF\r\n```\r\n\n\n### Value of Feature\n\n- More intuitive\r\n- More in line with common citation techniques",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7299/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7299/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7298",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7298/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7298/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7298/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7298",
        "id": 1855170403,
        "node_id": "I_kwDOIWuq585uk6dj",
        "number": 7298,
        "title": "[Question]: `RouterQueryEngine` what is recommended way to access selected engine?",
        "user": {
            "login": "h1Logic",
            "id": 19204087,
            "node_id": "MDQ6VXNlcjE5MjA0MDg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/19204087?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/h1Logic",
            "html_url": "https://github.com/h1Logic",
            "followers_url": "https://api.github.com/users/h1Logic/followers",
            "following_url": "https://api.github.com/users/h1Logic/following{/other_user}",
            "gists_url": "https://api.github.com/users/h1Logic/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/h1Logic/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/h1Logic/subscriptions",
            "organizations_url": "https://api.github.com/users/h1Logic/orgs",
            "repos_url": "https://api.github.com/users/h1Logic/repos",
            "events_url": "https://api.github.com/users/h1Logic/events{/privacy}",
            "received_events_url": "https://api.github.com/users/h1Logic/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-08-17T14:54:18Z",
        "updated_at": "2023-10-24T06:30:24Z",
        "closed_at": "2023-10-24T06:30:24Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, \r\n\r\nwhat is recommended way to access selected tool/engine in `RouterQueryEngine`? As far as i can tell it's only logged via `logger.info()` but it's not stored anywhere. It would be great if either it can be returned or stored as `property` (or example 'last_selected_engine_ind`).\r\n\r\nThanks!  ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7298/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7298/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7297",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7297/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7297/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7297/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7297",
        "id": 1855161194,
        "node_id": "PR_kwDOIWuq585YKqR9",
        "number": 7297,
        "title": "pin langchain version to avoid pydantic v2",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-17T14:49:05Z",
        "updated_at": "2023-08-17T16:31:11Z",
        "closed_at": "2023-08-17T16:31:10Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7297",
            "html_url": "https://github.com/run-llama/llama_index/pull/7297",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7297.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7297.patch",
            "merged_at": "2023-08-17T16:31:10Z"
        },
        "body": "# Description\r\n\r\nLangchain is moving to pydantic v2 in a staged process. We likely don't need to follow the same migration plan, but we can at least pin the langchain version for now and be ready for when they fully migrate.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7297/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7297/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7296",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7296/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7296/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7296/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7296",
        "id": 1854835959,
        "node_id": "I_kwDOIWuq585ujoz3",
        "number": 7296,
        "title": "[Question]: How to add previous Chat context when querying an index?",
        "user": {
            "login": "niels-bosman",
            "id": 25898715,
            "node_id": "MDQ6VXNlcjI1ODk4NzE1",
            "avatar_url": "https://avatars.githubusercontent.com/u/25898715?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/niels-bosman",
            "html_url": "https://github.com/niels-bosman",
            "followers_url": "https://api.github.com/users/niels-bosman/followers",
            "following_url": "https://api.github.com/users/niels-bosman/following{/other_user}",
            "gists_url": "https://api.github.com/users/niels-bosman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/niels-bosman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/niels-bosman/subscriptions",
            "organizations_url": "https://api.github.com/users/niels-bosman/orgs",
            "repos_url": "https://api.github.com/users/niels-bosman/repos",
            "events_url": "https://api.github.com/users/niels-bosman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/niels-bosman/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-08-17T11:42:49Z",
        "updated_at": "2023-08-23T02:04:46Z",
        "closed_at": "2023-08-23T02:04:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am looking for a way to send the context of my chat application to Llama index via the .query() function but it seems like it only accepts a string:\r\n\r\n```py\r\nstreaming_response = index.as_query_engine(\r\n        streaming=True, similarity_top_k=1\r\n    ).query(query_text)\r\n```\r\n\r\nI would like to know how I can make it so Llama understands the context of my chats like I can do with OpenAI:\r\n\r\n```js\r\nopenai.ChatCompletion.create(\r\n  model=\"gpt-3.5-turbo\",\r\n  messages=[\r\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\r\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\r\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\r\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\r\n    ]\r\n)\r\n```\r\n\r\nAny tips on how I can achieve this using the Llama API? Thanks.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7296/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7296/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7295",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7295/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7295/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7295/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7295",
        "id": 1854697867,
        "node_id": "PR_kwDOIWuq585YJENb",
        "number": 7295,
        "title": "Avoid infinite loop on small chunk sizes",
        "user": {
            "login": "JPMoresmau",
            "id": 122273,
            "node_id": "MDQ6VXNlcjEyMjI3Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/122273?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JPMoresmau",
            "html_url": "https://github.com/JPMoresmau",
            "followers_url": "https://api.github.com/users/JPMoresmau/followers",
            "following_url": "https://api.github.com/users/JPMoresmau/following{/other_user}",
            "gists_url": "https://api.github.com/users/JPMoresmau/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JPMoresmau/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JPMoresmau/subscriptions",
            "organizations_url": "https://api.github.com/users/JPMoresmau/orgs",
            "repos_url": "https://api.github.com/users/JPMoresmau/repos",
            "events_url": "https://api.github.com/users/JPMoresmau/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JPMoresmau/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-08-17T10:11:00Z",
        "updated_at": "2023-08-18T03:06:10Z",
        "closed_at": "2023-08-18T03:06:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7295",
            "html_url": "https://github.com/run-llama/llama_index/pull/7295",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7295.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7295.patch",
            "merged_at": "2023-08-18T03:06:09Z"
        },
        "body": "# Description\r\n\r\nWith a short chunk size, the merge method gets into an infinite loop.\r\n\r\nFixes #7287\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n- [X] I ran the code on the data that caused the problem and it fixed the issue.\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7295/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7295/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7294",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7294/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7294/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7294/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7294",
        "id": 1854591551,
        "node_id": "I_kwDOIWuq585uitI_",
        "number": 7294,
        "title": "[Bug]: No information on NLSQLTableQueryEngine",
        "user": {
            "login": "sidd4848",
            "id": 11235028,
            "node_id": "MDQ6VXNlcjExMjM1MDI4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11235028?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sidd4848",
            "html_url": "https://github.com/sidd4848",
            "followers_url": "https://api.github.com/users/sidd4848/followers",
            "following_url": "https://api.github.com/users/sidd4848/following{/other_user}",
            "gists_url": "https://api.github.com/users/sidd4848/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sidd4848/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sidd4848/subscriptions",
            "organizations_url": "https://api.github.com/users/sidd4848/orgs",
            "repos_url": "https://api.github.com/users/sidd4848/repos",
            "events_url": "https://api.github.com/users/sidd4848/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sidd4848/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T09:14:28Z",
        "updated_at": "2023-11-23T16:01:36Z",
        "closed_at": "2023-11-23T16:01:35Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI am using postgresql connection and below is the code I am trying to run but, I didnt find any proper way to modify the sql or add prompt. Can someone help me on that?\r\n```\r\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\r\n\r\nquery_engine = NLSQLTableQueryEngine(\r\n    sql_database=sql_database,\r\n    service_context = service_context_chatgpt,\r\n    tables = ['TABLE_A']\r\n)\r\nquery_str = \"Which state has the highest population?\"\r\nresponse = query_engine.query(query_str)\r\nprint(response)\r\n```\r\n\r\nerror:\r\n\r\n> sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation \"TABLE_A\" does not exist\r\n> LINE 1: SELECT state, count(*) as \"count\" FROM TABLE_A GROUP BY...\r\n\r\nThe proper query for the postgresql is \r\n`SELECT state, count(*) as \"count\" FROM SCHEMA_1.\"TABLE_A\" GROUP BY...`\r\n\r\nCan anyone help in figuring this out?\n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\ncopy paste the code and use postgresql or help in modifying the sql query it generates\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7294/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7294/timeline",
        "performed_via_github_app": null,
        "state_reason": "not_planned"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7293",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7293/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7293/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7293/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7293",
        "id": 1854473342,
        "node_id": "I_kwDOIWuq585uiQR-",
        "number": 7293,
        "title": "[Bug]: Not able to find key and not able to query from the database",
        "user": {
            "login": "sidd4848",
            "id": 11235028,
            "node_id": "MDQ6VXNlcjExMjM1MDI4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11235028?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sidd4848",
            "html_url": "https://github.com/sidd4848",
            "followers_url": "https://api.github.com/users/sidd4848/followers",
            "following_url": "https://api.github.com/users/sidd4848/following{/other_user}",
            "gists_url": "https://api.github.com/users/sidd4848/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sidd4848/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sidd4848/subscriptions",
            "organizations_url": "https://api.github.com/users/sidd4848/orgs",
            "repos_url": "https://api.github.com/users/sidd4848/repos",
            "events_url": "https://api.github.com/users/sidd4848/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sidd4848/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T07:58:05Z",
        "updated_at": "2023-08-17T08:36:52Z",
        "closed_at": "2023-08-17T08:36:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nCode:\r\n```\r\ndbschema='B'\r\nconnection = create_engine('postgresql://....', connect_args={'options': '-csearch_path={}'.format(dbschema)})\r\n\r\nopenai_api_key = os.getenv(\"OPENAI_API_KEY\")\r\nopenai_api_base = os.getenv(\"OPENAI_API_BASE\")\r\n\r\n# Create an AzureOpenAI LLM predictor\r\nllm = AzureOpenAI(api_key=openai_api_key, api_base=openai_api_base, engine=\"gpt-35-turbo\")\r\n\r\nsql_database = SQLDatabase(connection, include_tables=[\"B\"])\r\n\r\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\r\n\r\nquery_engine = NLSQLTableQueryEngine(\r\n    sql_database=sql_database,\r\n    tables = [\"B\"]\r\n)\r\nquery_str = \"Which state has the highest population?\"\r\nresponse = query_engine.query(query_str)\r\nprint(response)\r\n```\r\nError:\r\n\r\n> \r\n> openai.error.AuthenticationError: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable O\r\n> PENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys i\r\n> n the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\r\n\r\nIf I use openai library and then add the keys, still it is not able to find the engine or deployment id\r\n\r\nAny way I can use it?\n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\nDocumentation is unclear on how to connect it properly\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7293/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7293/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7292",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7292/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7292/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7292/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7292",
        "id": 1854212313,
        "node_id": "I_kwDOIWuq585uhQjZ",
        "number": 7292,
        "title": "[Bug]: not able to find the SQL table",
        "user": {
            "login": "sidd4848",
            "id": 11235028,
            "node_id": "MDQ6VXNlcjExMjM1MDI4",
            "avatar_url": "https://avatars.githubusercontent.com/u/11235028?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sidd4848",
            "html_url": "https://github.com/sidd4848",
            "followers_url": "https://api.github.com/users/sidd4848/followers",
            "following_url": "https://api.github.com/users/sidd4848/following{/other_user}",
            "gists_url": "https://api.github.com/users/sidd4848/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sidd4848/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sidd4848/subscriptions",
            "organizations_url": "https://api.github.com/users/sidd4848/orgs",
            "repos_url": "https://api.github.com/users/sidd4848/repos",
            "events_url": "https://api.github.com/users/sidd4848/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sidd4848/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T04:09:47Z",
        "updated_at": "2023-08-17T07:44:19Z",
        "closed_at": "2023-08-17T07:44:19Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nWhile using this query:\r\n```\r\nsql_database = SQLDatabase(connection, schema='A', include_tables=[\"B\"])\r\nprint(sql_database.table_info)\r\n```\r\n\r\nafter that I wanted to run the below query:\r\n```\r\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\r\n\r\nquery_engine = NLSQLTableQueryEngine(\r\n    sql_database=sql_database,\r\n    tables = ['B']\r\n)\r\n```\r\n\r\nbut all I am getting is sqlalchemy.exc.NoSuchTableError: B\r\n\r\n\r\n\r\n### Version\r\n\r\nlatest\r\n\r\n### Steps to Reproduce\r\n\r\nI connected the database connection/engine to postgresql using library:  from sqlalchemy import create_engine\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7292/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7292/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7291",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7291/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7291/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7291/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7291",
        "id": 1854186963,
        "node_id": "PR_kwDOIWuq585YHVPt",
        "number": 7291,
        "title": "Add Awadb vector store",
        "user": {
            "login": "rouch789",
            "id": 75009371,
            "node_id": "MDQ6VXNlcjc1MDA5Mzcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/75009371?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rouch789",
            "html_url": "https://github.com/rouch789",
            "followers_url": "https://api.github.com/users/rouch789/followers",
            "following_url": "https://api.github.com/users/rouch789/following{/other_user}",
            "gists_url": "https://api.github.com/users/rouch789/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rouch789/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rouch789/subscriptions",
            "organizations_url": "https://api.github.com/users/rouch789/orgs",
            "repos_url": "https://api.github.com/users/rouch789/repos",
            "events_url": "https://api.github.com/users/rouch789/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rouch789/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-08-17T03:31:13Z",
        "updated_at": "2023-08-19T01:28:46Z",
        "closed_at": "2023-08-19T01:28:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7291",
            "html_url": "https://github.com/run-llama/llama_index/pull/7291",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7291.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7291.patch",
            "merged_at": "2023-08-19T01:28:46Z"
        },
        "body": "# Description\r\n\r\nAdded new Awadb vector repository and corresponding test files\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7291/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7291/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7290",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7290/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7290/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7290/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7290",
        "id": 1854169298,
        "node_id": "I_kwDOIWuq585uhGDS",
        "number": 7290,
        "title": "[Bug]: Callback events are not enclosed within a trace",
        "user": {
            "login": "axiomofjoy",
            "id": 15664869,
            "node_id": "MDQ6VXNlcjE1NjY0ODY5",
            "avatar_url": "https://avatars.githubusercontent.com/u/15664869?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axiomofjoy",
            "html_url": "https://github.com/axiomofjoy",
            "followers_url": "https://api.github.com/users/axiomofjoy/followers",
            "following_url": "https://api.github.com/users/axiomofjoy/following{/other_user}",
            "gists_url": "https://api.github.com/users/axiomofjoy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axiomofjoy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axiomofjoy/subscriptions",
            "organizations_url": "https://api.github.com/users/axiomofjoy/orgs",
            "repos_url": "https://api.github.com/users/axiomofjoy/repos",
            "events_url": "https://api.github.com/users/axiomofjoy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axiomofjoy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-08-17T03:10:10Z",
        "updated_at": "2023-08-23T02:01:50Z",
        "closed_at": "2023-08-23T02:01:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhile building a callback and testing with an OpenAI chat agent, I noticed that the `on_event_start` and `on_event_end` callback hooks are called without being preceded by a call to `start_trace` and without being followed by a call to `end_trace`. I had implemented the flush logic inside of `end_trace`, so my accumulated trace data is not flushed at the end of the trace.\r\n\r\n<img width=\"519\" alt=\"Screenshot 2023-08-16 at 7 54 12 PM\" src=\"https://github.com/jerryjliu/llama_index/assets/15664869/596201ce-ba00-47e5-bdc9-cc9702ab9d5d\">\r\n\n\n### Version\n\nlatest main (3506143d)\n\n### Steps to Reproduce\n\nRun the following script:\r\n\r\n```python\r\nimport sys\r\nimport logging\r\nfrom gcsfs import GCSFileSystem\r\nfrom llama_index import ServiceContext, StorageContext, load_index_from_storage\r\nfrom llama_index.callbacks import CallbackManager\r\nfrom llama_index.embeddings.openai import OpenAIEmbedding\r\nfrom llama_index.graph_stores.simple import SimpleGraphStore\r\nfrom llama_index.llms import ChatMessage, MessageRole, OpenAI\r\nfrom llama_index.callbacks.base_handler import BaseCallbackHandler\r\nfrom llama_index.callbacks.schema import CBEventType\r\nfrom typing import Any, Dict, Optional, List\r\n\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\nlogging.basicConfig(level=logging.DEBUG, stream=sys.stdout)\r\n\r\n\r\nclass DebugCallbackHandler(BaseCallbackHandler):\r\n    def on_event_start(\r\n        self,\r\n        event_type: CBEventType,\r\n        payload: Optional[Dict[str, Any]] = None,\r\n        event_id: str = \"\",\r\n        **kwargs: Any,\r\n    ) -> str:\r\n        logger.info(f\"on_event_start: {event_type.value}\")\r\n\r\n    def on_event_end(\r\n        self,\r\n        event_type: CBEventType,\r\n        payload: Optional[Dict[str, Any]] = None,\r\n        event_id: str = \"\",\r\n        **kwargs: Any,\r\n    ) -> None:\r\n        logger.info(f\"on_event_end: {event_type.value}\")\r\n\r\n    def start_trace(self, trace_id: Optional[str] = None) -> None:\r\n        logger.info(f\"start_trace: {trace_id}\")\r\n\r\n    def end_trace(\r\n        self,\r\n        trace_id: Optional[str] = None,\r\n        trace_map: Optional[Dict[str, List[str]]] = None,\r\n    ) -> None:\r\n        logger.info(f\"end_trace: {trace_id}\")\r\n\r\n\r\nfile_system = GCSFileSystem(project=\"public-assets-275721\")\r\nindex_path = (\r\n    \"arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/\"\r\n)\r\nstorage_context = StorageContext.from_defaults(\r\n    fs=file_system,\r\n    persist_dir=index_path,\r\n    graph_store=SimpleGraphStore(),  # prevents unauthorized request to GCS\r\n)\r\ncallback_handler = DebugCallbackHandler(\r\n    event_ends_to_ignore=[], event_starts_to_ignore=[]\r\n)\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0),\r\n    embed_model=OpenAIEmbedding(model=\"text-embedding-ada-002\"),\r\n    callback_manager=CallbackManager(handlers=[callback_handler]),\r\n)\r\nindex = load_index_from_storage(\r\n    storage_context,\r\n    service_context=service_context,\r\n)\r\nagent = index.as_chat_engine(\r\n    chat_mode=\"openai\",\r\n    callback_manager=CallbackManager(handlers=[callback_handler]),\r\n)\r\n\r\nresponse = agent.chat(\r\n    \"Can you explain what that means?\",\r\n    chat_history=[\r\n        ChatMessage(role=MessageRole.USER, content=\"What is Arize?\"),\r\n        ChatMessage(\r\n            role=MessageRole.ASSISTANT,\r\n            content=\"Arize is a ML observability platform.\",\r\n        ),\r\n    ],\r\n)\r\nprint(response)\r\n```\n\n### Relevant Logs/Tracbacks\n\n```shell\nDEBUG:asyncio:Using selector: KqueueSelector\r\nDEBUG:google.auth._default:Checking None for explicit credentials as part of auth process...\r\nDEBUG:google.auth._default:Checking Cloud SDK credentials as part of auth process...\r\nDEBUG:gcsfs.credentials:Connection with method \"google_default\" failed\r\nTraceback (most recent call last):\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 232, in connect\r\n    self.connect(method=meth)\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 249, in connect\r\n    self.__getattribute__(\"_connect_\" + method)()\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 88, in _connect_google_default\r\n    raise ValueError(msg.format(self.project, project))\r\nValueError: User-provided project 'public-assets-275721' does not match the google default project 'primal-oxide-268801'. Either\r\n\r\n  1. Accept the google-default project by not passing a `project` to GCSFileSystem\r\n  2. Configure the default project to match the user-provided project (gcloud config set project)\r\n  3. Use an authorization method other than 'google_default' by providing 'token=...'\r\n\r\nDEBUG:gcsfs.credentials:Connection with method \"cache\" failed\r\nTraceback (most recent call last):\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 232, in connect\r\n    self.connect(method=meth)\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 249, in connect\r\n    self.__getattribute__(\"_connect_\" + method)()\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 104, in _connect_cache\r\n    raise ValueError(\"No cached tokens\")\r\nValueError: No cached tokens\r\nDEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\r\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (1): metadata.google.internal:80\r\nWARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 1 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x172985270>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\r\nDEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\r\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (2): metadata.google.internal:80\r\nWARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 2 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x172985570>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\r\nDEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\r\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (3): metadata.google.internal:80\r\nWARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 3 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x172985930>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\r\nDEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\r\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (4): metadata.google.internal:80\r\nWARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 4 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x172985e70>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\r\nDEBUG:google.auth.transport.requests:Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true\r\nDEBUG:urllib3.connectionpool:Starting new HTTP connection (5): metadata.google.internal:80\r\nWARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 5 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1729863b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\r\nDEBUG:gcsfs.credentials:Connection with method \"cloud\" failed\r\nTraceback (most recent call last):\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/google/auth/compute_engine/credentials.py\", line 115, in refresh\r\n    self._retrieve_info(request)\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/google/auth/compute_engine/credentials.py\", line 88, in _retrieve_info\r\n    info = _metadata.get_service_account_info(\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/google/auth/compute_engine/_metadata.py\", line 287, in get_service_account_info\r\n    return get(request, path, params={\"recursive\": \"true\"})\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/google/auth/compute_engine/_metadata.py\", line 216, in get\r\n    raise exceptions.TransportError(\r\ngoogle.auth.exceptions.TransportError: Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Compute Engine Metadata server unavailable\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 97, in _connect_cloud\r\n    self.credentials.refresh(req)\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/google/auth/compute_engine/credentials.py\", line 121, in refresh\r\n    six.raise_from(new_exc, caught_exc)\r\n  File \"<string>\", line 3, in raise_from\r\ngoogle.auth.exceptions.RefreshError: Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Compute Engine Metadata server unavailable\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 232, in connect\r\n    self.connect(method=meth)\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 249, in connect\r\n    self.__getattribute__(\"_connect_\" + method)()\r\n  File \"/Users/xandersong/miniforge3/envs/llmapps/lib/python3.10/site-packages/gcsfs/credentials.py\", line 99, in _connect_cloud\r\n    raise ValueError(\"Invalid gcloud credentials\") from error\r\nValueError: Invalid gcloud credentials\r\nDEBUG:gcsfs.credentials:Connected with method anon\r\nDEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/docstore.json.\r\nDEBUG:gcsfs:GET: b/{}/o/{}, ('arize-assets', 'phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/docstore.json'), None\r\nDEBUG:fsspec:<File-like object GCSFileSystem, arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/docstore.json> read: 0 - 1678221\r\nDEBUG:gcsfs:GET: https://storage.googleapis.com/download/storage/v1/b/arize-assets/o/phoenix%2Fdatasets%2Funstructured%2Fllm%2Fllama-index%2Farize-docs%2Findex%2Fdocstore.json?alt=media, (), {'Range': 'bytes=0-1678220'}\r\nDEBUG:llama_index.storage.kvstore.simple_kvstore:Loading llama_index.storage.kvstore.simple_kvstore from arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/index_store.json.\r\nDEBUG:gcsfs:GET: b/{}/o/{}, ('arize-assets', 'phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/index_store.json'), None\r\nDEBUG:fsspec:<File-like object GCSFileSystem, arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/index_store.json> read: 0 - 107263\r\nDEBUG:gcsfs:GET: https://storage.googleapis.com/download/storage/v1/b/arize-assets/o/phoenix%2Fdatasets%2Funstructured%2Fllm%2Fllama-index%2Farize-docs%2Findex%2Findex_store.json?alt=media, (), {'Range': 'bytes=0-107262'}\r\nDEBUG:gcsfs:GET: b/{}/o/{}, ('arize-assets', 'phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/vector_store.json'), None\r\nDEBUG:llama_index.vector_stores.simple:Loading llama_index.vector_stores.simple from arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/vector_store.json.\r\nDEBUG:gcsfs:GET: b/{}/o/{}, ('arize-assets', 'phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/vector_store.json'), None\r\nDEBUG:fsspec:<File-like object GCSFileSystem, arize-assets/phoenix/datasets/unstructured/llm/llama-index/arize-docs/index/vector_store.json> read: 0 - 43966360\r\nDEBUG:gcsfs:GET: https://storage.googleapis.com/download/storage/v1/b/arize-assets/o/phoenix%2Fdatasets%2Funstructured%2Fllm%2Fllama-index%2Farize-docs%2Findex%2Fvector_store.json?alt=media, (), {'Range': 'bytes=0-43966359'}\r\n[nltk_data] Downloading package punkt to\r\n[nltk_data]     /Users/xandersong/Library/Caches/llama_index...\r\n[nltk_data]   Unzipping tokenizers/punkt.zip.\r\nINFO:llama_index.indices.loading:Loading all indices.\r\nINFO:__main__:start_trace: index_construction\r\nINFO:__main__:end_trace: index_construction\r\nINFO:__main__:on_event_start: llm\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"What is Arize?\"}, {\"role\": \"assistant\", \"content\": \"Arize is a ML observability platform.\"}, {\"role\": \"user\", \"content\": \"Can you explain what that means?\"}], \"stream\": false, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0, \"max_tokens\": null, \"functions\": [{\"name\": \"query_engine_tool\", \"description\": \"Useful for running a natural language query\\\\nagainst a knowledge base and get back a natural language response.\\\\n\", \"parameters\": {\"title\": \"DefaultToolFnSchema\", \"description\": \"Default tool function Schema.\", \"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}}], \"function_call\": \"auto\"}' message='Post details'\r\nDEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\r\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443\r\nDEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\r\nDEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4666 request_id=5136dd250bd363ef02e6331851a3eaeb response_code=200\r\nINFO:__main__:on_event_end: llm\r\nCertainly! ML observability refers to the ability to understand and monitor the behavior and performance of machine learning models in production. It involves tracking and analyzing various metrics, such as model accuracy, latency, and resource utilization, to ensure that the models are performing as expected and to identify any issues or anomalies.\r\n\r\nArize is a platform that provides ML observability tools and capabilities. It helps data scientists, machine learning engineers, and AI practitioners gain insights into their models' performance and behavior in real-world scenarios. Arize allows users to monitor and analyze key metrics, visualize model performance, and detect any drift or degradation in model performance over time.\r\n\r\nBy using Arize, organizations can ensure that their machine learning models are delivering accurate and reliable results, identify and troubleshoot any issues that may arise, and ultimately improve the overall performance and effectiveness of their ML systems.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7290/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7290/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7289",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7289/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7289/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7289/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7289",
        "id": 1854135241,
        "node_id": "PR_kwDOIWuq585YHKXf",
        "number": 7289,
        "title": "move LLM and embeddings to pydantic",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-08-17T02:21:45Z",
        "updated_at": "2023-08-18T17:27:49Z",
        "closed_at": "2023-08-18T17:27:48Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7289",
            "html_url": "https://github.com/run-llama/llama_index/pull/7289",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7289.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7289.patch",
            "merged_at": "2023-08-18T17:27:48Z"
        },
        "body": "# Description\r\n\r\nOur core components should be using pydantic. This makes type checking and serializing object configs extremely easy.\r\n\r\nNOTE: while langchain (and by association, LlamaIndex) is moving to pydantic V2, the migration is pretty straightforward for us.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# TODO\r\n\r\n- [x] Run as many embedding models/LLMs as I can to confirm they all work\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7289/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7289/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]