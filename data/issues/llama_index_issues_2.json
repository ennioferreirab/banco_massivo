[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9429",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9429/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9429/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9429/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9429",
        "id": 2035063517,
        "node_id": "I_kwDOIWuq5855TJrd",
        "number": 9429,
        "title": "[Question]: Is it possible to search for equations stored in the NebularGraph DB?",
        "user": {
            "login": "JinSeoung-Oh",
            "id": 78573459,
            "node_id": "MDQ6VXNlcjc4NTczNDU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/78573459?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JinSeoung-Oh",
            "html_url": "https://github.com/JinSeoung-Oh",
            "followers_url": "https://api.github.com/users/JinSeoung-Oh/followers",
            "following_url": "https://api.github.com/users/JinSeoung-Oh/following{/other_user}",
            "gists_url": "https://api.github.com/users/JinSeoung-Oh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JinSeoung-Oh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JinSeoung-Oh/subscriptions",
            "organizations_url": "https://api.github.com/users/JinSeoung-Oh/orgs",
            "repos_url": "https://api.github.com/users/JinSeoung-Oh/repos",
            "events_url": "https://api.github.com/users/JinSeoung-Oh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JinSeoung-Oh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 23,
        "created_at": "2023-12-11T08:07:58Z",
        "updated_at": "2023-12-13T01:47:42Z",
        "closed_at": "2023-12-13T01:38:14Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, I have a question about searching for equations stored in the NebularGraph DB.\r\nwhen I run print(graph_store.get('\uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac')), then it show\r\n\r\n'\uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac{name: \uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac} -[relationship:{relationship: =}]-> (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \uc7a5\ucc29 \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac - \ubcf4\ud5d8\uac70\ub9ac \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac) x (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \ubbf8\uc7a5\ucc29 \uae30\uac04/\uc8fc\ud589\uac70\ub9ac \uacc4\uc0b0\uae30\uac04){name: (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \uc7a5\ucc29 \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac - \ubcf4\ud5d8\uac70\ub9ac \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac) x (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \ubbf8\uc7a5\ucc29 \uae30\uac04/\uc8fc\ud589\uac70\ub9ac \uacc4\uc0b0\uae30\uac04)}'\r\n\r\nIt is come from \uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac = (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \uc7a5\ucc29 \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac - \ubcf4\ud5d8\uac70\ub9ac \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac) x (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \ubbf8\uc7a5\ucc29 \uae30\uac04/\uc8fc\ud589\uac70\ub9ac \uacc4\uc0b0\uae30\uac04)\r\n\r\nSo, if I ask about  '\uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac\ub294 \uc5b4\ub5bb\uac8c \uacc4\uc0b0 \ub418\ub098\uc694?', I would like the response to be\r\n'\uc6b4\ud589\uc815\ubcf4 \ud655\uc778 \uc7a5\ucc29 \uc774\uc804 \uae30\uac04\uc758 \uc8fc\ud589\uac70\ub9ac = (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \uc7a5\ucc29 \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac - \ubcf4\ud5d8\uac70\ub9ac \uc2dc \uace0\uc9c0\ub41c \uc8fc\ud589\uac70\ub9ac) x (\uc6b4\ud589\uc815\ubcf4 \ud655\uc778\uc7a5\uce58 \ubbf8\uc7a5\ucc29 \uae30\uac04/\uc8fc\ud589\uac70\ub9ac \uacc4\uc0b0\uae30\uac04)'\r\n\r\nBut, when I send query to RetrieverQueryEngine with KnowledgeGraphRAGRetriever, it seems like can not search for mathematical symbols like '=', '-','+','/' and 'x'\r\n\r\nSo I want to check KnowledgeGraphRAGRetriever with NebulaGraphStore cannot search for mathematical symbols or not\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9429/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9429/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9428",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9428/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9428/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9428/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9428",
        "id": 2034807239,
        "node_id": "I_kwDOIWuq5855SLHH",
        "number": 9428,
        "title": "[Bug]: Fetching source node of ObjectType DOCUMENT",
        "user": {
            "login": "dheerajiiitv",
            "id": 24246192,
            "node_id": "MDQ6VXNlcjI0MjQ2MTky",
            "avatar_url": "https://avatars.githubusercontent.com/u/24246192?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dheerajiiitv",
            "html_url": "https://github.com/dheerajiiitv",
            "followers_url": "https://api.github.com/users/dheerajiiitv/followers",
            "following_url": "https://api.github.com/users/dheerajiiitv/following{/other_user}",
            "gists_url": "https://api.github.com/users/dheerajiiitv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dheerajiiitv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dheerajiiitv/subscriptions",
            "organizations_url": "https://api.github.com/users/dheerajiiitv/orgs",
            "repos_url": "https://api.github.com/users/dheerajiiitv/repos",
            "events_url": "https://api.github.com/users/dheerajiiitv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dheerajiiitv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-11T04:32:34Z",
        "updated_at": "2023-12-11T23:22:01Z",
        "closed_at": "2023-12-11T23:22:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhy are we fetching ` ObjectType`: DOCUMENT, when source node is not None. As we are checking it node_id, it will not exists anyway. \r\n\r\nCurrent Code:\r\n```\r\ndef _build_node_list_from_query_result(\r\n        self, query_result: VectorStoreQueryResult\r\n    ) -> List[NodeWithScore]:\r\n           ....\r\n            for i in range(len(query_result.nodes)):\r\n                source_node = query_result.nodes[i].source_node\r\n                if (not self._vector_store.stores_text) or (\r\n                    source_node is not None and **source_node.node_type != ObjectType.TEXT**\r\n                ):\r\n                    node_id = query_result.nodes[i].node_id\r\n                    if node_id in self._docstore.docs:\r\n                        query_result.nodes[\r\n                            i\r\n                        ] = self._docstore.get_node(node_id)\r\n\r\n        log_vector_store_query_result(query_result)\r\n\r\n        node_with_scores: List[NodeWithScore] = []\r\n        for ind, node in enumerate(query_result.nodes):\r\n            score: Optional[float] = None\r\n            if query_result.similarities is not None:\r\n                score = query_result.similarities[ind]\r\n            node_with_scores.append(NodeWithScore(node=node, score=score))\r\n\r\n        return node_with_scores\r\n\r\n```\r\n`source_node.node_type != ObjectType.TEXT -> source_node.node_type != ObjectType.TEXT and source_node.node_type != ObjectType.DOCUMENT`\r\n\r\n\r\n\n\n### Version\n\n0.8.48\n\n### Steps to Reproduce\n\nWhile inserting nodes to the vector store, just add source node to type DOCUMENT. It will start looking for this obect in docstore, which is not use at all.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9428/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9428/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9427",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9427/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9427/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9427/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9427",
        "id": 2034761519,
        "node_id": "I_kwDOIWuq5855R_8v",
        "number": 9427,
        "title": "[Feature Request]: Postgres BM25 support",
        "user": {
            "login": "juleskuehn",
            "id": 1150048,
            "node_id": "MDQ6VXNlcjExNTAwNDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1150048?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juleskuehn",
            "html_url": "https://github.com/juleskuehn",
            "followers_url": "https://api.github.com/users/juleskuehn/followers",
            "following_url": "https://api.github.com/users/juleskuehn/following{/other_user}",
            "gists_url": "https://api.github.com/users/juleskuehn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juleskuehn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juleskuehn/subscriptions",
            "organizations_url": "https://api.github.com/users/juleskuehn/orgs",
            "repos_url": "https://api.github.com/users/juleskuehn/repos",
            "events_url": "https://api.github.com/users/juleskuehn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juleskuehn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T03:39:31Z",
        "updated_at": "2023-12-11T03:52:19Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Feature Description\r\n\r\nFeature: add a variation of PGVectorStore which uses ParadeDB's BM25 extension.\r\n\r\nBM25 is now possible in Postgres with a Rust extension [pg_bm25): https://github.com/paradedb/paradedb/tree/dev/pg_bm25\r\n\r\nUnsure if it might be better to use [pg_search](https://github.com/paradedb/paradedb/tree/dev/pg_search) and get HNSW at the same time..\r\n\r\nI'm interested in contributing on this myself, but am just starting to look into it. Interested to hear others' thoughts.\r\n\r\n### Reason\r\n\r\nAlthough the code comments for the PGVectorStore class currently suggest BM25 search is present in Postgres - it is not.\r\n\r\n### Value of Feature\r\n\r\nBM25 retrieval hit rate and MRR is measurable better than Postgres full text search with tsvector and tsquery. Indexing is also supposed to be faster with pg_bm25.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9427/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9427/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9426",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9426/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9426/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9426/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9426",
        "id": 2034645804,
        "node_id": "I_kwDOIWuq5855Rjss",
        "number": 9426,
        "title": "Slack Loader with large lack channels",
        "user": {
            "login": "sayanb",
            "id": 3595665,
            "node_id": "MDQ6VXNlcjM1OTU2NjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3595665?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sayanb",
            "html_url": "https://github.com/sayanb",
            "followers_url": "https://api.github.com/users/sayanb/followers",
            "following_url": "https://api.github.com/users/sayanb/following{/other_user}",
            "gists_url": "https://api.github.com/users/sayanb/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sayanb/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sayanb/subscriptions",
            "organizations_url": "https://api.github.com/users/sayanb/orgs",
            "repos_url": "https://api.github.com/users/sayanb/repos",
            "events_url": "https://api.github.com/users/sayanb/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sayanb/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T01:15:11Z",
        "updated_at": "2023-12-11T01:19:28Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi team,\r\n\r\nI am using the [Slack Loader ](https://llamahub.ai/l/slack)from Llama Hub. For smaller Slack channels it works fine. However, for larger channels with lots of messages created over months, I keep seeing this message:\r\n\r\n`Rate limit error reached, sleeping for: 10 seconds`\r\n\r\nIs there a recommended / idiomatic way to load larger Slack channels to avoid this issue?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9426/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9426/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9425",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9425/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9425/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9425/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9425",
        "id": 2034629704,
        "node_id": "I_kwDOIWuq5855RfxI",
        "number": 9425,
        "title": "[Feature Request]: Make llama-index compartible with models finetuned and hosted on modal.com",
        "user": {
            "login": "gich2009",
            "id": 83756959,
            "node_id": "MDQ6VXNlcjgzNzU2OTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/83756959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gich2009",
            "html_url": "https://github.com/gich2009",
            "followers_url": "https://api.github.com/users/gich2009/followers",
            "following_url": "https://api.github.com/users/gich2009/following{/other_user}",
            "gists_url": "https://api.github.com/users/gich2009/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gich2009/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gich2009/subscriptions",
            "organizations_url": "https://api.github.com/users/gich2009/orgs",
            "repos_url": "https://api.github.com/users/gich2009/repos",
            "events_url": "https://api.github.com/users/gich2009/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gich2009/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-11T00:54:05Z",
        "updated_at": "2023-12-11T01:01:44Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nModal.com is a cloud computing service that allows you to finetune and host models on their workers. They provide inference points for any models finetuned on their platform.\n\n### Reason\n\nI have not tried implementing the feature. I just read about the capabilities on modal.com and thought it would be a good integration feature for llama-index to allow for more configuration.\n\n### Value of Feature\n\nAn integration feature to allow users who host their models on modal to use llama-index for their RAG and prompt engineering pipelines.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9425/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9425/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9424",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9424/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9424/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9424/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9424",
        "id": 2034587746,
        "node_id": "PR_kwDOIWuq585hn6za",
        "number": 9424,
        "title": "fix F1 score definition, update copyright year",
        "user": {
            "login": "avyfain",
            "id": 4804875,
            "node_id": "MDQ6VXNlcjQ4MDQ4NzU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4804875?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/avyfain",
            "html_url": "https://github.com/avyfain",
            "followers_url": "https://api.github.com/users/avyfain/followers",
            "following_url": "https://api.github.com/users/avyfain/following{/other_user}",
            "gists_url": "https://api.github.com/users/avyfain/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/avyfain/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/avyfain/subscriptions",
            "organizations_url": "https://api.github.com/users/avyfain/orgs",
            "repos_url": "https://api.github.com/users/avyfain/repos",
            "events_url": "https://api.github.com/users/avyfain/events{/privacy}",
            "received_events_url": "https://api.github.com/users/avyfain/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-10T23:46:41Z",
        "updated_at": "2023-12-11T16:55:46Z",
        "closed_at": "2023-12-11T16:55:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9424",
            "html_url": "https://github.com/run-llama/llama_index/pull/9424",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9424.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9424.patch",
            "merged_at": "2023-12-11T16:55:46Z"
        },
        "body": "# Description\r\n\r\nF1 is not at all a metric about edit distance. This commit explains F1 using the previous precision and recall definitions.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nThis is just a documentation change.\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9424/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9424/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9423",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9423/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9423/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9423/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9423",
        "id": 2034537017,
        "node_id": "PR_kwDOIWuq585hnwsR",
        "number": 9423,
        "title": "Remediate RCE vulnerability CVE-2023-39662 - part 2",
        "user": {
            "login": "rostrovsky",
            "id": 13874614,
            "node_id": "MDQ6VXNlcjEzODc0NjE0",
            "avatar_url": "https://avatars.githubusercontent.com/u/13874614?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rostrovsky",
            "html_url": "https://github.com/rostrovsky",
            "followers_url": "https://api.github.com/users/rostrovsky/followers",
            "following_url": "https://api.github.com/users/rostrovsky/following{/other_user}",
            "gists_url": "https://api.github.com/users/rostrovsky/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rostrovsky/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rostrovsky/subscriptions",
            "organizations_url": "https://api.github.com/users/rostrovsky/orgs",
            "repos_url": "https://api.github.com/users/rostrovsky/repos",
            "events_url": "https://api.github.com/users/rostrovsky/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rostrovsky/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-10T21:16:05Z",
        "updated_at": "2023-12-11T00:34:33Z",
        "closed_at": "2023-12-11T00:34:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9423",
            "html_url": "https://github.com/run-llama/llama_index/pull/9423",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9423.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9423.patch",
            "merged_at": "2023-12-11T00:34:32Z"
        },
        "body": "# Description\r\n\r\nAdds additional safeguard that prevents RCE of code that contains private / dunder methods as presented in attack from: https://github.com/run-llama/llama_index/issues/7054#issuecomment-1829141330\r\n\r\nFixes #7054\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9423/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9423/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9422",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9422/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9422/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9422/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9422",
        "id": 2034428046,
        "node_id": "PR_kwDOIWuq585hnbOb",
        "number": 9422,
        "title": "Discussion#8390 : Added sql_only hook to return only sql without running it ",
        "user": {
            "login": "bkakadiya",
            "id": 1933579,
            "node_id": "MDQ6VXNlcjE5MzM1Nzk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1933579?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bkakadiya",
            "html_url": "https://github.com/bkakadiya",
            "followers_url": "https://api.github.com/users/bkakadiya/followers",
            "following_url": "https://api.github.com/users/bkakadiya/following{/other_user}",
            "gists_url": "https://api.github.com/users/bkakadiya/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bkakadiya/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bkakadiya/subscriptions",
            "organizations_url": "https://api.github.com/users/bkakadiya/orgs",
            "repos_url": "https://api.github.com/users/bkakadiya/repos",
            "events_url": "https://api.github.com/users/bkakadiya/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bkakadiya/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-10T15:57:23Z",
        "updated_at": "2023-12-11T16:58:01Z",
        "closed_at": "2023-12-11T16:58:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9422",
            "html_url": "https://github.com/run-llama/llama_index/pull/9422",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9422.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9422.patch",
            "merged_at": "2023-12-11T16:58:01Z"
        },
        "body": "# Description\r\n\r\nAs discussed on [Discussion#8390](https://github.com/run-llama/llama_index/discussions/8390) : Added sql_only hook to return only final sql without running it \r\n\r\nFixes # [Discussion#8390](https://github.com/run-llama/llama_index/discussions/8390)\r\n\r\n## Type of Change\r\n\r\n- New feature (non-breaking change which adds functionality) to get only final sql without running it. Default is set to existing behavior of returning final sql and result\r\n- I have added comment for this new flag but **might** require a documentation update in samples\r\n\r\n# How Has This Been Tested?\r\n\r\n- Added new unit/integration tests\r\n- `pytest tests` passed\r\n\r\n\r\n# Suggested Checklist:\r\n\r\n- I have performed a self-review of my own code\r\n- I have commented my code, particularly in hard-to-understand areas\r\n- I have made corresponding changes to the documentation\r\n- I have added tests that prove my fix is effective or that my feature works\r\n- New and existing unit tests pass locally with my changes\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9422/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9422/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9421",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9421/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9421/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9421/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9421",
        "id": 2034337588,
        "node_id": "PR_kwDOIWuq585hnJCD",
        "number": 9421,
        "title": "Fix cleanup process in  _delete_node of document_summary",
        "user": {
            "login": "jun10k",
            "id": 114048,
            "node_id": "MDQ6VXNlcjExNDA0OA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/114048?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jun10k",
            "html_url": "https://github.com/jun10k",
            "followers_url": "https://api.github.com/users/jun10k/followers",
            "following_url": "https://api.github.com/users/jun10k/following{/other_user}",
            "gists_url": "https://api.github.com/users/jun10k/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jun10k/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jun10k/subscriptions",
            "organizations_url": "https://api.github.com/users/jun10k/orgs",
            "repos_url": "https://api.github.com/users/jun10k/repos",
            "events_url": "https://api.github.com/users/jun10k/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jun10k/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-10T11:50:08Z",
        "updated_at": "2023-12-12T03:13:43Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9421",
            "html_url": "https://github.com/run-llama/llama_index/pull/9421",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9421.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9421.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nCannot remove doc from DocumentSummaryIndex by delete_ref_doc(...)\r\n\r\nAs designed, the user can remove the nodes from the document summary index according to \"doc_id\" by delete_ref_doc(...) which will call delete_nodes(...) from BaseIndex to do the work. \r\n<img width=\"600\" alt=\"\u622a\u5c4f2023-12-10 16 12 57\" src=\"https://github.com/run-llama/llama_index/assets/114048/d1b804fd-9830-4dce-985f-ac39acffcb4d\">\r\n\r\nHowever, it passes the related node_ids instead of doc_id itself. \r\n<img width=\"692\" alt=\"\u622a\u5c4f2023-12-10 16 10 15\" src=\"https://github.com/run-llama/llama_index/assets/114048/68e89cb2-d63d-40cc-adee-1dcec1ee443a\">\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9421/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9421/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9420",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9420/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9420/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9420/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9420",
        "id": 2034262412,
        "node_id": "PR_kwDOIWuq585hm5nH",
        "number": 9420,
        "title": "Feat/PgVector Support custom hnsw.ef_search and ivfflat.probes",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-10T07:59:16Z",
        "updated_at": "2023-12-11T05:22:47Z",
        "closed_at": "2023-12-10T17:24:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9420",
            "html_url": "https://github.com/run-llama/llama_index/pull/9420",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9420.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9420.patch",
            "merged_at": "2023-12-10T17:24:21Z"
        },
        "body": "# Description\r\n\r\nTo improve the retrieval performance on PgVector, it's suggested to set the appropriate `hnsw.ef_search` or `ivfflat.probes`, depending on the index engine you use.\r\n\r\n```sql\r\nSET hnsw.ef_search = 100;\r\n-- or\r\nSET ivfflat.probes = 10;\r\n```\r\n\r\nThis will also fix the https://github.com/run-llama/llama_index/issues/9419 bug\r\n\r\n**How to use**\r\n```python\r\nretriever = index.as_retriever(\r\n    vector_store_query_mode=query_mode,\r\n    similarity_top_k=top_k,\r\n    vector_store_kwargs={\r\n        \"hnsw_ef_search\": 300\r\n    },\r\n)\r\n```\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9420/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9420/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9419",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9419/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9419/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9419/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9419",
        "id": 2034261203,
        "node_id": "I_kwDOIWuq5855QFzT",
        "number": 9419,
        "title": "[Bug]: Unable to retrieve more than 40 nodes when using PgVectorStore with HNSW",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-10T07:54:21Z",
        "updated_at": "2023-12-10T07:56:31Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen using the PgVectorStore index that was created using PgVector and indexed with [HNSW](https://github.com/pgvector/pgvector?tab=readme-ov-file#hnsw), we can't retrieve more than 40 nodes.\r\n\r\nThis is an expected behavior of PgVector\r\n>  Specify the size of the dynamic candidate list for search (40 by default)\r\n\r\n> To search more than 40 nearest neighbors, increase this SET hnsw.ef_search = x; value. Where x is the value of nearest neighbors you want to return.\r\n\r\nTo overcome this issue, we need to set the `hnsw.ef_search` value to be higher than the number of nodes we want to retrieve.\r\n\r\n```\r\nSET hnsw.ef_search = 100;\r\n```\n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\nCreate a vector index with Postgres and set the table index with HNSW.\r\n\r\n```\r\nCREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9419/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9419/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9418",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9418/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9418/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9418/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9418",
        "id": 2034151793,
        "node_id": "I_kwDOIWuq5855PrFx",
        "number": 9418,
        "title": "BGE Reranker Fine-tuning",
        "user": {
            "login": "austinmw",
            "id": 12224358,
            "node_id": "MDQ6VXNlcjEyMjI0MzU4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12224358?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/austinmw",
            "html_url": "https://github.com/austinmw",
            "followers_url": "https://api.github.com/users/austinmw/followers",
            "following_url": "https://api.github.com/users/austinmw/following{/other_user}",
            "gists_url": "https://api.github.com/users/austinmw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/austinmw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/austinmw/subscriptions",
            "organizations_url": "https://api.github.com/users/austinmw/orgs",
            "repos_url": "https://api.github.com/users/austinmw/repos",
            "events_url": "https://api.github.com/users/austinmw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/austinmw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-10T00:39:19Z",
        "updated_at": "2023-12-10T02:57:23Z",
        "closed_at": "2023-12-10T02:57:23Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, is it possible to use LlamaIndex to fine-tune the BGE model as a reranker?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9418/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9418/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9417",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9417/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9417/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9417/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9417",
        "id": 2034080595,
        "node_id": "I_kwDOIWuq5855PZtT",
        "number": 9417,
        "title": "i get these error when i search ",
        "user": {
            "login": "nitin0909",
            "id": 153396782,
            "node_id": "U_kgDOCSSmLg",
            "avatar_url": "https://avatars.githubusercontent.com/u/153396782?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nitin0909",
            "html_url": "https://github.com/nitin0909",
            "followers_url": "https://api.github.com/users/nitin0909/followers",
            "following_url": "https://api.github.com/users/nitin0909/following{/other_user}",
            "gists_url": "https://api.github.com/users/nitin0909/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nitin0909/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nitin0909/subscriptions",
            "organizations_url": "https://api.github.com/users/nitin0909/orgs",
            "repos_url": "https://api.github.com/users/nitin0909/repos",
            "events_url": "https://api.github.com/users/nitin0909/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nitin0909/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-12-09T21:40:09Z",
        "updated_at": "2023-12-11T01:43:40Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\ni get error when i type for searching An error occured while performing search: [Errno 2] No such file or directory: '/tmp/llama_index'",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9417/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9417/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9416",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9416/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9416/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9416/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9416",
        "id": 2033970239,
        "node_id": "I_kwDOIWuq5855O-w_",
        "number": 9416,
        "title": "[Question]: Why OpenAI key is always needed, even each nodes have embedding from local model?",
        "user": {
            "login": "zzong2006",
            "id": 12367773,
            "node_id": "MDQ6VXNlcjEyMzY3Nzcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/12367773?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zzong2006",
            "html_url": "https://github.com/zzong2006",
            "followers_url": "https://api.github.com/users/zzong2006/followers",
            "following_url": "https://api.github.com/users/zzong2006/following{/other_user}",
            "gists_url": "https://api.github.com/users/zzong2006/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zzong2006/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zzong2006/subscriptions",
            "organizations_url": "https://api.github.com/users/zzong2006/orgs",
            "repos_url": "https://api.github.com/users/zzong2006/repos",
            "events_url": "https://api.github.com/users/zzong2006/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zzong2006/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-12-09T18:11:26Z",
        "updated_at": "2023-12-14T10:45:08Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI embeded every text by IngestionPipeline. But when I use VectorStoreIndex, It produces error about openai key.\r\n\r\n```python\r\nfrom llama_index.vector_stores.faiss import FaissVectorStore\r\nfrom llama_index.embeddings import HuggingFaceEmbedding\r\n\r\nembed_model = HuggingFaceEmbedding(\r\n    model_name=\"intfloat/multilingual-e5-large\",\r\n    max_length=512,\r\n    embed_batch_size=10\r\n)\r\n\r\npipeline = IngestionPipeline(\r\n    transformations=[\r\n        SentenceWindowNodeParser(\r\n            window_size=4,\r\n            sentence_splitter=splitter.split,\r\n            include_prev_next_rel=False,\r\n            include_metadata=True\r\n        ),\r\n        embed_model\r\n    ],\r\n)\r\n\r\nnodes = pipeline.run(documents=documents)\r\n\r\nd = 1024\r\nfaiss_index = faiss.IndexFlatL2(d)\r\nvector_store = FaissVectorStore(faiss_index=faiss_index)\r\nstorage_context = StorageContext.from_defaults(vector_store=vector_store,)\r\nindex = VectorStoreIndex(\r\n    nodes, \r\n    storage_context=storage_context, \r\n    show_progress=True\r\n)\r\n```\r\n\r\n```python\r\nLLMPredictor.__init__(self, llm, callback_manager, system_prompt, query_wrapper_prompt, pydantic_program_mode)\r\n     95 def __init__(\r\n     96     self,\r\n     97     llm: Optional[LLMType] = \"default\",\r\n   (...)\r\n    101     pydantic_program_mode: PydanticProgramMode = PydanticProgramMode.DEFAULT,\r\n    102 ) -> None:\r\n    103     \"\"\"Initialize params.\"\"\"\r\n--> 104     self._llm = resolve_llm(llm)\r\n    106     if callback_manager:\r\n    107         self._llm.callback_manager = callback_manager\r\n\r\nFile ~/.local/lib/python3.10/site-packages/llama_index/llms/utils.py:31, in resolve_llm(llm)\r\n     29         validate_openai_api_key(llm.api_key)\r\n     30     except ValueError as e:\r\n---> 31         raise ValueError(\r\n     32             \"\\n******\\n\"\r\n     33             \"Could not load OpenAI model. \"\r\n     34             \"If you intended to use OpenAI, please check your OPENAI_API_KEY.\\n\"\r\n     35             \"Original error:\\n\"\r\n     36             f\"{e!s}\"\r\n     37             \"\\nTo disable the LLM entirely, set llm=None.\"\r\n     38             \"\\n******\"\r\n     39         )\r\n     41 if isinstance(llm, str):\r\n     42     splits = llm.split(\":\", 1)\r\n\r\nValueError: \r\n******\r\nCould not load OpenAI model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\r\nOriginal error:\r\nNo API key found for OpenAI.\r\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\r\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\r\n\r\nTo disable the LLM entirely, set llm=None.\r\n******\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9416/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9416/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9415",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9415/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9415/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9415/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9415",
        "id": 2033856882,
        "node_id": "I_kwDOIWuq5855OjFy",
        "number": 9415,
        "title": "[Bug]: Invalid JSON Path -Simple JSON Query Engine Error",
        "user": {
            "login": "iamsaurabhc",
            "id": 19235748,
            "node_id": "MDQ6VXNlcjE5MjM1NzQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19235748?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iamsaurabhc",
            "html_url": "https://github.com/iamsaurabhc",
            "followers_url": "https://api.github.com/users/iamsaurabhc/followers",
            "following_url": "https://api.github.com/users/iamsaurabhc/following{/other_user}",
            "gists_url": "https://api.github.com/users/iamsaurabhc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iamsaurabhc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iamsaurabhc/subscriptions",
            "organizations_url": "https://api.github.com/users/iamsaurabhc/orgs",
            "repos_url": "https://api.github.com/users/iamsaurabhc/repos",
            "events_url": "https://api.github.com/users/iamsaurabhc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iamsaurabhc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-09T13:46:16Z",
        "updated_at": "2023-12-09T13:54:07Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nLoading the JSON value and schema from files, and trying to run a simple JSON Query Engine\r\n\r\n```\r\nf = open('SBIN.json')\r\njson_value = json.load(f)\r\nf.close()\r\n\r\nf = open('stock-schema.json')\r\njson_schema = json.load(f)\r\nf.close()\r\n```\r\n\r\nBut getting an error - `ValueError: Invalid JSON Path: The JSONPath query for this task would depend on the specific structure of the JSON data.`\r\n\r\nAny help would be appreciated.\n\n### Version\n\n0.9.10\n\n### Steps to Reproduce\n\npython main.py\n\n### Relevant Logs/Tracbacks\n\n```shell\nJsonPathParserError                       Traceback (most recent call last)\r\nFile ~/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/indices/struct_store/json_query.py:56, in default_output_processor(llm_output, json_value)\r\n     55 try:\r\n---> 56     datum: List[DatumInContext] = parse(expression).find(json_value)\r\n     57     if datum:\r\n\r\nFile ~/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/jsonpath_ng/ext/parser.py:172, in parse(path, debug)\r\n    171 def parse(path, debug=False):\r\n--> 172     return ExtentedJsonPathParser(debug=debug).parse(path)\r\n\r\nFile ~/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/jsonpath_ng/parser.py:45, in JsonPathParser.parse(self, string, lexer)\r\n     44 lexer = lexer or self.lexer_class()\r\n---> 45 return self.parse_token_stream(lexer.tokenize(string))\r\n\r\nFile ~/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/jsonpath_ng/parser.py:69, in JsonPathParser.parse_token_stream(self, token_iterator, start_symbol)\r\n     61 new_parser = ply.yacc.yacc(module=self,\r\n     62                            debug=self.debug,\r\n     63                            tabmodule = parsing_table_module,\r\n   (...)\r\n     66                            start = start_symbol,\r\n     67                            errorlog = logger)\r\n---> 69 return new_parser.parse(lexer = IteratorToTokenStream(token_iterator))\r\n\r\nFile ~/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/ply/yacc.py:333, in LRParser.parse(self, input, lexer, debug, tracking, tokenfunc)\r\n...\r\n     62     except Exception as exc:\r\n---> 63         raise ValueError(f\"Invalid JSON Path: {expression}\") from exc\r\n     65 return results\r\n\r\nValueError: Invalid JSON Path: Since the task requires specific data about a stock symbol (SBIN) and a specific month (November)\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9415/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9415/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9414",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9414/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9414/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9414/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9414",
        "id": 2033813677,
        "node_id": "I_kwDOIWuq5855OYit",
        "number": 9414,
        "title": "[Bug]: OutputParserException: Failed to parse pydantic object from guidance program",
        "user": {
            "login": "younes-io",
            "id": 3153107,
            "node_id": "MDQ6VXNlcjMxNTMxMDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3153107?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/younes-io",
            "html_url": "https://github.com/younes-io",
            "followers_url": "https://api.github.com/users/younes-io/followers",
            "following_url": "https://api.github.com/users/younes-io/following{/other_user}",
            "gists_url": "https://api.github.com/users/younes-io/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/younes-io/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/younes-io/subscriptions",
            "organizations_url": "https://api.github.com/users/younes-io/orgs",
            "repos_url": "https://api.github.com/users/younes-io/repos",
            "events_url": "https://api.github.com/users/younes-io/events{/privacy}",
            "received_events_url": "https://api.github.com/users/younes-io/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-09T11:37:31Z",
        "updated_at": "2023-12-09T11:40:41Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\n@Harsha-Nori:\r\n\r\nWhen I execute the code below taken from the [official docs](https://docs.llamaindex.ai/en/stable/examples/output_parsing/guidance_pydantic_program.html).\r\n\r\n```python\r\nfrom pydantic import BaseModel\r\nfrom typing import List\r\nfrom guidance.llms import OpenAI\r\n\r\nfrom llama_index.program import GuidancePydanticProgram\r\n\r\nclass Song(BaseModel):\r\n    title: str\r\n    length_seconds: int\r\n\r\n\r\nclass Album(BaseModel):\r\n    name: str\r\n    artist: str\r\n    songs: List[Song]\r\n    \r\nprogram = GuidancePydanticProgram(\r\n    output_cls=Album,\r\n    prompt_template_str=(\r\n        \"Generate an example album, with an artist and a list of songs. Using\"\r\n        \" the movie {{movie_name}} as inspiration\"\r\n    ),\r\n    guidance_llm=OpenAI(\r\n        api_type=str(openai.api_type),\r\n        api_key=str(openai.api_key),\r\n        api_base=str(openai.base_url),\r\n        api_version=str(openai.api_version),\r\n        model='gpt-35-turbo',\r\n        deployment_id=model_name,\r\n    ),\r\n    verbose=True,\r\n)\r\n\r\n# print(\"program.guidance_llm: \", program)\r\noutput = program(movie_name=\"The Shining\")\r\n```\r\n\r\nI get this log:\r\n\r\n\r\n```\r\nGenerate an example album, with an artist and a list of songs. Using the movie {{movie_name}} as inspiration\r\n`` `json\r\n{\r\n  \"name\": \"{{gen 'name' stop='\"'}}\",\r\n  \"artist\": \"{{gen 'artist' stop='\"'}}\",\r\n  \"songs\": [{{#geneach 'songs' stop=']'}}{{#unless @first}}, {{/unless}}{\r\n  \"title\": \"{{gen 'title' stop='\"'}}\",\r\n  \"length_seconds\": \"{{gen 'length_seconds' stop='\"'}}\",\r\n}{{/geneach}}],\r\n}\r\n` ``\r\n\r\nParserError: while parsing a flow mapping\r\n  in \"<unicode string>\", line 1, column 1:\r\n    {\r\n    ^\r\nexpected ',' or '}', but got '<scalar>'\r\n  in \"<unicode string>\", line 2, column 31:\r\n      \"name\": \"{gen 'name' stop='\"'}\",\r\n                                  ^\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nOutputParserException                     Traceback (most recent call last)\r\nFile ~/dev/dir/project/.venv/lib/python3.9/site-packages/llama_index/prompts/guidance_utils.py:149, in parse_pydantic_from_guidance_program(program, cls, verbose)\r\n    148     print(output)\r\n--> 149 json_dict = parse_json_markdown(output)\r\n    150 sub_questions = cls.parse_obj(json_dict)\r\n\r\nFile ~/dev/dir/project/.venv/lib/python3.9/site-packages/llama_index/output_parsers/utils.py:54, in parse_json_markdown(text)\r\n     53 except yaml.YAMLError as e_yaml:\r\n---> 54     raise OutputParserException(\r\n     55         f\"Got invalid JSON object. Error: {e_json} {e_yaml}. \"\r\n     56         f\"Got JSON string: {json_string}\"\r\n     57     )\r\n     58 except NameError as exc:\r\n\r\nOutputParserException: Got invalid JSON object. Error: Expecting ',' delimiter: line 2 column 31 (char 32) while parsing a flow mapping\r\n  in \"<unicode string>\", line 1, column 1:\r\n    {\r\n    ^\r\nexpected ',' or '}', but got '<scalar>'\r\n  in \"<unicode string>\", line 2, column 31:\r\n      \"name\": \"{gen 'name' stop='\"'}\",\r\n                                  ^. Got JSON string: {\r\n  \"name\": \"{gen 'name' stop='\"'}\",\r\n  \"artist\": \"{gen 'artist' stop='\"'}\",\r\n  \"songs\": [{#geneach 'songs' stop=']'}{#unless @first}, {/unless}{\r\n  \"title\": \"{gen 'title' stop='\"'}\",\r\n  \"length_seconds\": \"{gen 'length_seconds' stop='\"'}\",\r\n}{/geneach}],\r\n}\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nOutputParserException                     Traceback (most recent call last)\r\nCell In[27], line 35\r\n     17 program = GuidancePydanticProgram(\r\n     18     output_cls=Album,\r\n     19     prompt_template_str=(\r\n   (...)\r\n     31     verbose=True,\r\n     32 )\r\n     34 # print(\"program.guidance_llm: \", program)\r\n---> 35 output = program(movie_name=\"The Shining\")\r\n\r\nFile ~/dev/dir/project/.venv/lib/python3.9/site-packages/llama_index/program/guidance_program.py:80, in GuidancePydanticProgram.__call__(self, *args, **kwargs)\r\n     73 def __call__(\r\n     74     self,\r\n     75     *args: Any,\r\n     76     **kwargs: Any,\r\n     77 ) -> BaseModel:\r\n     78     executed_program = self._guidance_program(**kwargs)\r\n---> 80     return parse_pydantic_from_guidance_program(\r\n     81         program=executed_program, cls=self._output_cls\r\n     82     )\r\n\r\nFile ~/dev/dir/project/.venv/lib/python3.9/site-packages/llama_index/prompts/guidance_utils.py:152, in parse_pydantic_from_guidance_program(program, cls, verbose)\r\n    150     sub_questions = cls.parse_obj(json_dict)\r\n    151 except Exception as e:\r\n--> 152     raise OutputParserException(\r\n    153         \"Failed to parse pydantic object from guidance program\"\r\n    154     ) from e\r\n    155 return sub_questions\r\n\r\nOutputParserException: Failed to parse pydantic object from guidance program\r\n\r\n```\r\n\r\n### Version\r\n\r\nVersion: 0.9.13\r\n\r\n### Steps to Reproduce\r\n\r\nExecute the code above in a notebook (python 3.9.18)\r\n\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\ncf. above\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9414/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9414/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9413",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9413/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9413/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9413/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9413",
        "id": 2033805467,
        "node_id": "I_kwDOIWuq5855OWib",
        "number": 9413,
        "title": "[Question]: Different numbers of embeddings with the same local embedding model",
        "user": {
            "login": "stephanedebove",
            "id": 6358105,
            "node_id": "MDQ6VXNlcjYzNTgxMDU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6358105?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stephanedebove",
            "html_url": "https://github.com/stephanedebove",
            "followers_url": "https://api.github.com/users/stephanedebove/followers",
            "following_url": "https://api.github.com/users/stephanedebove/following{/other_user}",
            "gists_url": "https://api.github.com/users/stephanedebove/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stephanedebove/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stephanedebove/subscriptions",
            "organizations_url": "https://api.github.com/users/stephanedebove/orgs",
            "repos_url": "https://api.github.com/users/stephanedebove/repos",
            "events_url": "https://api.github.com/users/stephanedebove/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stephanedebove/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-09T11:14:22Z",
        "updated_at": "2023-12-11T12:08:56Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI\u2019m following up on this question which was closed before I had the time to add my code: https://github.com/run-llama/llama_index/issues/9272\r\n\r\nI get very different numbers of embeddings depending on whether I use an explicit text_splitter or not.\r\n\r\nUsing the attached graham file and the basic BAAI/bge-small-en embedding model\r\n[graham.txt](https://github.com/run-llama/llama_index/files/13612397/graham.txt), \r\n\r\nRunning this \r\n\r\n```\r\nfrom llama_index.embeddings import HuggingFaceEmbedding\r\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\", max_length=512)\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm, \r\n    embed_model=embed_model, \r\n)\r\n```\r\n\r\ngives me 18\u202fembeddings\r\n\r\n```\r\nParsing nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.09it/s]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:06<00:00,  2.86it/s]\r\n```\r\n\r\nRunning this\r\n\r\n```\r\nfrom llama_index.text_splitter import TokenTextSplitter\r\nfrom transformers import AutoTokenizer\r\ntext_splitter = TokenTextSplitter(\r\n    chunk_size=512,\r\n    tokenizer=AutoTokenizer.from_pretrained(\"BAAI/bge-small-en\").encode,\r\n)\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n    llm=llm, \r\n    embed_model=\"local:BAAI/bge-small-en\", \r\n    text_splitter=text_splitter,\r\n)\r\n```\r\ngives me 93 embeddings (and notice the error message)\r\n```\r\nParsing nodes:   0%|                                                                             | 0/1 [00:00<?, ?it/s]\r\nToken indices sequence length is longer than the specified maximum sequence length for this model (16918 > 512). Running this sequence through the model will result in indexing errors\r\nParsing nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.95s/it]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 93/93 [00:07<00:00, 11.94it/s]\r\n```\r\n\r\nI am basically just trying to use a local embedding model other than OpenAi, I\u202fwas originally experimenting with e5-multilingual-large, but I get the same problem with bge-small-en. So what is the correct way to setup a local embedding?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9413/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9413/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9412",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9412/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9412/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9412/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9412",
        "id": 2033773512,
        "node_id": "PR_kwDOIWuq585hlVHs",
        "number": 9412,
        "title": "Only capture valid python function names in ReAct output",
        "user": {
            "login": "cyberkaida",
            "id": 118712366,
            "node_id": "U_kgDOBxNoLg",
            "avatar_url": "https://avatars.githubusercontent.com/u/118712366?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyberkaida",
            "html_url": "https://github.com/cyberkaida",
            "followers_url": "https://api.github.com/users/cyberkaida/followers",
            "following_url": "https://api.github.com/users/cyberkaida/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyberkaida/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyberkaida/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyberkaida/subscriptions",
            "organizations_url": "https://api.github.com/users/cyberkaida/orgs",
            "repos_url": "https://api.github.com/users/cyberkaida/repos",
            "events_url": "https://api.github.com/users/cyberkaida/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyberkaida/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-09T09:57:16Z",
        "updated_at": "2023-12-11T22:31:17Z",
        "closed_at": "2023-12-11T22:04:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9412",
            "html_url": "https://github.com/run-llama/llama_index/pull/9412",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9412.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9412.patch",
            "merged_at": "2023-12-11T22:04:43Z"
        },
        "body": "Some LLMs output extra information at the end of the function name and cause llama_index to fail to find the function they want to call. Tighten the regular expression to only accept valid python function names (as used in the lookup) and ignore additional output.\r\n\r\nThis makes more LLMs work with the ReAct agent, even if they do not follow the instructions exactly.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [X] Added new unit/integration tests\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9412/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9412/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9411",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9411/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9411/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9411/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9411",
        "id": 2033752560,
        "node_id": "I_kwDOIWuq5855OJnw",
        "number": 9411,
        "title": "[Bug]: OpenAI agent with query engine tools crashes while calling the tool",
        "user": {
            "login": "vaibhavp4",
            "id": 4822281,
            "node_id": "MDQ6VXNlcjQ4MjIyODE=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4822281?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vaibhavp4",
            "html_url": "https://github.com/vaibhavp4",
            "followers_url": "https://api.github.com/users/vaibhavp4/followers",
            "following_url": "https://api.github.com/users/vaibhavp4/following{/other_user}",
            "gists_url": "https://api.github.com/users/vaibhavp4/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vaibhavp4/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vaibhavp4/subscriptions",
            "organizations_url": "https://api.github.com/users/vaibhavp4/orgs",
            "repos_url": "https://api.github.com/users/vaibhavp4/repos",
            "events_url": "https://api.github.com/users/vaibhavp4/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vaibhavp4/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-09T09:23:06Z",
        "updated_at": "2023-12-11T08:58:48Z",
        "closed_at": "2023-12-11T08:52:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI setup an openai agent with query engine tools \r\n\r\nThe agent was able to start and enter the chat repl\r\n\r\nBut it fails as soon as you submit a query\r\n![image](https://github.com/run-llama/llama_index/assets/4822281/24d48085-80a4-47d5-8009-4c14238e195e)\r\n\r\n(The editor also warns that agent code doesn't see query engine tools as a subclass of BaseTools)\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\n- setup openai agent with query tools engine as per this documentation https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_with_query_engine.html\r\n\r\n- Run the agent - agent.chat_repl()\r\n\r\n- Submit a query\n\n### Relevant Logs/Tracbacks\n\n```shell\nraise self._make_status_error_from_response(err.response) from None\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"'Tesla April 2022 Valuation' does not match '^[a-zA-Z0-9_-]{1,64}$' - 'tools.0.function.name'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9411/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9411/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9410",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9410/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9410/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9410/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9410",
        "id": 2033743661,
        "node_id": "PR_kwDOIWuq585hlOeo",
        "number": 9410,
        "title": "Check if __init__.py file exist in download/module.py to avoid crash when using download_loader",
        "user": {
            "login": "hexapode",
            "id": 208554,
            "node_id": "MDQ6VXNlcjIwODU1NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/208554?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hexapode",
            "html_url": "https://github.com/hexapode",
            "followers_url": "https://api.github.com/users/hexapode/followers",
            "following_url": "https://api.github.com/users/hexapode/following{/other_user}",
            "gists_url": "https://api.github.com/users/hexapode/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hexapode/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hexapode/subscriptions",
            "organizations_url": "https://api.github.com/users/hexapode/orgs",
            "repos_url": "https://api.github.com/users/hexapode/repos",
            "events_url": "https://api.github.com/users/hexapode/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hexapode/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-09T09:10:01Z",
        "updated_at": "2023-12-09T23:30:58Z",
        "closed_at": "2023-12-09T23:30:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9410",
            "html_url": "https://github.com/run-llama/llama_index/pull/9410",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9410.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9410.patch",
            "merged_at": "2023-12-09T23:30:57Z"
        },
        "body": "# Description\r\n\r\nWhen using download_loader, sometime llama_index raise an error if the init.py file did not exist in the llama_index/download repository. (Reproduced here: https://colab.research.google.com/drive/1DyESezohL-buXGn8DwpLHL2NlN172ZcZ?usp=sharing)\r\n\r\nThe propose fix check if the _init.py file exist before opening it with \"r+\".\r\n\r\nA test to check that the download loader function work and do not crash was added.\r\n\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nAdded new unit/integration tests\r\nI stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9410/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9410/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9409",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9409/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9409/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9409/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9409",
        "id": 2033736754,
        "node_id": "PR_kwDOIWuq585hlM_N",
        "number": 9409,
        "title": "Fix an issue where download_loader could crash if no __init__.py pre-exist in the download directory",
        "user": {
            "login": "hexapode",
            "id": 208554,
            "node_id": "MDQ6VXNlcjIwODU1NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/208554?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hexapode",
            "html_url": "https://github.com/hexapode",
            "followers_url": "https://api.github.com/users/hexapode/followers",
            "following_url": "https://api.github.com/users/hexapode/following{/other_user}",
            "gists_url": "https://api.github.com/users/hexapode/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hexapode/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hexapode/subscriptions",
            "organizations_url": "https://api.github.com/users/hexapode/orgs",
            "repos_url": "https://api.github.com/users/hexapode/repos",
            "events_url": "https://api.github.com/users/hexapode/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hexapode/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-09T08:56:50Z",
        "updated_at": "2023-12-09T08:58:11Z",
        "closed_at": "2023-12-09T08:57:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9409",
            "html_url": "https://github.com/run-llama/llama_index/pull/9409",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9409.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9409.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nBug: \r\nWhen using  download_loader, sometime llama_index raise an error if the __init__.py file did not exist in the llama_index/download repository. (Reproduced here: https://colab.research.google.com/drive/1DyESezohL-buXGn8DwpLHL2NlN172ZcZ?usp=sharing) \r\n\r\nThe propose fix check if the __init_.py file exist before opening it with \"r+\".\r\n\r\nA test to check that the download loader function work and do not crash was added.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- Added new unit/integration tests\r\n- I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9409/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9409/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9408",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9408/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9408/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9408/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9408",
        "id": 2033510067,
        "node_id": "I_kwDOIWuq5855NOaz",
        "number": 9408,
        "title": "[Question]: About setting the context_window and num_output",
        "user": {
            "login": "debraj135",
            "id": 16231057,
            "node_id": "MDQ6VXNlcjE2MjMxMDU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/16231057?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/debraj135",
            "html_url": "https://github.com/debraj135",
            "followers_url": "https://api.github.com/users/debraj135/followers",
            "following_url": "https://api.github.com/users/debraj135/following{/other_user}",
            "gists_url": "https://api.github.com/users/debraj135/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/debraj135/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/debraj135/subscriptions",
            "organizations_url": "https://api.github.com/users/debraj135/orgs",
            "repos_url": "https://api.github.com/users/debraj135/repos",
            "events_url": "https://api.github.com/users/debraj135/events{/privacy}",
            "received_events_url": "https://api.github.com/users/debraj135/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-09T01:09:54Z",
        "updated_at": "2023-12-09T16:19:01Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm wondering what is the right strategy to avoid running over the token limit after deploying llamaindex RAG in a Q&A setting. \r\n\r\nIs my understanding correct that context_window + number of tokens in the prompt template should be less than the max context_window of an llm? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9408/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9408/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9407",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9407/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9407/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9407/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9407",
        "id": 2033364273,
        "node_id": "I_kwDOIWuq5855Mq0x",
        "number": 9407,
        "title": "[Bug]: type errors with `RedisVectorStore` after #9135",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-08T22:02:37Z",
        "updated_at": "2023-12-08T22:39:23Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nhttps://github.com/run-llama/llama_index/pull/9135 moved `RedisVectorStore` to inherit from `BasePydanticVectorStore`. An unfortunate side effect here is now type checkers (`mypy==1.7.1`) fail for `RedisVectorStore`:\r\n\r\n```none\r\na.py:130:26: error: Argument \"vector_store\" to \"from_defaults\" of \"StorageContext\" has incompatible type \"RedisVectorStore\"; expected \"VectorStore | None\"  [arg-type]\r\n                vector_store=RedisVectorStore(index_name=index_name),\r\n                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:130:26: note: Following member(s) of \"RedisVectorStore\" have conflicts:\r\na.py:130:26: note:     Expected:\r\na.py:130:26: note:         def async_add(self, nodes: list[BaseNode], **kwargs: Any) -> Coroutine[Any, Any, list[str]]\r\na.py:130:26: note:     Got:\r\na.py:130:26: note:         def async_add(self, nodes: list[BaseNode]) -> Coroutine[Any, Any, list[str]]\r\n```\r\n\r\n### Version\r\n\r\n0.9.11\r\n\r\n### Steps to Reproduce\r\n\r\nPass a `RedisVectorStore` into `StorageContext.from_defaults`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9407/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9407/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9406",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9406/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9406/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9406/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9406",
        "id": 2033245703,
        "node_id": "PR_kwDOIWuq585hjjDE",
        "number": 9406,
        "title": "[WIP] Add prometheus evaluation notebook",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710958,
                "node_id": "LA_kwDOIWuq588AAAABc3-fLg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XXL",
                "name": "size:XXL",
                "color": "ffb8b8",
                "default": false,
                "description": "This PR changes 1000+ lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-08T20:03:24Z",
        "updated_at": "2023-12-14T18:31:24Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9406",
            "html_url": "https://github.com/run-llama/llama_index/pull/9406",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9406.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9406.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPR for showcasing correctness evaluation using open-source Prometheus evaluation.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9406/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9406/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9405",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9405/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9405/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9405/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9405",
        "id": 2033198678,
        "node_id": "I_kwDOIWuq5855MCZW",
        "number": 9405,
        "title": "[Bug]: ",
        "user": {
            "login": "kindler-king",
            "id": 53633591,
            "node_id": "MDQ6VXNlcjUzNjMzNTkx",
            "avatar_url": "https://avatars.githubusercontent.com/u/53633591?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kindler-king",
            "html_url": "https://github.com/kindler-king",
            "followers_url": "https://api.github.com/users/kindler-king/followers",
            "following_url": "https://api.github.com/users/kindler-king/following{/other_user}",
            "gists_url": "https://api.github.com/users/kindler-king/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kindler-king/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kindler-king/subscriptions",
            "organizations_url": "https://api.github.com/users/kindler-king/orgs",
            "repos_url": "https://api.github.com/users/kindler-king/repos",
            "events_url": "https://api.github.com/users/kindler-king/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kindler-king/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-12-08T19:27:03Z",
        "updated_at": "2023-12-09T15:38:59Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nUntil 4th December, 2023 my app used to work perfectly fine.\r\nHowever, after I restarted my caprover server from AWS on 5th December, 2023 to solve an issue with the deployment. The service which was using Llama broke down with an **ERROR:  Exception in ASGI application** , The code was reaching till before the highlighted part and then failing here for some reason.\r\n\r\nWhen running locally this was working but whenever I am trying to run it through my app, I am getting this ASGI exception in the logs. I would love to hear about any possible solutions as my app has been down for 4 days now due to this issue.\r\n\r\n\r\n\n\n### Version\n\n0.7.4\n\n### Steps to Reproduce\n\n![Capture](https://github.com/run-llama/llama_index/assets/53633591/3b1b4fd0-80e1-4ee8-8c3f-bab499229a66)\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9405/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9405/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9404",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9404/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9404/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9404/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9404",
        "id": 2032947735,
        "node_id": "I_kwDOIWuq5855LFIX",
        "number": 9404,
        "title": "[Bug]: Possible triangle reference",
        "user": {
            "login": "IvanPetrovMck",
            "id": 66677503,
            "node_id": "MDQ6VXNlcjY2Njc3NTAz",
            "avatar_url": "https://avatars.githubusercontent.com/u/66677503?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/IvanPetrovMck",
            "html_url": "https://github.com/IvanPetrovMck",
            "followers_url": "https://api.github.com/users/IvanPetrovMck/followers",
            "following_url": "https://api.github.com/users/IvanPetrovMck/following{/other_user}",
            "gists_url": "https://api.github.com/users/IvanPetrovMck/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/IvanPetrovMck/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/IvanPetrovMck/subscriptions",
            "organizations_url": "https://api.github.com/users/IvanPetrovMck/orgs",
            "repos_url": "https://api.github.com/users/IvanPetrovMck/repos",
            "events_url": "https://api.github.com/users/IvanPetrovMck/events{/privacy}",
            "received_events_url": "https://api.github.com/users/IvanPetrovMck/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-08T16:12:02Z",
        "updated_at": "2023-12-08T19:27:30Z",
        "closed_at": "2023-12-08T19:27:02Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": ".",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9404/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9404/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9403",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9403/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9403/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9403/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9403",
        "id": 2032819264,
        "node_id": "PR_kwDOIWuq585hiFsW",
        "number": 9403,
        "title": "Remove GPL-licensed aiostream dependency",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T15:03:02Z",
        "updated_at": "2023-12-08T15:47:26Z",
        "closed_at": "2023-12-08T15:40:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9403",
            "html_url": "https://github.com/run-llama/llama_index/pull/9403",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9403.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9403.patch",
            "merged_at": "2023-12-08T15:40:58Z"
        },
        "body": "# Description\r\n\r\n* aiostream is GPL licensed so it should not be used in a MIT licensed project\r\n* the code that is using aiostream can be written in a better way with an async generator\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nRan `tests/agent/react/test_react_agent.py::test_astream_chat_basic` that still passes. \r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9403/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9403/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9402",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9402/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9402/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9402/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9402",
        "id": 2032784156,
        "node_id": "PR_kwDOIWuq585hh96N",
        "number": 9402,
        "title": "[Docs] Fix link in /node_parsers/root.md",
        "user": {
            "login": "aaronjimv",
            "id": 67152883,
            "node_id": "MDQ6VXNlcjY3MTUyODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/67152883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aaronjimv",
            "html_url": "https://github.com/aaronjimv",
            "followers_url": "https://api.github.com/users/aaronjimv/followers",
            "following_url": "https://api.github.com/users/aaronjimv/following{/other_user}",
            "gists_url": "https://api.github.com/users/aaronjimv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aaronjimv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aaronjimv/subscriptions",
            "organizations_url": "https://api.github.com/users/aaronjimv/orgs",
            "repos_url": "https://api.github.com/users/aaronjimv/repos",
            "events_url": "https://api.github.com/users/aaronjimv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aaronjimv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-08T14:42:44Z",
        "updated_at": "2023-12-08T23:04:22Z",
        "closed_at": "2023-12-08T15:41:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9402",
            "html_url": "https://github.com/run-llama/llama_index/pull/9402",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9402.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9402.patch",
            "merged_at": "2023-12-08T15:41:50Z"
        },
        "body": "# Description\r\n\r\nThe link in node_parsers/root.md:\r\nhttps://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/root.html\r\n\r\n> You can read more about\u00a0`Node`\u00a0and\u00a0`Document`\u00a0properties\u00a0here.\r\n \r\nIts not working.\r\n\r\nI think that the correct link would be to:\r\n\r\n> /module_guides/loading/documents_and_nodes/root.md https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/root.html\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] My changes generate no new warnings\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9402/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9402/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9401",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9401/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9401/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9401/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9401",
        "id": 2032729230,
        "node_id": "I_kwDOIWuq5855KPyO",
        "number": 9401,
        "title": "[Question]: Similarity_top_k changes retriever nodes ordering",
        "user": {
            "login": "Cotum",
            "id": 82029831,
            "node_id": "MDQ6VXNlcjgyMDI5ODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/82029831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Cotum",
            "html_url": "https://github.com/Cotum",
            "followers_url": "https://api.github.com/users/Cotum/followers",
            "following_url": "https://api.github.com/users/Cotum/following{/other_user}",
            "gists_url": "https://api.github.com/users/Cotum/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Cotum/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Cotum/subscriptions",
            "organizations_url": "https://api.github.com/users/Cotum/orgs",
            "repos_url": "https://api.github.com/users/Cotum/repos",
            "events_url": "https://api.github.com/users/Cotum/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Cotum/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-12-08T14:12:56Z",
        "updated_at": "2023-12-13T13:10:26Z",
        "closed_at": "2023-12-13T13:10:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nDear all,\r\nI have a problem concerning the ordering of the retrieved chunks. This ordering changes when I change the similarity_top_k value everytime I perform a retriever.retrieve(text) with the same text.\r\n\r\nFor example , with similarity_top_k = 3, the top three chunks texts filenames are 10202.txt, 10202.txt and 01627.txt.\r\nBut if I change it to similarity_top_k = 30, the top three changes and become 00234.txt, 10202.txt and 00234.txt.\r\nI expect that this shouldn't happen, as the similarity_top_k gives the top scores within the total nodes of the collection and thus the ranking shouldn't depend on this value. Am I right ? \r\n\r\nI am using ChromaDB to save my embeddings and using HuggingFace model intfloat-multilingual-e5-base as embed_model.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9401/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9401/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9400",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9400/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9400/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9400/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9400",
        "id": 2032667718,
        "node_id": "PR_kwDOIWuq585hhkEr",
        "number": 9400,
        "title": "Remove unneeded where clause in postgres hybrid search query",
        "user": {
            "login": "mroedder-d7",
            "id": 129860311,
            "node_id": "U_kgDOB72C1w",
            "avatar_url": "https://avatars.githubusercontent.com/u/129860311?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mroedder-d7",
            "html_url": "https://github.com/mroedder-d7",
            "followers_url": "https://api.github.com/users/mroedder-d7/followers",
            "following_url": "https://api.github.com/users/mroedder-d7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mroedder-d7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mroedder-d7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mroedder-d7/subscriptions",
            "organizations_url": "https://api.github.com/users/mroedder-d7/orgs",
            "repos_url": "https://api.github.com/users/mroedder-d7/repos",
            "events_url": "https://api.github.com/users/mroedder-d7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mroedder-d7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-08T13:33:40Z",
        "updated_at": "2023-12-11T08:02:20Z",
        "closed_at": "2023-12-08T15:43:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9400",
            "html_url": "https://github.com/run-llama/llama_index/pull/9400",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9400.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9400.patch",
            "merged_at": "2023-12-08T15:43:33Z"
        },
        "body": "# Description\r\n\r\nI think the hybrid search postgres query does not need the additional where clause, as it massively restricts the volume of returned rows. Mostly for my case, the number of returned rows is 0.\r\n\r\nRanking and limiting is already performed in the circumference of the query generation, which should be sufficient enough to get good results.\r\nIf the query stays as is, that basically means that every (normalised) word needs to be existent in the node/db row that is currently evaluated. \r\n\r\nEven the current example (https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/postgres.ipynb) fails for me when setting similarity_top_k to 0.\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9400/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9400/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9399",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9399/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9399/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9399/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9399",
        "id": 2032649525,
        "node_id": "I_kwDOIWuq5855J8U1",
        "number": 9399,
        "title": "[Bug]: I updated my llama-index from 0.8.69.post2 to 0.9.10 and noticed memory growing over hours",
        "user": {
            "login": "alrooney",
            "id": 1009422,
            "node_id": "MDQ6VXNlcjEwMDk0MjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1009422?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/alrooney",
            "html_url": "https://github.com/alrooney",
            "followers_url": "https://api.github.com/users/alrooney/followers",
            "following_url": "https://api.github.com/users/alrooney/following{/other_user}",
            "gists_url": "https://api.github.com/users/alrooney/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/alrooney/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/alrooney/subscriptions",
            "organizations_url": "https://api.github.com/users/alrooney/orgs",
            "repos_url": "https://api.github.com/users/alrooney/repos",
            "events_url": "https://api.github.com/users/alrooney/events{/privacy}",
            "received_events_url": "https://api.github.com/users/alrooney/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 9,
        "created_at": "2023-12-08T13:21:43Z",
        "updated_at": "2023-12-14T18:44:40Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nMemory usage is stable with 0.8.69.post2 it grows significantly ~300Mb -> 1Gb over hours with 0.9.10.  Here is a graph:\r\n![image](https://github.com/run-llama/llama_index/assets/1009422/269b656c-8226-49e5-9841-19eafaa480d3)\r\nThe first deploy(c4248ec2) is going to 0.9.10 and the second deploy(bff4af04) is going back to 0.8.69.post2.  The steps likely represent a job I am running where I am periodically creating an index and sometimes adding documents but mostly not i.e. I am running this code every hour and sometimes (probably most of the time) documents is empty i.e. []\r\n```\r\ndef _setup_index(collection_name: str,\r\n                 documents: list = [],\r\n                 temperature: float = 0.0,\r\n                 model: str = \"gpt-3.5-turbo\"):\r\n    storage_context, service_context, token_counter = \\\r\n        _setup_contexts(collection_name, temperature = temperature, model = model)\r\n\r\n    index = VectorStoreIndex.from_documents(documents,\r\n                                            storage_context = storage_context,\r\n                                            service_context = service_context)\r\n    return index, token_counter\r\n\r\ndef _setup_contexts(collection_name: str,\r\n                    temperature: float,\r\n                    model: str):\r\n    # construct vector store\r\n    vector_store = QdrantVectorStore(\r\n        client=QDRANT_CLIENT,\r\n        collection_name=collection_name,\r\n    )\r\n\r\n    token_counter = TokenCountingHandler()\r\n    callback_manager = CallbackManager([token_counter])\r\n\r\n    service_context = ServiceContext.from_defaults(callback_manager=callback_manager,\r\n                                                   llm=OpenAI(model=model,\r\n                                                              temperature=temperature))\r\n```\r\nHope this helps track down the issue.\r\n\r\n### Version\r\n\r\n0.9.10\r\n\r\n### Steps to Reproduce\r\n\r\nCreate VectorStoreIndex and monitor memory usage.  See code above for how I am creating the index.\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9399/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9399/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9398",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9398/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9398/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9398/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9398",
        "id": 2032587677,
        "node_id": "I_kwDOIWuq5855JtOd",
        "number": 9398,
        "title": "[Bug]: ",
        "user": {
            "login": "chengdaqi",
            "id": 20795442,
            "node_id": "MDQ6VXNlcjIwNzk1NDQy",
            "avatar_url": "https://avatars.githubusercontent.com/u/20795442?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chengdaqi",
            "html_url": "https://github.com/chengdaqi",
            "followers_url": "https://api.github.com/users/chengdaqi/followers",
            "following_url": "https://api.github.com/users/chengdaqi/following{/other_user}",
            "gists_url": "https://api.github.com/users/chengdaqi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chengdaqi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chengdaqi/subscriptions",
            "organizations_url": "https://api.github.com/users/chengdaqi/orgs",
            "repos_url": "https://api.github.com/users/chengdaqi/repos",
            "events_url": "https://api.github.com/users/chengdaqi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chengdaqi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-08T12:39:13Z",
        "updated_at": "2023-12-08T12:40:53Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen I use the correct api-key, the requested URL is incorrect. When my api-key is incorrect, such as XX, the requested URL is correct but I get a 401 error, indicating that my api-key is incorrect.\r\n\r\n`embed_model = AzureOpenAIEmbedding(api_key=\"XXX\",\r\n                                   azure_endpoint=\"XXX\",\r\n                                   azure_deployment=\"XXX\",\r\n                                   model=\"text-embedding-ada-002\",\r\n                                   api_type='azure',\r\n                                   api_base=\"https://XXX.openai.azure.com\",\r\n                                   api_version=\"2023-07-01-preview\"\r\n                                   )\r\nservice_context = ServiceContext.from_defaults(embed_model=embed_model)\r\n\r\ndocuments = SimpleDirectoryReader(\"./data\").load_data()\r\n\r\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\n\r\nllm = AzureOpenAI(\r\n    engine=\"aios-gpt35-16k\", model=\"gpt-35-turbo-16k\", temperature=0.0\r\n)\r\n\r\nengine = index.as_query_engine()\r\nresponse = engine.query(\"What is azure openai service?\")`\r\n\r\nthe correct api-key, the requested URL is incorrect\uff1a\r\n![image](https://github.com/run-llama/llama_index/assets/20795442/256ce28e-764a-46e1-ad4f-732ff785b1a4)\r\n\r\nmy api-key is incorrect, such as XX, the requested URL is correct\r\n![image](https://github.com/run-llama/llama_index/assets/20795442/a868e25d-85c3-40f6-8243-043b54bcc021)\r\n\r\n\r\n\n\n### Version\n\n0.9.18\n\n### Steps to Reproduce\n\n![image](https://github.com/run-llama/llama_index/assets/20795442/f718e7e1-4753-4fb0-aa18-3ef25c532e0f)\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9398/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9398/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9397",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9397/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9397/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9397/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9397",
        "id": 2032530259,
        "node_id": "I_kwDOIWuq5855JfNT",
        "number": 9397,
        "title": "[Question]: How does the Vector Store Search work?",
        "user": {
            "login": "virezox",
            "id": 8643866,
            "node_id": "MDQ6VXNlcjg2NDM4NjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8643866?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/virezox",
            "html_url": "https://github.com/virezox",
            "followers_url": "https://api.github.com/users/virezox/followers",
            "following_url": "https://api.github.com/users/virezox/following{/other_user}",
            "gists_url": "https://api.github.com/users/virezox/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/virezox/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/virezox/subscriptions",
            "organizations_url": "https://api.github.com/users/virezox/orgs",
            "repos_url": "https://api.github.com/users/virezox/repos",
            "events_url": "https://api.github.com/users/virezox/events{/privacy}",
            "received_events_url": "https://api.github.com/users/virezox/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-08T11:57:47Z",
        "updated_at": "2023-12-08T14:11:55Z",
        "closed_at": "2023-12-08T14:11:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm currently using the pgvector extension for the PostgreSQL database as a vector store. I'm curious to know if all the embedding data, such as the original document (text), metadata, node_id, and vector data, will be loaded into the application memory during a similarity search. Or is there no need to load the data, and we simply provide the question embedding to the database, with the pgvector extension handling the rest? Additionally, how does the llama-index process similarity searches in technical detail?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9397/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9397/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9396",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9396/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9396/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9396/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9396",
        "id": 2032493095,
        "node_id": "PR_kwDOIWuq585hg9rI",
        "number": 9396,
        "title": "Fix result of BedrockEmbedding with Cohere model",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T11:32:16Z",
        "updated_at": "2023-12-08T15:47:38Z",
        "closed_at": "2023-12-08T15:44:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9396",
            "html_url": "https://github.com/run-llama/llama_index/pull/9396",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9396.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9396.patch",
            "merged_at": "2023-12-08T15:44:41Z"
        },
        "body": "# Description\r\n\r\nBedrockEmbedding with Cohere model currently returns List[List[float]]. Cohere accepts a list input strings and only one is sent. So the response is a list of embeddings with one element that must be unwrapped.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9396/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9396/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9395",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9395/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9395/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9395/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9395",
        "id": 2032356972,
        "node_id": "PR_kwDOIWuq585hggtU",
        "number": 9395,
        "title": "Fix HuggingFaceInferenceAPIEmbedding with sentence transformers",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T10:03:39Z",
        "updated_at": "2023-12-08T10:11:09Z",
        "closed_at": "2023-12-08T10:11:04Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9395",
            "html_url": "https://github.com/run-llama/llama_index/pull/9395",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9395.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9395.patch",
            "merged_at": "2023-12-08T10:11:04Z"
        },
        "body": "# Description\r\n\r\nHuggingface inference API used with sentence transformers such as `sentence-transformers/all-MiniLM-l6-v2` returns a one dimension np.array.\r\nCurrently it makes `_async_embed_single` fail because `squeeze(axis=0)` is called on that array.\r\nThe change is to return the array directly if it has only one dimension.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9395/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9395/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9394",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9394/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9394/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9394/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9394",
        "id": 2032297653,
        "node_id": "I_kwDOIWuq5855Ima1",
        "number": 9394,
        "title": "[Question]: stream output is empty",
        "user": {
            "login": "mistoFENG",
            "id": 46772998,
            "node_id": "MDQ6VXNlcjQ2NzcyOTk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/46772998?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mistoFENG",
            "html_url": "https://github.com/mistoFENG",
            "followers_url": "https://api.github.com/users/mistoFENG/followers",
            "following_url": "https://api.github.com/users/mistoFENG/following{/other_user}",
            "gists_url": "https://api.github.com/users/mistoFENG/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mistoFENG/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mistoFENG/subscriptions",
            "organizations_url": "https://api.github.com/users/mistoFENG/orgs",
            "repos_url": "https://api.github.com/users/mistoFENG/repos",
            "events_url": "https://api.github.com/users/mistoFENG/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mistoFENG/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-08T09:26:27Z",
        "updated_at": "2023-12-12T07:32:12Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [ ] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nVerison : \r\nllama-index         0.9.13\r\nvllm                     0.1.7\r\n\r\nMy code is as follows:\r\n```python\r\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, StorageContext, load_index_from_storage\r\nfrom llama_index.llms.vllm import VllmServer\r\nfrom llama_index.embeddings import HuggingFaceEmbedding\r\nfrom llama_index.prompts import PromptTemplate\r\nimport torch\r\n\r\n\r\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n\r\nembed_model = HuggingFaceEmbedding(model_name=\"./gte-large-zh\")\r\nllm = VllmServer(\r\n    api_url=\"http://localhost:36000/generate\", max_new_tokens=512,\r\n)\r\nservice_context = ServiceContext.from_defaults(\r\n    chunk_size=512, llm=llm, embed_model=embed_model\r\n)\r\n\r\ndocuments = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\r\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\r\n\r\nquery_engine = index.as_query_engine(streaming=True)\r\nstreaming_response = query_engine.query(\"who are you?\")\r\nfor text in streaming_response.response_gen:\r\n    print(\"text: \", text)\r\n```\r\nRunning the above code, the output is as follows:\r\n```\r\nINFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpqobfqyyh\r\nCreated a temporary directory at /tmp/tmpqobfqyyh\r\nINFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpqobfqyyh/_remote_module_non_scriptable.py\r\nWriting /tmp/tmpqobfqyyh/_remote_module_non_scriptable.py\r\nINFO:llama_index.indices.loading:Loading all indices.\r\nLoading all indices.\r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext: \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\ntext:  \r\n...\r\n```\r\nBut I print the source code llama_index/llms/vllm.py:373  `data = json.loads(chunk.decode(\"utf-8\"))` , there is output:\r\n```\r\ndata:  \r\nIn the essay,\r\ntext:  \r\ndata:  \r\nIn the essay, the\r\ntext:  \r\ndata:  \r\nIn the essay, the author\r\ntext:  \r\ndata:  \r\nIn the essay, the author,\r\ntext:  \r\ndata:  \r\nIn the essay, the author, Paul\r\ntext:  \r\ndata:  \r\nIn the essay, the author, Paul Graham\r\ntext:  \r\ndata:  \r\nIn the essay, the author, Paul Graham,\r\ntext:  \r\ndata:  \r\nIn the essay, the author, Paul Graham, discusses\r\n```\r\nPlease tell me how to solve the above problems. Is there something wrong with my usage? Looking forward to your answer, thanks\uff01",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9394/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9394/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9393",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9393/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9393/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9393/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9393",
        "id": 2032183560,
        "node_id": "PR_kwDOIWuq585hf6gO",
        "number": 9393,
        "title": "Fix Url Truncation in MetadataRepalcementDemo Notebook",
        "user": {
            "login": "ColeMurray",
            "id": 2492022,
            "node_id": "MDQ6VXNlcjI0OTIwMjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2492022?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ColeMurray",
            "html_url": "https://github.com/ColeMurray",
            "followers_url": "https://api.github.com/users/ColeMurray/followers",
            "following_url": "https://api.github.com/users/ColeMurray/following{/other_user}",
            "gists_url": "https://api.github.com/users/ColeMurray/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ColeMurray/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ColeMurray/subscriptions",
            "organizations_url": "https://api.github.com/users/ColeMurray/orgs",
            "repos_url": "https://api.github.com/users/ColeMurray/repos",
            "events_url": "https://api.github.com/users/ColeMurray/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ColeMurray/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-08T08:26:05Z",
        "updated_at": "2023-12-08T17:48:43Z",
        "closed_at": "2023-12-08T10:13:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9393",
            "html_url": "https://github.com/run-llama/llama_index/pull/9393",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9393.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9393.patch",
            "merged_at": "2023-12-08T10:13:10Z"
        },
        "body": "# Description\r\n\r\nFix url truncation in MetadataRepalcementDemo notebook.\r\nbug via discord user: @yaya90\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\nUses the correct url for the document\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [x ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9393/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9393/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9391",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9391/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9391/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9391/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9391",
        "id": 2032129175,
        "node_id": "PR_kwDOIWuq585hfuO8",
        "number": 9391,
        "title": "Update docs to highlight ingestion",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T08:00:15Z",
        "updated_at": "2023-12-11T17:00:22Z",
        "closed_at": "2023-12-11T17:00:21Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9391",
            "html_url": "https://github.com/run-llama/llama_index/pull/9391",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9391.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9391.patch",
            "merged_at": "2023-12-11T17:00:21Z"
        },
        "body": "- update docs to highlight document ingestion more explicitly\r\n- highlight our ingestionpipeline\r\n- highlight our text splitters\r\n- make it more clear what are the different APIs \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9391/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9391/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9390",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9390/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9390/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9390/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9390",
        "id": 2032096278,
        "node_id": "I_kwDOIWuq5855H1QW",
        "number": 9390,
        "title": "[Question]: How to save IndexNode ?",
        "user": {
            "login": "Plusholic",
            "id": 97847752,
            "node_id": "U_kgDOBdUJyA",
            "avatar_url": "https://avatars.githubusercontent.com/u/97847752?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Plusholic",
            "html_url": "https://github.com/Plusholic",
            "followers_url": "https://api.github.com/users/Plusholic/followers",
            "following_url": "https://api.github.com/users/Plusholic/following{/other_user}",
            "gists_url": "https://api.github.com/users/Plusholic/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Plusholic/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Plusholic/subscriptions",
            "organizations_url": "https://api.github.com/users/Plusholic/orgs",
            "repos_url": "https://api.github.com/users/Plusholic/repos",
            "events_url": "https://api.github.com/users/Plusholic/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Plusholic/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-08T07:36:20Z",
        "updated_at": "2023-12-11T00:31:57Z",
        "closed_at": "2023-12-11T00:31:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFirst, I'm using version '0.9.12'.\r\n\r\nI don't know where to find anything about that.\r\n\r\nI created IndexNode to use the RecursiveRetriever. \r\n\r\nHowever, when I save to a vector database (Faiss, Chroma DB, etc.) and load it, the IndexNode turns into a TextNode and the index_id attribute disappears. Also, the node_id changes while loading.\r\n\r\nHow can I solve this? I want to chunk about 5000 PDF files so that they can reference each other, store them in a vector database, and retrieve them.\r\n\r\nOf course, if I save them using the code below, it works fine when I load them, but it's too large.\r\n\r\n`\r\nvector_index_chunk = VectorStoreIndex(\r\n    all_nodes, service_context=service_context\r\n)\r\nvector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=10)\r\n`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9390/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9390/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9389",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9389/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9389/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9389/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9389",
        "id": 2031907348,
        "node_id": "PR_kwDOIWuq585he-Jt",
        "number": 9389,
        "title": "add zephyr 3b test",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T04:27:19Z",
        "updated_at": "2023-12-08T08:27:46Z",
        "closed_at": "2023-12-08T08:27:45Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9389",
            "html_url": "https://github.com/run-llama/llama_index/pull/9389",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9389.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9389.patch",
            "merged_at": "2023-12-08T08:27:45Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9389/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9389/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9388",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9388/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9388/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9388/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9388",
        "id": 2031815640,
        "node_id": "PR_kwDOIWuq585heqoQ",
        "number": 9388,
        "title": "Merge LLM + LLMPredictor, reorganize types",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-08T02:13:53Z",
        "updated_at": "2023-12-11T16:53:14Z",
        "closed_at": "2023-12-11T16:53:12Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9388",
            "html_url": "https://github.com/run-llama/llama_index/pull/9388",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9388.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9388.patch",
            "merged_at": "2023-12-11T16:53:12Z"
        },
        "body": "# Description\r\n\r\nThis PR merges both `LLMPredictor` and `LLM`.\r\n\r\nBy combining both of these into a single class, we can simplify function arguments.\r\n\r\nThe `LLM` class (open to name changes), handles prompt formatting and function calling, just like the old LLMPredictor. \r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n## Still TODO\r\n\r\n- [ ] add docs/api reference\r\n- [ ] officially depreceate LLMPredictor\r\n- [ ] add some basic tests\r\n- [ ] update interfaces that need `LLMPredictor` to use `LLMPromptMixin`\r\n- [ ] Fix `init` for LLMs to include new params\r\n- [ ] Fix LLMs that were previously using `messages_to_prompt` and `completion_to_prompt`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9388/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9388/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9387",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9387/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9387/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9387/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9387",
        "id": 2031766974,
        "node_id": "PR_kwDOIWuq585heggR",
        "number": 9387,
        "title": "Make HuggingFaceInferenceAPIEmbedding return native floats instead of numpy's float32",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-08T01:14:52Z",
        "updated_at": "2023-12-08T08:49:50Z",
        "closed_at": "2023-12-08T03:04:45Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9387",
            "html_url": "https://github.com/run-llama/llama_index/pull/9387",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9387.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9387.patch",
            "merged_at": "2023-12-08T03:04:45Z"
        },
        "body": "Fix #9386\r\n\r\n# Description\r\n\r\nMake HuggingFaceInferenceAPIEmbedding return native floats instead of numpy's float32\r\n\r\nFixes #9386\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9387/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9387/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9386",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9386/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9386/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9386/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9386",
        "id": 2031715420,
        "node_id": "I_kwDOIWuq5855GYRc",
        "number": 9386,
        "title": "[Bug]: Wrong type of returned value for HuggingFaceInferenceAPIEmbedding::_async_embed_single",
        "user": {
            "login": "cbornet",
            "id": 11633333,
            "node_id": "MDQ6VXNlcjExNjMzMzMz",
            "avatar_url": "https://avatars.githubusercontent.com/u/11633333?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cbornet",
            "html_url": "https://github.com/cbornet",
            "followers_url": "https://api.github.com/users/cbornet/followers",
            "following_url": "https://api.github.com/users/cbornet/following{/other_user}",
            "gists_url": "https://api.github.com/users/cbornet/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cbornet/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cbornet/subscriptions",
            "organizations_url": "https://api.github.com/users/cbornet/orgs",
            "repos_url": "https://api.github.com/users/cbornet/repos",
            "events_url": "https://api.github.com/users/cbornet/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cbornet/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-08T00:13:17Z",
        "updated_at": "2023-12-08T03:04:47Z",
        "closed_at": "2023-12-08T03:04:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\n`_async_embed_single` should return `Embedding/List[float]` but it returns `List[np.float32]`\r\nThis is because huggingface_hub's `AsyncInferenceClient::feature_extraction` returns `np.array[np.float32]` and the values are not converted to standard float.\r\nhttps://github.com/run-llama/llama_index/blob/main/llama_index/embeddings/huggingface.py#L238\r\nThis is a problem for components that expect a list of regular floats. In particular vector stores may not support numpy float32.\r\n\r\n### Version\r\n\r\nHEAD\r\n\r\n### Steps to Reproduce\r\n\r\nExample of failing test\r\n```python\r\ndef test_hugging_face():\r\n        embed_model = HuggingFaceInferenceAPIEmbedding(\r\n            model_name=\"facebook/bart-base\", token=get_required_env(\"HUGGINGFACE_HUB_KEY\")\r\n        )\r\n        embeddings = embed_model.get_query_embedding(\"Hello world\")\r\n>       assert isinstance(embeddings[0], float)\r\nE       assert False\r\nE        +  where False = isinstance(2.2749376, float)\r\n```\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9386/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9386/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9385",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9385/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9385/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9385/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9385",
        "id": 2031636614,
        "node_id": "I_kwDOIWuq5855GFCG",
        "number": 9385,
        "title": "[Question]: Why do the retrieved nodes of a query engine and a retriever differ?",
        "user": {
            "login": "kouskouss",
            "id": 106626673,
            "node_id": "U_kgDOBlr-cQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/106626673?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kouskouss",
            "html_url": "https://github.com/kouskouss",
            "followers_url": "https://api.github.com/users/kouskouss/followers",
            "following_url": "https://api.github.com/users/kouskouss/following{/other_user}",
            "gists_url": "https://api.github.com/users/kouskouss/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kouskouss/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kouskouss/subscriptions",
            "organizations_url": "https://api.github.com/users/kouskouss/orgs",
            "repos_url": "https://api.github.com/users/kouskouss/repos",
            "events_url": "https://api.github.com/users/kouskouss/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kouskouss/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T22:36:32Z",
        "updated_at": "2023-12-07T22:59:36Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI query the same index in two different ways, first I use the following retriever:\r\n\r\n```\r\nservice_context = ServiceContext.from_defaults(\r\n                                               embed_model=embed_model,\r\n                                               llm=None, \r\n                                               chunk_size=512,\r\n                                               chunk_overlap=50\r\n)\r\n\r\n# Load the vector index from the storage\r\nindex = load_index_from_storage(\r\n    StorageContext.from_defaults(persist_dir=vi_out_path),\r\n    service_context=service_context,\r\n)\r\n\r\n# MMR retriever.\r\nretriever = index.as_retriever(\r\n    similarity_top_k=5,\r\n    vector_store_query_mode=\"mmr\",    \r\n)\r\n\r\nretrieved_nodes = retriever.retrieve(query_str)\r\n```\r\n\r\nand then I used a query engine with llm=gpt-3.5-turbo-16k:\r\n\r\n```\r\nservice_context = ServiceContext.from_defaults(\r\n                                               embed_model=embed_model,\r\n                                               llm=llm, \r\n                                               chunk_size=512,\r\n                                               chunk_overlap=50\r\n)\r\n\r\n# Load the vector index from the storage\r\nindex = load_index_from_storage(\r\n    StorageContext.from_defaults(persist_dir=vi_out_path),\r\n    service_context=service_context,\r\n)\r\n\r\n# Query the index.\r\nquery_engine = index.as_query_engine(\r\n    similarity_top_k=5,\r\n    vector_store_query_mode=\"mmr\",\r\n    verbose=True,\r\n)\r\n\r\nresponse = query_engine.query(query_str)\r\nresponse.source_nodes\r\n```\r\n\r\n**As a result the chunks that the two methods retrieved were different** (the _retrieved_nodes_ were different from _response.source_nodes_). I don't understand how is this happening, because the indices were formed with the same embedding model, chunk size and chunk overlap and the query string uses the same embedding in each case, so by using similarity search the same chunks should be retrieved.\r\n\r\nThe only explicit difference is the specification of the llm for the _service_context_, but, for my understanding, that difference shouldn't affect the retrieval part of the process but only the response creation happening after the chunks are retrieved.\r\n\r\nCan somebody clarify why this difference in the results is obtained?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9385/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9385/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9384",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9384/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9384/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9384/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9384",
        "id": 2031617670,
        "node_id": "PR_kwDOIWuq585heBKV",
        "number": 9384,
        "title": "Update MM  LLM OpenAI Abstraction parameters",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-07T22:17:20Z",
        "updated_at": "2023-12-07T23:10:18Z",
        "closed_at": "2023-12-07T23:10:17Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9384",
            "html_url": "https://github.com/run-llama/llama_index/pull/9384",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9384.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9384.patch",
            "merged_at": "2023-12-07T23:10:17Z"
        },
        "body": "# Description\r\nRefactor OpenAI MM Abstraction\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9384/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9384/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9383",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9383/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9383/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9383/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9383",
        "id": 2031607240,
        "node_id": "I_kwDOIWuq5855F93I",
        "number": 9383,
        "title": "[Bug]: MetadataFilters does not allow condition = FilterCondition.OR",
        "user": {
            "login": "hlin-arrybyte",
            "id": 145089940,
            "node_id": "U_kgDOCKXllA",
            "avatar_url": "https://avatars.githubusercontent.com/u/145089940?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hlin-arrybyte",
            "html_url": "https://github.com/hlin-arrybyte",
            "followers_url": "https://api.github.com/users/hlin-arrybyte/followers",
            "following_url": "https://api.github.com/users/hlin-arrybyte/following{/other_user}",
            "gists_url": "https://api.github.com/users/hlin-arrybyte/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hlin-arrybyte/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hlin-arrybyte/subscriptions",
            "organizations_url": "https://api.github.com/users/hlin-arrybyte/orgs",
            "repos_url": "https://api.github.com/users/hlin-arrybyte/repos",
            "events_url": "https://api.github.com/users/hlin-arrybyte/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hlin-arrybyte/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-07T22:07:14Z",
        "updated_at": "2023-12-10T10:07:07Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI added MetadataFilters to my query engine. The query engine seems fine when I'm using the default FilterCondition.AND. When I try to use FilterCondition.OR, the query engine returns 'Empty response'. It also disregards any format requirement in the query. \r\n\r\n### Version\r\n\r\n0.9.13\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index.vector_stores.types import MetadataFilters, ExactMatchFilter\r\nfrom llama_index import Document, VectorStoreIndex\r\n\r\nraw = [{'yob': '1983', 'name': Elena}, {'yob': 'No info', 'name': 'Elena'}, {'yob': '1980', 'name': 'henz'}]\r\n\r\nlist_of_documents = [Document(metadata = {'yob' : r['yob']}, text = r['name']) for r in raw]\r\n\r\nindex = VectorStoreIndex.from_documents(list_of_documents, service_context=service_context)\r\nfilters = MetadataFilters(filters=[ExactMatchFilter(key=\"yob\", value='1983'), ExactMatchFilter(key=\"yob\", value='No info')], condition=FilterCondition.OR)\r\nquery_engine = index.as_query_engine(filters=filters, similarity_top_k=10)\r\nquery=\"Find records with name Elena.\"\r\nresponse=query_engine.query(query)\r\n\r\n---- Expect it to return record 1 and 2, instead return 'empty response'\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9383/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9383/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9382",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9382/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9382/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9382/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9382",
        "id": 2031333407,
        "node_id": "PR_kwDOIWuq585hdC2O",
        "number": 9382,
        "title": "Update FlagEmbeddingReranker Class and example",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-07T18:45:33Z",
        "updated_at": "2023-12-07T19:06:45Z",
        "closed_at": "2023-12-07T19:06:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9382",
            "html_url": "https://github.com/run-llama/llama_index/pull/9382",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9382.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9382.patch",
            "merged_at": "2023-12-07T19:06:44Z"
        },
        "body": "# Description\r\n\r\nComplete the previous https://github.com/run-llama/llama_index/pull/9285.\r\n\r\nSome findings:\r\n1. Apply FlagEmbeddingReranker can reduce query engine query time from 10.35 to 5.37s\r\n2. the answer seems good for this specific example. Top k will change a lot from my local testing.\r\n\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9382/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9382/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9381",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9381/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9381/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9381/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9381",
        "id": 2031328083,
        "node_id": "PR_kwDOIWuq585hdBtr",
        "number": 9381,
        "title": "Add AsyncInferenceClient complete response",
        "user": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-07T18:41:32Z",
        "updated_at": "2023-12-07T18:47:25Z",
        "closed_at": "2023-12-07T18:47:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9381",
            "html_url": "https://github.com/run-llama/llama_index/pull/9381",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9381.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9381.patch",
            "merged_at": "2023-12-07T18:47:25Z"
        },
        "body": "# Description\r\n\r\nPR to add `acomplete` for HuggingFaceInferenceAPI.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9381/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9381/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9380",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9380/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9380/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9380/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9380",
        "id": 2031265857,
        "node_id": "I_kwDOIWuq5855EqhB",
        "number": 9380,
        "title": "[Question]: Set other than temperature parameters for OpenAI",
        "user": {
            "login": "snassimr",
            "id": 6830626,
            "node_id": "MDQ6VXNlcjY4MzA2MjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6830626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snassimr",
            "html_url": "https://github.com/snassimr",
            "followers_url": "https://api.github.com/users/snassimr/followers",
            "following_url": "https://api.github.com/users/snassimr/following{/other_user}",
            "gists_url": "https://api.github.com/users/snassimr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snassimr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snassimr/subscriptions",
            "organizations_url": "https://api.github.com/users/snassimr/orgs",
            "repos_url": "https://api.github.com/users/snassimr/repos",
            "events_url": "https://api.github.com/users/snassimr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snassimr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T17:58:02Z",
        "updated_at": "2023-12-07T21:24:24Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI wonder how to set top_k and top_p for OpenAI model . \r\n\r\nI don't see the clear way to do it.\r\n\r\nHere the code is used now : \r\n\r\n` from llama_index.llms import OpenAI\r\n    llm = OpenAI(model = 'gpt-4', temperature = 0.0)`\r\n\r\nThanks",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9380/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9380/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9378",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9378/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9378/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9378/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9378",
        "id": 2031184954,
        "node_id": "PR_kwDOIWuq585hch8S",
        "number": 9378,
        "title": "Automatic translation of the README for those who don't speak english",
        "user": {
            "login": "hexapode",
            "id": 208554,
            "node_id": "MDQ6VXNlcjIwODU1NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/208554?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hexapode",
            "html_url": "https://github.com/hexapode",
            "followers_url": "https://api.github.com/users/hexapode/followers",
            "following_url": "https://api.github.com/users/hexapode/following{/other_user}",
            "gists_url": "https://api.github.com/users/hexapode/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hexapode/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hexapode/subscriptions",
            "organizations_url": "https://api.github.com/users/hexapode/orgs",
            "repos_url": "https://api.github.com/users/hexapode/repos",
            "events_url": "https://api.github.com/users/hexapode/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hexapode/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-07T17:14:53Z",
        "updated_at": "2023-12-07T17:15:32Z",
        "closed_at": "2023-12-07T17:15:28Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9378",
            "html_url": "https://github.com/run-llama/llama_index/pull/9378",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9378.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9378.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nAn automatic translation of the README with GPT3.5\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- New doc added in /i18n\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- I read the doc\r\n\r\n# Suggested Checklist:\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9378/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9378/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9377",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9377/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9377/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9377/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9377",
        "id": 2031133274,
        "node_id": "PR_kwDOIWuq585hcWkk",
        "number": 9377,
        "title": "feat: PgVectorStore support advanced metadata filtering",
        "user": {
            "login": "juleskuehn",
            "id": 1150048,
            "node_id": "MDQ6VXNlcjExNTAwNDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1150048?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juleskuehn",
            "html_url": "https://github.com/juleskuehn",
            "followers_url": "https://api.github.com/users/juleskuehn/followers",
            "following_url": "https://api.github.com/users/juleskuehn/following{/other_user}",
            "gists_url": "https://api.github.com/users/juleskuehn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juleskuehn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juleskuehn/subscriptions",
            "organizations_url": "https://api.github.com/users/juleskuehn/orgs",
            "repos_url": "https://api.github.com/users/juleskuehn/repos",
            "events_url": "https://api.github.com/users/juleskuehn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juleskuehn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-07T16:42:20Z",
        "updated_at": "2023-12-08T19:15:41Z",
        "closed_at": "2023-12-08T15:44:58Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9377",
            "html_url": "https://github.com/run-llama/llama_index/pull/9377",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9377.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9377.patch",
            "merged_at": "2023-12-08T15:44:58Z"
        },
        "body": "# Description\r\n\r\nApply `MetadataFilters.condition` to PGVectorStore query.\r\n\r\nFixes #9376 \r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nTested on Python 3.11 on Windows with:\r\n* no metadata filters applied\r\n* metadata filters with a single filter and either an \"and\" or \"or\" condition\r\n* multiple metadata filters with either an \"and\" or \"or\" condition.\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\nDue to limitations of my environment (work computer), I cannot create/run automated tests, or run `make`.\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9377/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9377/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9376",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9376/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9376/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9376/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9376",
        "id": 2031105168,
        "node_id": "I_kwDOIWuq5855EDSQ",
        "number": 9376,
        "title": "[Bug]: PGVectorStore metadata filters behaviour",
        "user": {
            "login": "juleskuehn",
            "id": 1150048,
            "node_id": "MDQ6VXNlcjExNTAwNDg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1150048?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/juleskuehn",
            "html_url": "https://github.com/juleskuehn",
            "followers_url": "https://api.github.com/users/juleskuehn/followers",
            "following_url": "https://api.github.com/users/juleskuehn/following{/other_user}",
            "gists_url": "https://api.github.com/users/juleskuehn/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/juleskuehn/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/juleskuehn/subscriptions",
            "organizations_url": "https://api.github.com/users/juleskuehn/orgs",
            "repos_url": "https://api.github.com/users/juleskuehn/repos",
            "events_url": "https://api.github.com/users/juleskuehn/events{/privacy}",
            "received_events_url": "https://api.github.com/users/juleskuehn/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T16:25:00Z",
        "updated_at": "2023-12-08T15:44:59Z",
        "closed_at": "2023-12-08T15:44:59Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nApplying the following `MetadataFilters` object via `PGVectorStore.as_retriever` does not behave as expected:\r\n\r\n```python\r\nvector_store = PGVectorStore.from_params(\r\n    database=DB_NAME,\r\n    host=url.host,\r\n    password=url.password,\r\n    port=url.port,\r\n    user=url.username,\r\n    table_name=DB_TABLE,\r\n    embed_dim=1536,  # openai embedding dimension\r\n    perform_setup=True,\r\n    hybrid_search=True,\r\n    text_search_config=\"english\",\r\n)\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    vector_store=vector_store,\r\n)\r\n\r\nvector_index = VectorStoreIndex.from_vector_store(\r\n    vector_store=vector_store, storage_context=storage_context\r\n)\r\n\r\n# I have several files loaded into the VectorStore already.\r\n# I want to retrieve chunks from only two of them.\r\nfilenames = [\"interpretation-act.pdf\", \"llama2.pdf\"]\r\n\r\nfilters = MetadataFilters(\r\n    filters=[\r\n        MetadataFilter(key=\"filename\", value=filename) for filename in filenames\r\n    ],\r\n    condition=\"or\",  # This is being ignored\r\n)\r\n\r\nretriever = vector_index.as_retriever(\r\n    vector_store_query_mode=\"hybrid\",\r\n    similarity_top_k=top_k,\r\n    filters=filters,\r\n)\r\n```\r\n\r\nThe `PGVectorStore._apply_filters_and_limit` function creates the following SQL, which includes `AND` operators, not `OR` as requested.\r\n\r\n```sql\r\nSELECT public.data_gradio_test.id, public.data_gradio_test.text, public.data_gradio_test.metadata_, public.data_gradio_test.node_id, public.data_gradio_test.embedding, public.data_gradio_test.text_search_tsv, public.data_gradio_test.embedding <=> :embedding_1 AS anon_1 \r\nFROM public.data_gradio_test \r\nWHERE metadata_->>'filename' = :value_filename AND metadata_->>'filename' = :value_filename ORDER BY public.data_gradio_test.embedding <=> :embedding_2\r\n LIMIT :param_1\r\n\r\nSELECT public.data_gradio_test.id, public.data_gradio_test.text, public.data_gradio_test.metadata_, public.data_gradio_test.node_id, public.data_gradio_test.embedding, public.data_gradio_test.text_search_tsv, ts_rank(public.data_gradio_test.text_search_tsv, plainto_tsquery(:param_1, :plainto_tsquery_1)) AS rank \r\nFROM public.data_gradio_test \r\nWHERE (public.data_gradio_test.text_search_tsv @@ plainto_tsquery(:param_1, :plainto_tsquery_1)) AND metadata_->>'filename' = :value_filename AND metadata_->>'filename' = :value_filename ORDER BY rank desc\r\n LIMIT :param_2\r\n```\r\n\r\nThis is due to the code in that function ignoring the `MetadataFilters.condition` property entirely:\r\n```python\r\ndef _apply_filters_and_limit(\r\n    self,\r\n    stmt: Select,\r\n    limit: int,\r\n    metadata_filters: Optional[MetadataFilters] = None,\r\n) -> Any:\r\n    import sqlalchemy\r\n\r\n    if metadata_filters:\r\n        for filter_ in metadata_filters.legacy_filters():\r\n            bind_parameter = f\"value_{filter_.key}\"\r\n            stmt = stmt.where(  # type: ignore\r\n                sqlalchemy.text(f\"metadata_->>'{filter_.key}' = :{bind_parameter}\")\r\n            )\r\n            stmt = stmt.params(  # type: ignore\r\n                **{bind_parameter: str(filter_.value)}\r\n            )\r\n    return stmt.limit(limit)  # type: ignore\r\n```\r\n\r\nThis was quite easy to fix so I will open a Pull Request momentarily.\r\n\r\n### Version\r\n\r\n0.9.13\r\n\r\n### Steps to Reproduce\r\n\r\nPass a `MetadataFilters` object with an \"or\" condition to `PGVectorStore.as_retriever(filters=...)`. See example code above.\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9376/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9376/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9375",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9375/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9375/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9375/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9375",
        "id": 2030976916,
        "node_id": "I_kwDOIWuq5855Dj-U",
        "number": 9375,
        "title": "[Bug]: OpenAIFinetuneEngine uses deprecated OpenAI API and doesn't work",
        "user": {
            "login": "daleksandroff",
            "id": 33901411,
            "node_id": "MDQ6VXNlcjMzOTAxNDEx",
            "avatar_url": "https://avatars.githubusercontent.com/u/33901411?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/daleksandroff",
            "html_url": "https://github.com/daleksandroff",
            "followers_url": "https://api.github.com/users/daleksandroff/followers",
            "following_url": "https://api.github.com/users/daleksandroff/following{/other_user}",
            "gists_url": "https://api.github.com/users/daleksandroff/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/daleksandroff/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/daleksandroff/subscriptions",
            "organizations_url": "https://api.github.com/users/daleksandroff/orgs",
            "repos_url": "https://api.github.com/users/daleksandroff/repos",
            "events_url": "https://api.github.com/users/daleksandroff/events{/privacy}",
            "received_events_url": "https://api.github.com/users/daleksandroff/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "ravi03071991",
                "id": 12198101,
                "node_id": "MDQ6VXNlcjEyMTk4MTAx",
                "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/ravi03071991",
                "html_url": "https://github.com/ravi03071991",
                "followers_url": "https://api.github.com/users/ravi03071991/followers",
                "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
                "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
                "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
                "repos_url": "https://api.github.com/users/ravi03071991/repos",
                "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
                "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T15:18:12Z",
        "updated_at": "2023-12-09T21:01:28Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nHi!\r\nI've been trying to use `OpenAIFinetuneEngine` with model `gpt-3.5-turbo`. \r\nAfter I run command `finetune_engine.finetune()` it goes into `Waiting for file to be ready...` and then doesn't run further. If I force the notebook to Stop the command, then I can see the error saying:\r\n\r\n> 'gpt-3.5-turbo can only be fine-tuned on the new fine-tuning API (`/fine_tuning/jobs`). This API (`/fine-tunes`) is being deprecated. Please refer to our documentation for more information: https://platform.openai.com/docs/api-reference/fine-tuning'\r\n\r\n\r\n<img width=\"1069\" alt=\"Screenshot 2023-12-07 at 16 10 14\" src=\"https://github.com/run-llama/llama_index/assets/33901411/0c77b6cc-de15-42ab-99a6-338df67e23dd\">\r\n<img width=\"1184\" alt=\"Screenshot 2023-12-07 at 16 10 27\" src=\"https://github.com/run-llama/llama_index/assets/33901411/a3478c1b-4dbf-449e-8f77-15314ed28bbd\">\r\n\r\n---\r\n\r\n\r\n\r\n\r\nIf I try to use another model `davinci` which supposed to work with `/fine-tunes` API, then I'm getting an error that there is no `message` object in the training file (which is not there as per the format needed for davinci).\r\n\r\n<img width=\"1204\" alt=\"Screenshot 2023-12-07 at 16 14 57\" src=\"https://github.com/run-llama/llama_index/assets/33901411/47483ffd-1f70-4bd0-beaa-afdeb9c188e6\">\r\n\r\n\r\n### Version\r\n\r\n0.9.11.post1\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index.finetuning import OpenAIFinetuneEngine\r\nfinetune_engine = OpenAIFinetuneEngine(\r\n    \"gpt-3.5-turbo\",\r\n    \"finetuning_corpus.jsonl\",\r\n)\r\nfinetune_engine.finetune()\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nBadRequestError: Error code: 400 - {'error': {'message': 'gpt-3.5-turbo can only be fine-tuned on the new fine-tuning API (`/fine_tuning/jobs`). This API (`/fine-tunes`) is being deprecated. Please refer to our documentation for more information: https://platform.openai.com/docs/api-reference/fine-tuning', 'type': 'invalid_request_error', 'param': None, 'code': None}}\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9375/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9375/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9374",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9374/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9374/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9374/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9374",
        "id": 2030964335,
        "node_id": "I_kwDOIWuq5855Dg5v",
        "number": 9374,
        "title": "[Bug]: AzureOpenAI is incorrect when using RetrieverQueryEngine",
        "user": {
            "login": "AlexJJJChen",
            "id": 126591882,
            "node_id": "U_kgDOB4ujig",
            "avatar_url": "https://avatars.githubusercontent.com/u/126591882?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AlexJJJChen",
            "html_url": "https://github.com/AlexJJJChen",
            "followers_url": "https://api.github.com/users/AlexJJJChen/followers",
            "following_url": "https://api.github.com/users/AlexJJJChen/following{/other_user}",
            "gists_url": "https://api.github.com/users/AlexJJJChen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AlexJJJChen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AlexJJJChen/subscriptions",
            "organizations_url": "https://api.github.com/users/AlexJJJChen/orgs",
            "repos_url": "https://api.github.com/users/AlexJJJChen/repos",
            "events_url": "https://api.github.com/users/AlexJJJChen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AlexJJJChen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T15:11:21Z",
        "updated_at": "2023-12-07T17:13:08Z",
        "closed_at": "2023-12-07T15:48:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nI tried to use the function of AutoMergingRetriever, when I ran the code \r\n\r\nauto_merging_engine = RetrieverQueryEngine.from_args(\r\n    automerging_retriever, node_postprocessors=[rerank])\r\n\r\nit showed the following bugs.\r\n\r\nhowever, when I used the same azure openai key, it worked successfully.\r\n\r\n### Version\r\n\r\n0.9.13\r\n\r\n### Steps to Reproduce\r\n\r\nfrom llama_index.node_parser import HierarchicalNodeParser\r\nfrom llama_index.node_parser import get_leaf_nodes\r\n\r\n# create the hierarchical node parser w/ default settings\r\nnode_parser = HierarchicalNodeParser.from_defaults(\r\n    chunk_sizes=[2048, 512, 128]\r\n)\r\nnodes = node_parser.get_nodes_from_documents([document])\r\n\r\n\r\nleaf_nodes = get_leaf_nodes(nodes)\r\n\r\nnodes_by_id = {node.node_id: node for node in nodes}\r\n\r\nparent_node = nodes_by_id[leaf_nodes[30].parent_node.node_id]\r\n\r\nfrom llama_index import ServiceContext\r\n\r\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\r\nllm = AzureOpenAI(model=\"gpt-4-32k\", engine= \"oh-ai-openai-eu-deployment-gpt-4-32k-0314\", temperature=0.1,azure_endpoint = \"\u201d, api_key=\"my key\",api_version = \"2023-07-01-preview\")\r\nauto_merging_context = ServiceContext.from_defaults(\r\n    llm=llm,\r\n    embed_model=embed_model,\r\n    node_parser=node_parser,\r\n)\r\n\r\nfrom llama_index import VectorStoreIndex, StorageContext\r\n\r\nstorage_context = StorageContext.from_defaults()\r\nstorage_context.docstore.add_documents(nodes)\r\n\r\nautomerging_index = VectorStoreIndex(\r\n    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\r\n)\r\n\r\nautomerging_index.storage_context.persist(persist_dir=\"./merging_index\")\r\n\r\nimport os\r\nfrom llama_index import VectorStoreIndex, StorageContext, load_index_from_storage\r\nfrom llama_index import load_index_from_storage\r\n\r\nif not os.path.exists(\"./merging_index\"):\r\n    storage_context = StorageContext.from_defaults()\r\n    storage_context.docstore.add_documents(nodes)\r\n\r\n    automerging_index = VectorStoreIndex(\r\n            leaf_nodes,\r\n            storage_context=storage_context,\r\n            service_context=auto_merging_context\r\n        )\r\n\r\n    automerging_index.storage_context.persist(persist_dir=\"./merging_index\")\r\nelse:\r\n    automerging_index = load_index_from_storage(\r\n        StorageContext.from_defaults(persist_dir=\"./merging_index\"),\r\n        service_context=auto_merging_context\r\n    )\r\n\r\nfrom llama_index.indices.postprocessor import SentenceTransformerRerank\r\nfrom llama_index.retrievers import AutoMergingRetriever\r\nfrom llama_index.query_engine import RetrieverQueryEngine\r\n\r\nautomerging_retriever = automerging_index.as_retriever(\r\n    similarity_top_k=12\r\n)\r\n\r\nretriever = AutoMergingRetriever(\r\n    automerging_retriever, \r\n    automerging_index.storage_context, \r\n    verbose=True\r\n)\r\n\r\nrerank = SentenceTransformerRerank(top_n=6, model=\"BAAI/bge-reranker-base\")\r\n\r\nauto_merging_engine = RetrieverQueryEngine.from_args(\r\n    automerging_retriever, node_postprocessors=[rerank]\r\n)\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n---------------------------------------------------------------------------\r\nAuthenticationError                       Traceback (most recent call last)\r\nCell In[60], line 1\r\n----> 1 auto_merging_response = auto_merging_engine.query(\r\n      2     \"Can banks reject account opening request from an individual purely based on nationality?\"\r\n      3 )\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/core/base_query_engine.py:30, in BaseQueryEngine.query(self, str_or_query_bundle)\r\n     28 if isinstance(str_or_query_bundle, str):\r\n     29     str_or_query_bundle = QueryBundle(str_or_query_bundle)\r\n---> 30 return self._query(str_or_query_bundle)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/query_engine/retriever_query_engine.py:171, in RetrieverQueryEngine._query(self, query_bundle)\r\n    167 with self.callback_manager.event(\r\n    168     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\r\n    169 ) as query_event:\r\n    170     nodes = self.retrieve(query_bundle)\r\n--> 171     response = self._response_synthesizer.synthesize(\r\n    172         query=query_bundle,\r\n    173         nodes=nodes,\r\n    174     )\r\n    176     query_event.on_end(payload={EventPayload.RESPONSE: response})\r\n    178 return response\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/response_synthesizers/base.py:146, in BaseSynthesizer.synthesize(self, query, nodes, additional_source_nodes, **response_kwargs)\r\n    141     query = QueryBundle(query_str=query)\r\n    143 with self._callback_manager.event(\r\n    144     CBEventType.SYNTHESIZE, payload={EventPayload.QUERY_STR: query.query_str}\r\n    145 ) as event:\r\n--> 146     response_str = self.get_response(\r\n    147         query_str=query.query_str,\r\n    148         text_chunks=[\r\n    149             n.node.get_content(metadata_mode=MetadataMode.LLM) for n in nodes\r\n    150         ],\r\n    151         **response_kwargs,\r\n    152     )\r\n    154     additional_source_nodes = additional_source_nodes or []\r\n    155     source_nodes = list(nodes) + list(additional_source_nodes)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/response_synthesizers/compact_and_refine.py:38, in CompactAndRefine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n     34 # use prompt helper to fix compact text_chunks under the prompt limitation\r\n     35 # TODO: This is a temporary fix - reason it's temporary is that\r\n     36 # the refine template does not account for size of previous answer.\r\n     37 new_texts = self._make_compact_text_chunks(query_str, text_chunks)\r\n---> 38 return super().get_response(\r\n     39     query_str=query_str,\r\n     40     text_chunks=new_texts,\r\n     41     prev_response=prev_response,\r\n     42     **response_kwargs,\r\n     43 )\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/response_synthesizers/refine.py:127, in Refine.get_response(self, query_str, text_chunks, prev_response, **response_kwargs)\r\n    123 for text_chunk in text_chunks:\r\n    124     if prev_response is None:\r\n    125         # if this is the first chunk, and text chunk already\r\n    126         # is an answer, then return it\r\n--> 127         response = self._give_response_single(\r\n    128             query_str, text_chunk, **response_kwargs\r\n    129         )\r\n    130     else:\r\n    131         # refine response if possible\r\n    132         response = self._refine_response_single(\r\n    133             prev_response, query_str, text_chunk, **response_kwargs\r\n    134         )\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/response_synthesizers/refine.py:182, in Refine._give_response_single(self, query_str, text_chunk, **response_kwargs)\r\n    178 if response is None and not self._streaming:\r\n    179     try:\r\n    180         structured_response = cast(\r\n    181             StructuredRefineResponse,\r\n--> 182             program(\r\n    183                 context_str=cur_text_chunk,\r\n    184                 output_cls=self._output_cls,\r\n    185                 **response_kwargs,\r\n    186             ),\r\n    187         )\r\n    188         query_satisfied = structured_response.query_satisfied\r\n    189         if query_satisfied:\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/response_synthesizers/refine.py:53, in DefaultRefineProgram.__call__(self, *args, **kwds)\r\n     52 def __call__(self, *args: Any, **kwds: Any) -> StructuredRefineResponse:\r\n---> 53     answer = self._llm_predictor.predict(\r\n     54         self._prompt,\r\n     55         **kwds,\r\n     56     )\r\n     57     return StructuredRefineResponse(answer=answer, query_satisfied=True)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/llm_predictor/base.py:219, in LLMPredictor.predict(self, prompt, output_cls, **prompt_args)\r\n    217     messages = prompt.format_messages(llm=self._llm, **prompt_args)\r\n    218     messages = self._extend_messages(messages)\r\n--> 219     chat_response = self._llm.chat(messages)\r\n    220     output = chat_response.message.content or \"\"\r\n    221 else:\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/llms/base.py:187, in llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat(_self, messages, **kwargs)\r\n    178 with wrapper_logic(_self) as callback_manager:\r\n    179     event_id = callback_manager.on_event_start(\r\n    180         CBEventType.LLM,\r\n    181         payload={\r\n   (...)\r\n    185         },\r\n    186     )\r\n--> 187     f_return_val = f(_self, messages, **kwargs)\r\n    189     if isinstance(f_return_val, Generator):\r\n    190         # intercept the generator and add a callback to the end\r\n    191         def wrapped_gen() -> ChatResponseGen:\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/llms/openai.py:220, in OpenAI.chat(self, messages, **kwargs)\r\n    218 else:\r\n    219     chat_fn = completion_to_chat_decorator(self._complete)\r\n--> 220 return chat_fn(messages, **kwargs)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/llama_index/llms/openai.py:275, in OpenAI._chat(self, messages, **kwargs)\r\n    273 client = self._get_client()\r\n    274 message_dicts = to_openai_message_dicts(messages)\r\n--> 275 response = client.chat.completions.create(\r\n    276     messages=message_dicts,\r\n    277     stream=False,\r\n    278     **self._get_model_kwargs(**kwargs),\r\n    279 )\r\n    280 openai_message = response.choices[0].message\r\n    281 message = from_openai_message(openai_message)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/trulens_eval/feedback/provider/endpoint/base.py:758, in Endpoint.wrap_function.<locals>.wrapper(*args, **kwargs)\r\n    755 logger.debug(f\"Calling wrapped {func.__name__} for {self.name}.\")\r\n    757 # Get the result of the wrapped function:\r\n--> 758 response: Any = func(*args, **kwargs)\r\n    760 bindings = inspect.signature(func).bind(*args, **kwargs)\r\n    762 # Get all of the callback classes suitable for handling this call.\r\n    763 # Note that we stored this in the INSTRUMENT attribute of the\r\n    764 # wrapper method.\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py:301, in required_args.<locals>.inner.<locals>.wrapper(*args, **kwargs)\r\n    299             msg = f\"Missing required argument: {quote(missing[0])}\"\r\n    300     raise TypeError(msg)\r\n--> 301 return func(*args, **kwargs)\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py:598, in Completions.create(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\r\n    551 @required_args([\"messages\", \"model\"], [\"messages\", \"model\", \"stream\"])\r\n    552 def create(\r\n    553     self,\r\n   (...)\r\n    596     timeout: float | httpx.Timeout | None | NotGiven = NOT_GIVEN,\r\n    597 ) -> ChatCompletion | Stream[ChatCompletionChunk]:\r\n--> 598     return self._post(\r\n    599         \"/chat/completions\",\r\n    600         body=maybe_transform(\r\n    601             {\r\n    602                 \"messages\": messages,\r\n    603                 \"model\": model,\r\n    604                 \"frequency_penalty\": frequency_penalty,\r\n    605                 \"function_call\": function_call,\r\n    606                 \"functions\": functions,\r\n    607                 \"logit_bias\": logit_bias,\r\n    608                 \"max_tokens\": max_tokens,\r\n    609                 \"n\": n,\r\n    610                 \"presence_penalty\": presence_penalty,\r\n    611                 \"response_format\": response_format,\r\n    612                 \"seed\": seed,\r\n    613                 \"stop\": stop,\r\n    614                 \"stream\": stream,\r\n    615                 \"temperature\": temperature,\r\n    616                 \"tool_choice\": tool_choice,\r\n    617                 \"tools\": tools,\r\n    618                 \"top_p\": top_p,\r\n    619                 \"user\": user,\r\n    620             },\r\n    621             completion_create_params.CompletionCreateParams,\r\n    622         ),\r\n    623         options=make_request_options(\r\n    624             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\r\n    625         ),\r\n    626         cast_to=ChatCompletion,\r\n    627         stream=stream or False,\r\n    628         stream_cls=Stream[ChatCompletionChunk],\r\n    629     )\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py:1096, in SyncAPIClient.post(self, path, cast_to, body, options, files, stream, stream_cls)\r\n   1082 def post(\r\n   1083     self,\r\n   1084     path: str,\r\n   (...)\r\n   1091     stream_cls: type[_StreamT] | None = None,\r\n   1092 ) -> ResponseT | _StreamT:\r\n   1093     opts = FinalRequestOptions.construct(\r\n   1094         method=\"post\", url=path, json_data=body, files=to_httpx_files(files), **options\r\n   1095     )\r\n-> 1096     return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py:856, in SyncAPIClient.request(self, cast_to, options, remaining_retries, stream, stream_cls)\r\n    847 def request(\r\n    848     self,\r\n    849     cast_to: Type[ResponseT],\r\n   (...)\r\n    854     stream_cls: type[_StreamT] | None = None,\r\n    855 ) -> ResponseT | _StreamT:\r\n--> 856     return self._request(\r\n    857         cast_to=cast_to,\r\n    858         options=options,\r\n    859         stream=stream,\r\n    860         stream_cls=stream_cls,\r\n    861         remaining_retries=remaining_retries,\r\n    862     )\r\n\r\nFile /opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py:908, in SyncAPIClient._request(self, cast_to, options, remaining_retries, stream, stream_cls)\r\n    905     if not err.response.is_closed:\r\n    906         err.response.read()\r\n--> 908     raise self._make_status_error_from_response(err.response) from None\r\n    909 except httpx.TimeoutException as err:\r\n    910     if response is not None:\r\n\r\nAuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 2aa8b6f1********************f79e. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9374/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9374/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9373",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9373/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9373/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9373/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9373",
        "id": 2030661995,
        "node_id": "I_kwDOIWuq5855CXFr",
        "number": 9373,
        "title": "[Bug]: agent.chat - Error : [] is too short - 'messages'",
        "user": {
            "login": "iamsaurabhc",
            "id": 19235748,
            "node_id": "MDQ6VXNlcjE5MjM1NzQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19235748?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iamsaurabhc",
            "html_url": "https://github.com/iamsaurabhc",
            "followers_url": "https://api.github.com/users/iamsaurabhc/followers",
            "following_url": "https://api.github.com/users/iamsaurabhc/following{/other_user}",
            "gists_url": "https://api.github.com/users/iamsaurabhc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iamsaurabhc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iamsaurabhc/subscriptions",
            "organizations_url": "https://api.github.com/users/iamsaurabhc/orgs",
            "repos_url": "https://api.github.com/users/iamsaurabhc/repos",
            "events_url": "https://api.github.com/users/iamsaurabhc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iamsaurabhc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "ravi03071991",
            "id": 12198101,
            "node_id": "MDQ6VXNlcjEyMTk4MTAx",
            "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ravi03071991",
            "html_url": "https://github.com/ravi03071991",
            "followers_url": "https://api.github.com/users/ravi03071991/followers",
            "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
            "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
            "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
            "repos_url": "https://api.github.com/users/ravi03071991/repos",
            "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "ravi03071991",
                "id": 12198101,
                "node_id": "MDQ6VXNlcjEyMTk4MTAx",
                "avatar_url": "https://avatars.githubusercontent.com/u/12198101?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/ravi03071991",
                "html_url": "https://github.com/ravi03071991",
                "followers_url": "https://api.github.com/users/ravi03071991/followers",
                "following_url": "https://api.github.com/users/ravi03071991/following{/other_user}",
                "gists_url": "https://api.github.com/users/ravi03071991/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/ravi03071991/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/ravi03071991/subscriptions",
                "organizations_url": "https://api.github.com/users/ravi03071991/orgs",
                "repos_url": "https://api.github.com/users/ravi03071991/repos",
                "events_url": "https://api.github.com/users/ravi03071991/events{/privacy}",
                "received_events_url": "https://api.github.com/users/ravi03071991/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T12:30:36Z",
        "updated_at": "2023-12-09T20:47:26Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nTrying to use a custom function in the tool using OpenAIAgent\r\n\r\nThe first run is successful and the function output is visible. For the second run, I'm getting an error.\r\n\r\nAttached relevant file for you guys. Any help would be appreciated!\r\n\r\nAlso, great work building this library! \r\n\r\n### Version\r\n\r\n0.9.10\r\n\r\n### Steps to Reproduce\r\n\r\npython agent.py\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nSTARTING TURN 1\r\n---------------\r\n\r\n=== Calling Function ===\r\nCalling function: GetStockHistoryWithIndicators with args: {\r\n  \"symbol\": \"SBIN\",\r\n  \"startDate\": \"2023-11-01\",\r\n  \"endDate\": \"2023-11-30\"\r\n}\r\nGot output: \"[{\\\"DATE\\\":1701302400000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":569.75,\\\"HIGH\\\":570.2,\\\"LOW\\\":563.65,\\\"PREV. CLOSE\\\":568.6,\\\"LTP\\\":565.15,\\\"CLOSE\\\":564.75,\\\"VWAP\\\":566.22,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":19758998,\\\"VALUE\\\":11187929536.5,\\\"NO OF TRADES\\\":314822,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-13122387.9847327564,\\\"volume_obv\\\":19758998,\\\"volume_cmf\\\":-0.6641221374,\\\"volume_fi\\\":0.0,\\\"volume_em\\\":0.0,\\\"volume_sma_em\\\":0.0,\\\"volume_vpt\\\":0.0,\\\"volume_vwap\\\":566.2,\\\"volume_mfi\\\":50.0,\\\"volume_nvi\\\":1000.0,\\\"volatility_bbm\\\":564.75,\\\"volatility_bbh\\\":564.75,\\\"volatility_bbl\\\":564.75,\\\"volatility_bbw\\\":0.0,\\\"volatility_bbp\\\":0.0,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":566.2,\\\"volatility_kch\\\":572.75,\\\"volatility_kcl\\\":559.65,\\\"volatility_kcw\\\":2.3136700812,\\\"volatility_kcp\\\":0.3893129771,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":563.65,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":566.925,\\\"volatility_dcw\\\":1.1598052236,\\\"volatility_dcp\\\":0.1679389313,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":100.0,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":0.0,\\\"momentum_uo\\\":0.0,\\\"momentum_stoch\\\":16.7938931298,\\\"momentum_stoch_signal\\\":16.7938931298,\\\"momentum_wr\\\":-83.2061068702,\\\"momentum_ao\\\":0.0,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.0,\\\"momentum_ppo_signal\\\":0.0,\\\"momentum_ppo_hist\\\":0.0,\\\"momentum_pvo\\\":0.0,\\\"momentum_pvo_signal\\\":0.0,\\\"momentum_pvo_hist\\\":0.0,\\\"momentum_kama\\\":564.75,\\\"others_dr\\\":0.0,\\\"others_dlr\\\":0.0,\\\"others_cr\\\":0.0},{\\\"DATE\\\":1701216000000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":568.0,\\\"HIGH\\\":569.0,\\\"LOW\\\":565.1,\\\"PREV. CLOSE\\\":564.45,\\\"LTP\\\":568.35,\\\"CLOSE\\\":568.6,\\\"VWAP\\\":567.58,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":10299034,\\\"VALUE\\\":5845506569.1499996185,\\\"NO OF TRADES\\\":206929,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-4935976.3437070074,\\\"volume_obv\\\":30058032,\\\"volume_cmf\\\":-0.1642148875,\\\"volume_fi\\\":39651280.9000002369,\\\"volume_em\\\":4.7334536424,\\\"volume_sma_em\\\":4.7334536424,\\\"volume_vpt\\\":70210.3247454628,\\\"volume_vwap\\\":566.6682723894,\\\"volume_mfi\\\":100.0,\\\"volume_nvi\\\":1006.8171757415,\\\"volatility_bbm\\\":566.675,\\\"volatility_bbh\\\":570.525,\\\"volatility_bbl\\\":562.825,\\\"volatility_bbw\\\":1.358803547,\\\"volatility_bbp\\\":0.75,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":566.8833333333,\\\"volatility_kch\\\":572.1083333333,\\\"volatility_kcl\\\":561.6583333333,\\\"volatility_kcw\\\":1.8434128127,\\\"volatility_kcp\\\":0.6642743222,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":563.65,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":566.925,\\\"volatility_dcw\\\":1.1558653549,\\\"volatility_dcp\\\":0.7557251908,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":100.0,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":100.0,\\\"momentum_uo\\\":35.6481481481,\\\"momentum_stoch\\\":75.572519084,\\\"momentum_stoch_signal\\\":46.1832061069,\\\"momentum_wr\\\":-24.427480916,\\\"momentum_ao\\\":0.0,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.0543545809,\\\"momentum_ppo_signal\\\":0.0108709162,\\\"momentum_ppo_hist\\\":0.0434836648,\\\"momentum_pvo\\\":-3.9596532201,\\\"momentum_pvo_signal\\\":-0.791930644,\\\"momentum_pvo_hist\\\":-3.1677225761,\\\"momentum_kama\\\":572.8998344107,\\\"others_dr\\\":0.6817175741,\\\"others_dlr\\\":0.6794043869,\\\"others_cr\\\":0.6817175741},{\\\"DATE\\\":1701129600000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":563.6,\\\"HIGH\\\":565.2,\\\"LOW\\\":561.1,\\\"PREV. CLOSE\\\":560.35,\\\"LTP\\\":564.8,\\\"CLOSE\\\":564.45,\\\"VWAP\\\":563.42,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":8153314,\\\"VALUE\\\":4593727819.6999998093,\\\"NO OF TRADES\\\":186090,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":234417.9001954477,\\\"volume_obv\\\":21904718,\\\"volume_cmf\\\":0.0061347721,\\\"volume_fi\\\":29153061.7571430877,\\\"volume_em\\\":-196.1165729665,\\\"volume_sma_em\\\":-95.6915596621,\\\"volume_vpt\\\":10702.3171830291,\\\"volume_vwap\\\":566.010026098,\\\"volume_mfi\\\":55.9878419246,\\\"volume_nvi\\\":999.4687915007,\\\"volatility_bbm\\\":565.9333333333,\\\"volatility_bbh\\\":569.7125160786,\\\"volatility_bbl\\\":562.1541505881,\\\"volatility_bbw\\\":1.3355575728,\\\"volatility_bbp\\\":0.3037494568,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":565.7833333333,\\\"volatility_kch\\\":570.6333333333,\\\"volatility_kcl\\\":560.9333333333,\\\"volatility_kcw\\\":1.7144372109,\\\"volatility_kcp\\\":0.3625429553,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":561.1,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":565.65,\\\"volatility_dcw\\\":1.6079632466,\\\"volatility_dcp\\\":0.3681318681,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":46.2783171521,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":97.6329673464,\\\"momentum_uo\\\":39.3442622951,\\\"momentum_stoch\\\":36.8131868132,\\\"momentum_stoch_signal\\\":43.0598663423,\\\"momentum_wr\\\":-63.1868131868,\\\"momentum_ao\\\":0.0,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.0377335453,\\\"momentum_ppo_signal\\\":0.016243442,\\\"momentum_ppo_hist\\\":0.0214901033,\\\"momentum_pvo\\\":-8.265273542,\\\"momentum_pvo_signal\\\":-2.2865992236,\\\"momentum_pvo_hist\\\":-5.9786743184,\\\"momentum_kama\\\":564.3886892043,\\\"others_dr\\\":-0.729862821,\\\"others_dlr\\\":-0.7325393509,\\\"others_cr\\\":-0.0531208499},{\\\"DATE\\\":1700784000000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":561.95,\\\"HIGH\\\":562.45,\\\"LOW\\\":559.25,\\\"PREV. CLOSE\\\":559.95,\\\"LTP\\\":560.7,\\\"CLOSE\\\":560.35,\\\"VWAP\\\":560.63,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":6529851,\\\"VALUE\\\":3660804948.5500001907,\\\"NO OF TRADES\\\":155259,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-1806160.5373045232,\\\"volume_obv\\\":15374867,\\\"volume_cmf\\\":-0.0403690705,\\\"volume_fi\\\":21163711.6346940547,\\\"volume_em\\\":-112.7131384774,\\\"volume_sma_em\\\":-101.3654192672,\\\"volume_vpt\\\":-36728.6139889087,\\\"volume_vwap\\\":565.2326103736,\\\"volume_mfi\\\":41.4518371735,\\\"volume_nvi\\\":992.2089420097,\\\"volatility_bbm\\\":564.5375,\\\"volatility_bbh\\\":570.3763247961,\\\"volatility_bbl\\\":558.6986752039,\\\"volatility_bbw\\\":2.0685339047,\\\"volatility_bbp\\\":0.1414090038,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":564.5083333333,\\\"volatility_kch\\\":568.9458333333,\\\"volatility_kcl\\\":560.0708333333,\\\"volatility_kcw\\\":1.572164568,\\\"volatility_kcp\\\":0.0314553991,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":559.25,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":564.725,\\\"volatility_dcw\\\":1.9396408565,\\\"volatility_dcp\\\":0.100456621,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":29.4471725012,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":93.4566803951,\\\"momentum_uo\\\":35.3191489362,\\\"momentum_stoch\\\":10.0456621005,\\\"momentum_stoch_signal\\\":40.8104559992,\\\"momentum_wr\\\":-89.9543378995,\\\"momentum_ao\\\":0.0,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.0336309198,\\\"momentum_ppo_signal\\\":0.0062685697,\\\"momentum_ppo_hist\\\":-0.0398994894,\\\"momentum_pvo\\\":-12.7219272763,\\\"momentum_pvo_signal\\\":-4.3736648341,\\\"momentum_pvo_hist\\\":-8.3482624421,\\\"momentum_kama\\\":561.4515773921,\\\"others_dr\\\":-0.7263708034,\\\"others_dlr\\\":-0.729021721,\\\"others_cr\\\":-0.779105799},{\\\"DATE\\\":1700697600000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":561.75,\\\"HIGH\\\":563.5,\\\"LOW\\\":558.3,\\\"PREV. CLOSE\\\":558.95,\\\"LTP\\\":560.5,\\\"CLOSE\\\":559.95,\\\"VWAP\\\":560.72,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":6376210,\\\"VALUE\\\":3575282774.3499999046,\\\"NO OF TRADES\\\":198344,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-4135929.5757658742,\\\"volume_obv\\\":8998657,\\\"volume_cmf\\\":-0.0809103947,\\\"volume_fi\\\":17775969.4011663571,\\\"volume_em\\\":4.0776574172,\\\"volume_sma_em\\\":-75.0046500961,\\\"volume_vpt\\\":-41280.204958838,\\\"volume_vwap\\\":564.6526755041,\\\"volume_mfi\\\":33.0695661095,\\\"volume_nvi\\\":991.5006640106,\\\"volatility_bbm\\\":563.62,\\\"volatility_bbh\\\":570.0029773617,\\\"volatility_bbl\\\":557.2370226383,\\\"volatility_bbw\\\":2.2649932088,\\\"volatility_bbp\\\":0.2125166053,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":563.7233333333,\\\"volatility_kch\\\":568.3133333333,\\\"volatility_kcl\\\":559.1333333333,\\\"volatility_kcw\\\":1.6284584045,\\\"volatility_kcp\\\":0.0889615105,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":558.3,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":564.25,\\\"volatility_dcw\\\":2.1113516199,\\\"volatility_dcp\\\":0.1386554622,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":28.3633589578,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":89.9054357118,\\\"momentum_uo\\\":34.668989547,\\\"momentum_stoch\\\":13.8655462185,\\\"momentum_stoch_signal\\\":20.241465044,\\\"momentum_wr\\\":-86.1344537815,\\\"momentum_ao\\\":0.0,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.0948875761,\\\"momentum_ppo_signal\\\":-0.0139626595,\\\"momentum_ppo_hist\\\":-0.0809249166,\\\"momentum_pvo\\\":-16.5939911604,\\\"momentum_pvo_signal\\\":-6.8177300994,\\\"momentum_pvo_hist\\\":-9.776261061,\\\"momentum_kama\\\":560.1514481603,\\\"others_dr\\\":-0.0713839565,\\\"others_dlr\\\":-0.0714094469,\\\"others_cr\\\":-0.8499335989},{\\\"DATE\\\":1700611200000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":562.95,\\\"HIGH\\\":564.5,\\\"LOW\\\":555.15,\\\"PREV. CLOSE\\\":561.5,\\\"LTP\\\":559.5,\\\"CLOSE\\\":558.95,\\\"VWAP\\\":559.0,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":14909071,\\\"VALUE\\\":8334245035.5,\\\"NO OF TRADES\\\":247815,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-6926397.4099902846,\\\"volume_obv\\\":-5910414,\\\"volume_cmf\\\":-0.10490333,\\\"volume_fi\\\":13106677.9152854495,\\\"volume_em\\\":-67.4170107581,\\\"volume_sma_em\\\":-73.4871222285,\\\"volume_vpt\\\":-67905.9233265488,\\\"volume_vwap\\\":563.4967053811,\\\"volume_mfi\\\":22.4665726252,\\\"volume_nvi\\\":991.5006640106,\\\"volatility_bbm\\\":562.8416666667,\\\"volatility_bbh\\\":569.6290119176,\\\"volatility_bbl\\\":556.0543214157,\\\"volatility_bbw\\\":2.4118133581,\\\"volatility_bbp\\\":0.2133145197,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":563.025,\\\"volatility_kch\\\":568.4083333333,\\\"volatility_kcl\\\":557.6416666667,\\\"volatility_kcw\\\":1.9122892708,\\\"volatility_kcp\\\":0.1215170279,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":562.675,\\\"volatility_dcw\\\":2.6739313898,\\\"volatility_dcp\\\":0.2524916944,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":25.806189293,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":86.4733676827,\\\"momentum_uo\\\":36.1366622865,\\\"momentum_stoch\\\":25.2491694352,\\\"momentum_stoch_signal\\\":16.3867925847,\\\"momentum_wr\\\":-74.7508305648,\\\"momentum_ao\\\":-0.7616666667,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.1560291363,\\\"momentum_ppo_signal\\\":-0.0423759549,\\\"momentum_ppo_hist\\\":-0.1136531814,\\\"momentum_pvo\\\":-14.9502192195,\\\"momentum_pvo_signal\\\":-8.4442279234,\\\"momentum_pvo_hist\\\":-6.5059912961,\\\"momentum_kama\\\":559.1971465372,\\\"others_dr\\\":-0.1785873739,\\\"others_dlr\\\":-0.1787470312,\\\"others_cr\\\":-1.0270030987},{\\\"DATE\\\":1700524800000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":566.0,\\\"HIGH\\\":566.65,\\\"LOW\\\":561.0,\\\"PREV. CLOSE\\\":563.75,\\\"LTP\\\":561.4,\\\"CLOSE\\\":561.5,\\\"VWAP\\\":563.11,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":14280013,\\\"VALUE\\\":8041232058.75,\\\"NO OF TRADES\\\":223495,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-18678974.4807867333,\\\"volume_obv\\\":8369599,\\\"volume_cmf\\\":-0.2325960735,\\\"volume_fi\\\":16436300.0916731507,\\\"volume_em\\\":158.263161245,\\\"volume_sma_em\\\":-34.8620749829,\\\"volume_vpt\\\":-2758.7131109678,\\\"volume_vwap\\\":563.4172727154,\\\"volume_mfi\\\":40.7702681496,\\\"volume_nvi\\\":996.0240143876,\\\"volatility_bbm\\\":562.65,\\\"volatility_bbh\\\":569.0036266359,\\\"volatility_bbl\\\":556.2963733641,\\\"volatility_bbw\\\":2.258464991,\\\"volatility_bbp\\\":0.4095005053,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":563.0285714286,\\\"volatility_kch\\\":568.45,\\\"volatility_kcl\\\":557.6071428571,\\\"volatility_kcw\\\":1.9258093982,\\\"volatility_kcp\\\":0.3590250329,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":562.675,\\\"volatility_dcw\\\":2.6748422643,\\\"volatility_dcp\\\":0.4219269103,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":40.5301211849,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":83.7745167919,\\\"momentum_uo\\\":35.6284153005,\\\"momentum_stoch\\\":42.1926910299,\\\"momentum_stoch_signal\\\":27.1024688945,\\\"momentum_wr\\\":-57.8073089701,\\\"momentum_ao\\\":-1.5078571429,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.1660808295,\\\"momentum_ppo_signal\\\":-0.0671169298,\\\"momentum_ppo_hist\\\":-0.0989638997,\\\"momentum_pvo\\\":-13.8349290908,\\\"momentum_pvo_signal\\\":-9.5223681569,\\\"momentum_pvo_hist\\\":-4.3125609339,\\\"momentum_kama\\\":559.7767135125,\\\"others_dr\\\":0.4562125414,\\\"others_dlr\\\":0.4551750462,\\\"others_cr\\\":-0.5754758743},{\\\"DATE\\\":1700438400000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":564.0,\\\"HIGH\\\":566.8,\\\"LOW\\\":560.6,\\\"PREV. CLOSE\\\":563.05,\\\"LTP\\\":563.5,\\\"CLOSE\\\":563.75,\\\"VWAP\\\":564.68,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":12714585,\\\"VALUE\\\":7179613743.4499998093,\\\"NO OF TRADES\\\":264832,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-18473900.5291737802,\\\"volume_obv\\\":21084184,\\\"volume_cmf\\\":-0.1985990845,\\\"volume_fi\\\":18175088.1142912731,\\\"volume_em\\\":-6.0953621373,\\\"volume_sma_em\\\":-30.7525445764,\\\"volume_vpt\\\":48190.2027394317,\\\"volume_vwap\\\":563.4581953752,\\\"volume_mfi\\\":51.0677784087,\\\"volume_nvi\\\":1000.0152058968,\\\"volatility_bbm\\\":562.7875,\\\"volatility_bbh\\\":568.7751435265,\\\"volatility_bbl\\\":556.7998564735,\\\"volatility_bbw\\\":2.1278523515,\\\"volatility_bbp\\\":0.5803738562,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":563.1145833333,\\\"volatility_kch\\\":568.6333333333,\\\"volatility_kcl\\\":557.5958333333,\\\"volatility_kcw\\\":1.9600806526,\\\"volatility_kcp\\\":0.5575688939,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":570.2,\\\"volatility_dcm\\\":562.675,\\\"volatility_dcw\\\":2.674188748,\\\"volatility_dcp\\\":0.5714285714,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":49.9653787458,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":81.6778290504,\\\"momentum_uo\\\":40.5264538263,\\\"momentum_stoch\\\":57.1428571429,\\\"momentum_stoch_signal\\\":41.5282392027,\\\"momentum_wr\\\":-42.8571428571,\\\"momentum_ao\\\":-1.458125,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.1401849133,\\\"momentum_ppo_signal\\\":-0.0817305265,\\\"momentum_ppo_hist\\\":-0.0584543869,\\\"momentum_pvo\\\":-13.6770952854,\\\"momentum_pvo_signal\\\":-10.3533135826,\\\"momentum_pvo_hist\\\":-3.3237817028,\\\"momentum_kama\\\":560.7666650889,\\\"others_dr\\\":0.4007123776,\\\"others_dlr\\\":0.3999116638,\\\"others_cr\\\":-0.1770694998},{\\\"DATE\\\":1700179200000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":574.5,\\\"HIGH\\\":574.5,\\\"LOW\\\":562.1,\\\"PREV. CLOSE\\\":584.65,\\\"LTP\\\":562.9,\\\"CLOSE\\\":563.05,\\\"VWAP\\\":566.16,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":37173221,\\\"VALUE\\\":21045979976.2999992371,\\\"NO OF TRADES\\\":682644,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-49951224.7630451471,\\\"volume_obv\\\":-16089037,\\\"volume_cmf\\\":-0.3836667651,\\\"volume_fi\\\":11861324.8551065642,\\\"volume_em\\\":153.4437922396,\\\"volume_sma_em\\\":-7.7280024744,\\\"volume_vpt\\\":2032.7664644837,\\\"volume_vwap\\\":564.3409708827,\\\"volume_mfi\\\":67.612898454,\\\"volume_nvi\\\":1000.0152058968,\\\"volatility_bbm\\\":562.8166666667,\\\"volatility_bbh\\\":568.4642816992,\\\"volatility_bbl\\\":557.1690516341,\\\"volatility_bbw\\\":2.0069110838,\\\"volatility_bbp\\\":0.5206576875,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":563.4962962963,\\\"volatility_kch\\\":569.7796296296,\\\"volatility_kcl\\\":557.212962963,\\\"volatility_kcw\\\":2.230124093,\\\"volatility_kcp\\\":0.4644857059,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":574.5,\\\"volatility_dcm\\\":564.825,\\\"volatility_dcw\\\":3.438064497,\\\"volatility_dcp\\\":0.4082687339,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":47.4434480021,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":79.5592740778,\\\"momentum_uo\\\":31.2468110787,\\\"momentum_stoch\\\":40.826873385,\\\"momentum_stoch_signal\\\":46.7208071859,\\\"momentum_wr\\\":-59.173126615,\\\"momentum_ao\\\":-0.5261111111,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":-0.1282159479,\\\"momentum_ppo_signal\\\":-0.0910276108,\\\"momentum_ppo_hist\\\":-0.0371883371,\\\"momentum_pvo\\\":-0.946469927,\\\"momentum_pvo_signal\\\":-8.4719448515,\\\"momentum_pvo_hist\\\":7.5254749245,\\\"momentum_kama\\\":561.0129338184,\\\"others_dr\\\":-0.1241685144,\\\"others_dlr\\\":-0.1242456674,\\\"others_cr\\\":-0.3010181496},{\\\"DATE\\\":1700092800000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":584.7,\\\"HIGH\\\":588.0,\\\"LOW\\\":582.9,\\\"PREV. CLOSE\\\":584.7,\\\"LTP\\\":584.1,\\\"CLOSE\\\":584.65,\\\"VWAP\\\":585.4,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":8622660,\\\"VALUE\\\":5047671165.75,\\\"NO OF TRADES\\\":179964,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-52656372.9983392879,\\\"volume_obv\\\":-7466377,\\\"volume_cmf\\\":-0.3793223403,\\\"volume_fi\\\":36773915.0186627954,\\\"volume_em\\\":1014.3621573853,\\\"volume_sma_em\\\":105.8375708433,\\\"volume_vpt\\\":332819.4745721126,\\\"volume_vwap\\\":565.6356009401,\\\"volume_mfi\\\":70.0399670357,\\\"volume_nvi\\\":1038.3782792426,\\\"volatility_bbm\\\":565.0,\\\"volatility_bbh\\\":579.1533035013,\\\"volatility_bbl\\\":550.8466964987,\\\"volatility_bbw\\\":5.0100189385,\\\"volatility_bbp\\\":1.1941842234,\\\"volatility_bbhi\\\":1.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":565.665,\\\"volatility_kch\\\":571.83,\\\"volatility_kcl\\\":559.5,\\\"volatility_kcw\\\":2.1797353557,\\\"volatility_kcp\\\":2.0397404704,\\\"volatility_kchi\\\":1.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.814159292,\\\"volatility_dcp\\\":0.898021309,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":80.3693886674,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":79.2188829621,\\\"momentum_uo\\\":48.1648232058,\\\"momentum_stoch\\\":89.802130898,\\\"momentum_stoch_signal\\\":62.5906204753,\\\"momentum_wr\\\":-10.197869102,\\\"momentum_ao\\\":2.2225,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.1877997946,\\\"momentum_ppo_signal\\\":-0.0352621297,\\\"momentum_ppo_hist\\\":0.2230619243,\\\"momentum_pvo\\\":-5.057790754,\\\"momentum_pvo_signal\\\":-7.789114032,\\\"momentum_pvo_hist\\\":2.731323278,\\\"momentum_kama\\\":563.5037126917,\\\"others_dr\\\":3.836249001,\\\"others_dlr\\\":3.7644943443,\\\"others_cr\\\":3.5236830456},{\\\"DATE\\\":1700006400000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":587.25,\\\"HIGH\\\":588.0,\\\"LOW\\\":582.6,\\\"PREV. CLOSE\\\":581.35,\\\"LTP\\\":584.0,\\\"CLOSE\\\":584.7,\\\"VWAP\\\":584.93,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":11397676,\\\"VALUE\\\":6666856921.25,\\\"NO OF TRADES\\\":221182,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-55189189.8872280419,\\\"volume_obv\\\":3931299,\\\"volume_cmf\\\":-0.3674022216,\\\"volume_fi\\\":31601910.5588539355,\\\"volume_em\\\":-7.1067119297,\\\"volume_sma_em\\\":94.543142566,\\\"volume_vpt\\\":333794.2180938786,\\\"volume_vwap\\\":567.112480453,\\\"volume_mfi\\\":63.7281490673,\\\"volume_nvi\\\":1038.3782792426,\\\"volatility_bbm\\\":566.7909090909,\\\"volatility_bbh\\\":584.4090721456,\\\"volatility_bbl\\\":549.1727460362,\\\"volatility_bbw\\\":6.2168121514,\\\"volatility_bbp\\\":1.0082564752,\\\"volatility_bbhi\\\":1.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":567.555,\\\"volatility_kch\\\":573.605,\\\"volatility_kcl\\\":561.505,\\\"volatility_kcw\\\":2.1319519694,\\\"volatility_kcp\\\":1.9169421488,\\\"volatility_kchi\\\":1.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7957880892,\\\"volatility_dcp\\\":0.899543379,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":80.3999990216,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":78.9668233449,\\\"momentum_uo\\\":48.6897035667,\\\"momentum_stoch\\\":89.9543378995,\\\"momentum_stoch_signal\\\":73.5277807275,\\\"momentum_wr\\\":-10.0456621005,\\\"momentum_ao\\\":5.5627272727,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.4325761692,\\\"momentum_ppo_signal\\\":0.0583055301,\\\"momentum_ppo_hist\\\":0.3742706391,\\\"momentum_pvo\\\":-7.0546470537,\\\"momentum_pvo_signal\\\":-7.6422206363,\\\"momentum_pvo_hist\\\":0.5875735826,\\\"momentum_kama\\\":566.2513086483,\\\"others_dr\\\":0.0085521252,\\\"others_dlr\\\":0.0085517595,\\\"others_cr\\\":3.5325365206},{\\\"DATE\\\":1699833600000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":581.0,\\\"HIGH\\\":582.5,\\\"LOW\\\":575.2,\\\"PREV. CLOSE\\\":581.3,\\\"LTP\\\":581.3,\\\"CLOSE\\\":581.35,\\\"VWAP\\\":578.71,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":11282362,\\\"VALUE\\\":6529178380.0500001907,\\\"NO OF TRADES\\\":177978,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-47461544.6817485392,\\\"volume_obv\\\":-7351063,\\\"volume_cmf\\\":-0.2938850019,\\\"volume_fi\\\":21687935.8075890541,\\\"volume_em\\\":-417.3328244564,\\\"volume_sma_em\\\":48.0089637458,\\\"volume_vpt\\\":269152.6708046697,\\\"volume_vwap\\\":567.9906943965,\\\"volume_mfi\\\":58.5532270827,\\\"volume_nvi\\\":1032.4289595308,\\\"volatility_bbm\\\":568.0041666667,\\\"volatility_bbh\\\":586.6937563863,\\\"volatility_bbl\\\":549.314576947,\\\"volatility_bbw\\\":6.580793176,\\\"volatility_bbp\\\":0.857039227,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":568.7666666667,\\\"volatility_kch\\\":575.1566666667,\\\"volatility_kcl\\\":562.3766666667,\\\"volatility_kcw\\\":2.2469671218,\\\"volatility_kcp\\\":1.4846113719,\\\"volatility_kchi\\\":1.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.783408279,\\\"volatility_dcp\\\":0.797564688,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":72.2689637581,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":77.043634751,\\\"momentum_uo\\\":51.1690911699,\\\"momentum_stoch\\\":79.7564687976,\\\"momentum_stoch_signal\\\":86.5043125317,\\\"momentum_wr\\\":-20.2435312024,\\\"momentum_ao\\\":7.6429166667,\\\"momentum_roc\\\":0.0,\\\"momentum_ppo\\\":0.5715419647,\\\"momentum_ppo_signal\\\":0.160952817,\\\"momentum_ppo_hist\\\":0.4105891477,\\\"momentum_pvo\\\":-8.7003894938,\\\"momentum_pvo_signal\\\":-7.8538544078,\\\"momentum_pvo_hist\\\":-0.846535086,\\\"momentum_kama\\\":567.238765432,\\\"others_dr\\\":-0.5729433898,\\\"others_dlr\\\":-0.5745910067,\\\"others_cr\\\":2.9393536963},{\\\"DATE\\\":1699747200000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":584.75,\\\"HIGH\\\":584.75,\\\"LOW\\\":580.1,\\\"PREV. CLOSE\\\":579.5,\\\"LTP\\\":580.85,\\\"CLOSE\\\":581.3,\\\"VWAP\\\":581.85,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":1947722,\\\"VALUE\\\":1133273076.5499999523,\\\"NO OF TRADES\\\":53935,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-48403990.810780853,\\\"volume_obv\\\":-9298785,\\\"volume_cmf\\\":-0.2961490081,\\\"volume_fi\\\":18575746.9636477418,\\\"volume_em\\\":853.497059642,\\\"volume_sma_em\\\":115.1329717372,\\\"volume_vpt\\\":268985.153646331,\\\"volume_vwap\\\":568.1582349529,\\\"volume_mfi\\\":59.1285203372,\\\"volume_nvi\\\":1032.3401637142,\\\"volatility_bbm\\\":569.0269230769,\\\"volatility_bbh\\\":588.3308332183,\\\"volatility_bbl\\\":549.7230129356,\\\"volatility_bbw\\\":6.7848846367,\\\"volatility_bbp\\\":0.8178909566,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":570.6133333333,\\\"volatility_kch\\\":577.0583333333,\\\"volatility_kcl\\\":564.1683333333,\\\"volatility_kcw\\\":2.2589728012,\\\"volatility_kcp\\\":1.3290664598,\\\"volatility_kchi\\\":1.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7730133088,\\\"volatility_dcp\\\":0.796042618,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.0,\\\"momentum_rsi\\\":72.151677774,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":75.5137296838,\\\"momentum_uo\\\":50.6849990528,\\\"momentum_stoch\\\":79.604261796,\\\"momentum_stoch_signal\\\":83.1050228311,\\\"momentum_wr\\\":-20.395738204,\\\"momentum_ao\\\":10.3303846154,\\\"momentum_roc\\\":2.9305002213,\\\"momentum_ppo\\\":0.6726631973,\\\"momentum_ppo_signal\\\":0.2632948931,\\\"momentum_ppo_hist\\\":0.4093683042,\\\"momentum_pvo\\\":-15.3770241619,\\\"momentum_pvo_signal\\\":-9.3584883586,\\\"momentum_pvo_hist\\\":-6.0185358033,\\\"momentum_kama\\\":568.9217809285,\\\"others_dr\\\":-0.0086006709,\\\"others_dlr\\\":-0.0086010407,\\\"others_cr\\\":2.9305002213},{\\\"DATE\\\":1699574400000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":577.8,\\\"HIGH\\\":581.0,\\\"LOW\\\":575.4,\\\"PREV. CLOSE\\\":578.35,\\\"LTP\\\":580.25,\\\"CLOSE\\\":579.5,\\\"VWAP\\\":578.7,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":6773038,\\\"VALUE\\\":3919567928.9000000954,\\\"NO OF TRADES\\\":119792,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-45259366.0250665545,\\\"volume_obv\\\":-16071823,\\\"volume_cmf\\\":-0.265890982,\\\"volume_fi\\\":14180430.4831266813,\\\"volume_em\\\":-349.326255072,\\\"volume_sma_em\\\":79.4053389057,\\\"volume_vpt\\\":248012.3884648422,\\\"volume_vwap\\\":568.5750436424,\\\"volume_mfi\\\":56.4211944646,\\\"volume_nvi\\\":1032.3401637142,\\\"volatility_bbm\\\":569.775,\\\"volatility_bbh\\\":589.1431162887,\\\"volatility_bbl\\\":550.4068837113,\\\"volatility_bbw\\\":6.7985139006,\\\"volatility_bbp\\\":0.7510569395,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":572.4083333333,\\\"volatility_kch\\\":579.0933333333,\\\"volatility_kcl\\\":565.7233333333,\\\"volatility_kcw\\\":2.3357451703,\\\"volatility_kcp\\\":1.030416355,\\\"volatility_kchi\\\":1.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7654337238,\\\"volatility_dcp\\\":0.7412480974,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.9460200317,\\\"momentum_rsi\\\":67.8806956185,\\\"momentum_stoch_rsi\\\":0.5670891672,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":73.3754818331,\\\"momentum_uo\\\":53.2521414363,\\\"momentum_stoch\\\":74.1248097412,\\\"momentum_stoch_signal\\\":77.828513445,\\\"momentum_wr\\\":-25.8751902588,\\\"momentum_ao\\\":11.7057142857,\\\"momentum_roc\\\":1.916989096,\\\"momentum_ppo\\\":0.7187621424,\\\"momentum_ppo_signal\\\":0.3543883429,\\\"momentum_ppo_hist\\\":0.3643737994,\\\"momentum_pvo\\\":-18.144794805,\\\"momentum_pvo_signal\\\":-11.1157496479,\\\"momentum_pvo_hist\\\":-7.0290451571,\\\"momentum_kama\\\":570.6670056156,\\\"others_dr\\\":-0.3096507827,\\\"others_dlr\\\":-0.3101311927,\\\"others_cr\\\":2.6117751217},{\\\"DATE\\\":1699488000000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":581.0,\\\"HIGH\\\":581.85,\\\"LOW\\\":576.5,\\\"PREV. CLOSE\\\":580.3,\\\"LTP\\\":577.6,\\\"CLOSE\\\":578.35,\\\"VWAP\\\":578.27,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":12434363,\\\"VALUE\\\":7190409015.1499996185,\\\"NO OF TRADES\\\":167584,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-49094263.0250664875,\\\"volume_obv\\\":-28506186,\\\"volume_cmf\\\":-0.2687856213,\\\"volume_fi\\\":10111866.4926800542,\\\"volume_em\\\":41.9502792383,\\\"volume_sma_em\\\":76.7299775009,\\\"volume_vpt\\\":223336.7759540577,\\\"volume_vwap\\\":569.6512876108,\\\"volume_mfi\\\":59.8017695665,\\\"volume_nvi\\\":1032.3401637142,\\\"volatility_bbm\\\":570.3466666667,\\\"volatility_bbh\\\":589.5408486555,\\\"volatility_bbl\\\":551.1524846778,\\\"volatility_bbw\\\":6.7307071683,\\\"volatility_bbp\\\":0.7084833138,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":574.24,\\\"volatility_kch\\\":580.94,\\\"volatility_kcl\\\":567.54,\\\"volatility_kcw\\\":2.3335190861,\\\"volatility_kcp\\\":0.8067164179,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7596549467,\\\"volatility_dcp\\\":0.7062404871,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":0.9895456857,\\\"momentum_rsi\\\":65.2242529068,\\\"momentum_stoch_rsi\\\":0.5312850659,\\\"momentum_stoch_rsi_k\\\":0.0,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":71.062921517,\\\"momentum_uo\\\":53.0911841748,\\\"momentum_stoch\\\":70.6240487062,\\\"momentum_stoch_signal\\\":74.7843734145,\\\"momentum_wr\\\":-29.3759512938,\\\"momentum_ao\\\":9.8616666667,\\\"momentum_roc\\\":2.4625741873,\\\"momentum_ppo\\\":0.730482376,\\\"momentum_ppo_signal\\\":0.4296071495,\\\"momentum_ppo_hist\\\":0.3008752265,\\\"momentum_pvo\\\":-16.6437761011,\\\"momentum_pvo_signal\\\":-12.2213549386,\\\"momentum_pvo_hist\\\":-4.4224211625,\\\"momentum_kama\\\":571.8097435694,\\\"others_dr\\\":-0.198446937,\\\"others_dlr\\\":-0.1986441038,\\\"others_cr\\\":2.408145197},{\\\"DATE\\\":1699401600000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":581.9,\\\"HIGH\\\":582.6,\\\"LOW\\\":579.0,\\\"PREV. CLOSE\\\":579.75,\\\"LTP\\\":580.4,\\\"CLOSE\\\":580.3,\\\"VWAP\\\":580.52,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":15434808,\\\"VALUE\\\":8960148835.6499996185,\\\"NO OF TRADES\\\":391419,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-53381709.6917336136,\\\"volume_obv\\\":-13071378,\\\"volume_cmf\\\":-0.2694862845,\\\"volume_fi\\\":12967010.650868468,\\\"volume_em\\\":37.9013461003,\\\"volume_sma_em\\\":79.0991126764,\\\"volume_vpt\\\":275377.7124112202,\\\"volume_vwap\\\":570.7878501662,\\\"volume_mfi\\\":61.1080184002,\\\"volume_nvi\\\":1032.3401637142,\\\"volatility_bbm\\\":570.96875,\\\"volatility_bbh\\\":590.1679646649,\\\"volatility_bbl\\\":551.7695353351,\\\"volatility_bbw\\\":6.7251367662,\\\"volatility_bbp\\\":0.7430112419,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":576.35,\\\"volatility_kch\\\":582.475,\\\"volatility_kcl\\\":570.225,\\\"volatility_kcw\\\":2.1254446083,\\\"volatility_kcp\\\":0.8224489796,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7533796727,\\\"volatility_dcp\\\":0.7656012177,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":1.0097771909,\\\"momentum_rsi\\\":67.5436509677,\\\"momentum_stoch_rsi\\\":0.7645090512,\\\"momentum_stoch_rsi_k\\\":0.6209610948,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":69.348726488,\\\"momentum_uo\\\":57.8784495,\\\"momentum_stoch\\\":76.5601217656,\\\"momentum_stoch_signal\\\":73.769660071,\\\"momentum_wr\\\":-23.4398782344,\\\"momentum_ao\\\":8.3446875,\\\"momentum_roc\\\":3.5602748282,\\\"momentum_ppo\\\":0.7582699258,\\\"momentum_ppo_signal\\\":0.4953397048,\\\"momentum_ppo_hist\\\":0.262930221,\\\"momentum_pvo\\\":-13.3785657445,\\\"momentum_pvo_signal\\\":-12.4527970998,\\\"momentum_pvo_hist\\\":-0.9257686448,\\\"momentum_kama\\\":573.3589624809,\\\"others_dr\\\":0.3371660759,\\\"others_dlr\\\":0.3365989455,\\\"others_cr\\\":2.7534307216},{\\\"DATE\\\":1699315200000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":574.8,\\\"HIGH\\\":581.2,\\\"LOW\\\":572.6,\\\"PREV. CLOSE\\\":574.35,\\\"LTP\\\":580.35,\\\"CLOSE\\\":579.75,\\\"VWAP\\\":577.36,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":17923281,\\\"VALUE\\\":10348172706.1000003815,\\\"NO OF TRADES\\\":466280,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-41502325.7731291354,\\\"volume_obv\\\":-30994659,\\\"volume_cmf\\\":-0.192131318,\\\"volume_fi\\\":9706322.7650302332,\\\"volume_em\\\":-187.1309164879,\\\"volume_sma_em\\\":79.7409452821,\\\"volume_vpt\\\":258390.2842706056,\\\"volume_vwap\\\":571.8301379674,\\\"volume_mfi\\\":57.6448978949,\\\"volume_nvi\\\":1032.3401637142,\\\"volatility_bbm\\\":571.4852941176,\\\"volatility_bbh\\\":590.564163387,\\\"volatility_bbl\\\":552.4064248483,\\\"volatility_bbw\\\":6.6769414596,\\\"volatility_bbp\\\":0.7165931787,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":577.83,\\\"volatility_kch\\\":584.25,\\\"volatility_kcl\\\":571.41,\\\"volatility_kcw\\\":2.222106848,\\\"volatility_kcp\\\":0.6495327103,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7481794087,\\\"volatility_dcp\\\":0.7488584475,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":1.0162645587,\\\"momentum_rsi\\\":66.2024748618,\\\"momentum_stoch_rsi\\\":0.739942601,\\\"momentum_stoch_rsi_k\\\":0.678578906,\\\"momentum_stoch_rsi_d\\\":0.0,\\\"momentum_tsi\\\":67.6552341868,\\\"momentum_uo\\\":53.9967493194,\\\"momentum_stoch\\\":74.8858447489,\\\"momentum_stoch_signal\\\":74.0233384069,\\\"momentum_wr\\\":-25.1141552511,\\\"momentum_ao\\\":7.6397058824,\\\"momentum_roc\\\":3.5360300027,\\\"momentum_ppo\\\":0.7635932745,\\\"momentum_ppo_signal\\\":0.5489904187,\\\"momentum_ppo_hist\\\":0.2146028557,\\\"momentum_pvo\\\":-9.1971392354,\\\"momentum_pvo_signal\\\":-11.8016655269,\\\"momentum_pvo_hist\\\":2.6045262915,\\\"momentum_kama\\\":574.346271377,\\\"others_dr\\\":-0.0947785628,\\\"others_dlr\\\":-0.0948235061,\\\"others_cr\\\":2.6560424967},{\\\"DATE\\\":1699228800000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":582.0,\\\"HIGH\\\":582.5,\\\"LOW\\\":573.25,\\\"PREV. CLOSE\\\":578.15,\\\"LTP\\\":573.95,\\\"CLOSE\\\":574.35,\\\"VWAP\\\":575.7,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":16499138,\\\"VALUE\\\":9498482029.9500007629,\\\"NO OF TRADES\\\":330138,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-54077344.4650209472,\\\"volume_obv\\\":-47493797,\\\"volume_cmf\\\":-0.2325813806,\\\"volume_fi\\\":-4408201.2299740314,\\\"volume_em\\\":54.6619465817,\\\"volume_sma_em\\\":91.6963085006,\\\"volume_vpt\\\":104711.3792253287,\\\"volume_vwap\\\":572.6456942837,\\\"volume_mfi\\\":54.5065842755,\\\"volume_nvi\\\":1022.7245761609,\\\"volatility_bbm\\\":571.6444444444,\\\"volatility_bbh\\\":590.2321610841,\\\"volatility_bbl\\\":553.0567278048,\\\"volatility_bbw\\\":6.5032440428,\\\"volatility_bbp\\\":0.5727780504,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":579.1283333333,\\\"volatility_kch\\\":585.8533333333,\\\"volatility_kcl\\\":572.4033333333,\\\"volatility_kcw\\\":2.3224558748,\\\"volatility_kcp\\\":0.1447335812,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7465790701,\\\"volatility_dcp\\\":0.5844748858,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":1.0517773248,\\\"momentum_rsi\\\":54.7150249499,\\\"momentum_stoch_rsi\\\":0.5295258895,\\\"momentum_stoch_rsi_k\\\":0.6779925139,\\\"momentum_stoch_rsi_d\\\":0.6591775049,\\\"momentum_tsi\\\":63.4651233938,\\\"momentum_uo\\\":49.3355955375,\\\"momentum_stoch\\\":58.4474885845,\\\"momentum_stoch_signal\\\":69.964485033,\\\"momentum_wr\\\":-41.5525114155,\\\"momentum_ao\\\":6.3955555556,\\\"momentum_roc\\\":2.7551659361,\\\"momentum_ppo\\\":0.6841350555,\\\"momentum_ppo_signal\\\":0.5760193461,\\\"momentum_ppo_hist\\\":0.1081157094,\\\"momentum_pvo\\\":-6.7158829717,\\\"momentum_pvo_signal\\\":-10.7845090158,\\\"momentum_pvo_hist\\\":4.0686260442,\\\"momentum_kama\\\":574.3464841983,\\\"others_dr\\\":-0.9314359638,\\\"others_dlr\\\":-0.9358009544,\\\"others_cr\\\":1.6998671979},{\\\"DATE\\\":1698969600000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":576.0,\\\"HIGH\\\":579.5,\\\"LOW\\\":573.45,\\\"PREV. CLOSE\\\":572.1,\\\"LTP\\\":579.15,\\\"CLOSE\\\":578.15,\\\"VWAP\\\":577.35,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":11371371,\\\"VALUE\\\":6565279355.4499998093,\\\"NO OF TRADES\\\":205720,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-47780800.1922938004,\\\"volume_obv\\\":-36122426,\\\"volume_cmf\\\":-0.1959187302,\\\"volume_fi\\\":2394571.7743078982,\\\"volume_em\\\":-74.4853017283,\\\"volume_sma_em\\\":86.0846685616,\\\"volume_vpt\\\":179946.3575486501,\\\"volume_vwap\\\":573.3035249602,\\\"volume_mfi\\\":58.970724108,\\\"volume_nvi\\\":1029.4911007355,\\\"volatility_bbm\\\":571.9868421053,\\\"volatility_bbh\\\":590.3105926437,\\\"volatility_bbl\\\":553.6630915668,\\\"volatility_bbw\\\":6.4070531661,\\\"volatility_bbp\\\":0.6681740286,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":580.1766666667,\\\"volatility_kch\\\":586.2666666667,\\\"volatility_kcl\\\":574.0866666667,\\\"volatility_kcw\\\":2.0993605396,\\\"volatility_kcp\\\":0.333607006,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":0.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7431391042,\\\"volatility_dcp\\\":0.700152207,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":1.0151679938,\\\"momentum_rsi\\\":59.9779079189,\\\"momentum_stoch_rsi\\\":0.6259266169,\\\"momentum_stoch_rsi_k\\\":0.6317983691,\\\"momentum_stoch_rsi_d\\\":0.6627899297,\\\"momentum_tsi\\\":60.5124395692,\\\"momentum_uo\\\":50.4719724405,\\\"momentum_stoch\\\":70.0152207002,\\\"momentum_stoch_signal\\\":67.7828513445,\\\"momentum_wr\\\":-29.9847792998,\\\"momentum_ao\\\":5.8252631579,\\\"momentum_roc\\\":2.9652715939,\\\"momentum_ppo\\\":0.6667629503,\\\"momentum_ppo_signal\\\":0.5941680669,\\\"momentum_ppo_hist\\\":0.0725948834,\\\"momentum_pvo\\\":-7.6584702872,\\\"momentum_pvo_signal\\\":-10.1593012701,\\\"momentum_pvo_hist\\\":2.5008309829,\\\"momentum_kama\\\":574.6742296003,\\\"others_dr\\\":0.6616174806,\\\"others_dlr\\\":0.6594383984,\\\"others_cr\\\":2.372731297},{\\\"DATE\\\":1698883200000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":571.1,\\\"HIGH\\\":575.45,\\\"LOW\\\":567.6,\\\"PREV. CLOSE\\\":566.4,\\\"LTP\\\":572.0,\\\"CLOSE\\\":572.1,\\\"VWAP\\\":571.18,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":11148516,\\\"VALUE\\\":6367849377.0,\\\"NO OF TRADES\\\":212716,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-46147578.1031218618,\\\"volume_obv\\\":-47270942,\\\"volume_cmf\\\":-0.1809501512,\\\"volume_fi\\\":-7583013.0220217276,\\\"volume_em\\\":-348.5441470416,\\\"volume_sma_em\\\":66.0041588271,\\\"volume_vpt\\\":63283.6890370189,\\\"volume_vwap\\\":574.2961541448,\\\"volume_mfi\\\":60.0400997438,\\\"volume_nvi\\\":1018.718081347,\\\"volatility_bbm\\\":571.9925,\\\"volatility_bbh\\\":589.8523509232,\\\"volatility_bbl\\\":554.1326490768,\\\"volatility_bbw\\\":6.2447850009,\\\"volatility_bbp\\\":0.5030095436,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":578.83,\\\"volatility_kch\\\":585.195,\\\"volatility_kcl\\\":572.465,\\\"volatility_kcw\\\":2.1992640326,\\\"volatility_kcp\\\":-0.0286724273,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":1.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7430822957,\\\"volatility_dcp\\\":0.5159817352,\\\"volatility_atr\\\":0.0,\\\"volatility_ui\\\":1.0754207991,\\\"momentum_rsi\\\":50.0123177487,\\\"momentum_stoch_rsi\\\":0.2378285833,\\\"momentum_stoch_rsi_k\\\":0.4644270299,\\\"momentum_stoch_rsi_d\\\":0.591405971,\\\"momentum_tsi\\\":55.1249625855,\\\"momentum_uo\\\":50.8280521754,\\\"momentum_stoch\\\":41.9708029197,\\\"momentum_stoch_signal\\\":56.8111707348,\\\"momentum_wr\\\":-58.0291970803,\\\"momentum_ao\\\":4.34,\\\"momentum_roc\\\":1.4811529933,\\\"momentum_ppo\\\":0.5616739206,\\\"momentum_ppo_signal\\\":0.5876692377,\\\"momentum_ppo_hist\\\":-0.0259953171,\\\"momentum_pvo\\\":-8.4868543726,\\\"momentum_pvo_signal\\\":-9.8248118906,\\\"momentum_pvo_hist\\\":1.337957518,\\\"momentum_kama\\\":574.3075122324,\\\"others_dr\\\":-1.046441235,\\\"others_dlr\\\":-1.05195493,\\\"others_cr\\\":1.3014608234},{\\\"DATE\\\":1698796800000,\\\"SERIES\\\":\\\"EQ\\\",\\\"OPEN\\\":566.25,\\\"HIGH\\\":569.65,\\\"LOW\\\":563.85,\\\"PREV. CLOSE\\\":565.55,\\\"LTP\\\":567.3,\\\"CLOSE\\\":566.4,\\\"VWAP\\\":567.16,\\\"52W H\\\":629.55,\\\"52W L\\\":499.35,\\\"VOLUME\\\":13575575,\\\"VALUE\\\":7699515897.6499996185,\\\"NO OF TRADES\\\":240220,\\\"SYMBOL\\\":\\\"SBIN\\\",\\\"volume_adi\\\":-47786009.5686392188,\\\"volume_obv\\\":-60846517,\\\"volume_cmf\\\":-0.1392975904,\\\"volume_fi\\\":-17554122.2331615686,\\\"volume_em\\\":-204.006091823,\\\"volume_sma_em\\\":40.1277836079,\\\"volume_vpt\\\":-71973.7441040413,\\\"volume_vwap\\\":574.5965712167,\\\"volume_mfi\\\":52.8018836042,\\\"volume_nvi\\\":1018.718081347,\\\"volatility_bbm\\\":572.075,\\\"volatility_bbh\\\":589.8151099207,\\\"volatility_bbl\\\":554.3348900793,\\\"volatility_bbw\\\":6.2020224344,\\\"volatility_bbp\\\":0.3400517239,\\\"volatility_bbhi\\\":0.0,\\\"volatility_bbli\\\":0.0,\\\"volatility_kcc\\\":576.9833333333,\\\"volatility_kch\\\":583.3883333333,\\\"volatility_kcl\\\":570.5783333333,\\\"volatility_kcw\\\":2.2201681158,\\\"volatility_kcp\\\":-0.3261774655,\\\"volatility_kchi\\\":0.0,\\\"volatility_kcli\\\":1.0,\\\"volatility_dcl\\\":555.15,\\\"volatility_dch\\\":588.0,\\\"volatility_dcm\\\":571.575,\\\"volatility_dcw\\\":5.7422540751,\\\"volatility_dcp\\\":0.3424657534,\\\"volatility_atr\\\":7.9547619048,\\\"volatility_ui\\\":1.3209284072,\\\"momentum_rsi\\\":42.7973733337,\\\"momentum_stoch_rsi\\\":0.0,\\\"momentum_stoch_rsi_k\\\":0.2879184001,\\\"momentum_stoch_rsi_d\\\":0.4613812664,\\\"momentum_tsi\\\":48.1564982797,\\\"momentum_uo\\\":47.6406640002,\\\"momentum_stoch\\\":21.1678832117,\\\"momentum_stoch_signal\\\":44.3846356105,\\\"momentum_wr\\\":-78.8321167883,\\\"momentum_ao\\\":1.7978571429,\\\"momentum_roc\\\":0.5949738034,\\\"momentum_ppo\\\":0.3937692131,\\\"momentum_ppo_signal\\\":0.5488892328,\\\"momentum_ppo_hist\\\":-0.1551200196,\\\"momentum_pvo\\\":-7.6066398516,\\\"momentum_pvo_signal\\\":-9.3811774828,\\\"momentum_pvo_hist\\\":1.7745376312,\\\"momentum_kama\\\":572.8160721681,\\\"others_dr\\\":-0.9963293131,\\\"others_dlr\\\":-1.0013258895,\\\"others_cr\\\":0.2921646746}]\"\r\n========================\r\n\r\nSTARTING TURN 2\r\n---------------\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/Agent.py\", line 28, in <module>\r\n    response = agent.chat(\"What was the stock price movement of SBIN stock during November 2023?\")\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/callbacks/utils.py\", line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 438, in chat\r\n    chat_response = self._chat(\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 360, in _chat\r\n    agent_chat_response = self._get_agent_response(mode=mode, **llm_chat_kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/agent/openai_agent.py\", line 322, in _get_agent_response\r\n    chat_response: ChatResponse = self._llm.chat(**llm_chat_kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/llms/base.py\", line 187, in wrapped_llm_chat\r\n    f_return_val = f(_self, messages, **kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 200, in chat\r\n    return chat_fn(messages, **kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/llama_index/llms/openai.py\", line 254, in _chat\r\n    response = self._client.chat.completions.create(\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 301, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\r\n    return self._post(\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/openai/_base_client.py\", line 1096, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/openai/_base_client.py\", line 856, in request\r\n    return self._request(\r\n  File \"/Users/saurabhc/Documents/kernelPI/pifin/env/lib/python3.10/site-packages/openai/_base_client.py\", line 908, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"[] is too short - 'messages'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\r\n```\r\n\r\n![Screenshot 2023-12-07 at 5 57 23\u202fPM](https://github.com/run-llama/llama_index/assets/19235748/00fd37d7-295f-43ea-9400-7ca268a67457)\r\n![Screenshot 2023-12-07 at 5 57 28\u202fPM](https://github.com/run-llama/llama_index/assets/19235748/e11d48ac-108f-4e58-8667-597609fb4827)\r\n\r\n![Screenshot 2023-12-07 at 5 55 48\u202fPM](https://github.com/run-llama/llama_index/assets/19235748/04c22d62-d74d-450e-a624-b541c8f0e8f0)\r\n![Screenshot 2023-12-07 at 5 57 05\u202fPM](https://github.com/run-llama/llama_index/assets/19235748/7c00a3c1-1554-43b7-b8c6-706b096b7607)\r\n\r\n![Screenshot 2023-12-07 at 5 57 13\u202fPM](https://github.com/run-llama/llama_index/assets/19235748/8b90ac12-f29e-4fbd-a740-ebb9c87d7ff7)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9373/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9373/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9372",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9372/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9372/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9372/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9372",
        "id": 2030602399,
        "node_id": "PR_kwDOIWuq585hahCB",
        "number": 9372,
        "title": "Proposal : Update the evaluation correctness function to be more robust.",
        "user": {
            "login": "hexapode",
            "id": 208554,
            "node_id": "MDQ6VXNlcjIwODU1NA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/208554?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hexapode",
            "html_url": "https://github.com/hexapode",
            "followers_url": "https://api.github.com/users/hexapode/followers",
            "following_url": "https://api.github.com/users/hexapode/following{/other_user}",
            "gists_url": "https://api.github.com/users/hexapode/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hexapode/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hexapode/subscriptions",
            "organizations_url": "https://api.github.com/users/hexapode/orgs",
            "repos_url": "https://api.github.com/users/hexapode/repos",
            "events_url": "https://api.github.com/users/hexapode/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hexapode/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-07T11:54:09Z",
        "updated_at": "2023-12-09T13:57:39Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9372",
            "html_url": "https://github.com/run-llama/llama_index/pull/9372",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9372.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9372.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nProposal : Update the evaluation correctness function to be more robust.\r\n\r\nWhen using RagEvaluatorPack on a large dataset, sometime GPT3/4 will return a malformated answer, raising an error in correctness.py and interumpting the benchmark (that could be costly).\r\n\r\nSuch case emerge when the LLM :\r\n - prefix the answer with ```\\n```\r\n - do not answer correctly such as: ```I'm not sure how to evaluate this case so I will say 3.0```\r\n - Something in the content made the LLM go off-road\r\n \r\nTo make the parsing more robust, I change the prompt to output the score in the form ```[SCORE:4.2]``` instead of only a number.\r\n\r\nI then use a regexp to retrieve the score instead of assuming first line.\r\n\r\nI use a regexp to remove the ```[SCORE:2.3]``` pattern from the llm answer to get a reasoning, without relying on line marker.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9372/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9372/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9371",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9371/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9371/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9371/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9371",
        "id": 2030568912,
        "node_id": "I_kwDOIWuq5855CAXQ",
        "number": 9371,
        "title": "[Bug]: ContextChatEngine",
        "user": {
            "login": "ingracano",
            "id": 33283926,
            "node_id": "MDQ6VXNlcjMzMjgzOTI2",
            "avatar_url": "https://avatars.githubusercontent.com/u/33283926?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ingracano",
            "html_url": "https://github.com/ingracano",
            "followers_url": "https://api.github.com/users/ingracano/followers",
            "following_url": "https://api.github.com/users/ingracano/following{/other_user}",
            "gists_url": "https://api.github.com/users/ingracano/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ingracano/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ingracano/subscriptions",
            "organizations_url": "https://api.github.com/users/ingracano/orgs",
            "repos_url": "https://api.github.com/users/ingracano/repos",
            "events_url": "https://api.github.com/users/ingracano/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ingracano/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T11:33:33Z",
        "updated_at": "2023-12-07T13:02:50Z",
        "closed_at": "2023-12-07T13:02:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe functionality is compromised when using a version higher than 0.8.55. An error consistently arises in the chat/stream method whit this error:\r\n```\r\n    File\"/usr/local/lib/python3.11/site-packages/llama_index/callbacks/utils.py\", line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/llama_index/chat_engine/context.py\", line 197, in stream_chat\r\n    all_messages = prefix_messages + self._memory.get(\r\n                                     ^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 88, in get\r\n    raise ValueError(\"Initial token count exceeds token limit\")\r\nValueError: Initial token count exceeds token limit\r\n```\n\n### Version\n\n0.9.13\n\n### Steps to Reproduce\n\nWe create a chat engine with chat_mode='context' a system_prompt and mak_token sets to 1300. As model we use gpt4-32k with Azure OpenAI (AzureChatOpenAI class of langchain)\n\n### Relevant Logs/Tracbacks\n\n```shell\nFile\"/usr/local/lib/python3.11/site-packages/llama_index/callbacks/utils.py\", line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/llama_index/chat_engine/context.py\", line 197, in stream_chat\r\n    all_messages = prefix_messages + self._memory.get(\r\n                                     ^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 88, in get\r\n    raise ValueError(\"Initial token count exceeds token limit\")\r\nValueError: Initial token count exceeds token limit\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9371/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9371/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9370",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9370/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9370/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9370/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9370",
        "id": 2030261198,
        "node_id": "I_kwDOIWuq5855A1PO",
        "number": 9370,
        "title": "[Question]: Configure context text for as_query_engine",
        "user": {
            "login": "debraj135",
            "id": 16231057,
            "node_id": "MDQ6VXNlcjE2MjMxMDU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/16231057?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/debraj135",
            "html_url": "https://github.com/debraj135",
            "followers_url": "https://api.github.com/users/debraj135/followers",
            "following_url": "https://api.github.com/users/debraj135/following{/other_user}",
            "gists_url": "https://api.github.com/users/debraj135/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/debraj135/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/debraj135/subscriptions",
            "organizations_url": "https://api.github.com/users/debraj135/orgs",
            "repos_url": "https://api.github.com/users/debraj135/repos",
            "events_url": "https://api.github.com/users/debraj135/events{/privacy}",
            "received_events_url": "https://api.github.com/users/debraj135/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T09:16:46Z",
        "updated_at": "2023-12-07T15:51:38Z",
        "closed_at": "2023-12-07T15:51:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIt seems that the context text includes the `page_label` and the `file_name` when I use a `VectorStoreIndex` as `as_query_engine`. What would be the appropriate way to remove this and only include the contents of the text?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9370/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9370/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9369",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9369/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9369/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9369/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9369",
        "id": 2030120199,
        "node_id": "PR_kwDOIWuq585hY05q",
        "number": 9369,
        "title": "Modify typing of vector_store to satisfy mypy",
        "user": {
            "login": "mroedder-d7",
            "id": 129860311,
            "node_id": "U_kgDOB72C1w",
            "avatar_url": "https://avatars.githubusercontent.com/u/129860311?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mroedder-d7",
            "html_url": "https://github.com/mroedder-d7",
            "followers_url": "https://api.github.com/users/mroedder-d7/followers",
            "following_url": "https://api.github.com/users/mroedder-d7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mroedder-d7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mroedder-d7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mroedder-d7/subscriptions",
            "organizations_url": "https://api.github.com/users/mroedder-d7/orgs",
            "repos_url": "https://api.github.com/users/mroedder-d7/repos",
            "events_url": "https://api.github.com/users/mroedder-d7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mroedder-d7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-07T07:59:32Z",
        "updated_at": "2023-12-07T21:15:15Z",
        "closed_at": "2023-12-07T21:15:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9369",
            "html_url": "https://github.com/run-llama/llama_index/pull/9369",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9369.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9369.patch",
            "merged_at": "2023-12-07T21:15:15Z"
        },
        "body": "# Description\r\n\r\nLike mentioned in #9340\r\n\r\nFixes #9340 \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9369/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9369/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9368",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9368/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9368/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9368/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9368",
        "id": 2030078174,
        "node_id": "I_kwDOIWuq5855AIje",
        "number": 9368,
        "title": "[Question]: nebula close connection happened an exception !",
        "user": {
            "login": "gdonlyathw",
            "id": 62211305,
            "node_id": "MDQ6VXNlcjYyMjExMzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/62211305?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gdonlyathw",
            "html_url": "https://github.com/gdonlyathw",
            "followers_url": "https://api.github.com/users/gdonlyathw/followers",
            "following_url": "https://api.github.com/users/gdonlyathw/following{/other_user}",
            "gists_url": "https://api.github.com/users/gdonlyathw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gdonlyathw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gdonlyathw/subscriptions",
            "organizations_url": "https://api.github.com/users/gdonlyathw/orgs",
            "repos_url": "https://api.github.com/users/gdonlyathw/repos",
            "events_url": "https://api.github.com/users/gdonlyathw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gdonlyathw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-07T07:30:44Z",
        "updated_at": "2023-12-07T09:38:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI runned the sample code\uff1a\r\nhttps://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html\r\n\r\nI get the response from nebula successfully.\r\n\r\nbut when the code run finished, happed an exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"xxx\\lib\\site-packages\\llama_index\\graph_stores\\nebulagraph.py\", line 248, in __del__\r\n  File \"xxx\\lib\\site-packages\\nebula3\\gclient\\net\\SessionPool.py\", line 273, in close\r\n  File \"xxx\\lib\\site-packages\\nebula3\\gclient\\net\\Session.py\", line 288, in _sign_out\r\n  File \"xxx\\lib\\site-packages\\nebula3\\gclient\\net\\Connection.py\", line 205, in signout\r\n  File \"xxx\\lib\\site-packages\\nebula3\\graph\\GraphService.py\", line 1603, in signout\r\n  File \"xxx\\lib\\site-packages\\nebula3\\graph\\GraphService.py\", line 1606, in send_signout\r\nAttributeError: 'NoneType' object has no attribute 'CALL'\r\n\r\n\r\nfrom the exception, I guess it caused by release nebula connection.,but I don't know how to resolve it !\r\n\r\nI used  nebula3-python-3.4.0 and server nebula3.6.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9368/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9368/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9367",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9367/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9367/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9367/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9367",
        "id": 2029972126,
        "node_id": "PR_kwDOIWuq585hYUvu",
        "number": 9367,
        "title": "OpenAIAssistantAgent.from_existing, bugfixes: _achat, etc",
        "user": {
            "login": "ton77v",
            "id": 50094687,
            "node_id": "MDQ6VXNlcjUwMDk0Njg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/50094687?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ton77v",
            "html_url": "https://github.com/ton77v",
            "followers_url": "https://api.github.com/users/ton77v/followers",
            "following_url": "https://api.github.com/users/ton77v/following{/other_user}",
            "gists_url": "https://api.github.com/users/ton77v/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ton77v/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ton77v/subscriptions",
            "organizations_url": "https://api.github.com/users/ton77v/orgs",
            "repos_url": "https://api.github.com/users/ton77v/repos",
            "events_url": "https://api.github.com/users/ton77v/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ton77v/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-07T06:01:30Z",
        "updated_at": "2023-12-14T09:33:49Z",
        "closed_at": "2023-12-12T15:57:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9367",
            "html_url": "https://github.com/run-llama/llama_index/pull/9367",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9367.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9367.patch",
            "merged_at": "2023-12-12T15:57:06Z"
        },
        "body": "# Description\r\n\r\nI've added a new method \"from_existing\" allowing to re-use the Open AI Assistant instead of creating a new one every time.\r\n\r\nFixed a critical bug in _achat method that was originally returning the synchronous _chat eventually making synchronous tool calls from async environment\r\n\r\nAdded a minor improvement - option to explicitly set an api key for Open AI Assistant\r\n\r\nAlso fixed less critical bug:  instructions_prefix parameter ignored in run_assistant method\r\n\r\nFixes issues:\r\nhttps://github.com/run-llama/llama_index/issues/9366\r\nhttps://github.com/run-llama/llama_index/issues/9021\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nAdded `tests/agent/openai/test_openai_assistant_agent.py`\r\n+ I'm using this code in my project for a while\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n- [x] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9367/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 2,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9367/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9366",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9366/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9366/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9366/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9366",
        "id": 2029946915,
        "node_id": "I_kwDOIWuq5854_ogj",
        "number": 9366,
        "title": "[Bug]: OpenAIAssistantAgent._achat method returns synchronous self._chat",
        "user": {
            "login": "ton77v",
            "id": 50094687,
            "node_id": "MDQ6VXNlcjUwMDk0Njg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/50094687?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ton77v",
            "html_url": "https://github.com/ton77v",
            "followers_url": "https://api.github.com/users/ton77v/followers",
            "following_url": "https://api.github.com/users/ton77v/following{/other_user}",
            "gists_url": "https://api.github.com/users/ton77v/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ton77v/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ton77v/subscriptions",
            "organizations_url": "https://api.github.com/users/ton77v/orgs",
            "repos_url": "https://api.github.com/users/ton77v/repos",
            "events_url": "https://api.github.com/users/ton77v/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ton77v/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-07T05:40:26Z",
        "updated_at": "2023-12-12T22:24:11Z",
        "closed_at": "2023-12-12T22:24:11Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nOpenAIAssistantAgent's _achat method returns the synchronous _chat that eventually uses synchronous tools.\r\n\r\nThis eliminates all the advantages of async. In case if your sync version of the tool leverages asyncio.run(async_version()), this will raise RuntimeError\r\n\r\nI've created a patch for myself and will add a PR fixing this\n\n### Version\n\nv0.9.13\n\n### Steps to Reproduce\n\n1. Create an Assistant with async tool\r\n2. Run assistant.achat(...)\n\n### Relevant Logs/Tracbacks\n\n```shell\nasync def _achat(\r\n        self,\r\n        message: str,\r\n        chat_history: Optional[List[ChatMessage]] = None,\r\n        function_call: Union[str, dict] = \"auto\",\r\n        mode: ChatResponseMode = ChatResponseMode.WAIT,\r\n    ) -> AGENT_CHAT_RESPONSE_TYPE:\r\n        return self._chat(\r\n            message,\r\n            chat_history=chat_history,\r\n            function_call=function_call,\r\n            mode=mode,\r\n        )\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9366/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9366/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9365",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9365/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9365/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9365/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9365",
        "id": 2029839351,
        "node_id": "PR_kwDOIWuq585hX3PW",
        "number": 9365,
        "title": "Upd changelog",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-07T03:59:35Z",
        "updated_at": "2023-12-07T04:07:02Z",
        "closed_at": "2023-12-07T04:07:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9365",
            "html_url": "https://github.com/run-llama/llama_index/pull/9365",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9365.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9365.patch",
            "merged_at": "2023-12-07T04:07:01Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9365/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9365/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9364",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9364/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9364/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9364/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9364",
        "id": 2029743788,
        "node_id": "I_kwDOIWuq5854-26s",
        "number": 9364,
        "title": "[Bug]: OpenAIAgent function calling gives error when using AzureOpenAI LLM",
        "user": {
            "login": "haolxx",
            "id": 143557447,
            "node_id": "U_kgDOCI6DRw",
            "avatar_url": "https://avatars.githubusercontent.com/u/143557447?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/haolxx",
            "html_url": "https://github.com/haolxx",
            "followers_url": "https://api.github.com/users/haolxx/followers",
            "following_url": "https://api.github.com/users/haolxx/following{/other_user}",
            "gists_url": "https://api.github.com/users/haolxx/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/haolxx/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/haolxx/subscriptions",
            "organizations_url": "https://api.github.com/users/haolxx/orgs",
            "repos_url": "https://api.github.com/users/haolxx/repos",
            "events_url": "https://api.github.com/users/haolxx/events{/privacy}",
            "received_events_url": "https://api.github.com/users/haolxx/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-07T02:22:55Z",
        "updated_at": "2023-12-07T02:24:46Z",
        "closed_at": "2023-12-07T02:24:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nBadRequestError: Error code: 400 - {'error': {'message': 'Unrecognized request arguments supplied: tool_choice, tools', 'type': 'invalid_request_error', 'param': None, 'code': None}}\r\n\r\nCould this be related to updates on Azure OpenAI side? \r\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling?tabs=python\r\n\r\nImportant\r\nThe functions and function_call parameters have been deprecated with the release of the [2023-12-01-preview](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2023-12-01-preview/inference.json) version of the API. The replacement for functions is the [tools](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions) parameter. The replacement for function_call is the [tool_choice](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions) parameter.\r\n\r\n\r\n### Version\r\n\r\ntested both 0.8.69 and 0.9.11.post1\r\n\r\n### Steps to Reproduce\r\n\r\nhttps://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_with_query_engine.html\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nBadRequestError: Error code: 400 - {'error': {'message': 'Unrecognized request arguments supplied: tool_choice, tools', 'type': 'invalid_request_error', 'param': None, 'code': None}}\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9364/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9364/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9363",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9363/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9363/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9363/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9363",
        "id": 2029585224,
        "node_id": "PR_kwDOIWuq585hXDkf",
        "number": 9363,
        "title": "add ollama pack example",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T23:49:54Z",
        "updated_at": "2023-12-07T00:34:48Z",
        "closed_at": "2023-12-07T00:34:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9363",
            "html_url": "https://github.com/run-llama/llama_index/pull/9363",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9363.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9363.patch",
            "merged_at": "2023-12-07T00:34:47Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9363/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9363/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9362",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9362/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9362/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9362/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9362",
        "id": 2029571478,
        "node_id": "PR_kwDOIWuq585hXAnN",
        "number": 9362,
        "title": "Bug fix for `asyncio_mod` in `LabelledRagDataset`",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-06T23:32:25Z",
        "updated_at": "2023-12-11T20:04:34Z",
        "closed_at": "2023-12-11T20:04:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9362",
            "html_url": "https://github.com/run-llama/llama_index/pull/9362",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9362.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9362.patch",
            "merged_at": "2023-12-11T20:04:33Z"
        },
        "body": "# Description\r\n\r\nQuick fix on a bug when `show_progress` is `False` and `asyncio_mod`'s `gather` method doesn't have the `desc` param.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9362/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9362/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9361",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9361/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9361/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9361/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9361",
        "id": 2029568648,
        "node_id": "PR_kwDOIWuq585hW__i",
        "number": 9361,
        "title": "fix llava example using response text",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T23:29:16Z",
        "updated_at": "2023-12-06T23:33:54Z",
        "closed_at": "2023-12-06T23:33:53Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9361",
            "html_url": "https://github.com/run-llama/llama_index/pull/9361",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9361.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9361.patch",
            "merged_at": "2023-12-06T23:33:53Z"
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9361/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9361/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9360",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9360/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9360/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9360/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9360",
        "id": 2029500282,
        "node_id": "PR_kwDOIWuq585hWwyJ",
        "number": 9360,
        "title": "Change Llava Old Model to MM LLM",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T22:30:22Z",
        "updated_at": "2023-12-06T22:35:17Z",
        "closed_at": "2023-12-06T22:35:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9360",
            "html_url": "https://github.com/run-llama/llama_index/pull/9360",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9360.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9360.patch",
            "merged_at": "2023-12-06T22:35:16Z"
        },
        "body": "# Description\r\n\r\n* Change more than 1 image for Replicate model limit to warning instead of error\r\n*  Change old Llava model to new MM LLM\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9360/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9360/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9359",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9359/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9359/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9359/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9359",
        "id": 2029471601,
        "node_id": "I_kwDOIWuq585490dx",
        "number": 9359,
        "title": "[Question]: Can't get metadata from weaviate",
        "user": {
            "login": "macarneiro1",
            "id": 133670114,
            "node_id": "U_kgDOB_ek4g",
            "avatar_url": "https://avatars.githubusercontent.com/u/133670114?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/macarneiro1",
            "html_url": "https://github.com/macarneiro1",
            "followers_url": "https://api.github.com/users/macarneiro1/followers",
            "following_url": "https://api.github.com/users/macarneiro1/following{/other_user}",
            "gists_url": "https://api.github.com/users/macarneiro1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/macarneiro1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/macarneiro1/subscriptions",
            "organizations_url": "https://api.github.com/users/macarneiro1/orgs",
            "repos_url": "https://api.github.com/users/macarneiro1/repos",
            "events_url": "https://api.github.com/users/macarneiro1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/macarneiro1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-06T22:12:06Z",
        "updated_at": "2023-12-06T22:37:38Z",
        "closed_at": "2023-12-06T22:37:37Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\n### Description\r\n\r\nI recently upgraded from `gpt_index` version 0.5.12 to `llama_index` version 0.9.6. In the previous version, I used the following code to embed documents and query for document IDs:\r\n\r\n```python\r\n# Code snippet for gpt_index (0.5.12)\r\nweaviate_docs = [...]\r\ncontext = ServiceContext.from_defaults(...)\r\nindex = GPTWeaviateIndex([...])\r\n\r\n# Querying for document ID\r\nmetadata_filter = {'key':'value'}\r\nfilter = _build_filter(metadata_filter)\r\nquery_result = weaviate_client.query.get(...).with_where(filter).with_additional(['id']).do()\r\n```\r\nHere I would embed my documents. When querying to get the document id I would do \r\n```python\r\ndef _build_filter(metadata):\r\n    operands = []\r\n    for key in metadata:\r\n        querystr = f'*\\\\\"{key}\\\\\": \\\\\"{_replace_special_chars(metadata[key])}\\\\\"*'\r\n        operands.append({\r\n            \"path\": [\"extra_info\"],\r\n            \"operator\": \"Like\",\r\n            \"valueString\": querystr\r\n        })\r\n    return {\r\n        \"operator\": \"And\",\r\n        \"operands\": operands\r\n    }\r\nmetadata_filter = {'key':'value'}\r\nfilter = _build_filter(metadata_filter)\r\nquery_result = weaviate_client.query\\\r\n            .get(index_hash, ['doc_id'])\\\r\n            .with_where(filter)\\\r\n            .with_additional(['id'])\\\r\n            .do()\r\n```\r\nIn the new version using llama_index (0.9.6), I modified the code as follows:\r\n```python\r\n# Code snippet for llama_index (0.9.6)\r\nweaviate_docs = [...]\r\ncontext = ServiceContext.from_defaults(...)\r\nvector_store = WeaviateVectorStore(...)\r\nstorage_context = StorageContext.from_defaults(...)\r\nindex = VectorStoreIndex.from_documents(...)\r\n```\r\n### Expected behavior\r\n```python\r\n{'data': {'Get': {'Velho_index_Node': [{'_additional': {'id': '5093a058-75aa-489c-a0cd-f10f3047dc76'},\r\n     'doc_id': '8286541e-2487-496e-b78a-c8e0d76667bb'}]}}}\r\n```\r\n### Actual behavior\r\nHowever, when attempting to query for document IDs using a similar approach, I encountered the following error:\r\n```python\r\n> {'data': {'Get': {'Indexdeteste4_Node': None}}, 'errors': [{'locations': [{'column': 6, 'line': 1}], 'message': \"invalid 'where' filter: child >operand at position 0: no such prop with name 'extra_info' found in class 'Indexdeteste4_Node' in the schema. Check your ?>schema files for which properties in this class are available\", 'path': ['Get', 'Indexdeteste4_Node']}]}\r\n```\r\nI tried to change the path and the querystr use insert instead of from_documents but nothing seems to work. Any ideas?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9359/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9359/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9358",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9358/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9358/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9358/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9358",
        "id": 2029468729,
        "node_id": "I_kwDOIWuq58549zw5",
        "number": 9358,
        "title": "[Question]: Time consuming indexing .pdf files with VectorStoreIndex",
        "user": {
            "login": "debraj135",
            "id": 16231057,
            "node_id": "MDQ6VXNlcjE2MjMxMDU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/16231057?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/debraj135",
            "html_url": "https://github.com/debraj135",
            "followers_url": "https://api.github.com/users/debraj135/followers",
            "following_url": "https://api.github.com/users/debraj135/following{/other_user}",
            "gists_url": "https://api.github.com/users/debraj135/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/debraj135/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/debraj135/subscriptions",
            "organizations_url": "https://api.github.com/users/debraj135/orgs",
            "repos_url": "https://api.github.com/users/debraj135/repos",
            "events_url": "https://api.github.com/users/debraj135/events{/privacy}",
            "received_events_url": "https://api.github.com/users/debraj135/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-06T22:09:38Z",
        "updated_at": "2023-12-08T02:23:43Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm using `VectorStoreIndex` to index .pdf files. My documents are being created using `SimpleDirectoryReader`. \r\n\r\nI end up with nearly 100,000 chunks. After completing `Generating embeddings:` for all chunks, the flow seems to be stuck under `VectorStoreIndex.from_documents` for nearly an hour. I was wondering what could be leading to it.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9358/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9358/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9357",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9357/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9357/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9357/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9357",
        "id": 2029459174,
        "node_id": "PR_kwDOIWuq585hWngf",
        "number": 9357,
        "title": "Init Llava Demo Example",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T22:02:05Z",
        "updated_at": "2023-12-08T15:52:39Z",
        "closed_at": "2023-12-08T15:52:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9357",
            "html_url": "https://github.com/run-llama/llama_index/pull/9357",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9357.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9357.patch",
            "merged_at": "2023-12-08T15:52:38Z"
        },
        "body": "# Description\r\nExamples:\r\n1. Llava image caption with text recursive index\r\n2. LLava Pydantic structured output\r\n3. Using step 2 output for MultiModal Retrieval with image/text index\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9357/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9357/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9355",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9355/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9355/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9355/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9355",
        "id": 2029316500,
        "node_id": "I_kwDOIWuq58549OmU",
        "number": 9355,
        "title": "[Question]: Retrieval similarity threshold",
        "user": {
            "login": "debraj135",
            "id": 16231057,
            "node_id": "MDQ6VXNlcjE2MjMxMDU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/16231057?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/debraj135",
            "html_url": "https://github.com/debraj135",
            "followers_url": "https://api.github.com/users/debraj135/followers",
            "following_url": "https://api.github.com/users/debraj135/following{/other_user}",
            "gists_url": "https://api.github.com/users/debraj135/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/debraj135/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/debraj135/subscriptions",
            "organizations_url": "https://api.github.com/users/debraj135/orgs",
            "repos_url": "https://api.github.com/users/debraj135/repos",
            "events_url": "https://api.github.com/users/debraj135/events{/privacy}",
            "received_events_url": "https://api.github.com/users/debraj135/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-06T20:18:20Z",
        "updated_at": "2023-12-06T20:26:48Z",
        "closed_at": "2023-12-06T20:20:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nIs there any way to specify a cosine similarity threshold in addition to the `similarity_top_k` when using a `VectorStoreIndex` as `index.as_query_engine(...)`?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9355/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9355/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9354",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9354/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9354/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9354/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9354",
        "id": 2029221993,
        "node_id": "PR_kwDOIWuq585hVzdi",
        "number": 9354,
        "title": "Upd Llava Model version from Replicate",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-06T19:13:25Z",
        "updated_at": "2023-12-06T22:01:42Z",
        "closed_at": "2023-12-06T22:01:41Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9354",
            "html_url": "https://github.com/run-llama/llama_index/pull/9354",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9354.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9354.patch",
            "merged_at": "2023-12-06T22:01:41Z"
        },
        "body": "# Description\r\n\r\nhttps://replicate.com/yorickvp/llava-13b\r\nModel version updated.\r\nNeed some testing\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9354/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9354/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9353",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9353/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9353/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9353/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9353",
        "id": 2029211245,
        "node_id": "I_kwDOIWuq5854805t",
        "number": 9353,
        "title": "[Question]: I want to add conversation history to my LLM index implementation with GPT-3.5 Turbo model.",
        "user": {
            "login": "akashkumar398",
            "id": 24894328,
            "node_id": "MDQ6VXNlcjI0ODk0MzI4",
            "avatar_url": "https://avatars.githubusercontent.com/u/24894328?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/akashkumar398",
            "html_url": "https://github.com/akashkumar398",
            "followers_url": "https://api.github.com/users/akashkumar398/followers",
            "following_url": "https://api.github.com/users/akashkumar398/following{/other_user}",
            "gists_url": "https://api.github.com/users/akashkumar398/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/akashkumar398/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/akashkumar398/subscriptions",
            "organizations_url": "https://api.github.com/users/akashkumar398/orgs",
            "repos_url": "https://api.github.com/users/akashkumar398/repos",
            "events_url": "https://api.github.com/users/akashkumar398/events{/privacy}",
            "received_events_url": "https://api.github.com/users/akashkumar398/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T19:05:30Z",
        "updated_at": "2023-12-06T19:17:56Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI want to keep the last 5 conversations so that the context includes the history and answers the question while retaining the previous question's context. For example, if I ask about a job number once and the next time, even if I don't provide the job number, it should be available to answer the question, keeping the job number in context.\r\n\r\nhere is my code where i want to add memory/conversational history  like langchain \r\n#llm _openai under the hood\r\nimport os\r\nimport openai\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-bE\"\r\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\r\n\r\nimport tiktoken\r\nfrom llama_index.callbacks import CallbackManager, TokenCountingHandler\r\ntoken_counter = TokenCountingHandler(\r\n    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\r\n)\r\n\r\ncallback_manager = CallbackManager([token_counter])\r\n\r\nfrom llama_index import ServiceContext, LLMPredictor, OpenAIEmbedding, PromptHelper\r\nfrom llama_index.llms import OpenAI\r\nfrom llama_index import ServiceContext\r\nllm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\r\n\r\nservice_context = ServiceContext.from_defaults(\r\n  llm=llm,callback_manager=callback_manager\r\n)\r\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\r\n\r\nquery_engine = NLSQLTableQueryEngine(\r\n    sql_database=sql_database,\r\n    service_context=service_context\r\n)\r\n\r\nquery_str = \"when was order number 10100 shiiped?\"\r\nresponse = query_engine.query(query_str)",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9353/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9353/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9352",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9352/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9352/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9352/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9352",
        "id": 2029179680,
        "node_id": "I_kwDOIWuq58548tMg",
        "number": 9352,
        "title": "[Bug]: QdrantVectorStore can delete a collection unintentionally",
        "user": {
            "login": "alexbrand",
            "id": 545723,
            "node_id": "MDQ6VXNlcjU0NTcyMw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/545723?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/alexbrand",
            "html_url": "https://github.com/alexbrand",
            "followers_url": "https://api.github.com/users/alexbrand/followers",
            "following_url": "https://api.github.com/users/alexbrand/following{/other_user}",
            "gists_url": "https://api.github.com/users/alexbrand/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/alexbrand/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/alexbrand/subscriptions",
            "organizations_url": "https://api.github.com/users/alexbrand/orgs",
            "repos_url": "https://api.github.com/users/alexbrand/repos",
            "events_url": "https://api.github.com/users/alexbrand/events{/privacy}",
            "received_events_url": "https://api.github.com/users/alexbrand/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-06T18:44:52Z",
        "updated_at": "2023-12-07T21:13:00Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n## Issue\r\nOn instantiation, QdrantVectorStore uses the qdrant client to determine whether the target collection exists and stores whether it exists or not in an instance variable.\r\n\r\nWhen it comes time to add vectors, QdrantVectorStore first checks the instance variable and issues a **recreate** (instead of a **create**) if the collection was determined to be non-existent. \r\n\r\nThis is fine in most situations, except that the code used to determine whether the collection exists assumes that the collection **does not** exist when it gets an unexpected response from Qdrant, such as an HTTP 500 error (perhaps even timeouts, although I'm not certain about that). In these situations, the error is swallowed and the collection is recreated, resulting in data loss.\r\n\r\n## Code in Question\r\n\r\nThis is the code that checks for collection existence ([permalink](https://github.com/run-llama/llama_index/blob/85ddd8e2ef1daf4a21ec85adeee55f1fac849bdb/llama_index/vector_stores/qdrant.py#L329C2-L338C20)):\r\n```\r\n    def _collection_exists(self, collection_name: str) -> bool:\r\n        \"\"\"Check if a collection exists.\"\"\"\r\n        from grpc import RpcError\r\n        from qdrant_client.http.exceptions import UnexpectedResponse\r\n\r\n        try:\r\n            self._client.get_collection(collection_name)\r\n        except (RpcError, UnexpectedResponse, ValueError):\r\n            return False\r\n        return True\r\n```\r\n\r\n\r\n\r\nThis is the check in `add` ([permalink](https://github.com/run-llama/llama_index/blob/85ddd8e2ef1daf4a21ec85adeee55f1fac849bdb/llama_index/vector_stores/qdrant.py#L96C5-L109C14)):\r\n```\r\ndef add(self, nodes: List[BaseNode], **add_kwargs: Any) -> List[str]:\r\n        \"\"\"Add nodes to index.\r\n\r\n        Args:\r\n            nodes: List[BaseNode]: list of nodes with embeddings\r\n\r\n        \"\"\"\r\n        from qdrant_client.http import models as rest\r\n\r\n        if len(nodes) > 0 and not self._collection_initialized:\r\n            self._create_collection(\r\n                collection_name=self.collection_name,\r\n                vector_size=len(nodes[0].get_embedding()),\r\n            )\r\n```\r\n\r\nThis is self._create_collection ([permalink](https://github.com/run-llama/llama_index/blob/85ddd8e2ef1daf4a21ec85adeee55f1fac849bdb/llama_index/vector_stores/qdrant.py#L296)). Notice the `recreate_collection` call.\r\n```\r\ndef _create_collection(self, collection_name: str, vector_size: int) -> None:\r\n        \"\"\"Create a Qdrant collection.\"\"\"\r\n        from qdrant_client.http import models as rest\r\n\r\n        self._client.recreate_collection(\r\n            collection_name=collection_name,\r\n            vectors_config=rest.VectorParams(\r\n                size=vector_size,\r\n                distance=rest.Distance.COSINE,\r\n            ),\r\n        )\r\n        self._collection_initialized = True\r\n\r\n```\n\n### Version\n\nmain\n\n### Steps to Reproduce\n\nI was investigating a related bug (creating the collection out of band results in collection deletion) with the following repro script:\r\n\r\n```\r\nfrom llama_index.vector_stores import QdrantVectorStore\r\nfrom llama_index.vector_stores.types import NodeWithEmbedding\r\nfrom llama_index.schema import TextNode\r\nfrom qdrant_client import QdrantClient, models\r\n\r\nclient = QdrantClient(url=\"http://localhost\", api_key=\"secret\")\r\n\r\n# At this point, the collection does not exist yet.\r\n# On init(), QdrantVectorStore reaches out to Qdrant and determine whether the\r\n# collection exists. It does not, so it sets internal state (_collection_initialized) to False.\r\nvector_store = QdrantVectorStore(client=client, collection_name=\"my_collection\")\r\n\r\n# We create the collection \"out of band\", using the QdrantClient.\r\nclient.create_collection(\r\n    collection_name=\"my_collection\",\r\n    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE),\r\n)\r\n\r\n# dummy node for illustration purposes\r\nnodes = [NodeWithEmbedding(node=TextNode(text=\"dummy\"), embedding=[1, 2, 3])]\r\n\r\n# On add, QdrantVectorStore checks its internal state to determine whether the\r\n# collection exists. Because _collection_initialzed was set to False on init(),\r\n# it assumes it does not.\r\n# Now comes the kicker. QdrantVectorStore proceeds to create the collection by\r\n# calling RECREATE_COLLECTION on the qdrant client, which first issues a DELETE\r\n# and then a CREATE.\r\nvector_store.add(nodes)\r\n```\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9352/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9352/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9351",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9351/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9351/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9351/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9351",
        "id": 2029126877,
        "node_id": "PR_kwDOIWuq585hVehs",
        "number": 9351,
        "title": "move system prompt for context chat engine",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-06T18:13:22Z",
        "updated_at": "2023-12-06T18:24:01Z",
        "closed_at": "2023-12-06T18:24:00Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9351",
            "html_url": "https://github.com/run-llama/llama_index/pull/9351",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9351.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9351.patch",
            "merged_at": "2023-12-06T18:24:00Z"
        },
        "body": "# Description\r\n\r\nMove system prompt for context chat engine to the top \r\n\r\nFixes https://github.com/run-llama/llama_index/issues/9350\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9351/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9351/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9350",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9350/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9350/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9350/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9350",
        "id": 2029119985,
        "node_id": "I_kwDOIWuq58548enx",
        "number": 9350,
        "title": "[Bug]: ContextChatEngine user supplied system prompt is concatenated below the context, is it misplaced?",
        "user": {
            "login": "mingqxu7",
            "id": 50094870,
            "node_id": "MDQ6VXNlcjUwMDk0ODcw",
            "avatar_url": "https://avatars.githubusercontent.com/u/50094870?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mingqxu7",
            "html_url": "https://github.com/mingqxu7",
            "followers_url": "https://api.github.com/users/mingqxu7/followers",
            "following_url": "https://api.github.com/users/mingqxu7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mingqxu7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mingqxu7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mingqxu7/subscriptions",
            "organizations_url": "https://api.github.com/users/mingqxu7/orgs",
            "repos_url": "https://api.github.com/users/mingqxu7/repos",
            "events_url": "https://api.github.com/users/mingqxu7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mingqxu7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-06T18:09:21Z",
        "updated_at": "2023-12-06T18:24:41Z",
        "closed_at": "2023-12-06T18:24:01Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nLANG_CONTEXT_TEMPLATE = (\r\n    \"Context information is below.\"\r\n    \"\\n--------------------\\n\"\r\n    \"{context_str}\"\r\n    \"\\n--------------------\\n\"\r\n    \"Query: {query_str}\\n\"\r\n    \"Answer in {language_str}:\\n\"\r\n)\r\n\r\nsystem_prompt=\"You are a helpful assitant. Assuming no prior knowledge, answer the question based on provided context below\"\r\n\r\nchat_engine = ContextChatEngine.from_defaults(\r\n            retriever=retriever, \r\n            service_context=service_context,\r\n            system_prompt=self.system_prompt,\r\n            context_template=LANG_CONTEXT_TEMPLATE\r\n)\r\n\r\nThe log file shows that the openai request, the context appears before the user supplied system prompt:\r\n\r\n2023-12-06 09:43:45,980 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/deployments/gpt-4-turbo/chat/completions', 'headers': {'api-key': 'ac3099f837a54de5bdcd00ec0d1f0aac'}, 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': '\\n\\nContext information is below.\\n--------------------\\npage_label: 86\\nfile_path: ....<context info>...Query=<query_str>\\nAnswer in Simplified Chinese:\\n \\nYou are a helpful assitant. Assuming no prior knowledge, answer the question based on provided context below\"\r\n\r\nTwo issues with the above arrangements:\r\n1. Recency bias: the user supplied prompt is in English, even though the context requires that the answer be in Chinese, the answer sometimes are still in English. \r\n2. \"...based on the context below\", in fact the context is above.  \r\n3. such an arrangement appears to be the opposite of what I have learned Re: RAG, which is: \r\n\r\n[{'role': <MessageRole.SYSTEM: 'system'>, 'content': '\\nYou are a helpful assitant. Assuming no prior knowledge, answer the question based on provided context below. \\n\\n \\n\\nContext information is below.\\n--------------------\\npage_label: 86\\nfile_path: ....<context info>...\".  \r\n\r\n\r\n\n\n### Version\n\n0.9.9\n\n### Steps to Reproduce\n\nsee above\n\n### Relevant Logs/Tracbacks\n\n```shell\nsee above.\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9350/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9350/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9349",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9349/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9349/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9349/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9349",
        "id": 2028928089,
        "node_id": "PR_kwDOIWuq585hUyuO",
        "number": 9349,
        "title": "[version] bump to v0.9.13",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-06T16:21:49Z",
        "updated_at": "2023-12-06T17:42:35Z",
        "closed_at": "2023-12-06T17:42:34Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9349",
            "html_url": "https://github.com/run-llama/llama_index/pull/9349",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9349.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9349.patch",
            "merged_at": "2023-12-06T17:42:34Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9349/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9349/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9348",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9348/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9348/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9348/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9348",
        "id": 2028770341,
        "node_id": "I_kwDOIWuq58547JQl",
        "number": 9348,
        "title": "[Question]: How to define a qwen llm model (qwen turbo)",
        "user": {
            "login": "LiamHoo",
            "id": 53430154,
            "node_id": "MDQ6VXNlcjUzNDMwMTU0",
            "avatar_url": "https://avatars.githubusercontent.com/u/53430154?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/LiamHoo",
            "html_url": "https://github.com/LiamHoo",
            "followers_url": "https://api.github.com/users/LiamHoo/followers",
            "following_url": "https://api.github.com/users/LiamHoo/following{/other_user}",
            "gists_url": "https://api.github.com/users/LiamHoo/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/LiamHoo/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/LiamHoo/subscriptions",
            "organizations_url": "https://api.github.com/users/LiamHoo/orgs",
            "repos_url": "https://api.github.com/users/LiamHoo/repos",
            "events_url": "https://api.github.com/users/LiamHoo/events{/privacy}",
            "received_events_url": "https://api.github.com/users/LiamHoo/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-06T15:08:59Z",
        "updated_at": "2023-12-06T15:10:54Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHow to define a qwen llm model (qwen turbo) that is not local, but an API similar to OpenAI. I need to use apikey to access it and support stream.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9348/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9348/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9347",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9347/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9347/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9347/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9347",
        "id": 2028718332,
        "node_id": "I_kwDOIWuq585468j8",
        "number": 9347,
        "title": "[Bug]: StorageContext is long to load",
        "user": {
            "login": "Cotum",
            "id": 82029831,
            "node_id": "MDQ6VXNlcjgyMDI5ODMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/82029831?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Cotum",
            "html_url": "https://github.com/Cotum",
            "followers_url": "https://api.github.com/users/Cotum/followers",
            "following_url": "https://api.github.com/users/Cotum/following{/other_user}",
            "gists_url": "https://api.github.com/users/Cotum/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Cotum/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Cotum/subscriptions",
            "organizations_url": "https://api.github.com/users/Cotum/orgs",
            "repos_url": "https://api.github.com/users/Cotum/repos",
            "events_url": "https://api.github.com/users/Cotum/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Cotum/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-06T14:44:37Z",
        "updated_at": "2023-12-06T14:53:05Z",
        "closed_at": "2023-12-06T14:49:07Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nHello, I am new to Llama-index and apologize if the problem is trivial but I didn't find any related issue.\r\nI am trying to load embedding vectors from a local saved directory using : \r\n```\r\nstorage_context = StorageContext.from_defaults(\r\n        docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storage_directory),\r\n        vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storage_directory, namespace = \"default\"),\r\n        index_store=SimpleIndexStore.from_persist_dir(persist_dir=storage_directory),\r\n    )\r\n```\r\nHowever, it seems that the loading of the storage context is very long compared to the number of chunk present in the directory :\r\n6519 chunks in 50 seconds.\r\nIs it a normal speed ? Is there a way to speed up the process, maybe by going through a vector database ?\n\n### Version\n\n0.9.4\n\n### Steps to Reproduce\n\nI have a set of 100 documents that is parsed into 6519 chunks and whose embedding is saved locally using the embed-model \"int-float/multilingual-e5-base\" through the HuggingFaceEmbedding class in the global service context.\r\nThen loading the local database through a storagecontext using the same global service is pretty long.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9347/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9347/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9346",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9346/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9346/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9346/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9346",
        "id": 2028631592,
        "node_id": "I_kwDOIWuq58546nYo",
        "number": 9346,
        "title": "[Feature Request]: Ensure all generations are tracked as events in callback manager",
        "user": {
            "login": "anna-springbokai",
            "id": 129185179,
            "node_id": "U_kgDOB7M1mw",
            "avatar_url": "https://avatars.githubusercontent.com/u/129185179?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/anna-springbokai",
            "html_url": "https://github.com/anna-springbokai",
            "followers_url": "https://api.github.com/users/anna-springbokai/followers",
            "following_url": "https://api.github.com/users/anna-springbokai/following{/other_user}",
            "gists_url": "https://api.github.com/users/anna-springbokai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/anna-springbokai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/anna-springbokai/subscriptions",
            "organizations_url": "https://api.github.com/users/anna-springbokai/orgs",
            "repos_url": "https://api.github.com/users/anna-springbokai/repos",
            "events_url": "https://api.github.com/users/anna-springbokai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/anna-springbokai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-06T14:02:10Z",
        "updated_at": "2023-12-06T17:21:25Z",
        "closed_at": "2023-12-06T17:21:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nMake sure that all LLM generations are passed as events to the callback manager to enable consistent tracing. At the moment some LLM generations (e.g. those by OpenAIQuestionGenerator) do not costitute callback events.\n\n### Reason\n\nWe would like to be able to trace all events (generations, embedding, retrieval, etc.) using tools such as phoenix or langfuse. We can mostly do it via callbacks.\r\nBut some LLM generations (e.g. those by OpenAIQuestionGenerator) are not passed as events to the callback manager, which means they can't be traced together with other events. Would be useful to make sure everything can be traced uniformly.\n\n### Value of Feature\n\nTracing of LLM usage with callbacks is only half useful if it does not trace all generations.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9346/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9346/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9345",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9345/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9345/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9345/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9345",
        "id": 2028628796,
        "node_id": "I_kwDOIWuq58546ms8",
        "number": 9345,
        "title": "[Question]: default value of the threshold of mmr",
        "user": {
            "login": "kouskouss",
            "id": 106626673,
            "node_id": "U_kgDOBlr-cQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/106626673?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kouskouss",
            "html_url": "https://github.com/kouskouss",
            "followers_url": "https://api.github.com/users/kouskouss/followers",
            "following_url": "https://api.github.com/users/kouskouss/following{/other_user}",
            "gists_url": "https://api.github.com/users/kouskouss/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kouskouss/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kouskouss/subscriptions",
            "organizations_url": "https://api.github.com/users/kouskouss/orgs",
            "repos_url": "https://api.github.com/users/kouskouss/repos",
            "events_url": "https://api.github.com/users/kouskouss/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kouskouss/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T14:00:50Z",
        "updated_at": "2023-12-06T14:16:32Z",
        "closed_at": "2023-12-06T14:16:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nWhat is the default value of the mmr threshold in a query engine? \r\nFor example here: \r\n`query_engine = index.as_query_engine(\r\n    similarity_top_k=5,\r\n    vector_store_query_mode=\"mmr\",\r\n    verbose=True,)`",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9345/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9345/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9344",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9344/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9344/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9344/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9344",
        "id": 2028453068,
        "node_id": "PR_kwDOIWuq585hTJfp",
        "number": 9344,
        "title": "Fix links and typo in llava_multi_modal_tesla_10q.ipynb",
        "user": {
            "login": "aaronjimv",
            "id": 67152883,
            "node_id": "MDQ6VXNlcjY3MTUyODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/67152883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/aaronjimv",
            "html_url": "https://github.com/aaronjimv",
            "followers_url": "https://api.github.com/users/aaronjimv/followers",
            "following_url": "https://api.github.com/users/aaronjimv/following{/other_user}",
            "gists_url": "https://api.github.com/users/aaronjimv/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/aaronjimv/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/aaronjimv/subscriptions",
            "organizations_url": "https://api.github.com/users/aaronjimv/orgs",
            "repos_url": "https://api.github.com/users/aaronjimv/repos",
            "events_url": "https://api.github.com/users/aaronjimv/events{/privacy}",
            "received_events_url": "https://api.github.com/users/aaronjimv/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-06T12:39:57Z",
        "updated_at": "2023-12-06T17:46:32Z",
        "closed_at": "2023-12-06T15:16:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9344",
            "html_url": "https://github.com/run-llama/llama_index/pull/9344",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9344.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9344.patch",
            "merged_at": "2023-12-06T15:16:40Z"
        },
        "body": "# Description\r\n\r\nThis PR improve links for better reading and delete extras `#` in llava_multi_modal_tesla_10q.ipynb\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] My changes generate no new warnings\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9344/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9344/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9343",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9343/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9343/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9343/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9343",
        "id": 2028378157,
        "node_id": "I_kwDOIWuq58545pgt",
        "number": 9343,
        "title": "[Feature Request]: Enable completely offline operation",
        "user": {
            "login": "Pascal-So",
            "id": 18399125,
            "node_id": "MDQ6VXNlcjE4Mzk5MTI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/18399125?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Pascal-So",
            "html_url": "https://github.com/Pascal-So",
            "followers_url": "https://api.github.com/users/Pascal-So/followers",
            "following_url": "https://api.github.com/users/Pascal-So/following{/other_user}",
            "gists_url": "https://api.github.com/users/Pascal-So/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Pascal-So/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Pascal-So/subscriptions",
            "organizations_url": "https://api.github.com/users/Pascal-So/orgs",
            "repos_url": "https://api.github.com/users/Pascal-So/repos",
            "events_url": "https://api.github.com/users/Pascal-So/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Pascal-So/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T11:55:59Z",
        "updated_at": "2023-12-06T12:05:29Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nWhen using huggingface models and embeddings that have been downloaded in advance, it should be possible to run llama_index on a computer that is not connected to the internet at all, since the usage doesn't depend on openai or any other online services then.\n\n### Reason\n\nRight now, even just this import line leads to a network timeout if the computer is not connected to the internet:\r\n\r\n```python\r\nfrom llama_index.embeddings import LangchainEmbedding\r\n```\r\n\r\n<details>\r\n<summary>\r\n(full error message here)\r\n</summary>\r\n\r\n```\r\nFile \"/app/server.py\", line 8, in <module>\r\n  from llama_index.embeddings import LangchainEmbedding\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/__init__.py\", line 21, in <module>\r\n  from llama_index.indices import (\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/indices/__init__.py\", line 4, in <module>\r\n  from llama_index.indices.composability.graph import ComposableGraph\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/indices/composability/__init__.py\", line 4, in <module>\r\n  from llama_index.indices.composability.graph import ComposableGraph\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/indices/composability/graph.py\", line 7, in <module>\r\n  from llama_index.indices.base import BaseIndex\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/indices/base.py\", line 6, in <module>\r\n  from llama_index.chat_engine.types import BaseChatEngine, ChatMode\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/chat_engine/__init__.py\", line 1, in <module>\r\n  from llama_index.chat_engine.condense_question import CondenseQuestionChatEngine\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/chat_engine/condense_question.py\", line 6, in <module>\r\n  from llama_index.chat_engine.types import (\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/chat_engine/types.py\", line 11, in <module>\r\n  from llama_index.memory import BaseMemory\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/memory/__init__.py\", line 1, in <module>\r\n  from llama_index.memory.chat_memory_buffer import ChatMemoryBuffer\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 12, in <module>\r\n  class ChatMemoryBuffer(BaseMemory):\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/memory/chat_memory_buffer.py\", line 18, in ChatMemoryBuffer\r\n  default_factory=cast(Callable[[], Any], GlobalsHelper().tokenizer),\r\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/llama_index/utils.py\", line 55, in tokenizer\r\n  enc = tiktoken.get_encoding(\"gpt2\")\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/tiktoken/registry.py\", line 73, in get_encoding\r\n  enc = Encoding(**constructor())\r\n                   ^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/tiktoken_ext/openai_public.py\", line 11, in gpt2\r\n  mergeable_ranks = data_gym_to_mergeable_bpe_ranks(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/tiktoken/load.py\", line 82, in data_gym_to_mergeable_bpe_ranks\r\n  vocab_bpe_contents = read_file_cached(vocab_bpe_file).decode()\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/tiktoken/load.py\", line 50, in read_file_cached\r\n  contents = read_file(blobpath)\r\n             ^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/tiktoken/load.py\", line 24, in read_file\r\n  resp = requests.get(blobpath)\r\n         ^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/requests/api.py\", line 73, in get\r\n  return request(\"get\", url, params=params, **kwargs)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/requests/api.py\", line 59, in request\r\n  return session.request(method=method, url=url, **kwargs)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\r\n  resp = self.send(prep, **send_kwargs)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\r\n  r = adapter.send(request, **kwargs)\r\n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/usr/local/lib/python3.11/site-packages/requests/adapters.py\", line 507, in send\r\n  raise ConnectTimeout(e, request=request)\r\nrequests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/encodings/main/vocab.bpe (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f0c8803b350>, 'Connection to openaipublic.blob.core.windows.net timed out. (connect timeout=None)'))\r\n```\r\n\r\n</details>\r\n\r\nSince for this application I'm only using the embeddings and no chat, therefore I managed to \"fix\" this by rewriting the `GlobalsHelper.tokenizer` method to just return `None`, so that `tiktoken.get_encoding(\"gpt2\")` is no longer called. I also had to use `set_global_tokenizer(..)` to prevent another network timeout later on.\r\n\r\nIt would be nice if this use case worked out of the box without me having to modify the library.\n\n### Value of Feature\n\nOur use case is that we want to search across documents that shouldn't leave our internal network. While I don't believe that the llama_index library will leak any information on purpose, we believe it's best to add additional safety measures, just in case any of the libraries in the dependency tree suddenly hit a bug or receive a malicious update.\r\n\r\nBeing able to run completely offline is also a feature that would enhance user trust in the library, and as such I believe that this is a feature that you could then prominently advertise in the readme and on the website of the library, once the necessary changes have been made. From what I've seen, it also seems like the required changes shouldn't be too massive.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9343/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9343/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9342",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9342/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9342/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9342/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9342",
        "id": 2028322318,
        "node_id": "I_kwDOIWuq58545b4O",
        "number": 9342,
        "title": "[Bug]: Empty Messages OpenAI Error",
        "user": {
            "login": "Daniel199438",
            "id": 16019073,
            "node_id": "MDQ6VXNlcjE2MDE5MDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/16019073?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Daniel199438",
            "html_url": "https://github.com/Daniel199438",
            "followers_url": "https://api.github.com/users/Daniel199438/followers",
            "following_url": "https://api.github.com/users/Daniel199438/following{/other_user}",
            "gists_url": "https://api.github.com/users/Daniel199438/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Daniel199438/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Daniel199438/subscriptions",
            "organizations_url": "https://api.github.com/users/Daniel199438/orgs",
            "repos_url": "https://api.github.com/users/Daniel199438/repos",
            "events_url": "https://api.github.com/users/Daniel199438/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Daniel199438/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-12-06T11:21:44Z",
        "updated_at": "2023-12-06T12:58:04Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI get an error message after a successful call history of a LlamaHub tool and probably a response or summary to my prompt following error message\n\n### Version\n\n0.9.12\n\n### Steps to Reproduce\n\nExecute this code: \r\n\r\n` \r\n\r\n    gmail_client = GmailToolSpec()\r\n    gmail_client.set_credentials(delegated_credentials)\r\n    # gmail_client.load_data()\r\n        \r\n     gmail_tools = gmail_client.to_tool_list()\r\n    # gcal_tools = GoogleCalendarToolSpec().to_tool_list()\r\n\r\n    print(\"Wrapping gmail \" + gmail_tools[0].metadata.name)\r\n    gmail_load_and_search_tools = LoadAndSearchToolSpec.from_defaults(\r\n        gmail_tools[0],\r\n    ).to_tool_list()\r\n\r\n    all_tools = [\r\n        *gmail_load_and_search_tools,\r\n        *gmail_tools[1::],\r\n    ]\r\n\r\n    agent = OpenAIAgent.from_tools(all_tools, verbose=True)\r\n\r\n    agent.chat(question)\r\n\r\n`\n\n### Relevant Logs/Tracbacks\n\n```shell\nSTARTING TURN 3\r\n---------------\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ONEWORX\\Documents\\AutoGen Test\\app.py\", line 125, in <module>\r\n    print(answer_gmail_questions(\"Kannst du mir meine letzten 5 Mails zusammenfassen?\"))\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\Documents\\AutoGen Test\\gmail.py\", line 65, in answer_gmail_questions\r\n    agent.chat(question)\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\callbacks\\utils.py\", line 39, in wrapper\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\agent\\openai_agent.py\", line 438, in chat\r\n    chat_response = self._chat(\r\n                    ^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\agent\\openai_agent.py\", line 360, in _chat\r\n    agent_chat_response = self._get_agent_response(mode=mode, **llm_chat_kwargs)\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\agent\\openai_agent.py\", line 322, in _get_agent_response\r\n    chat_response: ChatResponse = self._llm.chat(**llm_chat_kwargs)\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\llms\\base.py\", line 187, in wrapped_llm_chat\r\n    f_return_val = f(_self, messages, **kwargs)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\llms\\openai.py\", line 220, in chat\r\n    return chat_fn(messages, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\llama_index\\llms\\openai.py\", line 275, in _chat\r\n    response = client.chat.completions.create(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 301, in wrapper\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 598, in create\r\n    return self._post(\r\n           ^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\openai\\_base_client.py\", line 1096, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\openai\\_base_client.py\", line 856, in request\r\n    return self._request(\r\n           ^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\ONEWORX\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\openai\\_base_client.py\", line 908, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"[] is too short - 'messages'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9342/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9342/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9341",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9341/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9341/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9341/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9341",
        "id": 2028165610,
        "node_id": "PR_kwDOIWuq585hSKJF",
        "number": 9341,
        "title": "add Ollama Embedding class",
        "user": {
            "login": "chnsagitchen",
            "id": 34412583,
            "node_id": "MDQ6VXNlcjM0NDEyNTgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/34412583?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/chnsagitchen",
            "html_url": "https://github.com/chnsagitchen",
            "followers_url": "https://api.github.com/users/chnsagitchen/followers",
            "following_url": "https://api.github.com/users/chnsagitchen/following{/other_user}",
            "gists_url": "https://api.github.com/users/chnsagitchen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/chnsagitchen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/chnsagitchen/subscriptions",
            "organizations_url": "https://api.github.com/users/chnsagitchen/orgs",
            "repos_url": "https://api.github.com/users/chnsagitchen/repos",
            "events_url": "https://api.github.com/users/chnsagitchen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/chnsagitchen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-12-06T09:55:07Z",
        "updated_at": "2023-12-07T03:51:27Z",
        "closed_at": "2023-12-07T03:51:27Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9341",
            "html_url": "https://github.com/run-llama/llama_index/pull/9341",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9341.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9341.patch",
            "merged_at": "2023-12-07T03:51:27Z"
        },
        "body": "# Description\r\n\r\nAdd Ollama embedding class for generate embedding for query or document in local with Ollama\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n- [ ] I test  the implementation with my local Ollama service\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9341/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9341/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9340",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9340/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9340/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9340/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9340",
        "id": 2028151608,
        "node_id": "I_kwDOIWuq58544yM4",
        "number": 9340,
        "title": "[Documentation]: Chroma VectorStore mypy error",
        "user": {
            "login": "mroedder-d7",
            "id": 129860311,
            "node_id": "U_kgDOB72C1w",
            "avatar_url": "https://avatars.githubusercontent.com/u/129860311?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mroedder-d7",
            "html_url": "https://github.com/mroedder-d7",
            "followers_url": "https://api.github.com/users/mroedder-d7/followers",
            "following_url": "https://api.github.com/users/mroedder-d7/following{/other_user}",
            "gists_url": "https://api.github.com/users/mroedder-d7/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mroedder-d7/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mroedder-d7/subscriptions",
            "organizations_url": "https://api.github.com/users/mroedder-d7/orgs",
            "repos_url": "https://api.github.com/users/mroedder-d7/repos",
            "events_url": "https://api.github.com/users/mroedder-d7/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mroedder-d7/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-12-06T09:47:22Z",
        "updated_at": "2023-12-07T21:15:16Z",
        "closed_at": "2023-12-07T21:15:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nhttps://docs.llamaindex.ai/en/stable/examples/vector_stores/ChromaIndexDemo.html\r\n\r\nMypy 1.7.1 complains:\r\n```\r\nArgument \"vector_store\" to \"from_defaults\" of \"StorageContext\" has incompatible type \"ChromaVectorStore\"; expected \"VectorStore | None\"\r\n```\n\n### Documentation Link\n\nhttps://docs.llamaindex.ai/en/stable/examples/vector_stores/ChromaIndexDemo.html",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9340/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9340/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9339",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9339/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9339/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9339/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9339",
        "id": 2028023700,
        "node_id": "I_kwDOIWuq58544S-U",
        "number": 9339,
        "title": "[Bug]: Llama index Guidance for Sub-Question Query Engine",
        "user": {
            "login": "xHeler",
            "id": 53053071,
            "node_id": "MDQ6VXNlcjUzMDUzMDcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/53053071?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xHeler",
            "html_url": "https://github.com/xHeler",
            "followers_url": "https://api.github.com/users/xHeler/followers",
            "following_url": "https://api.github.com/users/xHeler/following{/other_user}",
            "gists_url": "https://api.github.com/users/xHeler/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xHeler/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xHeler/subscriptions",
            "organizations_url": "https://api.github.com/users/xHeler/orgs",
            "repos_url": "https://api.github.com/users/xHeler/repos",
            "events_url": "https://api.github.com/users/xHeler/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xHeler/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-12-06T08:35:38Z",
        "updated_at": "2023-12-11T09:20:45Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nGuidence package with the newest version throwing an error with openai library.\r\nVersion of guidance 0.0.64.\r\nVersion of llamaindex 0.9.12\r\n\n\n### Version\n\n0.9.12\n\n### Steps to Reproduce\n\nJust try to run our google colab example:\r\nhttps://docs.llamaindex.ai/en/latest/examples/output_parsing/guidance_sub_question.html#\n\n### Relevant Logs/Tracbacks\n\n```shell\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/llms/_openai.py\", line 665, in __call__\r\n    out = await self.llm.caller(**call_args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/llms/_openai.py\", line 348, in _library_call\r\n    prev_base = openai.api_base\r\nAttributeError: module 'openai' has no attribute 'api_base'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 109, in run\r\n    await self.visit(self.parse_tree, VariableStack([self.program._variables], self))\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 559, in visit\r\n    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 524, in visit\r\n    command_output = await command_function(*positional_args, **named_args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/library/_geneach.py\", line 119, in geneach\r\n    new_content += await parser.visit(\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 559, in visit\r\n    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 559, in visit\r\n    visited_children.append(await self.visit(child, variable_stack, inner_next_node, inner_next_next_node, inner_prev_node, node, parent_node))\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 266, in visit\r\n    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 266, in <listcomp>\r\n    visited_children = [await self.visit(child, variable_stack, next_node, next_next_node, prev_node, node, parent_node) for child in node]\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/_program_executor.py\", line 379, in visit\r\n    command_output = await command_function(*positional_args, **named_args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/library/_gen.py\", line 140, in gen\r\n    gen_obj = await parser.llm_session(\r\n  File \"/usr/local/lib/python3.10/dist-packages/guidance/llms/_openai.py\", line 667, in __call__\r\n    except openai.error.RateLimitError:\r\nAttributeError: module 'openai' has no attribute 'error'\r\n\r\nError in program:  module 'openai' has no attribute 'error'\r\n---------------------------------------------------------------------------\r\nJSONDecodeError                           Traceback (most recent call last)\r\n/usr/local/lib/python3.10/dist-packages/llama_index/output_parsers/utils.py in parse_json_markdown(text)\r\n     44     try:\r\n---> 45         json_obj = json.loads(json_string)\r\n     46     except json.JSONDecodeError as e_json:\r\n\r\n22 frames\r\nJSONDecodeError: Expecting property name enclosed in double quotes: line 2 column 14 (char 15)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nParserError                               Traceback (most recent call last)\r\nParserError: while parsing a flow mapping\r\n  in \"<unicode string>\", line 2, column 13:\r\n      \"items\": [{#geneach 'items' stop=']'}{#unl ... \r\n                ^\r\nexpected ',' or '}', but got '<scalar>'\r\n  in \"<unicode string>\", line 3, column 47:\r\n     ... n\": \"{gen 'sub_question' stop='\"'}\",\r\n                                         ^\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nOutputParserException                     Traceback (most recent call last)\r\nOutputParserException: Got invalid JSON object. Error: Expecting property name enclosed in double quotes: line 2 column 14 (char 15) while parsing a flow mapping\r\n  in \"<unicode string>\", line 2, column 13:\r\n      \"items\": [{#geneach 'items' stop=']'}{#unl ... \r\n                ^\r\nexpected ',' or '}', but got '<scalar>'\r\n  in \"<unicode string>\", line 3, column 47:\r\n     ... n\": \"{gen 'sub_question' stop='\"'}\",\r\n                                         ^. Got JSON string: {\r\n  \"items\": [{#geneach 'items' stop=']'}{#unless @first}, {/unless}{\r\n  \"sub_question\": \"{gen 'sub_question' stop='\"'}\",\r\n  \"tool_name\": \"{gen 'tool_name' stop='\"'}\",\r\n}{/geneach}],\r\n}\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nOutputParserException                     Traceback (most recent call last)\r\n/usr/local/lib/python3.10/dist-packages/llama_index/prompts/guidance_utils.py in parse_pydantic_from_guidance_program(program, cls, verbose)\r\n    150         sub_questions = cls.parse_obj(json_dict)\r\n    151     except Exception as e:\r\n--> 152         raise OutputParserException(\r\n    153             \"Failed to parse pydantic object from guidance program\"\r\n    154         ) from e\r\n\r\nOutputParserException: Failed to parse pydantic object from guidance program\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9339/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9339/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9338",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9338/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9338/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9338/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9338",
        "id": 2027974244,
        "node_id": "I_kwDOIWuq58544G5k",
        "number": 9338,
        "title": "[Bug]: docstore and SentenceSplitter result in duplicate source nodes",
        "user": {
            "login": "stdweird",
            "id": 1517606,
            "node_id": "MDQ6VXNlcjE1MTc2MDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1517606?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stdweird",
            "html_url": "https://github.com/stdweird",
            "followers_url": "https://api.github.com/users/stdweird/followers",
            "following_url": "https://api.github.com/users/stdweird/following{/other_user}",
            "gists_url": "https://api.github.com/users/stdweird/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stdweird/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stdweird/subscriptions",
            "organizations_url": "https://api.github.com/users/stdweird/orgs",
            "repos_url": "https://api.github.com/users/stdweird/repos",
            "events_url": "https://api.github.com/users/stdweird/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stdweird/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T08:15:47Z",
        "updated_at": "2023-12-06T08:23:22Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWe are trying to setup an ingestion pipeline with a vectorstore and a docstore to trigger the upsert/skip magic of the nodes produced via a SentenceSplitter ran on multiple documents. the documents have a custom `id_` similar to the `filename_as_id` in `SimpleDirectoryReader.load_data` for easy reprocessing. but the nodes that come out of the splitter have a regular uuid `id_`.\r\n\r\nthis gives following issue: some of the identical splitted nodes get inserted multiple times on reprocessing, and with the uuid doc `id_` they are not detectable with the `_dedup_results` function in the postgres vectorstore. from a quick glance it looks like these are typically the everythig-except-the-first splitted node(s) when a document is actually split. for some reason, the first node is handled ok. (but this is first impression)\r\n\r\nas a fix, we would like to be able to also customise the node `id_`, similar to the document id, eg doing a `<ref_doc_id_>_nodepart_<idx>` in the SentenceSplitter/node parser. this would fix the issue, and similar to the document `id_` make it safe to reprocess the documents with the docstore magic in place.\r\n\r\nhowever, this will also cause another issue: when the document is split in the same or more number of nodes, everything is ok (the node id - hash comparison will trigger upserts if needed) . but for a document that gets split in fewer nodes (say X nodes), the vectorstore (and docstore) will still contain nodes with `<ref_doc._id_>_nodepart_<idx>` with `idx > X`. not sure how the docstore is supposed to handle that cleanup.\n\n### Version\n\nlatest 0.9.12\n\n### Steps to Reproduce\n\nworking on an easy reproducer\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9338/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9338/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9337",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9337/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9337/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9337/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9337",
        "id": 2027967231,
        "node_id": "I_kwDOIWuq58544FL_",
        "number": 9337,
        "title": "[Question]:  How to increase the performance of extracting triples from words by using Knowledge Graph Index",
        "user": {
            "login": "nttng207",
            "id": 82324319,
            "node_id": "MDQ6VXNlcjgyMzI0MzE5",
            "avatar_url": "https://avatars.githubusercontent.com/u/82324319?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nttng207",
            "html_url": "https://github.com/nttng207",
            "followers_url": "https://api.github.com/users/nttng207/followers",
            "following_url": "https://api.github.com/users/nttng207/following{/other_user}",
            "gists_url": "https://api.github.com/users/nttng207/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nttng207/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nttng207/subscriptions",
            "organizations_url": "https://api.github.com/users/nttng207/orgs",
            "repos_url": "https://api.github.com/users/nttng207/repos",
            "events_url": "https://api.github.com/users/nttng207/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nttng207/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T08:13:39Z",
        "updated_at": "2023-12-06T08:21:57Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI tried increasing the max triplet per chunk but it just took longer to get the index but query performance didn't improve much. Is there any solution to this problem?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9337/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9337/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9336",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9336/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9336/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9336/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9336",
        "id": 2027849366,
        "node_id": "I_kwDOIWuq58543oaW",
        "number": 9336,
        "title": "[Question]: How to add a new relationship to a persisted knowledge graph?",
        "user": {
            "login": "JinSeoung-Oh",
            "id": 78573459,
            "node_id": "MDQ6VXNlcjc4NTczNDU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/78573459?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JinSeoung-Oh",
            "html_url": "https://github.com/JinSeoung-Oh",
            "followers_url": "https://api.github.com/users/JinSeoung-Oh/followers",
            "following_url": "https://api.github.com/users/JinSeoung-Oh/following{/other_user}",
            "gists_url": "https://api.github.com/users/JinSeoung-Oh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JinSeoung-Oh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JinSeoung-Oh/subscriptions",
            "organizations_url": "https://api.github.com/users/JinSeoung-Oh/orgs",
            "repos_url": "https://api.github.com/users/JinSeoung-Oh/repos",
            "events_url": "https://api.github.com/users/JinSeoung-Oh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JinSeoung-Oh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 20,
        "created_at": "2023-12-06T07:26:29Z",
        "updated_at": "2023-12-13T04:23:43Z",
        "closed_at": "2023-12-13T04:21:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi, on this time, I want to add new relationship to a persisted KnowledgeGraph\r\nIt is easy to find about VectorDB, but about KnowledgeGraph is so hard.\r\n\r\nI already know how to add new relationship to knowledgeGraphIndex class, but I cannot find \r\nhow to add new relationship to a persisted KG\r\n\r\nTo load persisted KG, I used this code\r\n\r\nstorage_context = StorageContext.from_defaults(\r\n    docstore = SimpleDocumentStore.from_persist_dir(persist_dir=os.getcwd() + \"/kg/graph/test\"),\r\n    vector_store = SimpleVectorStore.from_persist_dir(persist_dir=os.getcwd() + \"/kg/graph/test\"),\r\n    index_store = SimpleIndexStore.from_persist_dir(persist_dir=os.getcwd() + \"/kg/graph/test\"))\r\n\r\nfrom llama_index import load_index_from_storage, load_indices_from_storage, load_graph_from_storage\r\n\r\nindex = load_index_from_storage(storage_context)\r\nindices = load_indices_from_storage(storage_context)\r\ngraph = load_graph_from_storage(storage_context)\r\n\r\nCan I apply upsert method on index? or graph?\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9336/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9336/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9335",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9335/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9335/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9335/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9335",
        "id": 2027518113,
        "node_id": "I_kwDOIWuq58542Xih",
        "number": 9335,
        "title": "[Feature Request]:  Can support memgraph for graph indexing",
        "user": {
            "login": "kingle-zhuang",
            "id": 142277746,
            "node_id": "U_kgDOCHr8cg",
            "avatar_url": "https://avatars.githubusercontent.com/u/142277746?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kingle-zhuang",
            "html_url": "https://github.com/kingle-zhuang",
            "followers_url": "https://api.github.com/users/kingle-zhuang/followers",
            "following_url": "https://api.github.com/users/kingle-zhuang/following{/other_user}",
            "gists_url": "https://api.github.com/users/kingle-zhuang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kingle-zhuang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kingle-zhuang/subscriptions",
            "organizations_url": "https://api.github.com/users/kingle-zhuang/orgs",
            "repos_url": "https://api.github.com/users/kingle-zhuang/repos",
            "events_url": "https://api.github.com/users/kingle-zhuang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kingle-zhuang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-06T02:20:50Z",
        "updated_at": "2023-12-06T02:29:06Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nmemgraph is high performance then others, so maybe we can support it\n\n### Reason\n\nhigh performance low cost, compatible with neo4j\n\n### Value of Feature\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9335/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9335/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9334",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9334/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9334/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9334/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/9334",
        "id": 2027288264,
        "node_id": "I_kwDOIWuq58541fbI",
        "number": 9334,
        "title": "[Question]: Add TextNode metadata to help Retriever ",
        "user": {
            "login": "snassimr",
            "id": 6830626,
            "node_id": "MDQ6VXNlcjY4MzA2MjY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6830626?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/snassimr",
            "html_url": "https://github.com/snassimr",
            "followers_url": "https://api.github.com/users/snassimr/followers",
            "following_url": "https://api.github.com/users/snassimr/following{/other_user}",
            "gists_url": "https://api.github.com/users/snassimr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/snassimr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/snassimr/subscriptions",
            "organizations_url": "https://api.github.com/users/snassimr/orgs",
            "repos_url": "https://api.github.com/users/snassimr/repos",
            "events_url": "https://api.github.com/users/snassimr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/snassimr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-12-05T23:10:28Z",
        "updated_at": "2023-12-06T03:27:54Z",
        "closed_at": "2023-12-06T03:27:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi ,\r\n\r\nI wonder if it's possible to append some metadata that would appended to TextNode's text during search.\r\n\r\nI suppose including this metadata will help retriever greatly.\r\n\r\nI can't rely on Document metadata provided by PDF parser . Actually , I want similar functionality for Nodes\r\n\r\nThanks,\r\nNissim",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9334/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9334/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9333",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9333/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9333/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9333/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9333",
        "id": 2027269884,
        "node_id": "PR_kwDOIWuq585hPH8h",
        "number": 9333,
        "title": "Make OpenAIAgent compatible with OpenAILike",
        "user": {
            "login": "wdhorton",
            "id": 13503072,
            "node_id": "MDQ6VXNlcjEzNTAzMDcy",
            "avatar_url": "https://avatars.githubusercontent.com/u/13503072?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wdhorton",
            "html_url": "https://github.com/wdhorton",
            "followers_url": "https://api.github.com/users/wdhorton/followers",
            "following_url": "https://api.github.com/users/wdhorton/following{/other_user}",
            "gists_url": "https://api.github.com/users/wdhorton/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wdhorton/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wdhorton/subscriptions",
            "organizations_url": "https://api.github.com/users/wdhorton/orgs",
            "repos_url": "https://api.github.com/users/wdhorton/repos",
            "events_url": "https://api.github.com/users/wdhorton/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wdhorton/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-12-05T22:51:15Z",
        "updated_at": "2023-12-05T22:56:20Z",
        "closed_at": "2023-12-05T22:56:19Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9333",
            "html_url": "https://github.com/run-llama/llama_index/pull/9333",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9333.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9333.patch",
            "merged_at": "2023-12-05T22:56:19Z"
        },
        "body": "# Description\r\n\r\nI was using an OpenAILike LLM that supports function calling, but it was failing because this line depends specifically on certain OpenAI model names. It looks like `llm.metadata.is_function_calling_model` should be preferred for this check now, and it resolves the issue I was having.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9333/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9333/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9332",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9332/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9332/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9332/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9332",
        "id": 2027117685,
        "node_id": "PR_kwDOIWuq585hOl-C",
        "number": 9332,
        "title": "LabeledRagDataset strategies for reducing RateLimitError from openai",
        "user": {
            "login": "nerdai",
            "id": 92402603,
            "node_id": "U_kgDOBYHzqw",
            "avatar_url": "https://avatars.githubusercontent.com/u/92402603?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nerdai",
            "html_url": "https://github.com/nerdai",
            "followers_url": "https://api.github.com/users/nerdai/followers",
            "following_url": "https://api.github.com/users/nerdai/following{/other_user}",
            "gists_url": "https://api.github.com/users/nerdai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nerdai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nerdai/subscriptions",
            "organizations_url": "https://api.github.com/users/nerdai/orgs",
            "repos_url": "https://api.github.com/users/nerdai/repos",
            "events_url": "https://api.github.com/users/nerdai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nerdai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710946,
                "node_id": "LA_kwDOIWuq588AAAABc3-fIg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:L",
                "name": "size:L",
                "color": "eb9500",
                "default": false,
                "description": "This PR changes 100-499 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-05T21:03:08Z",
        "updated_at": "2023-12-06T15:57:36Z",
        "closed_at": "2023-12-06T15:57:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9332",
            "html_url": "https://github.com/run-llama/llama_index/pull/9332",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9332.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9332.patch",
            "merged_at": "2023-12-06T15:57:35Z"
        },
        "body": "# Description\r\n\r\n- add prediction caching when making predictions on a `LabelledRagDataset`\r\n- adds `batch_size` and `sleep_time_in_seconds` params for strategies to slow down openai api calls and reduce RateLimitError \r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9332/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9332/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9331",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9331/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9331/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9331/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9331",
        "id": 2027084973,
        "node_id": "PR_kwDOIWuq585hOeyJ",
        "number": 9331,
        "title": "Init Image Query Engine for MultiModal",
        "user": {
            "login": "hatianzhang",
            "id": 2142132,
            "node_id": "MDQ6VXNlcjIxNDIxMzI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2142132?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hatianzhang",
            "html_url": "https://github.com/hatianzhang",
            "followers_url": "https://api.github.com/users/hatianzhang/followers",
            "following_url": "https://api.github.com/users/hatianzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/hatianzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hatianzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hatianzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/hatianzhang/orgs",
            "repos_url": "https://api.github.com/users/hatianzhang/repos",
            "events_url": "https://api.github.com/users/hatianzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hatianzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6225900672,
                "node_id": "LA_kwDOIWuq588AAAABcxe0gA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/lgtm",
                "name": "lgtm",
                "color": "238636",
                "default": false,
                "description": "This PR has been approved by a maintainer"
            },
            {
                "id": 6232710935,
                "node_id": "LA_kwDOIWuq588AAAABc3-fFw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:M",
                "name": "size:M",
                "color": "ebb800",
                "default": false,
                "description": "This PR changes 30-99 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-05T20:39:35Z",
        "updated_at": "2023-12-05T22:32:33Z",
        "closed_at": "2023-12-05T22:32:32Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9331",
            "html_url": "https://github.com/run-llama/llama_index/pull/9331",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9331.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9331.patch",
            "merged_at": "2023-12-05T22:32:32Z"
        },
        "body": "# Description\r\n\r\nUsing Image as input query to synthesis final results\r\n\r\nUsage: \r\n```\r\nfrom llama_index.multi_modal_llms.openai import OpenAIMultiModal\r\nfrom llama_index import SimpleDirectoryReader\r\nfrom llama_index.schema import ImageDocument\r\nfrom llama_index.prompts import PromptTemplate\r\n\r\n\r\nqa_tmpl_str = (\r\n    \"Given the images provided, \"\r\n    \"answer the query.\\n\"\r\n    \"Query: {query_str}\\n\"\r\n    \"Answer: \"\r\n)\r\n\r\nqa_tmpl = PromptTemplate(qa_tmpl_str)\r\n\r\n\r\nopenai_mm_llm = OpenAIMultiModal(\r\n    model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500\r\n)\r\n\r\nquery_engine = index.as_query_engine(\r\n    multi_modal_llm=openai_mm_llm, image_qa_template=qa_tmpl\r\n)\r\n\r\nquery_str = \"Tell me more about the Van Gogh painting. \"\r\nresponse = query_engine.image_query(\"./mixed_wiki/2.jpg\", query_str)\r\n```\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] I have added Google Colab support for the newly added notebooks.\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n- [ ] I ran `make format; make lint` to appease the lint gods\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9331/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9331/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9330",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9330/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9330/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9330/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9330",
        "id": 2027024709,
        "node_id": "PR_kwDOIWuq585hORdK",
        "number": 9330,
        "title": "update savepath name for FAISS",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710919,
                "node_id": "LA_kwDOIWuq588AAAABc3-fBw",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:S",
                "name": "size:S",
                "color": "77b800",
                "default": false,
                "description": "This PR changes 10-29 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-05T20:01:48Z",
        "updated_at": "2023-12-05T20:08:29Z",
        "closed_at": "2023-12-05T20:08:28Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9330",
            "html_url": "https://github.com/run-llama/llama_index/pull/9330",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9330.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9330.patch",
            "merged_at": "2023-12-05T20:08:28Z"
        },
        "body": "# Description\r\n\r\nFaiss vector store was not using the correct default vector store name.\r\n\r\nFixes https://github.com/run-llama/llama_index/issues/9110\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9330/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9330/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9329",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9329/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9329/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9329/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9329",
        "id": 2027001432,
        "node_id": "PR_kwDOIWuq585hOMNV",
        "number": 9329,
        "title": "fix another comma",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-05T19:48:34Z",
        "updated_at": "2023-12-05T19:48:42Z",
        "closed_at": "2023-12-05T19:48:41Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9329",
            "html_url": "https://github.com/run-llama/llama_index/pull/9329",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9329.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9329.patch",
            "merged_at": "2023-12-05T19:48:41Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9329/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9329/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9328",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9328/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9328/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9328/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9328",
        "id": 2026989335,
        "node_id": "PR_kwDOIWuq585hOJjc",
        "number": 9328,
        "title": "remove comma",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-12-05T19:39:53Z",
        "updated_at": "2023-12-05T19:40:17Z",
        "closed_at": "2023-12-05T19:40:16Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9328",
            "html_url": "https://github.com/run-llama/llama_index/pull/9328",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9328.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9328.patch",
            "merged_at": "2023-12-05T19:40:16Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9328/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9328/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/9327",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/9327/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/9327/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/9327/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/9327",
        "id": 2026969715,
        "node_id": "PR_kwDOIWuq585hOFR9",
        "number": 9327,
        "title": "add badge to gdrive notebook ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6232710905,
                "node_id": "LA_kwDOIWuq588AAAABc3-e-Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/size:XS",
                "name": "size:XS",
                "color": "00ff00",
                "default": false,
                "description": "This PR changes 0-9 lines, ignoring generated files."
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-12-05T19:26:14Z",
        "updated_at": "2023-12-05T19:35:00Z",
        "closed_at": "2023-12-05T19:34:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/9327",
            "html_url": "https://github.com/run-llama/llama_index/pull/9327",
            "diff_url": "https://github.com/run-llama/llama_index/pull/9327.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/9327.patch",
            "merged_at": "2023-12-05T19:34:59Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/9327/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/9327/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]