[
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/255",
        "id": 1620222114,
        "node_id": "I_kwDOG1WDQc5gkqCi",
        "number": 255,
        "title": "[Chatllama] Supervised Finetune on LLaMA-7B",
        "user": {
            "login": "cmnfriend",
            "id": 45878717,
            "node_id": "MDQ6VXNlcjQ1ODc4NzE3",
            "avatar_url": "https://avatars.githubusercontent.com/u/45878717?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cmnfriend",
            "html_url": "https://github.com/cmnfriend",
            "followers_url": "https://api.github.com/users/cmnfriend/followers",
            "following_url": "https://api.github.com/users/cmnfriend/following{/other_user}",
            "gists_url": "https://api.github.com/users/cmnfriend/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cmnfriend/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cmnfriend/subscriptions",
            "organizations_url": "https://api.github.com/users/cmnfriend/orgs",
            "repos_url": "https://api.github.com/users/cmnfriend/repos",
            "events_url": "https://api.github.com/users/cmnfriend/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cmnfriend/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 29,
        "created_at": "2023-03-12T03:37:13Z",
        "updated_at": "2023-03-17T05:06:13Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "**I tried** `python main.py artifacts/config/config_uie.yaml --type ACTOR` **with the SHP dataset, but got nan loss.**\r\n\r\n![1](https://user-images.githubusercontent.com/45878717/224522208-7c9e42bc-ec8f-4825-adf5-d5a3a5dd29fc.jpg)\r\n\r\n**Here is my** `config_uie.yaml`**. The other parts (trainer_config, reward_config, critic_config) are the same with the original**  `config.yaml`**. Could you please tell me how I can fix this problem? Thank you! :)**\r\n\r\n```\r\nactor_config:\r\n  model: \"llama-7B\"\r\n  model_path: \"/root/InstructUIE/run_llama/llama/7B\"\r\n  checkpoint_folder: \"/root/InstructUIE/run_llama/llama/7B/checkpoints\"\r\n  tokenizer_folder: \"/root/InstructUIE/run_llama/llama/tokenizer.model\"\r\n  train_dataset_path: \"./datasets/actor_training_data.json\"\r\n  validation_dataset_path: null\r\n  froze_embeddings: True\r\n  use_fairscale: True\r\n  max_sequence_length: 1024\r\n  max_tokens: 512\r\n  temperature: 0.8\r\n  batch_size: 1\r\n  iteration_per_print: 1\r\n  lr: 0.00001\r\n  epochs: 3\r\n  deepspeed_enable: False\r\n  deepspeed_config_path: \"/root/InstructUIE/ds_configs/stage2_llama.config\"\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/255/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/254",
        "id": 1620166247,
        "node_id": "I_kwDOG1WDQc5gkcZn",
        "number": 254,
        "title": "[Chatllama]: MultiGPU support for training",
        "user": {
            "login": "TejaGollapudi",
            "id": 20994488,
            "node_id": "MDQ6VXNlcjIwOTk0NDg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/20994488?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TejaGollapudi",
            "html_url": "https://github.com/TejaGollapudi",
            "followers_url": "https://api.github.com/users/TejaGollapudi/followers",
            "following_url": "https://api.github.com/users/TejaGollapudi/following{/other_user}",
            "gists_url": "https://api.github.com/users/TejaGollapudi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TejaGollapudi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TejaGollapudi/subscriptions",
            "organizations_url": "https://api.github.com/users/TejaGollapudi/orgs",
            "repos_url": "https://api.github.com/users/TejaGollapudi/repos",
            "events_url": "https://api.github.com/users/TejaGollapudi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TejaGollapudi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-03-11T22:35:17Z",
        "updated_at": "2023-04-04T10:09:21Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I'm trying to train the actor model (BLOOM 1.5B) on a multi-GPU setup (3-V100s).\r\n When I observe the GPU usage, only the GPU:0 is utilized and I run out of memory if I increase the batch_size.\r\n\r\nCould you add multi-GPU support using HuggingFace's accelerate to facilitate the training of larger models with a larger batch size?\r\n\r\nThank you",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/254/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/253",
        "id": 1620061694,
        "node_id": "PR_kwDOG1WDQc5L0pd9",
        "number": 253,
        "title": "[Chatllama] fix embedding out of bounds",
        "user": {
            "login": "HuangLK",
            "id": 3390197,
            "node_id": "MDQ6VXNlcjMzOTAxOTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3390197?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/HuangLK",
            "html_url": "https://github.com/HuangLK",
            "followers_url": "https://api.github.com/users/HuangLK/followers",
            "following_url": "https://api.github.com/users/HuangLK/following{/other_user}",
            "gists_url": "https://api.github.com/users/HuangLK/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/HuangLK/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/HuangLK/subscriptions",
            "organizations_url": "https://api.github.com/users/HuangLK/orgs",
            "repos_url": "https://api.github.com/users/HuangLK/repos",
            "events_url": "https://api.github.com/users/HuangLK/events{/privacy}",
            "received_events_url": "https://api.github.com/users/HuangLK/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-03-11T16:12:44Z",
        "updated_at": "2023-03-20T10:46:13Z",
        "closed_at": "2023-03-14T13:27:09Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/253",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/253",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/253.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/253.patch",
            "merged_at": "2023-03-14T13:27:09Z"
        },
        "body": "while token_id is -1, embedding will cause out of bounds.\r\nhttps://github.com/nebuly-ai/nebullvm/blob/ca085a979b5b596bf0ecd477e4c4deff3725661c/apps/accelerate/chatllama/chatllama/llama_model.py#L482\r\n\r\npartial error message:\r\n```plain\r\n/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [120,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize\r\n` failed.\r\n/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [120,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize\r\n` failed.\r\n/opt/conda/conda-bld/pytorch_1659484808560/work/aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [120,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize\r\n` failed.\r\n\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 1,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/253/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/252",
        "id": 1620035777,
        "node_id": "I_kwDOG1WDQc5gj8jB",
        "number": 252,
        "title": "[Chatllama]: How to train llama-7B with multiple GPU?",
        "user": {
            "login": "bnuzhanyu",
            "id": 21094531,
            "node_id": "MDQ6VXNlcjIxMDk0NTMx",
            "avatar_url": "https://avatars.githubusercontent.com/u/21094531?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bnuzhanyu",
            "html_url": "https://github.com/bnuzhanyu",
            "followers_url": "https://api.github.com/users/bnuzhanyu/followers",
            "following_url": "https://api.github.com/users/bnuzhanyu/following{/other_user}",
            "gists_url": "https://api.github.com/users/bnuzhanyu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bnuzhanyu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bnuzhanyu/subscriptions",
            "organizations_url": "https://api.github.com/users/bnuzhanyu/orgs",
            "repos_url": "https://api.github.com/users/bnuzhanyu/repos",
            "events_url": "https://api.github.com/users/bnuzhanyu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bnuzhanyu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-11T14:45:17Z",
        "updated_at": "2023-03-14T09:53:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I downloaded the llama-7B model which MP=1.\r\nI modified the config:\r\nactor_config:\r\n  device: \"cuda:1,2,5,7\"\r\n  model: \"llama-7B\"\r\n\r\nI tried: `torchrun --nproc_per_node=4 artifacts/main.py artifacts/config/config.yaml --type ACTOR` \r\nand get: AssertionError: Loading a checkpoint for MP=1 but world size is 4.\r\n\r\nI tried: `python artifacts/main.py artifacts/config/config.yaml`\r\nIt seems it use cuda:0, and out of cuda memory.\r\n\r\nSo, I have two questions:\r\n1. how can I train models with multiple GPU?\r\n2. Is llama-7B can be trained on multiple GPU?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/252/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/251",
        "id": 1620021451,
        "node_id": "I_kwDOG1WDQc5gj5DL",
        "number": 251,
        "title": "[Chatllama] Actor training for GPT2 while using deepspeed",
        "user": {
            "login": "Yottaxx",
            "id": 44809630,
            "node_id": "MDQ6VXNlcjQ0ODA5NjMw",
            "avatar_url": "https://avatars.githubusercontent.com/u/44809630?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Yottaxx",
            "html_url": "https://github.com/Yottaxx",
            "followers_url": "https://api.github.com/users/Yottaxx/followers",
            "following_url": "https://api.github.com/users/Yottaxx/following{/other_user}",
            "gists_url": "https://api.github.com/users/Yottaxx/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Yottaxx/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Yottaxx/subscriptions",
            "organizations_url": "https://api.github.com/users/Yottaxx/orgs",
            "repos_url": "https://api.github.com/users/Yottaxx/repos",
            "events_url": "https://api.github.com/users/Yottaxx/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Yottaxx/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-03-11T14:24:48Z",
        "updated_at": "2023-03-23T10:36:15Z",
        "closed_at": "2023-03-23T10:36:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When deepspeed is not used, it can run normally, but once deepspeed is used, the following error will appear.\r\n\r\n\r\npython3 artifacts/main.py artifacts/config/config.yaml --type=ACTOR\r\n\r\nCurrent device used :cuda\r\n[2023-03-11 22:21:18,832] [INFO] [logging.py:77:log_dist] [Rank -1] DeepSpeed info: version=0.8.2, git-hash=unknown, git-branch=unknown\r\n[2023-03-11 22:21:18,833] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\r\n[2023-03-11 22:21:19,066] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.108.17.77, master_port=29500\r\n[2023-03-11 22:21:19,067] [INFO] [comm.py:661:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\r\n[2023-03-11 22:21:19,069] [WARNING] [config.py:54:read_zero_config_deprecated] DeepSpeedConfig: this format of ZeRO optimization setup is deprecated. Please use the following format: \r\nZeRO optimization should be enabled as:\r\n\"session_params\": {\r\n  \"zero_optimization\": {\r\n    \"stage\": [0|1|2],\r\n    \"stage3_max_live_parameters\" : 1000000000,\r\n    \"stage3_max_reuse_distance\" : 1000000000,\r\n    \"allgather_partitions\": [true|false],\r\n    \"allgather_bucket_size\": 500000000,\r\n    \"reduce_scatter\": [true|false],\r\n    \"contiguous_gradients\" : [true|false]\r\n    \"overlap_comm\": [true|false],\r\n    \"reduce_bucket_size\": 500000000,\r\n    \"load_from_fp32_weights\": [true|false],\r\n    \"cpu_offload\": [true|false] (deprecated),\r\n    \"cpu_offload_params\" : [true|false] (deprecated),\r\n    \"cpu_offload_use_pin_memory\": [true|false] (deprecated),\r\n    \"sub_group_size\" : 1000000000000,\r\n    \"offload_param\": {...},\r\n    \"offload_optimizer\": {...},\r\n    \"ignore_unused_parameters\": [true|false],\r\n    \"round_robin_gradients\": [true|false]\r\n    }\r\n}\r\n\r\n[2023-03-11 22:21:19,243] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\r\nInstalled CUDA version 11.1 does not match the version torch was compiled with 11.3 but since the APIs are compatible, accepting this combination\r\nUsing /home/zx/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...\r\nDetected CUDA files, patching ldflags\r\nEmitting ninja build file /home/zx/.cache/torch_extensions/py38_cu113/fused_adam/build.ninja...\r\nBuilding extension module fused_adam...\r\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\nninja: no work to do.\r\nLoading extension module fused_adam...\r\nTime to load fused_adam op: 0.4941389560699463 seconds\r\n[2023-03-11 22:21:20,495] [INFO] [logging.py:77:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\r\n[2023-03-11 22:21:20,501] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\r\n[2023-03-11 22:21:20,501] [INFO] [logging.py:77:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\r\n[2023-03-11 22:21:20,516] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\r\n[2023-03-11 22:21:20,517] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed using client LR scheduler\r\n[2023-03-11 22:21:20,517] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\r\n[2023-03-11 22:21:20,517] [INFO] [logging.py:77:log_dist] [Rank 0] step=0, skipped=0, lr=[0.00015], mom=[(0.9, 0.999)]\r\n[2023-03-11 22:21:20,517] [INFO] [config.py:1010:print] DeepSpeedEngine configuration:\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   activation_checkpointing_config  {\r\n    \"partition_activations\": false, \r\n    \"contiguous_memory_optimization\": false, \r\n    \"cpu_checkpointing\": false, \r\n    \"number_checkpoints\": null, \r\n    \"synchronize_checkpoint_boundary\": false, \r\n    \"profile\": false\r\n}\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   amp_enabled .................. False\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   amp_params ................... False\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   autotuning_config ............ {\r\n    \"enabled\": false, \r\n    \"start_step\": null, \r\n    \"end_step\": null, \r\n    \"metric_path\": null, \r\n    \"arg_mappings\": null, \r\n    \"metric\": \"throughput\", \r\n    \"model_info\": null, \r\n    \"results_dir\": \"autotuning_results\", \r\n    \"exps_dir\": \"autotuning_exps\", \r\n    \"overwrite\": true, \r\n    \"fast\": true, \r\n    \"start_profile_step\": 3, \r\n    \"end_profile_step\": 5, \r\n    \"tuner_type\": \"gridsearch\", \r\n    \"tuner_early_stopping\": 5, \r\n    \"tuner_num_trials\": 50, \r\n    \"model_info_path\": null, \r\n    \"mp_size\": 1, \r\n    \"max_train_batch_size\": null, \r\n    \"min_train_batch_size\": 1, \r\n    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \r\n    \"min_train_micro_batch_size_per_gpu\": 1, \r\n    \"num_tuning_micro_batch_sizes\": 3\r\n}\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   bfloat16_enabled ............. False\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   checkpoint_parallel_write_pipeline  False\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   checkpoint_tag_validation_enabled  True\r\n[2023-03-11 22:21:20,518] [INFO] [config.py:1014:print]   checkpoint_tag_validation_fail  False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9ff98b3880>\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   communication_data_type ...... None\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   curriculum_enabled_legacy .... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   curriculum_params_legacy ..... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   data_efficiency_enabled ...... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   dataloader_drop_last ......... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   disable_allgather ............ False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   dump_state ................... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   dynamic_loss_scale_args ...... None\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_enabled ........... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_gas_boundary_resolution  1\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_layer_name ........ bert.encoder.layer\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_layer_num ......... 0\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_max_iter .......... 100\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_stability ......... 1e-06\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_tol ............... 0.01\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   eigenvalue_verbose ........... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   elasticity_enabled ........... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   flops_profiler_config ........ {\r\n    \"enabled\": false, \r\n    \"profile_step\": 1, \r\n    \"module_depth\": -1, \r\n    \"top_modules\": 1, \r\n    \"detailed\": true, \r\n    \"output_file\": null\r\n}\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   fp16_auto_cast ............... False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   fp16_enabled ................. True\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   fp16_master_weights_and_gradients  False\r\n[2023-03-11 22:21:20,519] [INFO] [config.py:1014:print]   global_rank .................. 0\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   grad_accum_dtype ............. None\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   gradient_accumulation_steps .. 1\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   gradient_clipping ............ 0.0\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   gradient_predivide_factor .... 1.0\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   initial_dynamic_scale ........ 65536\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   load_universal_checkpoint .... False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   loss_scale ................... 0\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   memory_breakdown ............. False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   nebula_config ................ {\r\n    \"enabled\": false, \r\n    \"persistent_storage_path\": null, \r\n    \"persistent_time_interval\": 100, \r\n    \"num_of_version_in_retention\": 2, \r\n    \"enable_nebula_load\": true, \r\n    \"load_path\": null\r\n}\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   optimizer_legacy_fusion ...... False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   optimizer_name ............... adam\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   optimizer_params ............. {'lr': 0.00015}\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   pld_enabled .................. False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   pld_params ................... False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   prescale_gradients ........... False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   scheduler_name ............... None\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   scheduler_params ............. None\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   sparse_attention ............. None\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   sparse_gradients_enabled ..... False\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   steps_per_print .............. 10\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   train_batch_size ............. 8\r\n[2023-03-11 22:21:20,520] [INFO] [config.py:1014:print]   train_micro_batch_size_per_gpu  8\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   use_node_local_storage ....... False\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   wall_clock_breakdown ......... False\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   world_size ................... 1\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   zero_allow_untested_optimizer  False\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   zero_enabled ................. False\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:1014:print]   zero_optimization_stage ...... 0\r\n[2023-03-11 22:21:20,521] [INFO] [config.py:999:print_user_config]   json = {\r\n    \"train_batch_size\": 8, \r\n    \"gradient_accumulation_steps\": 1, \r\n    \"optimizer\": {\r\n        \"type\": \"Adam\", \r\n        \"params\": {\r\n            \"lr\": 0.00015\r\n        }\r\n    }, \r\n    \"fp16\": {\r\n        \"enabled\": true\r\n    }, \r\n    \"zero_optimization\": false\r\n}\r\nUsing /home/zx/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...\r\nEmitting ninja build file /home/zx/.cache/torch_extensions/py38_cu113/utils/build.ninja...\r\nBuilding extension module utils...\r\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\nninja: no work to do.\r\nLoading extension module utils...\r\nTime to load utils op: 0.6288671493530273 seconds\r\nStart Actor Model Pretraining\r\n[2023-03-11 22:21:22,680] [INFO] [fused_optimizer.py:383:_update_scale] \r\nGrad overflow on iteration 0\r\n[2023-03-11 22:21:22,680] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0\r\n[2023-03-11 22:21:22,680] [INFO] [logging.py:77:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0\r\nEpoch: 1/32, Iteration: 1/367127, Training Loss: 7.484375\r\n[2023-03-11 22:21:22,833] [INFO] [fused_optimizer.py:383:_update_scale] \r\nGrad overflow on iteration 1\r\n[2023-03-11 22:21:22,833] [INFO] [fused_optimizer.py:384:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\r\n[2023-03-11 22:21:22,833] [INFO] [logging.py:77:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\r\nEpoch: 1/32, Iteration: 2/367127, Training Loss: 7.1875\r\nToken indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [276,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [148,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [102,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\nTraceback (most recent call last):\r\n  File \"artifacts/main.py\", line 58, in <module>\r\n    actor_trainer.train()\r\n  File \"/home/zx/experiments/nebullvm/apps/accelerate/chatllama/artifacts/chatllamaCore/rlhf/actor.py\", line 379, in train\r\n    est_output = self.model_engine(\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/deepspeed/utils/nvtx.py\", line 11, in wrapped_fn\r\n    ret_val = func(*args, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/deepspeed/runtime/engine.py\", line 1832, in forward\r\n    loss = self.module(*inputs, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"<@beartype(chatllamaCore.rlhf.actor.ActorModel.forward) at 0x7fa00594b0d0>\", line 51, in forward\r\n  File \"/home/zx/experiments/nebullvm/apps/accelerate/chatllama/artifacts/chatllamaCore/rlhf/actor.py\", line 120, in forward\r\n    model_output = self.model.forward(\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1043, in forward\r\n    transformer_outputs = self.transformer(\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 887, in forward\r\n    outputs = block(\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 388, in forward\r\n    attn_outputs = self.attn(\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 329, in forward\r\n    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\r\n  File \"/home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 199, in _attn\r\n    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\r\nRuntimeError: CUDA error: device-side assert triggered\r\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\nterminate called after throwing an instance of 'c10::Error'\r\n  what():  NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:173, unhandled cuda error, NCCL version 2.10.3\r\nProcess Group destroyed on rank 0\r\nException raised from ncclCommAbort at ../torch/csrc/distributed/c10d/NCCLUtils.hpp:173 (most recent call first):\r\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x3e (0x7fa00e9e11ee in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libc10.so)\r\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x5c (0x7fa00e9bc5e8 in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libc10.so)\r\nframe #2: <unknown function> + 0x1c0291 (0x7fa05133c291 in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so)\r\nframe #3: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0x118 (0x7fa05131fad8 in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so)\r\nframe #4: c10d::ProcessGroupNCCL::~ProcessGroupNCCL() + 0x9 (0x7fa05131fda9 in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_cuda_cpp.so)\r\nframe #5: <unknown function> + 0x9b8beb (0x7fa060b2ebeb in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\r\nframe #6: <unknown function> + 0x36658f (0x7fa0604dc58f in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\r\nframe #7: <unknown function> + 0x36747f (0x7fa0604dd47f in /home/zx/anaconda3/envs/gpt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)\r\nframe #8: python3() [0x4d398e]\r\nframe #9: python3() [0x4f96b6]\r\nframe #10: python3() [0x4d398e]\r\nframe #11: python3() [0x4f96b6]\r\nframe #12: python3() [0x4d398e]\r\nframe #13: python3() [0x5a70db]\r\nframe #14: python3() [0x4ccae4]\r\n<omitting python frames>\r\nframe #19: __libc_start_main + 0xf3 (0x7fa07a47b0b3 in /lib/x86_64-linux-gnu/libc.so.6)\r\nframe #20: python3() [0x579c8d]\r\n\r\nAborted (core dumped)\r\n\r\n\r\n`\r\nactor_config:\r\n  model: \"gpt2\"\r\n  model_path: \"path-to-model\"\r\n  checkpoint_folder: \"./models\"\r\n  tokenizer_folder: \"path-to-tokenizer\"\r\n  train_dataset_path: \"./datasets/actor_training_data.json\"\r\n  validation_dataset_path: null\r\n  froze_embeddings: True\r\n  use_fairscale: False\r\n  max_sequence_length: 512\r\n  max_tokens: 512\r\n  temperature: 0.9\r\n  batch_size: 1\r\n  iteration_per_print: 1\r\n  lr: 0.0001\r\n  epochs: 32\r\n  deepspeed_enable: True\r\n  deepspeed_config_path: \"/home/zx/experiments/nebullvm/apps/accelerate/chatllama/artifacts/config/ds_config.json\"\r\n\r\n\r\nds_config\r\n{\r\n    \"train_batch_size\": 8,\r\n    \"gradient_accumulation_steps\": 1,\r\n    \"optimizer\": {\r\n      \"type\": \"Adam\",\r\n      \"params\": {\r\n        \"lr\": 0.00015\r\n      }\r\n    },\r\n    \"fp16\": {\r\n      \"enabled\": true\r\n    },\r\n    \"zero_optimization\": false\r\n  }\r\n`",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/251/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/250",
        "id": 1620011789,
        "node_id": "PR_kwDOG1WDQc5L0fhD",
        "number": 250,
        "title": "[Chatllama] fix sign error of entropy bonus",
        "user": {
            "login": "HuangLK",
            "id": 3390197,
            "node_id": "MDQ6VXNlcjMzOTAxOTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3390197?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/HuangLK",
            "html_url": "https://github.com/HuangLK",
            "followers_url": "https://api.github.com/users/HuangLK/followers",
            "following_url": "https://api.github.com/users/HuangLK/following{/other_user}",
            "gists_url": "https://api.github.com/users/HuangLK/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/HuangLK/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/HuangLK/subscriptions",
            "organizations_url": "https://api.github.com/users/HuangLK/orgs",
            "repos_url": "https://api.github.com/users/HuangLK/repos",
            "events_url": "https://api.github.com/users/HuangLK/events{/privacy}",
            "received_events_url": "https://api.github.com/users/HuangLK/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-11T13:56:20Z",
        "updated_at": "2023-03-20T13:01:21Z",
        "closed_at": "2023-03-20T13:01:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/250",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/250",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/250.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/250.patch",
            "merged_at": null
        },
        "body": "#247 fix the sign error for maximizing entropy bonus.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/250/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/249",
        "id": 1620009982,
        "node_id": "PR_kwDOG1WDQc5L0fLs",
        "number": 249,
        "title": "[chatllama] Fix model load and save. ",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-11T13:49:48Z",
        "updated_at": "2023-03-13T11:58:10Z",
        "closed_at": "2023-03-13T11:58:10Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/249",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/249",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/249.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/249.patch",
            "merged_at": "2023-03-13T11:58:10Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/249/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/248",
        "id": 1619927788,
        "node_id": "PR_kwDOG1WDQc5L0P51",
        "number": 248,
        "title": "[Speedster] Fix #239",
        "user": {
            "login": "Telemaco019",
            "id": 24567368,
            "node_id": "MDQ6VXNlcjI0NTY3MzY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/24567368?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Telemaco019",
            "html_url": "https://github.com/Telemaco019",
            "followers_url": "https://api.github.com/users/Telemaco019/followers",
            "following_url": "https://api.github.com/users/Telemaco019/following{/other_user}",
            "gists_url": "https://api.github.com/users/Telemaco019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Telemaco019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Telemaco019/subscriptions",
            "organizations_url": "https://api.github.com/users/Telemaco019/orgs",
            "repos_url": "https://api.github.com/users/Telemaco019/repos",
            "events_url": "https://api.github.com/users/Telemaco019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Telemaco019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-11T08:15:04Z",
        "updated_at": "2023-04-14T07:54:11Z",
        "closed_at": "2023-04-14T07:54:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/248",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/248",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/248.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/248.patch",
            "merged_at": null
        },
        "body": "Fix #239 - raise ValueError if input_data is empty or model is None",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/248/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/247",
        "id": 1619924183,
        "node_id": "I_kwDOG1WDQc5gjhTX",
        "number": 247,
        "title": "[Chatllama]why use entropy as a part of loss",
        "user": {
            "login": "HuangLK",
            "id": 3390197,
            "node_id": "MDQ6VXNlcjMzOTAxOTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3390197?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/HuangLK",
            "html_url": "https://github.com/HuangLK",
            "followers_url": "https://api.github.com/users/HuangLK/followers",
            "following_url": "https://api.github.com/users/HuangLK/following{/other_user}",
            "gists_url": "https://api.github.com/users/HuangLK/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/HuangLK/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/HuangLK/subscriptions",
            "organizations_url": "https://api.github.com/users/HuangLK/orgs",
            "repos_url": "https://api.github.com/users/HuangLK/repos",
            "events_url": "https://api.github.com/users/HuangLK/events{/privacy}",
            "received_events_url": "https://api.github.com/users/HuangLK/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-11T07:59:38Z",
        "updated_at": "2023-03-14T09:53:45Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "@PierpaoloSorbellini Hi, I\u2019m confused about the policy loss in RLHF. Does it mean to minimize the entropy while updating the policy? If so, could you please refer me to some related algorithms/papers for further understanding? \r\nThanks for the great work.\r\n\r\nhttps://github.com/nebuly-ai/nebullvm/blob/ca085a979b5b596bf0ecd477e4c4deff3725661c/apps/accelerate/chatllama/chatllama/rlhf/trainer.py#L491-L516",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/247/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/246",
        "id": 1619844118,
        "node_id": "I_kwDOG1WDQc5gjNwW",
        "number": 246,
        "title": "Struggle with training LLaMA with a single GPU using both PT v1 and v2",
        "user": {
            "login": "linhduongtuan",
            "id": 22388092,
            "node_id": "MDQ6VXNlcjIyMzg4MDky",
            "avatar_url": "https://avatars.githubusercontent.com/u/22388092?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/linhduongtuan",
            "html_url": "https://github.com/linhduongtuan",
            "followers_url": "https://api.github.com/users/linhduongtuan/followers",
            "following_url": "https://api.github.com/users/linhduongtuan/following{/other_user}",
            "gists_url": "https://api.github.com/users/linhduongtuan/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/linhduongtuan/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/linhduongtuan/subscriptions",
            "organizations_url": "https://api.github.com/users/linhduongtuan/orgs",
            "repos_url": "https://api.github.com/users/linhduongtuan/repos",
            "events_url": "https://api.github.com/users/linhduongtuan/events{/privacy}",
            "received_events_url": "https://api.github.com/users/linhduongtuan/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-03-11T02:26:16Z",
        "updated_at": "2023-03-14T08:46:18Z",
        "closed_at": "2023-03-14T08:46:18Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Dear Nebuly,\r\nI love your code base and want to try how to train the LLaMA with a single GPU. This code I use is here https://github.com/nebuly-ai/nebullvm/blob/main/apps/accelerate/chatllama/chatllama/llama_model.py, and set ModelArgs: 'use_fairscale: bool = False' \r\nHowever, I struggle with an error. This message's shown that:\r\n\"\r\n    self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\r\n  File \"/home/linh/anaconda3/envs/a/lib/python3.9/site-packages/torch/nn/modules/sparse.py\", line 139, in __init__\r\n    self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs))\r\nRuntimeError: Trying to create tensor with negative dimension -1: [-1, 512]\r\n\"\r\nCan you help me to fix/test this code again.\r\n\r\nThank in advance.\r\nLinh",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/246/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/245",
        "id": 1619782075,
        "node_id": "I_kwDOG1WDQc5gi-m7",
        "number": 245,
        "title": "[Chatllama] Training Reward Model on Human Preference Data",
        "user": {
            "login": "TonyZhanghm",
            "id": 32423612,
            "node_id": "MDQ6VXNlcjMyNDIzNjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/32423612?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TonyZhanghm",
            "html_url": "https://github.com/TonyZhanghm",
            "followers_url": "https://api.github.com/users/TonyZhanghm/followers",
            "following_url": "https://api.github.com/users/TonyZhanghm/following{/other_user}",
            "gists_url": "https://api.github.com/users/TonyZhanghm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TonyZhanghm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TonyZhanghm/subscriptions",
            "organizations_url": "https://api.github.com/users/TonyZhanghm/orgs",
            "repos_url": "https://api.github.com/users/TonyZhanghm/repos",
            "events_url": "https://api.github.com/users/TonyZhanghm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TonyZhanghm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-03-11T00:04:47Z",
        "updated_at": "2023-03-16T04:06:27Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi! Is there a specific reason that we train the reward model based on absolute scores rather than pairwise human preferences on the same prompts, as most of the other rlhf work?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/245/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/244",
        "id": 1619752862,
        "node_id": "I_kwDOG1WDQc5gi3ee",
        "number": 244,
        "title": "[Chatllama] Supervised Finetune on llama-7B",
        "user": {
            "login": "TonyZhanghm",
            "id": 32423612,
            "node_id": "MDQ6VXNlcjMyNDIzNjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/32423612?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TonyZhanghm",
            "html_url": "https://github.com/TonyZhanghm",
            "followers_url": "https://api.github.com/users/TonyZhanghm/followers",
            "following_url": "https://api.github.com/users/TonyZhanghm/following{/other_user}",
            "gists_url": "https://api.github.com/users/TonyZhanghm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TonyZhanghm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TonyZhanghm/subscriptions",
            "organizations_url": "https://api.github.com/users/TonyZhanghm/orgs",
            "repos_url": "https://api.github.com/users/TonyZhanghm/repos",
            "events_url": "https://api.github.com/users/TonyZhanghm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TonyZhanghm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2023-03-10T23:30:03Z",
        "updated_at": "2023-03-16T11:31:34Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi! I downloaded the SHP dataset and was trying to run the actor training. I ran into several issues here with vanilla python, torchrun, and deepspeed. ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/244/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/243",
        "id": 1618682662,
        "node_id": "I_kwDOG1WDQc5geyMm",
        "number": 243,
        "title": "[Chatllama] Input/completion in reward training vs. RL training",
        "user": {
            "login": "menandro",
            "id": 14872148,
            "node_id": "MDQ6VXNlcjE0ODcyMTQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/14872148?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/menandro",
            "html_url": "https://github.com/menandro",
            "followers_url": "https://api.github.com/users/menandro/followers",
            "following_url": "https://api.github.com/users/menandro/following{/other_user}",
            "gists_url": "https://api.github.com/users/menandro/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/menandro/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/menandro/subscriptions",
            "organizations_url": "https://api.github.com/users/menandro/orgs",
            "repos_url": "https://api.github.com/users/menandro/repos",
            "events_url": "https://api.github.com/users/menandro/events{/privacy}",
            "received_events_url": "https://api.github.com/users/menandro/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-10T09:59:10Z",
        "updated_at": "2023-03-23T10:34:26Z",
        "closed_at": "2023-03-23T10:34:25Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Why is it in reward training, the input and completion is appended as:\r\n`user_input + \" \" + completion` (reward.py line 254)\r\nwhere as in RL training, the equivalent task_response is:\r\n`input + \"\\n\" + completion` (trainer.py line 680)? ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/243/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/242",
        "id": 1618553568,
        "node_id": "I_kwDOG1WDQc5geSrg",
        "number": 242,
        "title": "[Chatllama] Actor training for llama-7b",
        "user": {
            "login": "tqjack",
            "id": 38412243,
            "node_id": "MDQ6VXNlcjM4NDEyMjQz",
            "avatar_url": "https://avatars.githubusercontent.com/u/38412243?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tqjack",
            "html_url": "https://github.com/tqjack",
            "followers_url": "https://api.github.com/users/tqjack/followers",
            "following_url": "https://api.github.com/users/tqjack/following{/other_user}",
            "gists_url": "https://api.github.com/users/tqjack/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tqjack/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tqjack/subscriptions",
            "organizations_url": "https://api.github.com/users/tqjack/orgs",
            "repos_url": "https://api.github.com/users/tqjack/repos",
            "events_url": "https://api.github.com/users/tqjack/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tqjack/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-10T08:21:01Z",
        "updated_at": "2023-03-14T09:51:03Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hello all,\r\nSince the project has supported deepspeed, can you provide training script and detail deepspeed config file? I am trying to do actor training using a 3090 GPU 24 VRAM by command `deepspeed artifacts/main.py artifacts/config/config.yaml --type=ACTOR` and it didn't work. I expect deepspeed can help to offload the full model state to CPU. By the way, is it possible I can train llama-7b with multiple GPUs?\r\n\r\noutput is like:\r\n[2023-03-10 08:15:49,649] [WARNING] [runner.py:186:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\r\nDetected CUDA_VISIBLE_DEVICES=2: setting --include=localhost:2\r\n[2023-03-10 08:15:49,715] [INFO] [runner.py:548:main] cmd = /usr/local/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMl19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None artifacts/main.py artifacts/config/config.yaml --type=ACTOR\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.16.2-1+cuda11.8\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.16.2-1\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.16.2-1\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.16.2-1+cuda11.8\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.16.2-1\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [2]}\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:162:main] dist_world_size=1\r\n[2023-03-10 08:15:51,874] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=2\r\nCurrent device used :cuda\r\nlocal_rank: 0 world_size: 1\r\n> initializing model parallel with size 1\r\n> initializing ddp with size 1\r\n> initializing pipeline with size 1\r\nLoading\r\n[2023-03-10 08:16:08,124] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown\r\n[2023-03-10 08:16:08,199] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\r\nInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\r\nUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...\r\nDetected CUDA files, patching ldflags\r\nEmitting ninja build file /root/.cache/torch_extensions/py38_cu117/cpu_adam/build.ninja...\r\nBuilding extension module cpu_adam...\r\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\nninja: no work to do.\r\nLoading extension module cpu_adam...\r\nTime to load cpu_adam op: 3.182528018951416 seconds\r\nAdam Optimizer #0 is created with AVX512 arithmetic capability.\r\nConfig: alpha=0.000150, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\r\n[2023-03-10 08:16:15,024] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer\r\n[2023-03-10 08:16:15,041] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\r\n[2023-03-10 08:16:15,041] [INFO] [utils.py:52:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\r\n[2023-03-10 08:16:15,041] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\r\n[2023-03-10 08:16:15,154] [INFO] [utils.py:831:see_memory_usage] Stage 3 initialize beginning\r\n[2023-03-10 08:16:15,155] [INFO] [utils.py:832:see_memory_usage] MA 13.55 GB         Max_MA 13.55 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:15,155] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 39.31 GB, percent = 6.2%\r\n[2023-03-10 08:16:15,158] [INFO] [stage3.py:114:__init__] Reduce bucket size 10000000\r\n[2023-03-10 08:16:15,158] [INFO] [stage3.py:115:__init__] Prefetch bucket size 10000000\r\nUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...\r\nEmitting ninja build file /root/.cache/torch_extensions/py38_cu117/utils/build.ninja...\r\nBuilding extension module utils...\r\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\r\nninja: no work to do.\r\nLoading extension module utils...\r\nTime to load utils op: 0.6208884716033936 seconds\r\n[2023-03-10 08:16:15,888] [INFO] [utils.py:831:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\r\n[2023-03-10 08:16:15,889] [INFO] [utils.py:832:see_memory_usage] MA 13.55 GB         Max_MA 13.55 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:15,890] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 39.38 GB, percent = 6.3%\r\nParameter Offload: Total persistent parameters: 266240 in 65 params\r\n[2023-03-10 08:16:24,363] [INFO] [utils.py:831:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\r\n[2023-03-10 08:16:24,364] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 13.55 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:24,364] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 51.89 GB, percent = 8.2%\r\n[2023-03-10 08:16:24,431] [INFO] [utils.py:831:see_memory_usage] Before creating fp16 partitions\r\n[2023-03-10 08:16:24,432] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:24,432] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 51.89 GB, percent = 8.2%\r\n[2023-03-10 08:16:32,470] [INFO] [utils.py:831:see_memory_usage] After creating fp16 partitions: 7\r\n[2023-03-10 08:16:32,471] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:32,471] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 55.88 GB, percent = 8.9%\r\n[2023-03-10 08:16:32,535] [INFO] [utils.py:831:see_memory_usage] Before creating fp32 partitions\r\n[2023-03-10 08:16:32,535] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:32,536] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 55.87 GB, percent = 8.9%\r\n[2023-03-10 08:16:35,983] [INFO] [utils.py:831:see_memory_usage] After creating fp32 partitions\r\n[2023-03-10 08:16:35,983] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:35,984] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 80.59 GB, percent = 12.8%\r\n[2023-03-10 08:16:36,040] [INFO] [utils.py:831:see_memory_usage] Before initializing optimizer states\r\n[2023-03-10 08:16:36,041] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:36,041] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 80.6 GB, percent = 12.8%\r\n[2023-03-10 08:16:44,680] [INFO] [utils.py:831:see_memory_usage] After initializing optimizer states\r\n[2023-03-10 08:16:44,680] [INFO] [utils.py:832:see_memory_usage] MA 1.0 GB         Max_MA 1.0 GB         CA 13.8 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:44,681] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 154.52 GB, percent = 24.5%\r\n[2023-03-10 08:16:44,681] [INFO] [stage3.py:382:_setup_for_real_optimizer] optimizer state initialized\r\n[2023-03-10 08:16:46,710] [INFO] [utils.py:831:see_memory_usage] After initializing ZeRO optimizer\r\n[2023-03-10 08:16:46,710] [INFO] [utils.py:832:see_memory_usage] MA 1.02 GB         Max_MA 1.51 GB         CA 14.05 GB         Max_CA 14 GB\r\n[2023-03-10 08:16:46,711] [INFO] [utils.py:840:see_memory_usage] CPU Virtual Memory:  used = 166.85 GB, percent = 26.5%\r\n[2023-03-10 08:16:46,711] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\r\n[2023-03-10 08:16:46,711] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler\r\n[2023-03-10 08:16:46,711] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\r\n[2023-03-10 08:16:46,711] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.00015], mom=[(0.9, 0.999)]\r\n[2023-03-10 08:16:46,712] [INFO] [config.py:1008:print] DeepSpeedEngine configuration:\r\n[2023-03-10 08:16:46,712] [INFO] [config.py:1012:print]   activation_checkpointing_config  {\r\n    \"partition_activations\": false,\r\n    \"contiguous_memory_optimization\": false,\r\n    \"cpu_checkpointing\": false,\r\n    \"number_checkpoints\": null,\r\n    \"synchronize_checkpoint_boundary\": false,\r\n    \"profile\": false\r\n}\r\n[2023-03-10 08:16:46,712] [INFO] [config.py:1012:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\r\n[2023-03-10 08:16:46,712] [INFO] [config.py:1012:print]   amp_enabled .................. False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   amp_params ................... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   autotuning_config ............ {\r\n    \"enabled\": false,\r\n    \"start_step\": null,\r\n    \"end_step\": null,\r\n    \"metric_path\": null,\r\n    \"arg_mappings\": null,\r\n    \"metric\": \"throughput\",\r\n    \"model_info\": null,\r\n    \"results_dir\": \"autotuning_results\",\r\n    \"exps_dir\": \"autotuning_exps\",\r\n    \"overwrite\": true,\r\n    \"fast\": true,\r\n    \"start_profile_step\": 3,\r\n    \"end_profile_step\": 5,\r\n    \"tuner_type\": \"gridsearch\",\r\n    \"tuner_early_stopping\": 5,\r\n    \"tuner_num_trials\": 50,\r\n    \"model_info_path\": null,\r\n    \"mp_size\": 1,\r\n    \"max_train_batch_size\": null,\r\n    \"min_train_batch_size\": 1,\r\n    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03,\r\n    \"min_train_micro_batch_size_per_gpu\": 1,\r\n    \"num_tuning_micro_batch_sizes\": 3\r\n}\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   bfloat16_enabled ............. False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   checkpoint_parallel_write_pipeline  False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   checkpoint_tag_validation_enabled  True\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   checkpoint_tag_validation_fail  False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa9bad81040>\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   communication_data_type ...... None\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   curriculum_enabled_legacy .... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   curriculum_params_legacy ..... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   data_efficiency_enabled ...... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   dataloader_drop_last ......... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   disable_allgather ............ False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   dump_state ................... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   dynamic_loss_scale_args ...... None\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   eigenvalue_enabled ........... False\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   eigenvalue_gas_boundary_resolution  1\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   eigenvalue_layer_name ........ bert.encoder.layer\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   eigenvalue_layer_num ......... 0\r\n[2023-03-10 08:16:46,713] [INFO] [config.py:1012:print]   eigenvalue_max_iter .......... 100\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   eigenvalue_stability ......... 1e-06\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   eigenvalue_tol ............... 0.01\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   eigenvalue_verbose ........... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   elasticity_enabled ........... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   flops_profiler_config ........ {\r\n    \"enabled\": false,\r\n    \"profile_step\": 1,\r\n    \"module_depth\": -1,\r\n    \"top_modules\": 1,\r\n    \"detailed\": true,\r\n    \"output_file\": null\r\n}\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   fp16_auto_cast ............... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   fp16_enabled ................. True\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   fp16_master_weights_and_gradients  False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   global_rank .................. 0\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   grad_accum_dtype ............. None\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   gradient_accumulation_steps .. 1\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   gradient_clipping ............ 0.0\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   gradient_predivide_factor .... 1.0\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   initial_dynamic_scale ........ 65536\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   load_universal_checkpoint .... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   loss_scale ................... 0\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   memory_breakdown ............. False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fa9bad77f40>\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   nebula_config ................ {\r\n    \"enabled\": false,\r\n    \"persistent_storage_path\": null,\r\n    \"persistent_time_interval\": 100,\r\n    \"num_of_version_in_retention\": 2,\r\n    \"enable_nebula_load\": true,\r\n    \"load_path\": null\r\n}\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   optimizer_legacy_fusion ...... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   optimizer_name ............... adam\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   optimizer_params ............. {'lr': 0.00015}\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   pld_enabled .................. False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   pld_params ................... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   prescale_gradients ........... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   scheduler_name ............... None\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   scheduler_params ............. None\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   sparse_attention ............. None\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   sparse_gradients_enabled ..... False\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   steps_per_print .............. 10\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   train_batch_size ............. 8\r\n[2023-03-10 08:16:46,714] [INFO] [config.py:1012:print]   train_micro_batch_size_per_gpu  8\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   use_node_local_storage ....... False\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   wall_clock_breakdown ......... False\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   world_size ................... 1\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   zero_allow_untested_optimizer  False\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=10000000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=10000000 param_persistence_threshold=100000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   zero_enabled ................. True\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:1012:print]   zero_optimization_stage ...... 3\r\n[2023-03-10 08:16:46,715] [INFO] [config.py:997:print_user_config]   json = {\r\n    \"train_batch_size\": 8,\r\n    \"gradient_accumulation_steps\": 1,\r\n    \"optimizer\": {\r\n        \"type\": \"Adam\",\r\n        \"params\": {\r\n            \"lr\": 0.00015\r\n        }\r\n    },\r\n    \"fp16\": {\r\n        \"enabled\": true\r\n    },\r\n    \"zero_optimization\": {\r\n        \"stage\": 3,\r\n        \"contiguous_gradients\": true,\r\n        \"stage3_max_live_parameters\": 1.000000e+09,\r\n        \"stage3_max_reuse_distance\": 1.000000e+09,\r\n        \"stage3_prefetch_bucket_size\": 1.000000e+07,\r\n        \"stage3_param_persistence_threshold\": 1.000000e+05,\r\n        \"reduce_bucket_size\": 1.000000e+07,\r\n        \"sub_group_size\": 1.000000e+09,\r\n        \"offload_optimizer\": {\r\n            \"device\": \"cpu\"\r\n        },\r\n        \"offload_param\": {\r\n            \"device\": \"cpu\"\r\n        }\r\n    }\r\n}\r\nUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...\r\nNo modifications detected for re-loaded extension module utils, skipping build step...\r\nLoading extension module utils...\r\nTime to load utils op: 0.0004918575286865234 seconds\r\nStart Actor Model Pretraining\r\n/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"artifacts/main.py\", line 56, in <module>\r\n    actor_trainer.train()\r\n  File \"/chatllama/chatllama/rlhf/actor.py\", line 379, in train\r\n    est_output = self.model_engine(\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/deepspeed/utils/nvtx.py\", line 11, in wrapped_fn\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/deepspeed/runtime/engine.py\", line 1836, in forward\r\n    loss = self.module(*inputs, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\r\n    result = forward_call(*input, **kwargs)\r\n  File \"<@beartype(chatllama.rlhf.actor.ActorModel.forward) at 0x7fa9c74578b0>\", line 51, in forward\r\n  File \"/chatllama/chatllama/rlhf/actor.py\", line 120, in forward\r\n    model_output = self.model.forward(\r\n  File \"/chatllama/chatllama/llama_model.py\", line 475, in forward\r\n    logits = self._forward(tokens, attention_mask)\r\n  File \"/chatllama/chatllama/llama_model.py\", line 508, in _forward\r\n    h, _, _ = layer(h, kv_mask, freqs_cis)\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\r\n    result = forward_call(*input, **kwargs)\r\n  File \"/chatllama/chatllama/llama_model.py\", line 402, in forward\r\n    attn, cache_k, cache_v = self.attention.forward(\r\n  File \"/chatllama/chatllama/llama_model.py\", line 282, in forward\r\n    xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\r\n    result = forward_call(*input, **kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\nRuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\r\n[2023-03-10 08:17:03,966] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 62980\r\n[2023-03-10 08:17:03,967] [ERROR] [launch.py:324:sigkill_handler] ['/usr/local/bin/python', '-u', 'artifacts/main.py', '--local_rank=0', 'artifacts/config/config.yaml', '--type=ACTOR'] exits with return code = 1\r\n\r\n\r\nactor_config\r\n```\r\n  model: \"llama-7B\"\r\n  model_path: \"./7B\"\r\n  checkpoint_folder: \"./models\"\r\n  tokenizer_folder: \"./tokenizer.model\"\r\n  train_dataset_path: \"./datasets/actor_training_data.json\"\r\n  validation_dataset_path: null\r\n  froze_embeddings: True\r\n  use_fairscale: True\r\n  max_sequence_length: 1024\r\n  max_tokens: 512\r\n  temperature: 0.9\r\n  batch_size: 1\r\n  iteration_per_print: 1\r\n  lr: 0.0001\r\n  epochs: 32\r\n  deepspeed_enable: True\r\n  deepspeed_config_path: \"./artifacts/config/ds_config.json\"\r\n```\r\nds_config.json\r\n```\r\n{\r\n    \"train_batch_size\": 8,\r\n    \"gradient_accumulation_steps\": 1,\r\n    \"optimizer\": {\r\n      \"type\": \"Adam\",\r\n      \"params\": {\r\n        \"lr\": 0.00015\r\n      }\r\n    },\r\n    \"fp16\": {\r\n      \"enabled\": true\r\n    },\r\n    \"zero_optimization\": {\r\n        \"stage\": 3,\r\n        \"contiguous_gradients\": true,\r\n        \"stage3_max_live_parameters\": 1e9,\r\n        \"stage3_max_reuse_distance\": 1e9,\r\n        \"stage3_prefetch_bucket_size\": 1e7,\r\n        \"stage3_param_persistence_threshold\": 1e5,\r\n        \"reduce_bucket_size\": 1e7,\r\n        \"sub_group_size\": 1e9,\r\n        \"offload_optimizer\": {\r\n            \"device\": \"cpu\"\r\n         },\r\n        \"offload_param\": {\r\n            \"device\": \"cpu\"\r\n       }\r\n   }\r\n  }\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/242/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/241",
        "id": 1618502386,
        "node_id": "I_kwDOG1WDQc5geGLy",
        "number": 241,
        "title": "[Chatllama] it seems you don't support   flan_t5_xl to generate rewards training data",
        "user": {
            "login": "lonelydancer",
            "id": 548443,
            "node_id": "MDQ6VXNlcjU0ODQ0Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/548443?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lonelydancer",
            "html_url": "https://github.com/lonelydancer",
            "followers_url": "https://api.github.com/users/lonelydancer/followers",
            "following_url": "https://api.github.com/users/lonelydancer/following{/other_user}",
            "gists_url": "https://api.github.com/users/lonelydancer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lonelydancer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lonelydancer/subscriptions",
            "organizations_url": "https://api.github.com/users/lonelydancer/orgs",
            "repos_url": "https://api.github.com/users/lonelydancer/repos",
            "events_url": "https://api.github.com/users/lonelydancer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lonelydancer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-10T07:36:48Z",
        "updated_at": "2023-03-31T08:52:25Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "\r\nyou claim\"If you prefer avoiding external paid APIs, we suggest using HuggingFace\u2019s models (e.g. flan_t5_xl) as described in more detail in the [Supported models](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama#supported-models) section.\"\r\nhowerver,\r\npython artifacts/generate_rewards.py ./artifacts/datasets/reward_training_data.json --model flan_t5_xl\r\n\r\n self.llm = LLMChain(llm=openai_llm, prompt=prompt_template)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/241/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/240",
        "id": 1618397463,
        "node_id": "I_kwDOG1WDQc5gdskX",
        "number": 240,
        "title": "[Chatllama] RLHF training for Actor",
        "user": {
            "login": "Vincent131499",
            "id": 26675984,
            "node_id": "MDQ6VXNlcjI2Njc1OTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26675984?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Vincent131499",
            "html_url": "https://github.com/Vincent131499",
            "followers_url": "https://api.github.com/users/Vincent131499/followers",
            "following_url": "https://api.github.com/users/Vincent131499/following{/other_user}",
            "gists_url": "https://api.github.com/users/Vincent131499/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Vincent131499/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Vincent131499/subscriptions",
            "organizations_url": "https://api.github.com/users/Vincent131499/orgs",
            "repos_url": "https://api.github.com/users/Vincent131499/repos",
            "events_url": "https://api.github.com/users/Vincent131499/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Vincent131499/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-03-10T05:41:50Z",
        "updated_at": "2023-04-03T14:32:47Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I was training the actor with reinforcement learning, I encountered the following bug:\r\nCurrent device used :cuda\r\nStart RL Training\r\nEpisode: 1 of 100, Timestep: 1 of 8\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [113,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [148,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\r\n    values = self.critic.forward(sequences, sequences_mask)\r\n  File \"<@beartype(chatllama.rlhf.reward.RewardModel.forward) at 0x2afb7867aaf0>\", line 51, in forward\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/chatllama/rlhf/reward.py\", line 133, in forward\r\n    output = self.model(\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 831, in forward\r\n    position_embeds = self.wpe(position_ids)\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/torch/nn/modules/sparse.py\", line 158, in forward\r\n    return F.embedding(\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/torch/nn/functional.py\", line 2183, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: CUDA error: device-side assert triggered\r\n\r\nmy confilg.yaml:\r\ntrainer_config:\r\n  actor_lr: 0.00001\r\n  critic_lr: 0.00001\r\n  actor_eps_clip: 0.2\r\n  critic_eps_clip: 0.2\r\n  beta_s: 0.1\r\n  examples_path: \"./datasets/rlhf_training_data.json.repair\"\r\n  num_episodes: 100\r\n  max_timesteps: 8\r\n  update_timesteps: 8\r\n  num_examples: 8\r\n  batch_size: 1\r\n  epochs: 1\r\n  update_checkpoint: 8\r\n  checkpoint_folder: \"./models/checkpoints\"\r\n\r\nactor_config:\r\n  model: \"facebook/opt-125m\"\r\n  model_path: \"path-to-model\"\r\n  checkpoint_folder: \"./models\"\r\n  tokenizer_folder: \"path-to-tokenizer\"\r\n  train_dataset_path: \"./datasets/actor_training_data.json\"\r\n  validation_dataset_path: null\r\n  froze_embeddings: True\r\n  use_fairscale: False\r\n  max_sequence_length: 2048\r\n  max_tokens: 1024\r\n  temperature: 0.9\r\n  batch_size: 6\r\n  iteration_per_print: 100\r\n  lr: 0.0001\r\n  epochs: 5\r\n  deepspeed_enable: False\r\n  deepspeed_config_path: \"path-to-deepspeed-conf\"\r\n\r\nreward_config:\r\n  model: \"gpt2-large\"\r\n  model_head_hidden_size: 2048\r\n  model_folder: \"./models\"\r\n  train_dataset_path: \"./datasets/reward_training_data.json\"\r\n  validation_dataset_path: null\r\n  batch_size: 1\r\n  epochs: 32\r\n  iteration_per_print: 1\r\n  lr: 0.0001\r\n  deepspeed_enable: False\r\n  deepspeed_config_path: \"path-to-deepspeed-conf\"\r\n\r\ncritic_config:\r\n  model: \"gpt2-large\"\r\n  model_head_hidden_size: 2048\r\n  model_folder: \"./models\"\r\n  deepspeed_enable: False\r\n  deepspeed_config_path: \"path-to-deepspeed-conf\"",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/240/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/239",
        "id": 1617667277,
        "node_id": "I_kwDOG1WDQc5ga6TN",
        "number": 239,
        "title": "Speedster optimize_model should raise error if input data is missing",
        "user": {
            "login": "Telemaco019",
            "id": 24567368,
            "node_id": "MDQ6VXNlcjI0NTY3MzY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/24567368?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Telemaco019",
            "html_url": "https://github.com/Telemaco019",
            "followers_url": "https://api.github.com/users/Telemaco019/followers",
            "following_url": "https://api.github.com/users/Telemaco019/following{/other_user}",
            "gists_url": "https://api.github.com/users/Telemaco019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Telemaco019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Telemaco019/subscriptions",
            "organizations_url": "https://api.github.com/users/Telemaco019/orgs",
            "repos_url": "https://api.github.com/users/Telemaco019/repos",
            "events_url": "https://api.github.com/users/Telemaco019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Telemaco019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-09T17:20:45Z",
        "updated_at": "2023-03-09T17:30:08Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "## Description\r\n\r\nInvoking `optimize_model` with either `input_data=None` or `input_data=[]` generates the following output: \r\n```\r\n2023-03-09 18:09:34 | INFO     | Running Speedster on CPU\r\n``` \r\nHowever, the model is not optimized and no results are produced. Since `input_data` is necessary for optimizing the model, I think it would be useful to make it explicit by either raising an error or showing a proper log message when no input data is provided.\r\n\r\n## How to replicate\r\n\r\nSpeedster version: 0.2.1\r\nNebullvm version: 0.8.1\r\n\r\n```python\r\nimport torchvision.models as models\r\nfrom speedster.api.functions import optimize_model\r\n\r\n\r\ndef main():\r\n    optimize_model(\r\n        model=models.resnet50(),\r\n        input_data=[],\r\n        store_latencies=True,\r\n    )\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/239/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/238",
        "id": 1617427418,
        "node_id": "PR_kwDOG1WDQc5Lr6JO",
        "number": 238,
        "title": "add plotly to chatllama/setup.py",
        "user": {
            "login": "sebastianschramm",
            "id": 16114609,
            "node_id": "MDQ6VXNlcjE2MTE0NjA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16114609?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sebastianschramm",
            "html_url": "https://github.com/sebastianschramm",
            "followers_url": "https://api.github.com/users/sebastianschramm/followers",
            "following_url": "https://api.github.com/users/sebastianschramm/following{/other_user}",
            "gists_url": "https://api.github.com/users/sebastianschramm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sebastianschramm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sebastianschramm/subscriptions",
            "organizations_url": "https://api.github.com/users/sebastianschramm/orgs",
            "repos_url": "https://api.github.com/users/sebastianschramm/repos",
            "events_url": "https://api.github.com/users/sebastianschramm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sebastianschramm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-09T15:02:57Z",
        "updated_at": "2023-03-09T16:26:38Z",
        "closed_at": "2023-03-09T16:26:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/238",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/238",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/238.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/238.patch",
            "merged_at": "2023-03-09T16:26:38Z"
        },
        "body": "chatllama/rlhf/utils.py::TrainingStats uses graph_objects from plotly but plotly is missing in requirements.\r\n\r\nThis adds plotly to chatllama/setup.py",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/238/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/237",
        "id": 1617198559,
        "node_id": "PR_kwDOG1WDQc5LrHpG",
        "number": 237,
        "title": "defer import of llama_model to init of ActorModel fix #235",
        "user": {
            "login": "sebastianschramm",
            "id": 16114609,
            "node_id": "MDQ6VXNlcjE2MTE0NjA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16114609?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sebastianschramm",
            "html_url": "https://github.com/sebastianschramm",
            "followers_url": "https://api.github.com/users/sebastianschramm/followers",
            "following_url": "https://api.github.com/users/sebastianschramm/following{/other_user}",
            "gists_url": "https://api.github.com/users/sebastianschramm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sebastianschramm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sebastianschramm/subscriptions",
            "organizations_url": "https://api.github.com/users/sebastianschramm/orgs",
            "repos_url": "https://api.github.com/users/sebastianschramm/repos",
            "events_url": "https://api.github.com/users/sebastianschramm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sebastianschramm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-09T13:01:14Z",
        "updated_at": "2023-03-09T13:13:51Z",
        "closed_at": "2023-03-09T13:13:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/237",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/237",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/237.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/237.patch",
            "merged_at": "2023-03-09T13:13:50Z"
        },
        "body": "defer import of llama_model to init of ActorModel \r\n\r\nfix #235",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/237/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/236",
        "id": 1617164241,
        "node_id": "I_kwDOG1WDQc5gY_fR",
        "number": 236,
        "title": "[Chatllama] Actor for llama",
        "user": {
            "login": "Vincent131499",
            "id": 26675984,
            "node_id": "MDQ6VXNlcjI2Njc1OTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/26675984?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Vincent131499",
            "html_url": "https://github.com/Vincent131499",
            "followers_url": "https://api.github.com/users/Vincent131499/followers",
            "following_url": "https://api.github.com/users/Vincent131499/following{/other_user}",
            "gists_url": "https://api.github.com/users/Vincent131499/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Vincent131499/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Vincent131499/subscriptions",
            "organizations_url": "https://api.github.com/users/Vincent131499/orgs",
            "repos_url": "https://api.github.com/users/Vincent131499/repos",
            "events_url": "https://api.github.com/users/Vincent131499/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Vincent131499/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-03-09T12:44:59Z",
        "updated_at": "2023-03-31T07:20:12Z",
        "closed_at": "2023-03-31T07:20:11Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "When I was using llama-7B to train actor, the following bug appeared:\r\n\r\nCurrent device used :cuda\r\nLoading\r\nStart Actor Model Pretraining\r\nTraceback (most recent call last):\r\n  File \"artifacts/main.py\", line 51, in <module>\r\n    actor_trainer.train()\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/chatllama/rlhf/actor.py\", line 373, in train\r\n    est_output = self.model(training_input, attention_mask)\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\r\n    return forward_call(*input, **kwargs)\r\n  File \"<@beartype(chatllama.rlhf.actor.ActorModel.forward) at 0x2aff142815e0>\", line 51, in forward\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/chatllama/rlhf/actor.py\", line 114, in forward\r\n    model_output = self.model.forward(\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/chatllama/llama_model.py\", line 475, in forward\r\n    logits = self._forward(tokens, attention_mask)\r\n  File \"/mnt/lustre02/jiangsu/aispeech/home/gfl18/.conda/envs/py38-llm/lib/python3.8/site-packages/chatllama/llama_model.py\", line 497, in _forward\r\n    torch.where(kv_mask == 1, float(\"-inf\"), kv_mask).detach().long()\r\nRuntimeError: expected scalar type double but found long int\r\n\r\nMy environment is\uff1a\r\npython3.8\r\ntorch1.11.0+cuda113\r\n\r\nExcuse me, is it the torch version?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/236/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/235",
        "id": 1616983288,
        "node_id": "I_kwDOG1WDQc5gYTT4",
        "number": 235,
        "title": "actor training script throws Error : ModuleNotFoundError: No module named 'llama'",
        "user": {
            "login": "sebastianschramm",
            "id": 16114609,
            "node_id": "MDQ6VXNlcjE2MTE0NjA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/16114609?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sebastianschramm",
            "html_url": "https://github.com/sebastianschramm",
            "followers_url": "https://api.github.com/users/sebastianschramm/followers",
            "following_url": "https://api.github.com/users/sebastianschramm/following{/other_user}",
            "gists_url": "https://api.github.com/users/sebastianschramm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sebastianschramm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sebastianschramm/subscriptions",
            "organizations_url": "https://api.github.com/users/sebastianschramm/orgs",
            "repos_url": "https://api.github.com/users/sebastianschramm/repos",
            "events_url": "https://api.github.com/users/sebastianschramm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sebastianschramm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-09T11:11:08Z",
        "updated_at": "2023-03-09T13:13:52Z",
        "closed_at": "2023-03-09T13:13:52Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "While trying to run actor training of OPT-125M from huggingface the script throws an import error:\r\n```\r\n>> python artifacts/main.py artifacts/config/config.yaml --type ACTOR                            \r\nTraceback (most recent call last):\r\n  File \"/nebullvm/apps/accelerate/chatllama/artifacts/main.py\", line 3, in <module>\r\n    from chatllama.rlhf.actor import ActorTrainer\r\n  File \"/nebullvm/apps/accelerate/chatllama/chatllama/rlhf/actor.py\", line 16, in <module>\r\n    from chatllama.llama_model import load_model\r\n  File \"/nebullvm/apps/accelerate/chatllama/chatllama/llama_model.py\", line 26, in <module>\r\n    from llama import Tokenizer\r\nModuleNotFoundError: No module named 'llama'\r\n```\r\n\r\npython 3.10\r\nchatllama from main: 2227d3f40e8bb91cd8175a38b4debf763560cd7b\r\n\r\nconfig.yaml:\r\n```\r\nactor_config:\r\n  model: \"facebook/opt-125m\"\r\n  model_path: \"path-to-model\"\r\n  checkpoint_folder: \"./models\"\r\n  tokenizer_folder: \"path-to-tokenizer\"\r\n  train_dataset_path: \"./artifacts/datasets/actor_dataset.json\"\r\n  validation_dataset_path: null\r\n  # froze model embedding during training\r\n  froze_embeddings: True\r\n  # use fairscale layers to build the model instead of vanilla pytorch\r\n  use_fairscale: False\r\n  # max sequence length for the actor (i.e. prompt + completion) it depends on\r\n  # the model used.\r\n  max_sequence_length: 1024\r\n  # max tokens generated by the actor (completion only)\r\n  max_tokens: 512\r\n  # temperature for the actor\r\n  temperature: 0.9\r\n  batch_size: 1\r\n  # number iteration after print\r\n  iteration_per_print: 1\r\n  lr: 0.0001\r\n  epochs: 32\r\n  # deepspeed settings\r\n  deepspeed_enable: False\r\n  deepspeed_config_path: \"path-to-deepspeed-conf\"\r\n```\r\n\r\nI do not have the llama model nor do I want to use it.\r\nActor training does work for OPT-125M once I delay the import of `load_model`.\r\n\r\nPossible fix: delay import of `from chatllama.llama_model import load_model` until model type check in rlhf/actor.py::ActorModel\r\n\r\nI am happy to contribute with a MR once we agree on the expected behavior. I am not sure where the \"llama\" module is supposed to come from?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/235/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/234",
        "id": 1616802288,
        "node_id": "I_kwDOG1WDQc5gXnHw",
        "number": 234,
        "title": "[Chatllama] BUG?Assertion srcIndex < srcSelectDimSize failed.",
        "user": {
            "login": "iMountTai",
            "id": 35353688,
            "node_id": "MDQ6VXNlcjM1MzUzNjg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/35353688?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/iMountTai",
            "html_url": "https://github.com/iMountTai",
            "followers_url": "https://api.github.com/users/iMountTai/followers",
            "following_url": "https://api.github.com/users/iMountTai/following{/other_user}",
            "gists_url": "https://api.github.com/users/iMountTai/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/iMountTai/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/iMountTai/subscriptions",
            "organizations_url": "https://api.github.com/users/iMountTai/orgs",
            "repos_url": "https://api.github.com/users/iMountTai/repos",
            "events_url": "https://api.github.com/users/iMountTai/events{/privacy}",
            "received_events_url": "https://api.github.com/users/iMountTai/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 14,
        "created_at": "2023-03-09T09:36:14Z",
        "updated_at": "2023-04-03T14:31:48Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Amazing work. But may I ask how to solve the following problem?\r\n![image](https://user-images.githubusercontent.com/35353688/223980676-1d64ae78-9e3d-4847-9733-33e543f70931.png)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/234/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/233",
        "id": 1616793952,
        "node_id": "PR_kwDOG1WDQc5Lptu4",
        "number": 233,
        "title": "[Chatllama] support for accelerate from hf",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-09T09:31:38Z",
        "updated_at": "2023-03-23T15:35:02Z",
        "closed_at": "2023-03-23T15:34:42Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/233",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/233",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/233.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/233.patch",
            "merged_at": "2023-03-23T15:34:41Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/233/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/232",
        "id": 1616740359,
        "node_id": "I_kwDOG1WDQc5gXYAH",
        "number": 232,
        "title": "[Chatllama] cannot import name 'TrainingStats' from 'utils'",
        "user": {
            "login": "caldwbr",
            "id": 15356399,
            "node_id": "MDQ6VXNlcjE1MzU2Mzk5",
            "avatar_url": "https://avatars.githubusercontent.com/u/15356399?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/caldwbr",
            "html_url": "https://github.com/caldwbr",
            "followers_url": "https://api.github.com/users/caldwbr/followers",
            "following_url": "https://api.github.com/users/caldwbr/following{/other_user}",
            "gists_url": "https://api.github.com/users/caldwbr/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/caldwbr/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/caldwbr/subscriptions",
            "organizations_url": "https://api.github.com/users/caldwbr/orgs",
            "repos_url": "https://api.github.com/users/caldwbr/repos",
            "events_url": "https://api.github.com/users/caldwbr/events{/privacy}",
            "received_events_url": "https://api.github.com/users/caldwbr/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-09T09:01:29Z",
        "updated_at": "2023-03-23T10:32:53Z",
        "closed_at": "2023-03-23T10:32:53Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I got all the way, but at the last step, \"python artifacts/main.py artifacts/config/config.yaml --type REWARD\" it is throwing all kinds of errors, such as \"cannot import name 'TrainingStats' from 'utils',\" not liking the command \"sudo,\" not wanting to download chocolatey on windows 11 while simultaneously saying I already both have and don't have chocolatey.... Arrg",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/232/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/231",
        "id": 1616732838,
        "node_id": "PR_kwDOG1WDQc5LpgSb",
        "number": 231,
        "title": "Add self instruct dataset from HF",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-09T08:57:51Z",
        "updated_at": "2023-03-09T09:00:32Z",
        "closed_at": "2023-03-09T09:00:32Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/231",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/231",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/231.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/231.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/231/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/230",
        "id": 1616530617,
        "node_id": "PR_kwDOG1WDQc5Lozt8",
        "number": 230,
        "title": "bugfix: llama train raise AssertionError",
        "user": {
            "login": "pgzhang",
            "id": 37991273,
            "node_id": "MDQ6VXNlcjM3OTkxMjcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/37991273?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/pgzhang",
            "html_url": "https://github.com/pgzhang",
            "followers_url": "https://api.github.com/users/pgzhang/followers",
            "following_url": "https://api.github.com/users/pgzhang/following{/other_user}",
            "gists_url": "https://api.github.com/users/pgzhang/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/pgzhang/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/pgzhang/subscriptions",
            "organizations_url": "https://api.github.com/users/pgzhang/orgs",
            "repos_url": "https://api.github.com/users/pgzhang/repos",
            "events_url": "https://api.github.com/users/pgzhang/events{/privacy}",
            "received_events_url": "https://api.github.com/users/pgzhang/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-09T06:45:20Z",
        "updated_at": "2023-03-09T11:42:43Z",
        "closed_at": "2023-03-09T11:42:43Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/230",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/230",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/230.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/230.patch",
            "merged_at": "2023-03-09T11:42:43Z"
        },
        "body": "when use llama to train actor model, raise AssertionError: model parallel group is not initialized",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/230/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/229",
        "id": 1616357203,
        "node_id": "I_kwDOG1WDQc5gV6dT",
        "number": 229,
        "title": "[Chatllama] error when load  dataset when use deepspeed",
        "user": {
            "login": "bino282",
            "id": 17800187,
            "node_id": "MDQ6VXNlcjE3ODAwMTg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/17800187?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bino282",
            "html_url": "https://github.com/bino282",
            "followers_url": "https://api.github.com/users/bino282/followers",
            "following_url": "https://api.github.com/users/bino282/following{/other_user}",
            "gists_url": "https://api.github.com/users/bino282/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bino282/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bino282/subscriptions",
            "organizations_url": "https://api.github.com/users/bino282/orgs",
            "repos_url": "https://api.github.com/users/bino282/repos",
            "events_url": "https://api.github.com/users/bino282/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bino282/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-03-09T03:55:22Z",
        "updated_at": "2023-04-03T14:29:55Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "hi, when I use deepspeed , I encountered this error:\r\n[2023-03-09 10:46:33,647] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\r\nTraceback (most recent call last):\r\n  File \"/datahdd/nhanv/Projects/NLP/chatllama/artifacts/main.py\", line 50, in <module>\r\n    actor_trainer = ActorTrainer(config.actor)\r\n  File \"/home/ntq/miniconda3/envs/textgen/lib/python3.10/site-packages/chatllama/rlhf/actor.py\", line 324, in __init__\r\n    ) = deepspeed.initialize(\r\n  File \"/home/ntq/miniconda3/envs/textgen/lib/python3.10/site-packages/deepspeed/__init__.py\", line 125, in initialize\r\n    engine = DeepSpeedEngine(args=args,\r\n  File \"/home/ntq/miniconda3/envs/textgen/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 319, in __init__\r\n    self.training_dataloader = self.deepspeed_io(training_data)\r\n  File \"/home/ntq/miniconda3/envs/textgen/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1674, in deepspeed_io\r\n    raise ValueError(\"Training data must be a torch Dataset\")\r\nValueError: Training data must be a torch Dataset\r\nHow can I fix it?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/229/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/228",
        "id": 1615690527,
        "node_id": "PR_kwDOG1WDQc5Ll94G",
        "number": 228,
        "title": "Fix CI pipelines triggers",
        "user": {
            "login": "Telemaco019",
            "id": 24567368,
            "node_id": "MDQ6VXNlcjI0NTY3MzY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/24567368?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Telemaco019",
            "html_url": "https://github.com/Telemaco019",
            "followers_url": "https://api.github.com/users/Telemaco019/followers",
            "following_url": "https://api.github.com/users/Telemaco019/following{/other_user}",
            "gists_url": "https://api.github.com/users/Telemaco019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Telemaco019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Telemaco019/subscriptions",
            "organizations_url": "https://api.github.com/users/Telemaco019/orgs",
            "repos_url": "https://api.github.com/users/Telemaco019/repos",
            "events_url": "https://api.github.com/users/Telemaco019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Telemaco019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T18:03:28Z",
        "updated_at": "2023-03-09T08:21:11Z",
        "closed_at": "2023-03-08T18:48:44Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/228",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/228",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/228.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/228.patch",
            "merged_at": "2023-03-08T18:48:44Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/228/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/227",
        "id": 1615418365,
        "node_id": "PR_kwDOG1WDQc5LlDl2",
        "number": 227,
        "title": "Fix bug in reward model init when selecting the model to instantiate",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T14:59:17Z",
        "updated_at": "2023-03-09T13:10:11Z",
        "closed_at": "2023-03-09T13:10:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/227",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/227",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/227.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/227.patch",
            "merged_at": "2023-03-09T13:10:11Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/227/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/226",
        "id": 1615295898,
        "node_id": "I_kwDOG1WDQc5gR3Wa",
        "number": 226,
        "title": "Add support for pre-trained reward models",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "gagan3012",
            "id": 49101362,
            "node_id": "MDQ6VXNlcjQ5MTAxMzYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/49101362?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gagan3012",
            "html_url": "https://github.com/gagan3012",
            "followers_url": "https://api.github.com/users/gagan3012/followers",
            "following_url": "https://api.github.com/users/gagan3012/following{/other_user}",
            "gists_url": "https://api.github.com/users/gagan3012/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gagan3012/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gagan3012/subscriptions",
            "organizations_url": "https://api.github.com/users/gagan3012/orgs",
            "repos_url": "https://api.github.com/users/gagan3012/repos",
            "events_url": "https://api.github.com/users/gagan3012/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gagan3012/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "gagan3012",
                "id": 49101362,
                "node_id": "MDQ6VXNlcjQ5MTAxMzYy",
                "avatar_url": "https://avatars.githubusercontent.com/u/49101362?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/gagan3012",
                "html_url": "https://github.com/gagan3012",
                "followers_url": "https://api.github.com/users/gagan3012/followers",
                "following_url": "https://api.github.com/users/gagan3012/following{/other_user}",
                "gists_url": "https://api.github.com/users/gagan3012/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/gagan3012/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/gagan3012/subscriptions",
                "organizations_url": "https://api.github.com/users/gagan3012/orgs",
                "repos_url": "https://api.github.com/users/gagan3012/repos",
                "events_url": "https://api.github.com/users/gagan3012/events{/privacy}",
                "received_events_url": "https://api.github.com/users/gagan3012/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-08T13:44:52Z",
        "updated_at": "2023-03-24T08:41:49Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nOpenAssistant has released on HF the reward models they trained on the open-source datasets. Even if they are not tailored for the user need, we could lavarege them as a starting point for fine-tuning the user reward models.\r\n\r\nAvailable reward models:\r\n\r\n- [OpenAssistant/reward-model-deberta-v3-large-v2 \u00b7 Hugging Face](https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large-v2)\r\n- [OpenAssistant/reward-model-deberta-v3-large \u00b7 Hugging Face](https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large)\r\n- [OpenAssistant/reward-model-deberta-v3-base \u00b7 Hugging Face](https://huggingface.co/OpenAssistant/reward-model-deberta-v3-base)\r\n- [OpenAssistant/reward-model-electra-large-discriminator \u00b7 Hugging Face](https://huggingface.co/OpenAssistant/reward-model-electra-large-discriminator)\r\n\r\n# TODO\r\n\r\n- [ ]  Add the possibility to load the pretrained checkpoints for the reward model in ChatLLaMA\r\n- [ ]  Write unittests",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/226/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/225",
        "id": 1615291747,
        "node_id": "I_kwDOG1WDQc5gR2Vj",
        "number": 225,
        "title": "Add full support for offloading",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T13:41:47Z",
        "updated_at": "2023-03-08T13:41:47Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nDeepSpeed supports offloading during training using the Zero-Infinity technology. We should add examples of working configuration files for the models we support.\r\n\r\n# TODO\r\n\r\n- [ ]  Add examples of config files using Zero-Inifinty\r\n- [ ]  Add Off-loading section in the documentation",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/225/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/224",
        "id": 1615290569,
        "node_id": "I_kwDOG1WDQc5gR2DJ",
        "number": 224,
        "title": "[Chatllama] Use upvotes in Stanford dataset as a measure for reward",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828844,
                "node_id": "LA_kwDOG1WDQc7kCYPs",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/good%20first%20issue",
                "name": "good first issue",
                "color": "7057ff",
                "default": true,
                "description": "Good for newcomers"
            },
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "MattiaSangermano",
            "id": 43407984,
            "node_id": "MDQ6VXNlcjQzNDA3OTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/43407984?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MattiaSangermano",
            "html_url": "https://github.com/MattiaSangermano",
            "followers_url": "https://api.github.com/users/MattiaSangermano/followers",
            "following_url": "https://api.github.com/users/MattiaSangermano/following{/other_user}",
            "gists_url": "https://api.github.com/users/MattiaSangermano/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MattiaSangermano/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MattiaSangermano/subscriptions",
            "organizations_url": "https://api.github.com/users/MattiaSangermano/orgs",
            "repos_url": "https://api.github.com/users/MattiaSangermano/repos",
            "events_url": "https://api.github.com/users/MattiaSangermano/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MattiaSangermano/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "MattiaSangermano",
                "id": 43407984,
                "node_id": "MDQ6VXNlcjQzNDA3OTg0",
                "avatar_url": "https://avatars.githubusercontent.com/u/43407984?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/MattiaSangermano",
                "html_url": "https://github.com/MattiaSangermano",
                "followers_url": "https://api.github.com/users/MattiaSangermano/followers",
                "following_url": "https://api.github.com/users/MattiaSangermano/following{/other_user}",
                "gists_url": "https://api.github.com/users/MattiaSangermano/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/MattiaSangermano/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/MattiaSangermano/subscriptions",
                "organizations_url": "https://api.github.com/users/MattiaSangermano/orgs",
                "repos_url": "https://api.github.com/users/MattiaSangermano/repos",
                "events_url": "https://api.github.com/users/MattiaSangermano/events{/privacy}",
                "received_events_url": "https://api.github.com/users/MattiaSangermano/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-03-08T13:40:56Z",
        "updated_at": "2023-04-27T07:22:33Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nCurrently we are supporting the following datasets:\r\n- [Stanford Human Preferences Dataset (SHP)](https://huggingface.co/datasets/stanfordnlp/SHP)\r\n- [Anthropic RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf\r\n\r\nBut we are not using all the information contained in the dataset:\r\n- rejected answers from Anthropic\r\n- up-votes for Stanford.\r\n\r\nThe number of upvotes, for instance, could be used as a label for the reward model (after some normalisation) to judge the quality of the answer without asking to a model or a human to return a feedback. \r\n\r\nMoreover these datasets for training the reward models must be artificially augment with high quality negative examples to make the reward model learn not only what is good but also what is not. \r\n\r\nEventually a more robust research of possible useful datasets to be integrated must be carried out to ensure to support all the open-source datasets that can be relevant for the projects. \r\n\r\n# TODO\r\n\r\n- [ ]  Implement a conversion between upvotes and reward for Stanford dataset.\r\n- [ ] Understand how the rejected answer can be used to augment the dataset quality of the reward model.\r\n- [ ]  Test the validity of the conversion with a simple use case.\r\n- [ ] Introduce negative examples in the reward dataset that are meaningful to the model to assign the proper score.\r\n- [ ] Other datasets can be used? ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/224/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/223",
        "id": 1615289111,
        "node_id": "I_kwDOG1WDQc5gR1sX",
        "number": 223,
        "title": "Implement optimized inference for ChatLLaMA",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T13:39:57Z",
        "updated_at": "2023-03-08T13:39:57Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nChatLLaMA currently does not have either a playground or some scripts which allow the user to easily use the model for inference. It would be great to add a package for chatllama inference for efficiently loading chatllama in production. Note that it would be amazing to also provide some prompt templates for getting chat-like experience directly from the not fine-tuned LLaMA models.\r\n\r\n# TODO\r\n\r\n- [ ]  Add DeepSpeed Inference support to LLaMA model\r\n- [ ]  Support Flexgen for maximizing throughput\r\n- [ ]  Add support to Accelerate\r\n- [ ]  Implement a playground UI using GRADIO supporting multi-gpu deployment.\r\n- [ ]  Add prompts example for testing LLaMA as a chatbot before running RLHF training",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/223/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/222",
        "id": 1615286727,
        "node_id": "I_kwDOG1WDQc5gR1HH",
        "number": 222,
        "title": "Add documentation",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T13:38:15Z",
        "updated_at": "2023-03-08T13:39:14Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nCurrently ChatLLaMA documentation consists of just the readme on github. We should align chatllama with the other modules in nebullvm and add the `mkdocs`  documentation to `docs.nebuly.com`. \r\n\r\nAll documentation must be written in markdown format and put into a docs folder in the chatllama repo.\r\n\r\nThe documentation should give more details on both the model supported and on the dataset generation. In particular, on the dataset generation side we need to add more examples of usage and explain in more details the advantages of the different approaches.\r\n\r\nWe must put a section on the training on multiple-gpus. In articular we should explain how to properly use deep-speed and configure it for training the model.\r\n\r\n# TODO\r\n\r\n- [ ]  Add documentation in the docs folder.\r\n- [ ]  Build the docs with mkdocs\r\n- [ ]  Push the new docs in `docs.nebuly.com`",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/222/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/221",
        "id": 1615285783,
        "node_id": "I_kwDOG1WDQc5gR04X",
        "number": 221,
        "title": "[Chatllama] Add multiple sources for generating synthetic data",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828844,
                "node_id": "LA_kwDOG1WDQc7kCYPs",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/good%20first%20issue",
                "name": "good first issue",
                "color": "7057ff",
                "default": true,
                "description": "Good for newcomers"
            },
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-08T13:37:34Z",
        "updated_at": "2023-03-31T12:57:44Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nCurrently, chatllama supports the synthetic data generation just from OpenAI\u2019s `davinci-003`. \r\nBoth for conversations and for scores.\r\n\r\nIn order to avoid huge costs while generating data we should support  other API models (as the cheaper `gpt-3.5-turbo` ), other API providers and local models (Flan T5 seems a good candidate).\r\n\r\nFurthermore, in order to generate more diverse data, it could be beneficial to be able to use multiple prompt templates during the generation.\r\n\r\n# TODO\r\n\r\n- [ ]  Add support for `gpt-3.5-turbo` . Externally respect to LangChain models.\r\n- [ ]  Add preview of the costs associated with the API models (i.e. n_words / 0.75 * API_cost_per_token) before proceeding with the labelling. \r\n- [ ]  Modify langchain-based script for supporting multiple API models and providers.\r\n- [ ]  Add support for HF models to perform the generation task.\r\n- [ ]  Allow user to specify multiple templates when generating synthetic data that can be customisable to the user needs.\r\n- [ ]  Provide multiple template examples for dataset generation.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/221/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/220",
        "id": 1615283957,
        "node_id": "I_kwDOG1WDQc5gR0b1",
        "number": 220,
        "title": "Give indication on the size of the dataset needed for fine-tuning the model",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T13:36:11Z",
        "updated_at": "2023-03-08T13:36:38Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nOnce of the biggest difficulty when selecting and cleaning the data for training is to estimate to correct amount of data needed for training the model. \r\n\r\nChatLLaMA training and RLHF in general are quite early-technologies, not deeply studied by the literature. We should implement a function to be used as \u201crule of thumb\u201d for getting an estimation of the needed data from the model size.\r\n\r\nWe can extract the law from the Scaling law papers combined with OpenAI\u2019s InstructGPT paper.\r\n\r\n# TODO\r\n\r\n- [ ]  Implement a rule-of-thumb for estimating the data needed\r\n- [ ]  Validate the assumption on a small model",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/220/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/219",
        "id": 1615274790,
        "node_id": "I_kwDOG1WDQc5gRyMm",
        "number": 219,
        "title": "Generate custom dataset from few user samples",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-08T13:29:13Z",
        "updated_at": "2023-03-16T18:07:51Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nThe first huge difficulty for training an AI assistant is to get a dataset reach enough and big enough for starting the training at all. \r\n\r\nChatLLaMA needs three different type of data:\r\n\r\n- Instruction + human label for supervised fine-tuning of the Agent\r\n- Text example + human evaluation (score) for training the reward model\r\n- Unlabeled instructions to be used in RLHF\r\n\r\nIn case of a ChatBot the Instruction should contain \r\n\r\n- the Prompt for the model, describing the task it should perform\r\n- Previous chat interactions\r\n- User command\r\n\r\nGiven a few examples from the user we would like to generate synthetic data, which should be \u201caligned\u201d with the user data. \r\n\r\n# TODO\r\n\r\n- [ ]  Implement a function for analysing user data and produce the dataset needed for the Agent training\r\n- [ ]  Implement a data-generator for the reward model taking as input the \u201cRules\u201d to be used in the scoring functions. Rules must be written in a single txt-like file.\r\n- [ ]  Integrate generated datasets with available open-source datasets.\r\n- [ ]  Write unittest for the data-generation function",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/219/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/218",
        "id": 1615273272,
        "node_id": "I_kwDOG1WDQc5gRx04",
        "number": 218,
        "title": "[Chatllama] Add support to other open-source models",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828844,
                "node_id": "LA_kwDOG1WDQc7kCYPs",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/good%20first%20issue",
                "name": "good first issue",
                "color": "7057ff",
                "default": true,
                "description": "Good for newcomers"
            },
            {
                "id": 5241046875,
                "node_id": "LA_kwDOG1WDQc8AAAABOGQHWw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/chatllama",
                "name": "chatllama",
                "color": "bfd4f2",
                "default": false,
                "description": "Issue related to the ChatLLaMA module"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-08T13:28:05Z",
        "updated_at": "2023-04-03T14:28:17Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nLLaMA is a great model, however the weights license can be a huge barrier for users interested in the open-source LLM capabilities. The actual RLHF is designed around the LLaMA model, but it can be extended to other open-source models, like Flan-T5 or OPT.\r\n\r\n# TODO\r\n\r\n- [x]  Extend support of ChatLLaMA to HuggingFace models\r\n- [ ]  Add support for the encoder-decoder architectures (AutoModelsForSeq2Seq)\r\n- [x]  Add support for LLaMA from HF.\r\n- [x]  Add support for Cerebras GPT.\r\n- [ ]  Test the support for\r\n    - [ ]  FlanT5\r\n    - [x]  GPTJ\r\n    - [x]  GPTNeoX\r\n    - [x]  OPT\r\n    - [x]  BLOOM\r\n    - [x]  BLOOMZ\r\n    - [ ]  Galactica\r\n- [ ]  Implement unittest for the code\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/218/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/217",
        "id": 1615060589,
        "node_id": "I_kwDOG1WDQc5gQ95t",
        "number": 217,
        "title": "what is the training data format in chatllama actor_config/reward_config.",
        "user": {
            "login": "lonelydancer",
            "id": 548443,
            "node_id": "MDQ6VXNlcjU0ODQ0Mw==",
            "avatar_url": "https://avatars.githubusercontent.com/u/548443?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lonelydancer",
            "html_url": "https://github.com/lonelydancer",
            "followers_url": "https://api.github.com/users/lonelydancer/followers",
            "following_url": "https://api.github.com/users/lonelydancer/following{/other_user}",
            "gists_url": "https://api.github.com/users/lonelydancer/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lonelydancer/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lonelydancer/subscriptions",
            "organizations_url": "https://api.github.com/users/lonelydancer/orgs",
            "repos_url": "https://api.github.com/users/lonelydancer/repos",
            "events_url": "https://api.github.com/users/lonelydancer/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lonelydancer/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-08T10:46:40Z",
        "updated_at": "2023-03-10T16:54:26Z",
        "closed_at": "2023-03-10T16:54:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "can you release some data sample?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/217/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/216",
        "id": 1615055200,
        "node_id": "I_kwDOG1WDQc5gQ8lg",
        "number": 216,
        "title": "[Chatllama] assert _MODEL_PARALLEL_GROUP is not None, \"model parallel group is not initialized\"",
        "user": {
            "login": "seasidemym",
            "id": 12079248,
            "node_id": "MDQ6VXNlcjEyMDc5MjQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12079248?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seasidemym",
            "html_url": "https://github.com/seasidemym",
            "followers_url": "https://api.github.com/users/seasidemym/followers",
            "following_url": "https://api.github.com/users/seasidemym/following{/other_user}",
            "gists_url": "https://api.github.com/users/seasidemym/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seasidemym/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seasidemym/subscriptions",
            "organizations_url": "https://api.github.com/users/seasidemym/orgs",
            "repos_url": "https://api.github.com/users/seasidemym/repos",
            "events_url": "https://api.github.com/users/seasidemym/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seasidemym/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-08T10:42:30Z",
        "updated_at": "2023-04-03T14:27:49Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "How to use parallel training in actor. Simple demo is not work. The project is not solid.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/216/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/215",
        "id": 1614946651,
        "node_id": "I_kwDOG1WDQc5gQiFb",
        "number": 215,
        "title": "path_to_config_file.yaml",
        "user": {
            "login": "DarylLei",
            "id": 35752878,
            "node_id": "MDQ6VXNlcjM1NzUyODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/35752878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/DarylLei",
            "html_url": "https://github.com/DarylLei",
            "followers_url": "https://api.github.com/users/DarylLei/followers",
            "following_url": "https://api.github.com/users/DarylLei/following{/other_user}",
            "gists_url": "https://api.github.com/users/DarylLei/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/DarylLei/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/DarylLei/subscriptions",
            "organizations_url": "https://api.github.com/users/DarylLei/orgs",
            "repos_url": "https://api.github.com/users/DarylLei/repos",
            "events_url": "https://api.github.com/users/DarylLei/events{/privacy}",
            "received_events_url": "https://api.github.com/users/DarylLei/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-08T09:38:33Z",
        "updated_at": "2023-03-10T16:14:45Z",
        "closed_at": "2023-03-10T16:14:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "hello\uff0cWhere can I see a reference example",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/215/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/214",
        "id": 1614759436,
        "node_id": "I_kwDOG1WDQc5gP0YM",
        "number": 214,
        "title": "generate_dataset.py Error",
        "user": {
            "login": "seasidemym",
            "id": 12079248,
            "node_id": "MDQ6VXNlcjEyMDc5MjQ4",
            "avatar_url": "https://avatars.githubusercontent.com/u/12079248?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/seasidemym",
            "html_url": "https://github.com/seasidemym",
            "followers_url": "https://api.github.com/users/seasidemym/followers",
            "following_url": "https://api.github.com/users/seasidemym/following{/other_user}",
            "gists_url": "https://api.github.com/users/seasidemym/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/seasidemym/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/seasidemym/subscriptions",
            "organizations_url": "https://api.github.com/users/seasidemym/orgs",
            "repos_url": "https://api.github.com/users/seasidemym/repos",
            "events_url": "https://api.github.com/users/seasidemym/events{/privacy}",
            "received_events_url": "https://api.github.com/users/seasidemym/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-08T07:04:19Z",
        "updated_at": "2023-03-10T16:10:33Z",
        "closed_at": "2023-03-10T16:10:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "python generate_dateset.py [https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama/generate_dataset.py]\r\nImportError: cannot import name 'ConversationalBufferWindowMemory' from 'langchain.chains.conversation.memory'\r\n\r\nlook into /root/miniconda3/lib/python3.7/site-packages/langchain/chains/conversation/memory.py, only ConversationBufferMemory /ConversationSummaryMemory func. \r\n\r\nwhich python version and langchain version should be chosen?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/214/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/212",
        "id": 1614497161,
        "node_id": "PR_kwDOG1WDQc5Lh_MX",
        "number": 212,
        "title": "ConversationalBufferWindowMemory => ConversationBufferWindowMemory",
        "user": {
            "login": "bzantium",
            "id": 19511788,
            "node_id": "MDQ6VXNlcjE5NTExNzg4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19511788?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bzantium",
            "html_url": "https://github.com/bzantium",
            "followers_url": "https://api.github.com/users/bzantium/followers",
            "following_url": "https://api.github.com/users/bzantium/following{/other_user}",
            "gists_url": "https://api.github.com/users/bzantium/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bzantium/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bzantium/subscriptions",
            "organizations_url": "https://api.github.com/users/bzantium/orgs",
            "repos_url": "https://api.github.com/users/bzantium/repos",
            "events_url": "https://api.github.com/users/bzantium/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bzantium/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-08T01:47:08Z",
        "updated_at": "2023-03-08T18:43:13Z",
        "closed_at": "2023-03-08T18:43:13Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/212",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/212",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/212.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/212.patch",
            "merged_at": "2023-03-08T18:43:13Z"
        },
        "body": "```\r\nfrom langchain.chains.conversation.memory import (\r\n    ConversationalBufferWindowMemory,\r\n)\r\n```\r\n=>\r\n```\r\nfrom langchain.chains.conversation.memory import (\r\n    ConversationBufferWindowMemory,\r\n)\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/212/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/211",
        "id": 1614492935,
        "node_id": "I_kwDOG1WDQc5gOzUH",
        "number": 211,
        "title": "Examples for dataset/sections_dataset.json",
        "user": {
            "login": "TonyZhanghm",
            "id": 32423612,
            "node_id": "MDQ6VXNlcjMyNDIzNjEy",
            "avatar_url": "https://avatars.githubusercontent.com/u/32423612?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TonyZhanghm",
            "html_url": "https://github.com/TonyZhanghm",
            "followers_url": "https://api.github.com/users/TonyZhanghm/followers",
            "following_url": "https://api.github.com/users/TonyZhanghm/following{/other_user}",
            "gists_url": "https://api.github.com/users/TonyZhanghm/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TonyZhanghm/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TonyZhanghm/subscriptions",
            "organizations_url": "https://api.github.com/users/TonyZhanghm/orgs",
            "repos_url": "https://api.github.com/users/TonyZhanghm/repos",
            "events_url": "https://api.github.com/users/TonyZhanghm/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TonyZhanghm/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-03-08T01:42:06Z",
        "updated_at": "2023-03-10T16:11:42Z",
        "closed_at": "2023-03-10T16:11:42Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Hi! Would it be possible to provide a sample `dataset/sections_dataset.json` so we know how to create a custom dataset file? Or could you provide the code to transform either Anthropic or SHP into that format? Thanks!",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211/reactions",
            "total_count": 3,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/211/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/210",
        "id": 1613936110,
        "node_id": "PR_kwDOG1WDQc5LgG4O",
        "number": 210,
        "title": "Add data generation for extending RLHF dataset",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-07T17:51:32Z",
        "updated_at": "2023-03-07T17:55:50Z",
        "closed_at": "2023-03-07T17:55:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/210",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/210",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/210.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/210.patch",
            "merged_at": "2023-03-07T17:55:46Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/210/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/209",
        "id": 1613161739,
        "node_id": "PR_kwDOG1WDQc5Ldcyw",
        "number": 209,
        "title": "[Speedster]\u00a0Add support to Stable Diffusion Optimization",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-07T10:39:33Z",
        "updated_at": "2023-03-15T07:02:08Z",
        "closed_at": "2023-03-15T07:02:08Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/209",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/209",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/209.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/209.patch",
            "merged_at": "2023-03-15T07:02:08Z"
        },
        "body": "This PR introduces official support for Stable DIffusion models, together with some minor general fixes.\r\n\r\nExample of usage:\r\n```python\r\nimport torch\r\nfrom speedster import optimize_model\r\nfrom diffusers import StableDiffusionPipeline\r\n\r\n\r\n# Load Stable Diffusion 1.4 as example\r\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n\r\nif device == \"cuda\":\r\n    # On GPU we load by default the model in half precision, because it's faster and lighter.\r\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, revision='fp16', torch_dtype=torch.float16)\r\nelse:\r\n    pipe = StableDiffusionPipeline.from_pretrained(model_id)\r\n\r\n# Create some example input data\r\ninput_data = [\r\n    \"a photo of an astronaut riding a horse on mars\",\r\n    \"a monkey eating a banana in a forest\",\r\n    \"white car on a road surrounded by palm trees\",\r\n    \"a fridge full of bottles of beer\",\r\n    \"madara uchiha throwing asteroids against people\"\r\n]\r\n\r\n# Run Speedster optimization\r\noptimized_model = optimize_model(\r\n    model=pipe,\r\n    input_data=input_data,\r\n    optimization_time=\"unconstrained\",\r\n    ignore_compilers=[\"torch_tensor_rt\", \"tvm\"],\r\n    metric_drop_ths=0.1,\r\n)\r\n\r\n# Try the optimized model\r\ntest_prompt = \"futuristic llama with a cyberpunk city on the background\"\r\nres = optimized_model(test_prompt).images[0]\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209/reactions",
            "total_count": 2,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 2,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/209/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/208",
        "id": 1611213360,
        "node_id": "I_kwDOG1WDQc5gCSow",
        "number": 208,
        "title": "Error running Accelerate_Tensorflow_ResNet50_with_Speedster.ipynb in colab",
        "user": {
            "login": "convertthinking",
            "id": 125678133,
            "node_id": "U_kgDOB32yNQ",
            "avatar_url": "https://avatars.githubusercontent.com/u/125678133?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/convertthinking",
            "html_url": "https://github.com/convertthinking",
            "followers_url": "https://api.github.com/users/convertthinking/followers",
            "following_url": "https://api.github.com/users/convertthinking/following{/other_user}",
            "gists_url": "https://api.github.com/users/convertthinking/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/convertthinking/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/convertthinking/subscriptions",
            "organizations_url": "https://api.github.com/users/convertthinking/orgs",
            "repos_url": "https://api.github.com/users/convertthinking/repos",
            "events_url": "https://api.github.com/users/convertthinking/events{/privacy}",
            "received_events_url": "https://api.github.com/users/convertthinking/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-06T11:32:41Z",
        "updated_at": "2023-03-10T15:30:04Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "I've tried \r\n\r\nAccelerate_Tensorflow_ResNet50_with_Speedster.ipynb in Colab\r\n\r\nand get the following problem - version conflict\r\n\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n\r\ntensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\r\n\r\nonnx Requirement.parse('protobuf<4,>=3.20.2'), )\r\n\r\nRequirement.parse('protobuf<4,>=3.20.2'), {'onnx'})\r\n\r\nTrying to manually set versions didn't help.\r\n\r\nHow to fix this? ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/208/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/207",
        "id": 1611022322,
        "node_id": "I_kwDOG1WDQc5gBj_y",
        "number": 207,
        "title": "ModuleNotFoundError: No module named 'config'",
        "user": {
            "login": "MohamedAliRashad",
            "id": 26205298,
            "node_id": "MDQ6VXNlcjI2MjA1Mjk4",
            "avatar_url": "https://avatars.githubusercontent.com/u/26205298?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/MohamedAliRashad",
            "html_url": "https://github.com/MohamedAliRashad",
            "followers_url": "https://api.github.com/users/MohamedAliRashad/followers",
            "following_url": "https://api.github.com/users/MohamedAliRashad/following{/other_user}",
            "gists_url": "https://api.github.com/users/MohamedAliRashad/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/MohamedAliRashad/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/MohamedAliRashad/subscriptions",
            "organizations_url": "https://api.github.com/users/MohamedAliRashad/orgs",
            "repos_url": "https://api.github.com/users/MohamedAliRashad/repos",
            "events_url": "https://api.github.com/users/MohamedAliRashad/events{/privacy}",
            "received_events_url": "https://api.github.com/users/MohamedAliRashad/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 6,
        "created_at": "2023-03-06T09:40:58Z",
        "updated_at": "2023-03-10T16:20:46Z",
        "closed_at": "2023-03-10T16:20:46Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "`chatllama` is not able to import config",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/207/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/206",
        "id": 1610939332,
        "node_id": "PR_kwDOG1WDQc5LV-Gi",
        "number": 206,
        "title": "Fix ImportError in google colab",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-06T08:52:50Z",
        "updated_at": "2023-03-06T11:29:46Z",
        "closed_at": "2023-03-06T11:29:45Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/206",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/206",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/206.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/206.patch",
            "merged_at": "2023-03-06T11:29:45Z"
        },
        "body": "Fixes #205 ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/206/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/205",
        "id": 1610933267,
        "node_id": "I_kwDOG1WDQc5gBOQT",
        "number": 205,
        "title": "ImportError: cannot import name 'cfgs_to_fx_cfgs' from 'nebullvm.optional_modules.neural_compressor'",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-06T08:48:10Z",
        "updated_at": "2023-03-12T08:45:43Z",
        "closed_at": "2023-03-06T11:29:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "When installing and using the latest release of speedster in colab, it throws the following error: `ImportError: cannot import name 'cfgs_to_fx_cfgs' from 'nebullvm.optional_modules.neural_compressor' (/usr/local/lib/python3.8/dist-packages/nebullvm/optional_modules/neural_compressor.py)`",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/205/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/204",
        "id": 1610285216,
        "node_id": "PR_kwDOG1WDQc5LTyy3",
        "number": 204,
        "title": "Update README.md",
        "user": {
            "login": "SOCSChamp",
            "id": 121984408,
            "node_id": "U_kgDOB0VVmA",
            "avatar_url": "https://avatars.githubusercontent.com/u/121984408?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SOCSChamp",
            "html_url": "https://github.com/SOCSChamp",
            "followers_url": "https://api.github.com/users/SOCSChamp/followers",
            "following_url": "https://api.github.com/users/SOCSChamp/following{/other_user}",
            "gists_url": "https://api.github.com/users/SOCSChamp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SOCSChamp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SOCSChamp/subscriptions",
            "organizations_url": "https://api.github.com/users/SOCSChamp/orgs",
            "repos_url": "https://api.github.com/users/SOCSChamp/repos",
            "events_url": "https://api.github.com/users/SOCSChamp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SOCSChamp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-05T17:20:03Z",
        "updated_at": "2023-03-05T18:40:30Z",
        "closed_at": "2023-03-05T17:21:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/204",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/204",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/204.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/204.patch",
            "merged_at": "2023-03-05T17:21:43Z"
        },
        "body": "Add links for existing RLHF datasets",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/204/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/203",
        "id": 1609724647,
        "node_id": "PR_kwDOG1WDQc5LSHRX",
        "number": 203,
        "title": "RLHF updates",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-04T10:56:55Z",
        "updated_at": "2023-03-08T13:18:59Z",
        "closed_at": "2023-03-08T13:18:54Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/203",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/203",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/203.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/203.patch",
            "merged_at": "2023-03-08T13:18:54Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/203/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/202",
        "id": 1608067418,
        "node_id": "PR_kwDOG1WDQc5LMh13",
        "number": 202,
        "title": "ChatLlaMA fixes",
        "user": {
            "login": "AAnirudh07",
            "id": 86918353,
            "node_id": "MDQ6VXNlcjg2OTE4MzUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/86918353?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/AAnirudh07",
            "html_url": "https://github.com/AAnirudh07",
            "followers_url": "https://api.github.com/users/AAnirudh07/followers",
            "following_url": "https://api.github.com/users/AAnirudh07/following{/other_user}",
            "gists_url": "https://api.github.com/users/AAnirudh07/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/AAnirudh07/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/AAnirudh07/subscriptions",
            "organizations_url": "https://api.github.com/users/AAnirudh07/orgs",
            "repos_url": "https://api.github.com/users/AAnirudh07/repos",
            "events_url": "https://api.github.com/users/AAnirudh07/events{/privacy}",
            "received_events_url": "https://api.github.com/users/AAnirudh07/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-03T07:10:54Z",
        "updated_at": "2023-03-03T09:08:55Z",
        "closed_at": "2023-03-03T08:59:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/202",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/202",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/202.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/202.patch",
            "merged_at": "2023-03-03T08:59:03Z"
        },
        "body": "Hey @diegofiori!\r\nThank you for making `chatllama` public! I was looking into how to create my own dataset and came across this issue: \r\n- [https://github.com/nebuly-ai/nebullvm/issues/200](https://github.com/nebuly-ai/nebullvm/issues/200)\r\n\r\nIn the meantime, I decided to experiment with langchain agents to generate a dataset. During my experimentation, I encountered a few small bugs which I have fixed in this pull request:\r\n1. I added openai to the dependencies\r\n2. I updated the readme with instructions on how to add the openai api key as an environment variable\r\n3. I called the `main()` function in `generate_dataset.py` (currently the script executes but nothing is called).\r\n\r\n\r\nsuper excited for your training example!\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/202/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/201",
        "id": 1607240656,
        "node_id": "I_kwDOG1WDQc5fzIvQ",
        "number": 201,
        "title": "[Chatllama] documentation: update chat llama -> hardware requirements",
        "user": {
            "login": "TashaSkyUp",
            "id": 15312630,
            "node_id": "MDQ6VXNlcjE1MzEyNjMw",
            "avatar_url": "https://avatars.githubusercontent.com/u/15312630?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/TashaSkyUp",
            "html_url": "https://github.com/TashaSkyUp",
            "followers_url": "https://api.github.com/users/TashaSkyUp/followers",
            "following_url": "https://api.github.com/users/TashaSkyUp/following{/other_user}",
            "gists_url": "https://api.github.com/users/TashaSkyUp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/TashaSkyUp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/TashaSkyUp/subscriptions",
            "organizations_url": "https://api.github.com/users/TashaSkyUp/orgs",
            "repos_url": "https://api.github.com/users/TashaSkyUp/repos",
            "events_url": "https://api.github.com/users/TashaSkyUp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/TashaSkyUp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-02T17:51:02Z",
        "updated_at": "2023-03-14T09:56:05Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "some guidance on minimum hardware specifications for each model size would be great.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/201/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/200",
        "id": 1607198973,
        "node_id": "I_kwDOG1WDQc5fy-j9",
        "number": 200,
        "title": "[Chatllama] Question: How to load the ChatLLaMA model weights from the directory for training? Also, can you provide a sample of the training data?",
        "user": {
            "login": "Alla-Abdella",
            "id": 19640509,
            "node_id": "MDQ6VXNlcjE5NjQwNTA5",
            "avatar_url": "https://avatars.githubusercontent.com/u/19640509?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Alla-Abdella",
            "html_url": "https://github.com/Alla-Abdella",
            "followers_url": "https://api.github.com/users/Alla-Abdella/followers",
            "following_url": "https://api.github.com/users/Alla-Abdella/following{/other_user}",
            "gists_url": "https://api.github.com/users/Alla-Abdella/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Alla-Abdella/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Alla-Abdella/subscriptions",
            "organizations_url": "https://api.github.com/users/Alla-Abdella/orgs",
            "repos_url": "https://api.github.com/users/Alla-Abdella/repos",
            "events_url": "https://api.github.com/users/Alla-Abdella/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Alla-Abdella/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-03-02T17:19:27Z",
        "updated_at": "2023-03-23T10:26:41Z",
        "closed_at": "2023-03-23T10:26:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/200/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/198",
        "id": 1606672766,
        "node_id": "I_kwDOG1WDQc5fw-F-",
        "number": 198,
        "title": "No module named `loguru`",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-02T12:01:05Z",
        "updated_at": "2023-03-02T12:56:57Z",
        "closed_at": "2023-03-02T12:56:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "I have been trying to build up on the nebullvm implemetation of forward-forward and use some of the built in libraries. However, I am unable to run it on VSCode or codespaces or colab. I am getting the following error:\r\n```\r\nfrom loguru import logger\r\nModuleNotFoundError: No module named 'loguru'\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/198/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/197",
        "id": 1606407796,
        "node_id": "I_kwDOG1WDQc5fv9Z0",
        "number": 197,
        "title": "Improve Documentation and Sample Code",
        "user": {
            "login": "ylassoued",
            "id": 4647490,
            "node_id": "MDQ6VXNlcjQ2NDc0OTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4647490?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ylassoued",
            "html_url": "https://github.com/ylassoued",
            "followers_url": "https://api.github.com/users/ylassoued/followers",
            "following_url": "https://api.github.com/users/ylassoued/following{/other_user}",
            "gists_url": "https://api.github.com/users/ylassoued/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ylassoued/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ylassoued/subscriptions",
            "organizations_url": "https://api.github.com/users/ylassoued/orgs",
            "repos_url": "https://api.github.com/users/ylassoued/repos",
            "events_url": "https://api.github.com/users/ylassoued/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ylassoued/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-03-02T09:12:04Z",
        "updated_at": "2023-03-11T10:21:28Z",
        "closed_at": "2023-03-10T16:18:40Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Thank you very much for making this public. I have been struggling to understand how to fine tune ChatLLaMA as per the provided code snippet in the [Readme file](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama). It would be much appreciated if you could clarify the following points in the Readme file.\r\n1. Are all the training steps (reward, actor and RL training) required (in the order provided in the code snippet) to train ChatLLaMA, or is it sufficient to train the actor only (`ActorTrainer`)?\r\n2. The training dataset structures (JSON files) are not clear. In `ActorDataset` for example, it is mentioned that `\"completion\"` was `\"the output of the user\"`. What does this mean exactly? Does it mean the expected answer to `\"user_input\"`? Same for the other training datasets. Examples and more elaborate documentation would be much appreciated. \r\n3. How to load the ChatLLaMA model weights (from file/directory) for training? Any chance that you could add this to the training code snippet.\r\n4. It is mentioned in the Readme file that `\"alternatively, you can generate your own dataset using LangChain's agents\"`. Is this an alternative to the custom dataset? I tried to run `generate_dataset.py`, but it did not produce any output file, no errors either.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/197/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/196",
        "id": 1606103812,
        "node_id": "PR_kwDOG1WDQc5LF3_B",
        "number": 196,
        "title": "Addition of unsupervised CNN using forward forward algorithm ",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-02T04:52:51Z",
        "updated_at": "2023-03-02T04:52:51Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/196",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/196",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/196.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/196.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/196/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/195",
        "id": 1605402733,
        "node_id": "PR_kwDOG1WDQc5LDfyG",
        "number": 195,
        "title": "Update huggingface/Readme.md",
        "user": {
            "login": "eltociear",
            "id": 22633385,
            "node_id": "MDQ6VXNlcjIyNjMzMzg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/22633385?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/eltociear",
            "html_url": "https://github.com/eltociear",
            "followers_url": "https://api.github.com/users/eltociear/followers",
            "following_url": "https://api.github.com/users/eltociear/following{/other_user}",
            "gists_url": "https://api.github.com/users/eltociear/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/eltociear/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/eltociear/subscriptions",
            "organizations_url": "https://api.github.com/users/eltociear/orgs",
            "repos_url": "https://api.github.com/users/eltociear/repos",
            "events_url": "https://api.github.com/users/eltociear/events{/privacy}",
            "received_events_url": "https://api.github.com/users/eltociear/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-03-01T17:47:13Z",
        "updated_at": "2023-03-01T19:26:24Z",
        "closed_at": "2023-03-01T19:26:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/195",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/195",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/195.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/195.patch",
            "merged_at": "2023-03-01T19:26:24Z"
        },
        "body": "HuggingFace -> Hugging Face",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/195/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/194",
        "id": 1605259938,
        "node_id": "I_kwDOG1WDQc5frlKi",
        "number": 194,
        "title": "Have the llama weights been uploaded to bittorrent yet, to make them publicly accessible?",
        "user": {
            "login": "distbit0",
            "id": 10890247,
            "node_id": "MDQ6VXNlcjEwODkwMjQ3",
            "avatar_url": "https://avatars.githubusercontent.com/u/10890247?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/distbit0",
            "html_url": "https://github.com/distbit0",
            "followers_url": "https://api.github.com/users/distbit0/followers",
            "following_url": "https://api.github.com/users/distbit0/following{/other_user}",
            "gists_url": "https://api.github.com/users/distbit0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/distbit0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/distbit0/subscriptions",
            "organizations_url": "https://api.github.com/users/distbit0/orgs",
            "repos_url": "https://api.github.com/users/distbit0/repos",
            "events_url": "https://api.github.com/users/distbit0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/distbit0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-03-01T16:10:57Z",
        "updated_at": "2023-03-03T15:53:17Z",
        "closed_at": "2023-03-03T15:53:17Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "If not, is anyone working on this/planning to upload them?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/194/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/193",
        "id": 1604676933,
        "node_id": "I_kwDOG1WDQc5fpW1F",
        "number": 193,
        "title": "Haven't you given me the application form email? Do not know who has applied successfully, can pay to purchase the training set",
        "user": {
            "login": "haxx12113",
            "id": 15908768,
            "node_id": "MDQ6VXNlcjE1OTA4NzY4",
            "avatar_url": "https://avatars.githubusercontent.com/u/15908768?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/haxx12113",
            "html_url": "https://github.com/haxx12113",
            "followers_url": "https://api.github.com/users/haxx12113/followers",
            "following_url": "https://api.github.com/users/haxx12113/following{/other_user}",
            "gists_url": "https://api.github.com/users/haxx12113/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/haxx12113/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/haxx12113/subscriptions",
            "organizations_url": "https://api.github.com/users/haxx12113/orgs",
            "repos_url": "https://api.github.com/users/haxx12113/repos",
            "events_url": "https://api.github.com/users/haxx12113/events{/privacy}",
            "received_events_url": "https://api.github.com/users/haxx12113/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-03-01T10:17:02Z",
        "updated_at": "2023-03-10T16:43:26Z",
        "closed_at": "2023-03-10T16:43:26Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Haven't you given me the application form email? Do not know who has applied successfully, can pay to purchase the training set",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/193/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/192",
        "id": 1603762973,
        "node_id": "PR_kwDOG1WDQc5K98Uh",
        "number": 192,
        "title": "Benchmark-HuggingFace",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-28T20:29:06Z",
        "updated_at": "2023-02-28T20:29:06Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/192",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/192",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/192.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/192.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/192/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/191",
        "id": 1603366136,
        "node_id": "PR_kwDOG1WDQc5K8lwN",
        "number": 191,
        "title": "Add reward and actor training snippet to readme",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-28T16:09:59Z",
        "updated_at": "2023-02-28T16:19:56Z",
        "closed_at": "2023-02-28T16:19:55Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/191",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/191",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/191.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/191.patch",
            "merged_at": "2023-02-28T16:19:55Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/191/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/190",
        "id": 1603316540,
        "node_id": "PR_kwDOG1WDQc5K8a8w",
        "number": 190,
        "title": "Change distillate to distill",
        "user": {
            "login": "egrefen",
            "id": 1145770,
            "node_id": "MDQ6VXNlcjExNDU3NzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1145770?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/egrefen",
            "html_url": "https://github.com/egrefen",
            "followers_url": "https://api.github.com/users/egrefen/followers",
            "following_url": "https://api.github.com/users/egrefen/following{/other_user}",
            "gists_url": "https://api.github.com/users/egrefen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/egrefen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/egrefen/subscriptions",
            "organizations_url": "https://api.github.com/users/egrefen/orgs",
            "repos_url": "https://api.github.com/users/egrefen/repos",
            "events_url": "https://api.github.com/users/egrefen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/egrefen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-28T15:44:41Z",
        "updated_at": "2023-02-28T15:49:28Z",
        "closed_at": "2023-02-28T15:49:28Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/190",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/190",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/190.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/190.patch",
            "merged_at": "2023-02-28T15:49:28Z"
        },
        "body": "Addresses #189.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/190/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/189",
        "id": 1603308312,
        "node_id": "I_kwDOG1WDQc5fkIsY",
        "number": 189,
        "title": "\"distillate\" is incorrect",
        "user": {
            "login": "egrefen",
            "id": 1145770,
            "node_id": "MDQ6VXNlcjExNDU3NzA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1145770?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/egrefen",
            "html_url": "https://github.com/egrefen",
            "followers_url": "https://api.github.com/users/egrefen/followers",
            "following_url": "https://api.github.com/users/egrefen/following{/other_user}",
            "gists_url": "https://api.github.com/users/egrefen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/egrefen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/egrefen/subscriptions",
            "organizations_url": "https://api.github.com/users/egrefen/orgs",
            "repos_url": "https://api.github.com/users/egrefen/repos",
            "events_url": "https://api.github.com/users/egrefen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/egrefen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-28T15:39:59Z",
        "updated_at": "2023-03-02T09:48:30Z",
        "closed_at": "2023-03-02T09:48:30Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "Methods should be named after verbs. \"distillate\" is the product of distillation, not the act of distillation itself. The verb you are looking for is \"distill\".",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/189/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/188",
        "id": 1602649962,
        "node_id": "PR_kwDOG1WDQc5K6JOZ",
        "number": 188,
        "title": "Update training functions for actor and reward models",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-28T09:16:29Z",
        "updated_at": "2023-02-28T09:17:51Z",
        "closed_at": "2023-02-28T09:17:51Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/188",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/188",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/188.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/188.patch",
            "merged_at": "2023-02-28T09:17:51Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/188/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/187",
        "id": 1602453390,
        "node_id": "PR_kwDOG1WDQc5K5fXo",
        "number": 187,
        "title": "Fixed the spelling of leverages",
        "user": {
            "login": "theSekyi",
            "id": 9039160,
            "node_id": "MDQ6VXNlcjkwMzkxNjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/9039160?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/theSekyi",
            "html_url": "https://github.com/theSekyi",
            "followers_url": "https://api.github.com/users/theSekyi/followers",
            "following_url": "https://api.github.com/users/theSekyi/following{/other_user}",
            "gists_url": "https://api.github.com/users/theSekyi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/theSekyi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/theSekyi/subscriptions",
            "organizations_url": "https://api.github.com/users/theSekyi/orgs",
            "repos_url": "https://api.github.com/users/theSekyi/repos",
            "events_url": "https://api.github.com/users/theSekyi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/theSekyi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-28T06:33:26Z",
        "updated_at": "2023-02-28T09:11:27Z",
        "closed_at": "2023-02-28T09:11:26Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/187",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/187",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/187.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/187.patch",
            "merged_at": "2023-02-28T09:11:26Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/187/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/186",
        "id": 1601752483,
        "node_id": "I_kwDOG1WDQc5feM2j",
        "number": 186,
        "title": "Has Meta released the sourcecode for LLaMa? How was ChatLLaMa trained?",
        "user": {
            "login": "NightMachinery",
            "id": 36224762,
            "node_id": "MDQ6VXNlcjM2MjI0NzYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/36224762?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/NightMachinery",
            "html_url": "https://github.com/NightMachinery",
            "followers_url": "https://api.github.com/users/NightMachinery/followers",
            "following_url": "https://api.github.com/users/NightMachinery/following{/other_user}",
            "gists_url": "https://api.github.com/users/NightMachinery/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/NightMachinery/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/NightMachinery/subscriptions",
            "organizations_url": "https://api.github.com/users/NightMachinery/orgs",
            "repos_url": "https://api.github.com/users/NightMachinery/repos",
            "events_url": "https://api.github.com/users/NightMachinery/events{/privacy}",
            "received_events_url": "https://api.github.com/users/NightMachinery/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-02-27T18:46:19Z",
        "updated_at": "2023-03-05T15:53:30Z",
        "closed_at": "2023-03-05T15:53:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Has Meta released the sourcecode for LLaMa? How was ChatLLaMa trained?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/186/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/185",
        "id": 1601197951,
        "node_id": "PR_kwDOG1WDQc5K1S8k",
        "number": 185,
        "title": "Fix some comments and tokenizer outputs from P-Tuning to RLHF",
        "user": {
            "login": "PierpaoloSorbellini",
            "id": 47692350,
            "node_id": "MDQ6VXNlcjQ3NjkyMzUw",
            "avatar_url": "https://avatars.githubusercontent.com/u/47692350?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/PierpaoloSorbellini",
            "html_url": "https://github.com/PierpaoloSorbellini",
            "followers_url": "https://api.github.com/users/PierpaoloSorbellini/followers",
            "following_url": "https://api.github.com/users/PierpaoloSorbellini/following{/other_user}",
            "gists_url": "https://api.github.com/users/PierpaoloSorbellini/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/PierpaoloSorbellini/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/PierpaoloSorbellini/subscriptions",
            "organizations_url": "https://api.github.com/users/PierpaoloSorbellini/orgs",
            "repos_url": "https://api.github.com/users/PierpaoloSorbellini/repos",
            "events_url": "https://api.github.com/users/PierpaoloSorbellini/events{/privacy}",
            "received_events_url": "https://api.github.com/users/PierpaoloSorbellini/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-27T13:32:03Z",
        "updated_at": "2023-02-27T13:33:22Z",
        "closed_at": "2023-02-27T13:33:22Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/185",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/185",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/185.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/185.patch",
            "merged_at": "2023-02-27T13:33:22Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/185/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/184",
        "id": 1600205800,
        "node_id": "PR_kwDOG1WDQc5Kx8rJ",
        "number": 184,
        "title": "Add ChatLLaMA Implementation",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-26T21:19:44Z",
        "updated_at": "2023-02-26T21:22:32Z",
        "closed_at": "2023-02-26T21:22:26Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/184",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/184",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/184.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/184.patch",
            "merged_at": "2023-02-26T21:22:26Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/184/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/183",
        "id": 1599762858,
        "node_id": "PR_kwDOG1WDQc5Kwmbq",
        "number": 183,
        "title": "Added hugging face",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-25T16:44:30Z",
        "updated_at": "2023-02-25T16:44:47Z",
        "closed_at": "2023-02-25T16:44:47Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/183",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/183",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/183.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/183.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/183/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/182",
        "id": 1598818432,
        "node_id": "PR_kwDOG1WDQc5KtfLY",
        "number": 182,
        "title": "Cyclotomicextension hugging face added",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-02-24T15:11:28Z",
        "updated_at": "2023-02-28T20:31:33Z",
        "closed_at": "2023-02-28T20:31:33Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/182",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/182",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/182.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/182.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/182/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/181",
        "id": 1598385348,
        "node_id": "PR_kwDOG1WDQc5Kr_H0",
        "number": 181,
        "title": "Edit CONTRIBUTING.md file",
        "user": {
            "login": "mfumanelli",
            "id": 53374883,
            "node_id": "MDQ6VXNlcjUzMzc0ODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/53374883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mfumanelli",
            "html_url": "https://github.com/mfumanelli",
            "followers_url": "https://api.github.com/users/mfumanelli/followers",
            "following_url": "https://api.github.com/users/mfumanelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/mfumanelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mfumanelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mfumanelli/subscriptions",
            "organizations_url": "https://api.github.com/users/mfumanelli/orgs",
            "repos_url": "https://api.github.com/users/mfumanelli/repos",
            "events_url": "https://api.github.com/users/mfumanelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mfumanelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-24T10:49:00Z",
        "updated_at": "2023-03-01T19:31:11Z",
        "closed_at": "2023-03-01T19:31:10Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/181",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/181",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/181.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/181.patch",
            "merged_at": "2023-03-01T19:31:10Z"
        },
        "body": "Slipped in some fresh guidelines into the CONTRIBUTING.md file ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/181/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/180",
        "id": 1598250010,
        "node_id": "I_kwDOG1WDQc5fQ1wa",
        "number": 180,
        "title": "Add support for Hugging Face models to the benchmark function",
        "user": {
            "login": "mfumanelli",
            "id": 53374883,
            "node_id": "MDQ6VXNlcjUzMzc0ODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/53374883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mfumanelli",
            "html_url": "https://github.com/mfumanelli",
            "followers_url": "https://api.github.com/users/mfumanelli/followers",
            "following_url": "https://api.github.com/users/mfumanelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/mfumanelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mfumanelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mfumanelli/subscriptions",
            "organizations_url": "https://api.github.com/users/mfumanelli/orgs",
            "repos_url": "https://api.github.com/users/mfumanelli/repos",
            "events_url": "https://api.github.com/users/mfumanelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mfumanelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828844,
                "node_id": "LA_kwDOG1WDQc7kCYPs",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/good%20first%20issue",
                "name": "good first issue",
                "color": "7057ff",
                "default": true,
                "description": "Good for newcomers"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "assignees": [
            {
                "login": "cyclotomicextension",
                "id": 49843878,
                "node_id": "MDQ6VXNlcjQ5ODQzODc4",
                "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
                "gravatar_id": "",
                "url": "https://api.github.com/users/cyclotomicextension",
                "html_url": "https://github.com/cyclotomicextension",
                "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
                "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
                "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
                "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
                "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
                "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
                "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
                "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
                "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
                "type": "User",
                "site_admin": false
            }
        ],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-02-24T09:25:22Z",
        "updated_at": "2023-02-28T20:35:40Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "Modify the benchmark function to include compatibility with Hugging Face models \ud83c\udf08",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/180/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/179",
        "id": 1595618102,
        "node_id": "PR_kwDOG1WDQc5KinXR",
        "number": 179,
        "title": "Fix bug in checking data format",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-22T18:39:55Z",
        "updated_at": "2023-02-23T18:28:58Z",
        "closed_at": "2023-02-23T18:28:58Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/179",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/179",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/179.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/179.patch",
            "merged_at": "2023-02-23T18:28:57Z"
        },
        "body": "Closes #176 ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/179/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/178",
        "id": 1593574585,
        "node_id": "PR_kwDOG1WDQc5Kb0vh",
        "number": 178,
        "title": "Fix dynamic_info warning URL",
        "user": {
            "login": "mfumanelli",
            "id": 53374883,
            "node_id": "MDQ6VXNlcjUzMzc0ODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/53374883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mfumanelli",
            "html_url": "https://github.com/mfumanelli",
            "followers_url": "https://api.github.com/users/mfumanelli/followers",
            "following_url": "https://api.github.com/users/mfumanelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/mfumanelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mfumanelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mfumanelli/subscriptions",
            "organizations_url": "https://api.github.com/users/mfumanelli/orgs",
            "repos_url": "https://api.github.com/users/mfumanelli/repos",
            "events_url": "https://api.github.com/users/mfumanelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mfumanelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-21T14:23:25Z",
        "updated_at": "2023-02-24T09:21:14Z",
        "closed_at": "2023-02-24T09:21:14Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/178",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/178",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/178.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/178.patch",
            "merged_at": "2023-02-24T09:21:14Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/178/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/177",
        "id": 1593476364,
        "node_id": "I_kwDOG1WDQc5e-oUM",
        "number": 177,
        "title": "Example using Pytorch dataloader with a Coco Detection dataset is needed",
        "user": {
            "login": "tobymcclean",
            "id": 3801078,
            "node_id": "MDQ6VXNlcjM4MDEwNzg=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3801078?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tobymcclean",
            "html_url": "https://github.com/tobymcclean",
            "followers_url": "https://api.github.com/users/tobymcclean/followers",
            "following_url": "https://api.github.com/users/tobymcclean/following{/other_user}",
            "gists_url": "https://api.github.com/users/tobymcclean/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tobymcclean/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tobymcclean/subscriptions",
            "organizations_url": "https://api.github.com/users/tobymcclean/orgs",
            "repos_url": "https://api.github.com/users/tobymcclean/repos",
            "events_url": "https://api.github.com/users/tobymcclean/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tobymcclean/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-21T13:21:30Z",
        "updated_at": "2023-02-21T14:22:19Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "Unable to find an example that uses a Pytorch dataset and, more importantly, one that uses a Coco Detection dataset.\r\n\r\nWhen running the Yolov8 example, the following error is the output:\r\n\r\n> [ERROR] Unexpected exception AssertionError('The dataloader must include label to measure the metric!') happened during tuning.\r\n\r\nThe error makes sense, but there is no obvious way to use a real Coco Detection dataset. See for example, the OpenVINO Notebook for Yolov8 : [230-yolov8-optimization.ipynb](https://github.com/openvinotoolkit/openvino_notebooks/blob/main/notebooks/230-yolov8-optimization/230-yolov8-optimization.ipynb)",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/177/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/176",
        "id": 1590590202,
        "node_id": "I_kwDOG1WDQc5eznr6",
        "number": 176,
        "title": "Speedster input data not validating correctly",
        "user": {
            "login": "wcde",
            "id": 65939220,
            "node_id": "MDQ6VXNlcjY1OTM5MjIw",
            "avatar_url": "https://avatars.githubusercontent.com/u/65939220?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wcde",
            "html_url": "https://github.com/wcde",
            "followers_url": "https://api.github.com/users/wcde/followers",
            "following_url": "https://api.github.com/users/wcde/following{/other_user}",
            "gists_url": "https://api.github.com/users/wcde/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wcde/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wcde/subscriptions",
            "organizations_url": "https://api.github.com/users/wcde/orgs",
            "repos_url": "https://api.github.com/users/wcde/repos",
            "events_url": "https://api.github.com/users/wcde/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wcde/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-19T07:11:07Z",
        "updated_at": "2023-02-23T18:28:59Z",
        "closed_at": "2023-02-23T18:28:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "## Description\r\nTrying to use copy-pasted code from docs:\r\n```\r\ninput_data = [((torch.randn(1, 3, 256, 256), ), ) for _ in range(100)]\r\noptimized_model = optimize_model(\r\n    model, \r\n    input_data=input_data, \r\n    optimization_time=\"constrained\",\r\n    metric_drop_ths=0.05\r\n)\r\n```\r\nTried different models and inputs, same result. \r\n## Expected Behavior\r\nData loaded without errors.\r\n\r\n## Actual Behavior\r\nGot error:\r\n```\r\n File \"...\\venv\\lib\\site-packages\\speedster\\root_op.py\", line 224, in execute\r\n    raise ValueError(\r\n\r\nValueError: The provided data does not match the expected format.\r\nSpeedster supports data in the following formats:\r\n- PyTorch DataLoader\r\n- TensorFlow Dataset\r\n- List of tuples: [((input_0, ... ), label), ...]\r\nInputs and labels should be either tensors or numpy arrays,\r\ndepending on the framework used.\r\n```\r\n\r\n## Workaround:\r\nAfter replacing function `check_input_data` to stub everything else work correct:\r\n```\r\ndef check_input_data(input_data: Union[Iterable, Sequence]):\r\n    return True\r\n```\r\n\r\n## Environment:\r\n- Windows 11\r\n- Python 3.10.9\r\n- Torch 1.13.1+cu117\r\n- Speedster 0.2.1 from pip\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 1,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/176/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/175",
        "id": 1589540488,
        "node_id": "PR_kwDOG1WDQc5KOm2C",
        "number": 175,
        "title": "Add ToMe notebook and examples folder",
        "user": {
            "login": "mfumanelli",
            "id": 53374883,
            "node_id": "MDQ6VXNlcjUzMzc0ODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/53374883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mfumanelli",
            "html_url": "https://github.com/mfumanelli",
            "followers_url": "https://api.github.com/users/mfumanelli/followers",
            "following_url": "https://api.github.com/users/mfumanelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/mfumanelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mfumanelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mfumanelli/subscriptions",
            "organizations_url": "https://api.github.com/users/mfumanelli/orgs",
            "repos_url": "https://api.github.com/users/mfumanelli/repos",
            "events_url": "https://api.github.com/users/mfumanelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mfumanelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-17T15:31:40Z",
        "updated_at": "2023-02-20T09:17:59Z",
        "closed_at": "2023-02-20T09:17:59Z",
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/175",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/175",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/175.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/175.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/175/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/174",
        "id": 1589517745,
        "node_id": "I_kwDOG1WDQc5evh2x",
        "number": 174,
        "title": "Add ToMe to the techniques used by Speedster",
        "user": {
            "login": "mfumanelli",
            "id": 53374883,
            "node_id": "MDQ6VXNlcjUzMzc0ODgz",
            "avatar_url": "https://avatars.githubusercontent.com/u/53374883?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mfumanelli",
            "html_url": "https://github.com/mfumanelli",
            "followers_url": "https://api.github.com/users/mfumanelli/followers",
            "following_url": "https://api.github.com/users/mfumanelli/following{/other_user}",
            "gists_url": "https://api.github.com/users/mfumanelli/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mfumanelli/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mfumanelli/subscriptions",
            "organizations_url": "https://api.github.com/users/mfumanelli/orgs",
            "repos_url": "https://api.github.com/users/mfumanelli/repos",
            "events_url": "https://api.github.com/users/mfumanelli/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mfumanelli/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828840,
                "node_id": "LA_kwDOG1WDQc7kCYPo",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-17T15:14:26Z",
        "updated_at": "2023-02-21T16:11:25Z",
        "closed_at": null,
        "author_association": "MEMBER",
        "active_lock_reason": null,
        "body": "# Description\r\n**ToMe (Token Merging)** is an optimization technique recently released by Meta AI. It enables acceleration for Visual Transformers by merging tokens with very similar information, and thus speeding up attention.\r\n\r\nAfter some analysis, it is shown that ToMe allows greater acceleration of models when using the CPU than has been achieved so far with Speedster for Visual Transformers. As for the GPU, there is improvement in ViT speed only when using high batch sizes. \r\n\r\nI think it might be useful to implement among the different techniques used by Speedster also ToMe, this to make inference for this type of model on CPU even more efficient.\r\n\r\n# Useful materials\r\n[Analysis ToMe vs Speedster notebook](https://github.com/nebuly-ai/notebooks/blob/main/notebooks/token-merging.ipynb)\r\n[Analysis ToMe vs Speedster blog](https://www.nebuly.com/blog/token-merging-tome-meta-ais-new-optimization-technique-to-make-vit-faster)\r\n[Meta AI's blog](https://research.facebook.com/blog/2023/2/token-merging-your-vit-but-faster/)\r\n[Meta AI's paper](https://arxiv.org/abs/2210.09461)\r\n[Meta AI's repo](https://github.com/facebookresearch/ToMe)",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/174/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/173",
        "id": 1584319227,
        "node_id": "PR_kwDOG1WDQc5J8_l0",
        "number": 173,
        "title": "Update docs and notebooks for new release",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-14T15:01:09Z",
        "updated_at": "2023-02-15T12:54:31Z",
        "closed_at": "2023-02-15T12:54:30Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/173",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/173",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/173.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/173.patch",
            "merged_at": "2023-02-15T12:54:30Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/173/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/172",
        "id": 1578007293,
        "node_id": "I_kwDOG1WDQc5eDnr9",
        "number": 172,
        "title": "What data should be inputted to the speedster optimizer?",
        "user": {
            "login": "orestmalinovskyi-digica",
            "id": 75304184,
            "node_id": "MDQ6VXNlcjc1MzA0MTg0",
            "avatar_url": "https://avatars.githubusercontent.com/u/75304184?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/orestmalinovskyi-digica",
            "html_url": "https://github.com/orestmalinovskyi-digica",
            "followers_url": "https://api.github.com/users/orestmalinovskyi-digica/followers",
            "following_url": "https://api.github.com/users/orestmalinovskyi-digica/following{/other_user}",
            "gists_url": "https://api.github.com/users/orestmalinovskyi-digica/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/orestmalinovskyi-digica/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/orestmalinovskyi-digica/subscriptions",
            "organizations_url": "https://api.github.com/users/orestmalinovskyi-digica/orgs",
            "repos_url": "https://api.github.com/users/orestmalinovskyi-digica/repos",
            "events_url": "https://api.github.com/users/orestmalinovskyi-digica/events{/privacy}",
            "received_events_url": "https://api.github.com/users/orestmalinovskyi-digica/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-02-09T14:35:38Z",
        "updated_at": "2023-02-09T15:42:32Z",
        "closed_at": "2023-02-09T15:42:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "In all the example notebooks for PyTorch I see you use random tensors with labels of just zero. Nowhere it's specifically said what data should be used and in the documentation only once there's a general example on how to use torch dataloaders. \r\n\r\nSo I have a question: what is the expected input data to the optimizer? Can be anything as long as it goes through all layers of the model, or should it be a special calibration dataset with true data and true labels? Or is it in a manner that if for example you don't specify metric drop threshold, then the input can be any random data, but if you specify it, then you should provide with the true data and labels?",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/172/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/171",
        "id": 1576377102,
        "node_id": "PR_kwDOG1WDQc5Jif1f",
        "number": 171,
        "title": "Optimize memory usage and add initial support for stable diffusion.",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-08T15:55:17Z",
        "updated_at": "2023-02-14T13:09:29Z",
        "closed_at": "2023-02-14T13:09:29Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/171",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/171",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/171.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/171.patch",
            "merged_at": "2023-02-14T13:09:29Z"
        },
        "body": "This PR brings support for **stable diffusion** models, along with some **new features**. Moreover, in this PR we remove support for the legacy nebullvm.optimizie_model API.\r\n\r\n### New Features\r\n\r\n- The device param has been changed in order to support the selection of a specific device when working multi-gpu envs:\r\n    - **old way**: `device=\"cpu\"` or `device=\"gpu\"`\r\n    - **new way**: `device=\"cpu\"` or `device=\"cuda\"` or `device=\"gpu\"`, and the cuda/gpu options can be enriched with the index of the gpu that should be used (ex. `cuda:0`, `cuda:1` etc.)\r\n- Add support to input data with inconsistent batch size (needed for stable diffusion)\r\n- Added support to onnxruntime TensorrtExecutionProvider.\r\n- Implemented benchmark functions also for TensorFlow and ONNX.\r\n\r\n### Fixes\r\n- Optimized the gpu memory usage during speedster optimization\r\n- Fixed a bug in openvino when using static quantization\r\n- Now the tensorrt workspace size is dynamically computed according to the free memory available on the gpu device",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/171/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/170",
        "id": 1573107436,
        "node_id": "PR_kwDOG1WDQc5JXiV-",
        "number": 170,
        "title": "Implementing CNN as unsupervised learning using FFA",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-06T18:55:01Z",
        "updated_at": "2023-02-28T20:34:49Z",
        "closed_at": "2023-02-28T20:27:23Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/170",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/170",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/170.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/170.patch",
            "merged_at": null
        },
        "body": "Hello, I tried creating CNNBuildOperation, ConvBNReLU, ConvFFLayer and CNNForwardForwardTrainer where I trained CNN via KMeans clustering. Please let me know what you think!",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/170/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/169",
        "id": 1572681414,
        "node_id": "I_kwDOG1WDQc5dvTbG",
        "number": 169,
        "title": "Optimize ONNXTensorRTInferenceLearner for ONNX and TensorFlow interfaces",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-02-06T14:33:27Z",
        "updated_at": "2023-02-06T14:33:27Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "TensorRT inference time is not optimal when optimizing TensorFlow and ONNX models, we should investigate how we could optimize the `run` method of their inference learners to gain all the possible speed given by TensorRT.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/169/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/168",
        "id": 1571807880,
        "node_id": "PR_kwDOG1WDQc5JTKO8",
        "number": 168,
        "title": "ONNX To Pytorch Conversion",
        "user": {
            "login": "SuperSecureHuman",
            "id": 88489071,
            "node_id": "MDQ6VXNlcjg4NDg5MDcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/88489071?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/SuperSecureHuman",
            "html_url": "https://github.com/SuperSecureHuman",
            "followers_url": "https://api.github.com/users/SuperSecureHuman/followers",
            "following_url": "https://api.github.com/users/SuperSecureHuman/following{/other_user}",
            "gists_url": "https://api.github.com/users/SuperSecureHuman/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/SuperSecureHuman/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/SuperSecureHuman/subscriptions",
            "organizations_url": "https://api.github.com/users/SuperSecureHuman/orgs",
            "repos_url": "https://api.github.com/users/SuperSecureHuman/repos",
            "events_url": "https://api.github.com/users/SuperSecureHuman/events{/privacy}",
            "received_events_url": "https://api.github.com/users/SuperSecureHuman/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-02-06T02:52:02Z",
        "updated_at": "2023-03-05T02:20:59Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/168",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/168",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/168.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/168.patch",
            "merged_at": null
        },
        "body": "Addresses onnx to torch conversion from - https://github.com/nebuly-ai/nebullvm/issues/133",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/168/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/167",
        "id": 1569886439,
        "node_id": "PR_kwDOG1WDQc5JNILC",
        "number": 167,
        "title": "Add Faster Transformer compiler for Bert",
        "user": {
            "login": "cccntu",
            "id": 31893406,
            "node_id": "MDQ6VXNlcjMxODkzNDA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/31893406?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cccntu",
            "html_url": "https://github.com/cccntu",
            "followers_url": "https://api.github.com/users/cccntu/followers",
            "following_url": "https://api.github.com/users/cccntu/following{/other_user}",
            "gists_url": "https://api.github.com/users/cccntu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cccntu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cccntu/subscriptions",
            "organizations_url": "https://api.github.com/users/cccntu/orgs",
            "repos_url": "https://api.github.com/users/cccntu/repos",
            "events_url": "https://api.github.com/users/cccntu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cccntu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-02-03T13:58:26Z",
        "updated_at": "2023-04-18T06:19:22Z",
        "closed_at": "2023-04-18T06:19:22Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/167",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/167",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/167.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/167.patch",
            "merged_at": "2023-04-18T06:19:22Z"
        },
        "body": "WIP for #154\r\n\r\n- [x] Code to install FasterTransformer\r\n- [x] Code to optimize model using FasterTransformer\r\n\r\n# test this PR locally\r\nWIP for #154\r\n\r\n- [x] Code to install FasterTransformer\r\n- [x] Code to optimize model using FasterTransformer\r\n\r\n# test this PR locally\r\n- use the docker image (I'm not sure if the latest I have is actually the latest, it's id is 9e148a3a1d4f)\r\n```bash\r\ndocker run --rm --gpus all -ti nebulydocker/nebullvm:latest\r\n```\r\n##  install FasterTransformer\r\n\r\n```bash\r\ngit clone  <repo>\r\ncd nebullvm\r\ngit fetch <commit>\r\ngit checkout <commit>\r\n\r\n# install speedster and nebullvm separately\r\n# because speedster depends on nebullvm, it may try to install from pypi?\r\n\r\n# when installing speedster, it will install a release version of nebullvm, so we need to install it in 2 steps\r\npip install ./apps/accelerate/speedster\r\n# overwrite the release version of nebullvm with the local version\r\npip install .\r\n\r\n# note: when running `pip install`, it will create a build directory somewhere in the code directory\r\n\r\n# when installing \r\n# probably need to checkout to another directory before running the below command\r\n# so faster_transformer's library code is installed to the correct location\r\npython -m nebullvm.installers.auto_installer  --f torch --compilers faster_transformer\r\n```\r\n* verify installation is successful\r\n```python\r\nfrom nebullvm.operations.optimizations.compilers.utils import faster_transformer_is_available\r\nfaster_transformer_is_available()\r\n```\r\n* run the bert example\r\n```bash\r\npython notebooks/speedster/huggingface/faster_transformer_bert.py\r\n```\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/167/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/166",
        "id": 1561242878,
        "node_id": "PR_kwDOG1WDQc5IwL0V",
        "number": 166,
        "title": "OpenAlphaTensor: Improve memory management and speed up the acting process",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-29T11:18:40Z",
        "updated_at": "2023-01-29T11:19:08Z",
        "closed_at": "2023-01-29T11:19:03Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/166",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/166",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/166.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/166.patch",
            "merged_at": "2023-01-29T11:19:03Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/166/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/165",
        "id": 1559789302,
        "node_id": "PR_kwDOG1WDQc5Irasq",
        "number": 165,
        "title": "Add Encoder-Decoder model(T5) notebook",
        "user": {
            "login": "VinishUchiha",
            "id": 25880763,
            "node_id": "MDQ6VXNlcjI1ODgwNzYz",
            "avatar_url": "https://avatars.githubusercontent.com/u/25880763?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/VinishUchiha",
            "html_url": "https://github.com/VinishUchiha",
            "followers_url": "https://api.github.com/users/VinishUchiha/followers",
            "following_url": "https://api.github.com/users/VinishUchiha/following{/other_user}",
            "gists_url": "https://api.github.com/users/VinishUchiha/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/VinishUchiha/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/VinishUchiha/subscriptions",
            "organizations_url": "https://api.github.com/users/VinishUchiha/orgs",
            "repos_url": "https://api.github.com/users/VinishUchiha/repos",
            "events_url": "https://api.github.com/users/VinishUchiha/events{/privacy}",
            "received_events_url": "https://api.github.com/users/VinishUchiha/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-01-27T13:40:26Z",
        "updated_at": "2023-01-30T09:41:40Z",
        "closed_at": "2023-01-30T09:41:40Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/165",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/165",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/165.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/165.patch",
            "merged_at": "2023-01-30T09:41:40Z"
        },
        "body": "## I added a new notebook which demonstrate a way to optimize Encoder-Decoder model(T5) using Speedster.\r\n\r\nI used the same template of other huggingface notebooks, so others easy to follow along.\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/165/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/164",
        "id": 1557844115,
        "node_id": "PR_kwDOG1WDQc5Ik002",
        "number": 164,
        "title": "Fix torchscript fp16 on int inputs",
        "user": {
            "login": "cccntu",
            "id": 31893406,
            "node_id": "MDQ6VXNlcjMxODkzNDA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/31893406?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cccntu",
            "html_url": "https://github.com/cccntu",
            "followers_url": "https://api.github.com/users/cccntu/followers",
            "following_url": "https://api.github.com/users/cccntu/following{/other_user}",
            "gists_url": "https://api.github.com/users/cccntu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cccntu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cccntu/subscriptions",
            "organizations_url": "https://api.github.com/users/cccntu/orgs",
            "repos_url": "https://api.github.com/users/cccntu/repos",
            "events_url": "https://api.github.com/users/cccntu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cccntu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-26T09:31:14Z",
        "updated_at": "2023-01-26T17:03:20Z",
        "closed_at": "2023-01-26T17:03:20Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/164",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/164",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/164.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/164.patch",
            "merged_at": "2023-01-26T17:03:20Z"
        },
        "body": "use .half() only when input is float\r\n\r\nFixes #163 ",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/164/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/163",
        "id": 1557842332,
        "node_id": "I_kwDOG1WDQc5c2smc",
        "number": 163,
        "title": "int inputs gets converted to half()",
        "user": {
            "login": "cccntu",
            "id": 31893406,
            "node_id": "MDQ6VXNlcjMxODkzNDA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/31893406?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cccntu",
            "html_url": "https://github.com/cccntu",
            "followers_url": "https://api.github.com/users/cccntu/followers",
            "following_url": "https://api.github.com/users/cccntu/following{/other_user}",
            "gists_url": "https://api.github.com/users/cccntu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cccntu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cccntu/subscriptions",
            "organizations_url": "https://api.github.com/users/cccntu/orgs",
            "repos_url": "https://api.github.com/users/cccntu/repos",
            "events_url": "https://api.github.com/users/cccntu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cccntu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-01-26T09:29:41Z",
        "updated_at": "2023-01-26T17:03:21Z",
        "closed_at": "2023-01-26T17:03:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "Following the bert example notebook. I noticed this:\r\n\r\n```\r\nWARNING  | Optimization failed with DeepLearningFramework.PYTORCH interface of \r\nModelCompiler.TORCHSCRIPT. Got error Expected tensor for argument #1 'indices' \r\nto have one of the following scalar types: Long, Int; but got torch.cuda.HalfTensor\r\ninstead (while checking arguments for embedding). If possible the compilation will \r\nbe re-scheduled with another interface. Please consult the documentation for further\r\ninfo or open an issue on GitHub for receiving assistance.\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/163/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/162",
        "id": 1555240390,
        "node_id": "I_kwDOG1WDQc5csxXG",
        "number": 162,
        "title": "Add conversion from ONNX to TensorFlow to allow cross conversion PyTorch->ONNX->TensorFlow",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 3825828840,
                "node_id": "LA_kwDOG1WDQc7kCYPo",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 3825828841,
                "node_id": "LA_kwDOG1WDQc7kCYPp",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/help%20wanted",
                "name": "help wanted",
                "color": "008672",
                "default": true,
                "description": "Extra attention is needed"
            },
            {
                "id": 3825828844,
                "node_id": "LA_kwDOG1WDQc7kCYPs",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/good%20first%20issue",
                "name": "good first issue",
                "color": "7057ff",
                "default": true,
                "description": "Good for newcomers"
            },
            {
                "id": 4981513383,
                "node_id": "LA_kwDOG1WDQc8AAAABKOvcpw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/speedster",
                "name": "speedster",
                "color": "bfdadc",
                "default": false,
                "description": "Issue related to the Speedster App"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-01-24T15:57:50Z",
        "updated_at": "2023-03-28T15:28:14Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "At the moment we support only PyTorch to ONNX and TensorFlow to ONNX conversions. We could test and use this [repo](https://github.com/PINTO0309/onnx2tf) to convert an ONNX model to TensorFlow in order to support PyTorch to TensorFlow conversion.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/162/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/161",
        "id": 1555102878,
        "node_id": "PR_kwDOG1WDQc5IbrEo",
        "number": 161,
        "title": "Change auto installer API and small fixes",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-01-24T14:35:09Z",
        "updated_at": "2023-01-27T16:17:17Z",
        "closed_at": "2023-01-27T16:17:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/161",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/161",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/161.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/161.patch",
            "merged_at": "2023-01-27T16:17:16Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/161/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/160",
        "id": 1553449055,
        "node_id": "PR_kwDOG1WDQc5IWGJl",
        "number": 160,
        "title": "Fixes and improvements for TensorRT",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-23T17:04:53Z",
        "updated_at": "2023-01-23T21:56:24Z",
        "closed_at": "2023-01-23T21:56:24Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/160",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/160",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/160.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/160.patch",
            "merged_at": "2023-01-23T21:56:24Z"
        },
        "body": "This PR brings the following changes:\r\n- Fixes TensorRT behaviour when using dynamic shape. TensorRT requires to set a max, min and optimal value for each dynamic axis of the network inputs, so the dynamic_info structure has been changed in the following way:\r\n\r\n**old_way**:\r\n\r\n``` python\r\n# Set dynamic info\r\ndynamic_info = {\r\n    \"inputs\": [\r\n        {0: \"batch\", 2: \"dim_image\", 3: \"dim_image\"}\r\n    ],\r\n    \"outputs\": [\r\n        {0: \"batch\", 1: \"out_dim\"}\r\n    ]\r\n}\r\n```\r\n**new_way**:\r\n\r\n``` python\r\n# Set dynamic info\r\ndynamic_info = {\r\n    \"inputs\": [\r\n        {\r\n            0: {\"name\": \"batch\", \"min_val\": 1, \"opt_val\": 1, \"max_val\": 4}, \r\n            2: {\"name\": \"dim_image\", \"min_val\": 224, \"opt_val\": 256, \"max_val\": 320},  \r\n            3: {\"name\": \"dim_image\", \"min_val\": 224, \"opt_val\": 256, \"max_val\": 320},\r\n        } \r\n    ],\r\n    \"outputs\": [\r\n        {0: \"batch\", 1: \"out_dim\"}\r\n    ]\r\n}\r\n```\r\nThe old format is still supported, but does not work with TensorRT.\r\n\r\n- Fixes some issues with unit tests, and adds additional controls to ensure that an optimized model with dynamic shape works properly.\r\n- Improves significantly the performance of TensorRT with ONNX interface\r\n- Removes all custom code for yolov5, because now can be optimized directly without wrappers, and updates the notebook\r\n- Limits the gpu memory used by tensorflow, to avoid memory issues during tensorflow models optimization",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/160/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/159",
        "id": 1552171583,
        "node_id": "PR_kwDOG1WDQc5IR3YL",
        "number": 159,
        "title": "Speedster: Add save function and edit notebooks",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-22T15:54:20Z",
        "updated_at": "2023-01-23T22:56:14Z",
        "closed_at": "2023-01-23T22:55:50Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/159",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/159",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/159.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/159.patch",
            "merged_at": "2023-01-23T22:55:50Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/159/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/158",
        "id": 1551828118,
        "node_id": "I_kwDOG1WDQc5cfwSW",
        "number": 158,
        "title": "ONNX model doesn't run on GPU after save & load",
        "user": {
            "login": "cccntu",
            "id": 31893406,
            "node_id": "MDQ6VXNlcjMxODkzNDA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/31893406?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cccntu",
            "html_url": "https://github.com/cccntu",
            "followers_url": "https://api.github.com/users/cccntu/followers",
            "following_url": "https://api.github.com/users/cccntu/following{/other_user}",
            "gists_url": "https://api.github.com/users/cccntu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cccntu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cccntu/subscriptions",
            "organizations_url": "https://api.github.com/users/cccntu/orgs",
            "repos_url": "https://api.github.com/users/cccntu/repos",
            "events_url": "https://api.github.com/users/cccntu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cccntu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-01-21T15:20:21Z",
        "updated_at": "2023-01-22T11:02:08Z",
        "closed_at": "2023-01-22T11:02:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "# enviroment\r\n- GPU: 3090\r\n- cuda 11.7\r\n- docker image `nebulydocker/nebullvm:latest` \r\n# reproduce\r\n- run `Accelerate_Hugging_Face_PyTorch_BERT_with_Speedster` in the docker image `nebulydocker/nebullvm:latest` \r\n- change this line:\r\n```diff\r\n-  ignore_compilers=[\"tensor RT\"],  #\u00a0TensorRT does not work for this model\r\n+  ignore_compilers=[\"tensor_rt\", \"tvm\"],\r\n```\r\n```\r\n[Speedster results on NVIDIA GeForce RTX 3090]\r\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\r\n\u2503 Metric      \u2503 Original Model   \u2503 Optimized Model   \u2503 Improvement   \u2503\r\n\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\r\n\u2503 backend     \u2503 PYTORCH          \u2503 ONNXRuntime       \u2503               \u2503\r\n\u2503 latency     \u2503 0.0046 sec/batch \u2503 0.0019 sec/batch  \u2503 2.41x         \u2503\r\n\u2503 throughput  \u2503 219.60 data/sec  \u2503 530.05 data/sec   \u2503 2.41x         \u2503\r\n\u2503 model size  \u2503 438.03 MB        \u2503 219.36 MB         \u2503 -49%          \u2503\r\n\u2503 metric drop \u2503                  \u2503 0.0081            \u2503               \u2503\r\n\u2503 techniques  \u2503                  \u2503 fp16              \u2503               \u2503\r\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\r\n```\r\n\r\n\r\n- Save and then load the model\r\n```python\r\noptimized_model.save(save_path)\r\nfrom nebullvm.operations.inference_learners.base import LearnerMetadata\r\noptimized_model = LearnerMetadata.read(save_path).load_model(save_path)\r\n```\r\n- rerun the benchmark code and it's running on CPU instead of GPU\r\n```\r\nAverage response time for reloaded optimized BERT (no metric drop): 32.32806539010198 ms\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/158/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/157",
        "id": 1551751007,
        "node_id": "PR_kwDOG1WDQc5IQoc8",
        "number": 157,
        "title": "Bugfixes",
        "user": {
            "login": "valeriosofi",
            "id": 28647171,
            "node_id": "MDQ6VXNlcjI4NjQ3MTcx",
            "avatar_url": "https://avatars.githubusercontent.com/u/28647171?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/valeriosofi",
            "html_url": "https://github.com/valeriosofi",
            "followers_url": "https://api.github.com/users/valeriosofi/followers",
            "following_url": "https://api.github.com/users/valeriosofi/following{/other_user}",
            "gists_url": "https://api.github.com/users/valeriosofi/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/valeriosofi/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/valeriosofi/subscriptions",
            "organizations_url": "https://api.github.com/users/valeriosofi/orgs",
            "repos_url": "https://api.github.com/users/valeriosofi/repos",
            "events_url": "https://api.github.com/users/valeriosofi/events{/privacy}",
            "received_events_url": "https://api.github.com/users/valeriosofi/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-21T09:42:47Z",
        "updated_at": "2023-01-22T09:57:00Z",
        "closed_at": "2023-01-22T09:56:59Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/157",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/157",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/157.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/157.patch",
            "merged_at": "2023-01-22T09:56:59Z"
        },
        "body": "This PR solves the following problems:\r\n- fixes an error in the benchmark function with the device selection.\r\n- removes setuptools from tensorrt installation, it's not needed anymore by the newer version and it was causing issues with the azure pipelines.\r\n- adds missing port forwarding in the docker run command inside the notebooks readme.\r\n- fixes broken links in all the notebooks.\r\n- fixes an issue in the huggingface notebooks with the ignore_compilers parameter.\r\n- fixes an issue in the yolov5 notebook that could lead to misleading performance results.\r\n- fixes an issue with the device after saving and loading again a model, solving #158",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/157/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/156",
        "id": 1551748924,
        "node_id": "PR_kwDOG1WDQc5IQoFq",
        "number": 156,
        "title": "Fixed version compatibility error when importing speedster",
        "user": {
            "login": "arianGh1",
            "id": 78415162,
            "node_id": "MDQ6VXNlcjc4NDE1MTYy",
            "avatar_url": "https://avatars.githubusercontent.com/u/78415162?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/arianGh1",
            "html_url": "https://github.com/arianGh1",
            "followers_url": "https://api.github.com/users/arianGh1/followers",
            "following_url": "https://api.github.com/users/arianGh1/following{/other_user}",
            "gists_url": "https://api.github.com/users/arianGh1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/arianGh1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/arianGh1/subscriptions",
            "organizations_url": "https://api.github.com/users/arianGh1/orgs",
            "repos_url": "https://api.github.com/users/arianGh1/repos",
            "events_url": "https://api.github.com/users/arianGh1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/arianGh1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-01-21T09:32:15Z",
        "updated_at": "2023-01-22T09:51:52Z",
        "closed_at": "2023-01-22T09:51:52Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/156",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/156",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/156.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/156.patch",
            "merged_at": "2023-01-22T09:51:52Z"
        },
        "body": "when I wanted to run the cell containing `from speedster import optimize_model` on Google Colab this was the error that I got:  \r\n\r\n`ContextualVersionConflict: (protobuf 3.19.6 (/usr/local/lib/python3.8/dist-packages), Requirement.parse('protobuf<4,>=3.20.2'), {'onnx'})`  \r\n\r\nso I added this cell to the notebook and the problem was fixed:\r\n```\r\n!pip install virtualenv\r\n!virtualenv -p python3 newenv   \r\n!pip install protobuf==3.12.2 speedster onnx==1.8.0\r\n```",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/156/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/pull/155",
        "id": 1535364832,
        "node_id": "PR_kwDOG1WDQc5HfTr4",
        "number": 155,
        "title": "Update README.md patch 1 by adding multiple device option- CPU and GPU",
        "user": {
            "login": "cyclotomicextension",
            "id": 49843878,
            "node_id": "MDQ6VXNlcjQ5ODQzODc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/49843878?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyclotomicextension",
            "html_url": "https://github.com/cyclotomicextension",
            "followers_url": "https://api.github.com/users/cyclotomicextension/followers",
            "following_url": "https://api.github.com/users/cyclotomicextension/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyclotomicextension/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyclotomicextension/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyclotomicextension/subscriptions",
            "organizations_url": "https://api.github.com/users/cyclotomicextension/orgs",
            "repos_url": "https://api.github.com/users/cyclotomicextension/repos",
            "events_url": "https://api.github.com/users/cyclotomicextension/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyclotomicextension/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-01-16T18:59:15Z",
        "updated_at": "2023-01-16T21:39:25Z",
        "closed_at": "2023-01-16T21:39:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/pulls/155",
            "html_url": "https://github.com/nebuly-ai/nebuly/pull/155",
            "diff_url": "https://github.com/nebuly-ai/nebuly/pull/155.diff",
            "patch_url": "https://github.com/nebuly-ai/nebuly/pull/155.patch",
            "merged_at": "2023-01-16T21:39:25Z"
        },
        "body": "Having encountered errors when trying to implement the code provided on ReadME.md on my MacOS M1 VSCode version1.74.3 and Python 3.8 , I decided to add an option so that in case the VSCode does not have GPU available, it may switch to CPU without causing any troubles. Hence, I updated the ReadME.md file by adding the following lines of code in the USAGE section,:\r\n```\r\nimport os\r\nimport torch\r\n\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n```\r\n\r\nand setting `device=device` instead of `device=\"CUDA\"` in `trained_model=` part.",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/155/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154",
        "repository_url": "https://api.github.com/repos/nebuly-ai/nebuly",
        "labels_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154/labels{/name}",
        "comments_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154/comments",
        "events_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154/events",
        "html_url": "https://github.com/nebuly-ai/nebuly/issues/154",
        "id": 1534866546,
        "node_id": "I_kwDOG1WDQc5bfDRy",
        "number": 154,
        "title": "Implement a new optimizer for TF and torch using FasterTransformer as a backend",
        "user": {
            "login": "diegofiori",
            "id": 38586138,
            "node_id": "MDQ6VXNlcjM4NTg2MTM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/38586138?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/diegofiori",
            "html_url": "https://github.com/diegofiori",
            "followers_url": "https://api.github.com/users/diegofiori/followers",
            "following_url": "https://api.github.com/users/diegofiori/following{/other_user}",
            "gists_url": "https://api.github.com/users/diegofiori/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/diegofiori/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/diegofiori/subscriptions",
            "organizations_url": "https://api.github.com/users/diegofiori/orgs",
            "repos_url": "https://api.github.com/users/diegofiori/repos",
            "events_url": "https://api.github.com/users/diegofiori/events{/privacy}",
            "received_events_url": "https://api.github.com/users/diegofiori/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4981513383,
                "node_id": "LA_kwDOG1WDQc8AAAABKOvcpw",
                "url": "https://api.github.com/repos/nebuly-ai/nebuly/labels/speedster",
                "name": "speedster",
                "color": "bfdadc",
                "default": false,
                "description": "Issue related to the Speedster App"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-01-16T12:37:40Z",
        "updated_at": "2023-01-16T14:02:57Z",
        "closed_at": null,
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "# Description\r\n\r\nFasterTransformer is a library developed by Nvidia specifically for accelerating transformer architecture on Nvidia devices. We should test its performance and implement a conversion framework for converting TF, HF, and Torch models into the FasterTransformer supported objects.\r\n\r\n# Integration\r\n\r\nThe FasterTransformer integration will be considered in Speedster as a Compiler and it will have both the PyTorch and TensorFlow interface (Both frameworks are supported by the library). As all compilers the FasterTransformer one will need to support fp16 and int8 computations.\r\n\r\n# TODO list\r\n\r\n- [ ]  Implement a PoC using the OS-conversion (or implement our own conversion if it doesn\u2019t exists)\r\n- [ ]  Analyse the impact of the feature respect the actual Speedster\r\n- [ ]  If a positive impact of the feature is assessed we should implement it as a Compiler in Speedster. Note that when implementing a new Compiler we need to implement its `InferenceLearner` as well. `InferenceLearner`s are the Python object we use for wrapping the compiled model and expose an interface similar to the original model.\r\n- [ ]  Fork the nebullvm repo https://github.com/nebuly-ai/nebullvm\r\n- [ ]  Read the [Contribution Guidelines](https://github.com/nebuly-ai/nebullvm/blob/main/CONTRIBUTING.md)\r\n- [ ]  Create a PR to main explaining your changes and showing the improvements obtained using FasterTransformer respect the previous version\r\n\r\n# Resources:\r\n[FasterTransformer Library](https://github.com/NVIDIA/FasterTransformer)",
        "reactions": {
            "url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/nebuly-ai/nebuly/issues/154/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]