[
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7788",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7788/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7788/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7788/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7788",
        "id": 1909369922,
        "node_id": "PR_kwDOIWuq585bA_9c",
        "number": 7788,
        "title": "[version] bump version to 0.8.31",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T18:44:14Z",
        "updated_at": "2023-09-23T04:13:32Z",
        "closed_at": "2023-09-23T04:13:31Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7788",
            "html_url": "https://github.com/run-llama/llama_index/pull/7788",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7788.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7788.patch",
            "merged_at": "2023-09-23T04:13:31Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7788/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7788/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7787",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7787/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7787/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7787/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7787",
        "id": 1909316404,
        "node_id": "PR_kwDOIWuq585bA048",
        "number": 7787,
        "title": "Modernizing `mypy` to 1.5.1",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-22T18:00:22Z",
        "updated_at": "2023-09-22T18:26:37Z",
        "closed_at": "2023-09-22T18:23:39Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7787",
            "html_url": "https://github.com/run-llama/llama_index/pull/7787",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7787.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7787.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nCI test of newer `mypy`, to see the extent of the damage\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7787/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7787/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7786",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7786/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7786/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7786/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7786",
        "id": 1909262340,
        "node_id": "PR_kwDOIWuq585bApbB",
        "number": 7786,
        "title": "Add support for simple index and keyval stores that uses pickle as a storing mechanism instead of JSON files",
        "user": {
            "login": "mzyil",
            "id": 6615389,
            "node_id": "MDQ6VXNlcjY2MTUzODk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6615389?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mzyil",
            "html_url": "https://github.com/mzyil",
            "followers_url": "https://api.github.com/users/mzyil/followers",
            "following_url": "https://api.github.com/users/mzyil/following{/other_user}",
            "gists_url": "https://api.github.com/users/mzyil/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mzyil/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mzyil/subscriptions",
            "organizations_url": "https://api.github.com/users/mzyil/orgs",
            "repos_url": "https://api.github.com/users/mzyil/repos",
            "events_url": "https://api.github.com/users/mzyil/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mzyil/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6003643465,
                "node_id": "LA_kwDOIWuq588AAAABZdhUSQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/storage",
                "name": "storage",
                "color": "3176BF",
                "default": false,
                "description": ""
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-22T17:14:26Z",
        "updated_at": "2023-09-25T04:45:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7786",
            "html_url": "https://github.com/run-llama/llama_index/pull/7786",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7786.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7786.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nUsing JSON files as a storage mechanism costs a lot of time when the index structs become too big. This PR proposes a new index store paired with a keyval store that does away with JSON loading and data validation.\r\n\r\nWe recently had constructed a knowledge graph which amounted to a ~2 GB JSON file. It was painful to work with. Even with good hardware it took 10 mins to load. These new classes bypass JSON parsing and data validation of the `dataclasses` package in favor of pickled files, which brought down the loading times to 30 secs.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7786/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7786/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7785",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7785/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7785/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7785/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7785",
        "id": 1909239929,
        "node_id": "PR_kwDOIWuq585bAknJ",
        "number": 7785,
        "title": "Pass in llm into ChatMemoryBuffer for condense_question chat engine",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T16:56:28Z",
        "updated_at": "2023-09-22T18:51:46Z",
        "closed_at": "2023-09-22T18:51:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7785",
            "html_url": "https://github.com/run-llama/llama_index/pull/7785",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7785.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7785.patch",
            "merged_at": "2023-09-22T18:51:46Z"
        },
        "body": "# Description\r\n\r\nWas looking at understanding how the chat engine works with the `ChatMemoryBuffer` (for #7765) and noticed that the LLM wasn't getting passed into the `condense_question` engine. PR passes it in so that the token limit can be set from it.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] My changes generate no new warnings\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7785/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7785/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7784",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7784/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7784/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7784/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7784",
        "id": 1909221534,
        "node_id": "PR_kwDOIWuq585bAguA",
        "number": 7784,
        "title": "Addressing PyYAML import error",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-22T16:42:00Z",
        "updated_at": "2023-09-26T15:48:49Z",
        "closed_at": "2023-09-26T15:35:32Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7784",
            "html_url": "https://github.com/run-llama/llama_index/pull/7784",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7784.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7784.patch",
            "merged_at": "2023-09-26T15:35:32Z"
        },
        "body": "# Description\r\n\r\nhttps://github.com/jerryjliu/llama_index/pull/6246/files#diff-c241e91b7a68e1709456d4c87e62b00948d218cd4f8d483c26667ecfc58a8651R4 added `yaml`, but it's not reflected in `setup.py`.  Thus, it's possible to get `ImportError`.\r\n\r\nThis PR fixes that potential pitfall, and also adds PyYAML's type stub.  Imo it's not worth requiring all LlamaIndex users to install PyYAML just to enable one helper function.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7784/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7784/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7783",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7783/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7783/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7783/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7783",
        "id": 1909209790,
        "node_id": "PR_kwDOIWuq585bAeOy",
        "number": 7783,
        "title": "`StorageContext.persist` supporting `Path`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 6003643465,
                "node_id": "LA_kwDOIWuq588AAAABZdhUSQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/storage",
                "name": "storage",
                "color": "3176BF",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T16:32:05Z",
        "updated_at": "2023-09-26T18:18:00Z",
        "closed_at": "2023-09-26T17:43:08Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7783",
            "html_url": "https://github.com/run-llama/llama_index/pull/7783",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7783.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7783.patch",
            "merged_at": "2023-09-26T17:43:08Z"
        },
        "body": "# Description\r\n\r\nCloses https://github.com/jerryjliu/llama_index/issues/7777.\r\n- Looks like https://github.com/jerryjliu/llama_index/pull/3778 added support for a new control flow, that could have been just one, so I moved to just one control flow\r\n- Improved `concat_dirs` to have better arg names and cleaner docstring\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7783/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7783/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7782",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7782/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7782/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7782/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7782",
        "id": 1908687697,
        "node_id": "I_kwDOIWuq585xxENR",
        "number": 7782,
        "title": "[Bug]: RedisVectorStore cannot set a redis_url with a password",
        "user": {
            "login": "checkking",
            "id": 3713123,
            "node_id": "MDQ6VXNlcjM3MTMxMjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3713123?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/checkking",
            "html_url": "https://github.com/checkking",
            "followers_url": "https://api.github.com/users/checkking/followers",
            "following_url": "https://api.github.com/users/checkking/following{/other_user}",
            "gists_url": "https://api.github.com/users/checkking/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/checkking/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/checkking/subscriptions",
            "organizations_url": "https://api.github.com/users/checkking/orgs",
            "repos_url": "https://api.github.com/users/checkking/repos",
            "events_url": "https://api.github.com/users/checkking/events{/privacy}",
            "received_events_url": "https://api.github.com/users/checkking/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-22T10:58:34Z",
        "updated_at": "2023-11-03T19:17:38Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\n\r\nI use redis as my llama-index vector store. When I start with RedisVectorStore with no password redis, it is ok. But, when I set a password, I got an error. Here is my code:\r\n1) no password ok\r\n`        redisURL = \"redis://localhost:6379\"\r\n        index_name = \"yd_vector\"\r\n        vector_store = RedisVectorStore(\r\n            index_name=index_name,\r\n            index_prefix=\"llama\",\r\n            redis_url=redisURL,\r\n            overwrite=True,\r\n        )`\r\n\r\n2) when redis need password(the password I set is correct), no ok:\r\n`        #redisURL = \"redis://:redis20230901@localhost:6379\"\r\n        redisURL = \"redis://localhost:6379\"\r\n        index_name = \"yd_vector\"\r\n        vector_store = RedisVectorStore(\r\n            index_name=index_name,\r\n            index_prefix=\"llama\",\r\n            redis_url=redisURL,\r\n            overwrite=True,\r\n        )`\r\n\r\n\r\na error accurred:\r\n\r\nredis.exceptions.AuthenticationError: AUTH <password> called without any password configured for the default user. Are you sure your configuration is correct?\r\n<img width=\"1465\" alt=\"image\" src=\"https://github.com/jerryjliu/llama_index/assets/3713123/f90d6257-c8e2-47a2-a21b-8c330d770f2a\">\r\n\r\nThere my has a bug, please help me.\r\n\n\n### Version\n\n0.8.29.post1\n\n### Steps to Reproduce\n\njust use  the class RedisVectorStore and with a password redis-url, like \r\n`        redisURL = \"redis://localhost:6379\"\r\n        index_name = \"yd_vector\"\r\n        vector_store = RedisVectorStore(\r\n            index_name=index_name,\r\n            index_prefix=\"llama\",\r\n            redis_url=redisURL,\r\n            overwrite=True,\r\n        )``\n\n### Relevant Logs/Tracbacks\n\n```shell\nvector_store = RedisVectorStore(\r\n                   ^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/llama_index/vector_stores/redis.py\", line 112, in __init__\r\n    check_redis_modules_exist(self._redis_client)\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/llama_index/readers/redis/utils.py\", line 46, in check_redis_modules_exist\r\n    installed_modules = client.module_list()\r\n                        ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/commands/core.py\", line 5885, in module_list\r\n    return self.execute_command(\"MODULE LIST\")\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/client.py\", line 505, in execute_command\r\n    conn = self.connection or pool.get_connection(command_name, **options)\r\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/connection.py\", line 1073, in get_connection\r\n    connection.connect()\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/connection.py\", line 271, in connect\r\n    self.on_connect()\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/connection.py\", line 335, in on_connect\r\n    auth_response = self.read_response()\r\n                    ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/connection.py\", line 493, in read_response\r\n    response = self._parser.read_response(disable_decoding=disable_decoding)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/_parsers/resp2.py\", line 15, in read_response\r\n    result = self._read_response(disable_decoding=disable_decoding)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/anaconda3/lib/python3.11/site-packages/redis/_parsers/resp2.py\", line 38, in _read_response\r\n    raise error\r\nredis.exceptions.AuthenticationError: AUTH <password> called without any password configured for the default user. Are you sure your configuration is correct?\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7782/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7782/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7781",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7781/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7781/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7781/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7781",
        "id": 1908557080,
        "node_id": "PR_kwDOIWuq585a-QwY",
        "number": 7781,
        "title": "Fix broken link to example notebook in query_transformations.md",
        "user": {
            "login": "tleyden",
            "id": 296876,
            "node_id": "MDQ6VXNlcjI5Njg3Ng==",
            "avatar_url": "https://avatars.githubusercontent.com/u/296876?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tleyden",
            "html_url": "https://github.com/tleyden",
            "followers_url": "https://api.github.com/users/tleyden/followers",
            "following_url": "https://api.github.com/users/tleyden/following{/other_user}",
            "gists_url": "https://api.github.com/users/tleyden/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tleyden/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tleyden/subscriptions",
            "organizations_url": "https://api.github.com/users/tleyden/orgs",
            "repos_url": "https://api.github.com/users/tleyden/repos",
            "events_url": "https://api.github.com/users/tleyden/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tleyden/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T09:38:02Z",
        "updated_at": "2023-09-22T18:00:25Z",
        "closed_at": "2023-09-22T18:00:25Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7781",
            "html_url": "https://github.com/run-llama/llama_index/pull/7781",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7781.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7781.patch",
            "merged_at": "2023-09-22T18:00:25Z"
        },
        "body": "# Description\r\n\r\nFix broken link to example notebook in query_transformations.md.\r\n\r\nI used an absolute link like the other notebook links in this md doc.\r\n\r\nFixes # None - can file one if needed\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nNot tested, but it's just a broken link so it can't get any worse.\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7781/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7781/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7780",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7780/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7780/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7780/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7780",
        "id": 1908556239,
        "node_id": "PR_kwDOIWuq585a-Qkm",
        "number": 7780,
        "title": "Myscale/vectorstore patch",
        "user": {
            "login": "mpskex",
            "id": 8456706,
            "node_id": "MDQ6VXNlcjg0NTY3MDY=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8456706?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mpskex",
            "html_url": "https://github.com/mpskex",
            "followers_url": "https://api.github.com/users/mpskex/followers",
            "following_url": "https://api.github.com/users/mpskex/following{/other_user}",
            "gists_url": "https://api.github.com/users/mpskex/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mpskex/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mpskex/subscriptions",
            "organizations_url": "https://api.github.com/users/mpskex/orgs",
            "repos_url": "https://api.github.com/users/mpskex/repos",
            "events_url": "https://api.github.com/users/mpskex/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mpskex/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-22T09:37:35Z",
        "updated_at": "2023-09-25T07:08:55Z",
        "closed_at": "2023-09-23T17:02:15Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7780",
            "html_url": "https://github.com/run-llama/llama_index/pull/7780",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7780.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7780.patch",
            "merged_at": "2023-09-23T17:02:15Z"
        },
        "body": "# Description\r\n\r\nWe added meta-data filtering & Hybrid search to MyScale now.\r\n\r\n**NOTE**: Hybrid search for MyScale is currently implemented as an inline two-staged search hybrid with text match.\r\n\r\nspecial thanks to: @suchme19\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7780/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7780/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7779",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7779/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7779/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7779/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7779",
        "id": 1908531801,
        "node_id": "I_kwDOIWuq585xweJZ",
        "number": 7779,
        "title": "[Question]: about milvus version",
        "user": {
            "login": "JDZW2014",
            "id": 37505460,
            "node_id": "MDQ6VXNlcjM3NTA1NDYw",
            "avatar_url": "https://avatars.githubusercontent.com/u/37505460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JDZW2014",
            "html_url": "https://github.com/JDZW2014",
            "followers_url": "https://api.github.com/users/JDZW2014/followers",
            "following_url": "https://api.github.com/users/JDZW2014/following{/other_user}",
            "gists_url": "https://api.github.com/users/JDZW2014/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JDZW2014/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JDZW2014/subscriptions",
            "organizations_url": "https://api.github.com/users/JDZW2014/orgs",
            "repos_url": "https://api.github.com/users/JDZW2014/repos",
            "events_url": "https://api.github.com/users/JDZW2014/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JDZW2014/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-22T09:25:02Z",
        "updated_at": "2023-09-25T02:02:23Z",
        "closed_at": "2023-09-22T15:35:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nThanks for your great work!\r\nI am work with llama_index and milvus and meet \"ImportError: cannot import name 'MilvusClient' from 'pymilvus'\".\r\nI wandor to know which milvus version should we use?  \r\n The current version is pymilvus-2.2.0 and llama_index=0.8.29.post1",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7779/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7779/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7778",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7778/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7778/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7778/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7778",
        "id": 1908420702,
        "node_id": "PR_kwDOIWuq585a9y85",
        "number": 7778,
        "title": "add pydantic metadata extractor",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T08:17:22Z",
        "updated_at": "2023-09-22T18:29:25Z",
        "closed_at": "2023-09-22T18:29:24Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7778",
            "html_url": "https://github.com/run-llama/llama_index/pull/7778",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7778.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7778.patch",
            "merged_at": "2023-09-22T18:29:24Z"
        },
        "body": "# Description\r\n\r\nThis feature extracts metadata from text chunks into a pydantic object. It uses the pydantic program under the hood.\r\n\r\nTo avoid circular dependencies, migrated BasePydanticProgram to types.py. \r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7778/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7778/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7777",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7777/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7777/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7777/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7777",
        "id": 1908143463,
        "node_id": "I_kwDOIWuq585xu_Vn",
        "number": 7777,
        "title": "[Bug]: typing errors in `OllamaEmbeddings` and `StorageContext.persist`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-22T04:02:09Z",
        "updated_at": "2023-09-22T18:23:14Z",
        "closed_at": "2023-09-22T15:32:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nRunning a line like this through `mypy`:\r\n\r\n```python\r\nimport pathlib\r\n\r\nfrom langchain.embeddings import OllamaEmbeddings\r\nfrom llama_index import StorageContext\r\n\r\nSTORAGE_FOLDER = pathlib.Path(__file__).parent / \"storage\"\r\n\r\n_ = OllamaEmbeddings(model=\"llama2:13b\")\r\n\r\nStorageContext.from_defaults().persist(persist_dir=STORAGE_FOLDER)\r\n```\r\n\r\n### Version\r\n\r\n0.8.30\r\n\r\n### Steps to Reproduce\r\n\r\nRunning `mypy==1.5.1` on that file:\r\n\r\n```none\r\na.py:8:5: error: Missing named argument \"mirostat\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"mirostat_eta\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"mirostat_tau\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"num_ctx\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"num_gpu\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"num_thread\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"repeat_last_n\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"repeat_penalty\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"temperature\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"stop\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"tfs_z\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"top_k\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:8:5: error: Missing named argument \"top_p\" for \"OllamaEmbeddings\"  [call-arg]\r\n    _ = OllamaEmbeddings(model=\"llama2:13b\")\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\na.py:10:52: error: Argument \"persist_dir\" to \"persist\" of \"StorageContext\" has incompatible type \"Path\"; expected \"str\"  [arg-type]\r\n    StorageContext.from_defaults().persist(persist_dir=STORAGE_FOLDER)\r\n```\r\n\r\nThese imo are all type errors:\r\n- In `OllamaEmbeddings`, `= None` needs to be present as a default for the `Optional` fields\r\n- In `StorageContext.persist`, it should allow `os.PathLike`\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7777/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7777/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7776",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7776/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7776/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7776/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7776",
        "id": 1908119069,
        "node_id": "PR_kwDOIWuq585a8yTy",
        "number": 7776,
        "title": "chore: Expose debugger option of PGVectorStore",
        "user": {
            "login": "rendyfebry",
            "id": 1105460,
            "node_id": "MDQ6VXNlcjExMDU0NjA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1105460?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rendyfebry",
            "html_url": "https://github.com/rendyfebry",
            "followers_url": "https://api.github.com/users/rendyfebry/followers",
            "following_url": "https://api.github.com/users/rendyfebry/following{/other_user}",
            "gists_url": "https://api.github.com/users/rendyfebry/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rendyfebry/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rendyfebry/subscriptions",
            "organizations_url": "https://api.github.com/users/rendyfebry/orgs",
            "repos_url": "https://api.github.com/users/rendyfebry/repos",
            "events_url": "https://api.github.com/users/rendyfebry/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rendyfebry/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-22T03:24:01Z",
        "updated_at": "2023-09-22T15:47:02Z",
        "closed_at": "2023-09-22T15:47:01Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7776",
            "html_url": "https://github.com/run-llama/llama_index/pull/7776",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7776.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7776.patch",
            "merged_at": "2023-09-22T15:47:01Z"
        },
        "body": "# Description\r\n\r\nTo help user debug their PgVectorStore usage, I expose the debug option to enable SQLAlchemy debugger inside PgVectorStore.\r\n\r\n>:param echo=False: if True, the Engine will log all statements\r\n        as well as a ``repr()`` of their parameter lists to the default log\r\n        handler, which defaults to ``sys.stdout`` for output.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7776/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7776/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7775",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7775/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7775/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7775/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7775",
        "id": 1908107167,
        "node_id": "PR_kwDOIWuq585a8v0l",
        "number": 7775,
        "title": "Add konko llm integration",
        "user": {
            "login": "mahaddad",
            "id": 12946725,
            "node_id": "MDQ6VXNlcjEyOTQ2NzI1",
            "avatar_url": "https://avatars.githubusercontent.com/u/12946725?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/mahaddad",
            "html_url": "https://github.com/mahaddad",
            "followers_url": "https://api.github.com/users/mahaddad/followers",
            "following_url": "https://api.github.com/users/mahaddad/following{/other_user}",
            "gists_url": "https://api.github.com/users/mahaddad/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/mahaddad/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/mahaddad/subscriptions",
            "organizations_url": "https://api.github.com/users/mahaddad/orgs",
            "repos_url": "https://api.github.com/users/mahaddad/repos",
            "events_url": "https://api.github.com/users/mahaddad/events{/privacy}",
            "received_events_url": "https://api.github.com/users/mahaddad/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5870194649,
                "node_id": "LA_kwDOIWuq588AAAABXeQP2Q",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/llm",
                "name": "llm",
                "color": "799557",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-09-22T03:05:10Z",
        "updated_at": "2023-09-25T18:33:35Z",
        "closed_at": "2023-09-25T18:33:35Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7775",
            "html_url": "https://github.com/run-llama/llama_index/pull/7775",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7775.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7775.patch",
            "merged_at": "2023-09-25T18:33:35Z"
        },
        "body": "# Description\r\n\r\n_Thank you to the LlamaIndex team for the great project and in advance for your review. Let me know if I can provide any other additional information or do things differently in the future to make your lives easier \ud83d\ude4f _\r\n\r\nThe [Konko API](konko.ai) is a fully managed API designed to help application developers:\r\n\r\n- Select the right LLM(s) for their application\r\n- Prototype with various open-source and proprietary LLMs\r\n- Move to production in-line with their security, privacy, throughput, latency SLAs without infrastructure set-up or administration using Konko AI's SOC 2 compliant infrastructure\r\n\r\nWe attempted to minimize code duplication where possible, but in some instances needed to recreate certain functions because we required the ability to handle multiple api keys. \r\n\r\n- [\u2714\ufe0f  ] New feature (non-breaking change which adds functionality)\r\n- [ \u2714\ufe0f ] This change requires a documentation update (we've included documentation)\r\n\r\n# How Has This Been Tested?\r\n\r\nTo run our test files, please `pip install konko`, otherwise the tests will be skipped.\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ \u2714\ufe0f ] Added new unit/integration tests\r\n- [ \u2714\ufe0f ] Added new notebook (that tests end-to-end)\r\n- [\u2714\ufe0f  ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [\u2714\ufe0f  ] I have performed a self-review of my own code\r\n- [ \u2714\ufe0f ] I have commented my code, particularly in hard-to-understand areas\r\n- [ \u2714\ufe0f ] I have made corresponding changes to the documentation\r\n- [ \u2714\ufe0f ] My changes generate no new warnings\r\n- [ \u2714\ufe0f ] I have added tests that prove my fix is effective or that my feature works\r\n- [ \u2714\ufe0f ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7775/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7775/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7774",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7774/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7774/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7774/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7774",
        "id": 1908088681,
        "node_id": "PR_kwDOIWuq585a8r_F",
        "number": 7774,
        "title": "fix output parsers for selector templates",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T02:36:24Z",
        "updated_at": "2023-09-22T15:48:26Z",
        "closed_at": "2023-09-22T15:48:26Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7774",
            "html_url": "https://github.com/run-llama/llama_index/pull/7774",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7774.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7774.patch",
            "merged_at": "2023-09-22T15:48:25Z"
        },
        "body": "# Description\r\n\r\nIf the output parser is set on a selector template like `prompt_tempalte.output_parser = ...` it does not get inherited properly.\r\n\r\nInstead, we can inherit during prompt selection time\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7774/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7774/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7773",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7773/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7773/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7773/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7773",
        "id": 1908084586,
        "node_id": "PR_kwDOIWuq585a8rJO",
        "number": 7773,
        "title": "empty response when nodes are empty",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-22T02:30:01Z",
        "updated_at": "2023-09-22T15:47:21Z",
        "closed_at": "2023-09-22T15:47:20Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7773",
            "html_url": "https://github.com/run-llama/llama_index/pull/7773",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7773.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7773.patch",
            "merged_at": "2023-09-22T15:47:20Z"
        },
        "body": "# Description\r\n\r\nSometimes retrievers will not return any nodes. This causes some response synthesizers to freak out. We should just return an empty response in the base class.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7773/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7773/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7772",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7772/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7772/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7772/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7772",
        "id": 1908075932,
        "node_id": "PR_kwDOIWuq585a8pV3",
        "number": 7772,
        "title": "Add integration for DashVector (vector store)",
        "user": {
            "login": "xiaoyuxee",
            "id": 2851934,
            "node_id": "MDQ6VXNlcjI4NTE5MzQ=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2851934?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/xiaoyuxee",
            "html_url": "https://github.com/xiaoyuxee",
            "followers_url": "https://api.github.com/users/xiaoyuxee/followers",
            "following_url": "https://api.github.com/users/xiaoyuxee/following{/other_user}",
            "gists_url": "https://api.github.com/users/xiaoyuxee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/xiaoyuxee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/xiaoyuxee/subscriptions",
            "organizations_url": "https://api.github.com/users/xiaoyuxee/orgs",
            "repos_url": "https://api.github.com/users/xiaoyuxee/repos",
            "events_url": "https://api.github.com/users/xiaoyuxee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/xiaoyuxee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 5804135704,
                "node_id": "LA_kwDOIWuq588AAAABWfQVGA",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/vector%20store",
                "name": "vector store",
                "color": "4AE220",
                "default": false,
                "description": ""
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-22T02:16:51Z",
        "updated_at": "2023-10-22T03:44:36Z",
        "closed_at": "2023-10-22T03:44:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7772",
            "html_url": "https://github.com/run-llama/llama_index/pull/7772",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7772.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7772.patch",
            "merged_at": "2023-10-22T03:44:24Z"
        },
        "body": "# Description\r\n\r\nThis commit adds a VectorStore for DashVector vectorDB service.\r\n\r\n[DashVector](https://help.aliyun.com/document_detail/2510225.html) is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.\r\n\r\n## Type of Change\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n\r\n# How Has This Been Tested?\r\n\r\n- [ ] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7772/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7772/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7771",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7771/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7771/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7771/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7771",
        "id": 1907903033,
        "node_id": "PR_kwDOIWuq585a8EvC",
        "number": 7771,
        "title": "linter/typechecker-friendly improvements to cassandra test",
        "user": {
            "login": "hemidactylus",
            "id": 14221764,
            "node_id": "MDQ6VXNlcjE0MjIxNzY0",
            "avatar_url": "https://avatars.githubusercontent.com/u/14221764?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/hemidactylus",
            "html_url": "https://github.com/hemidactylus",
            "followers_url": "https://api.github.com/users/hemidactylus/followers",
            "following_url": "https://api.github.com/users/hemidactylus/following{/other_user}",
            "gists_url": "https://api.github.com/users/hemidactylus/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/hemidactylus/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/hemidactylus/subscriptions",
            "organizations_url": "https://api.github.com/users/hemidactylus/orgs",
            "repos_url": "https://api.github.com/users/hemidactylus/repos",
            "events_url": "https://api.github.com/users/hemidactylus/events{/privacy}",
            "received_events_url": "https://api.github.com/users/hemidactylus/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T23:14:37Z",
        "updated_at": "2023-09-22T08:45:11Z",
        "closed_at": "2023-09-22T02:22:23Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7771",
            "html_url": "https://github.com/run-llama/llama_index/pull/7771",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7771.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7771.patch",
            "merged_at": "2023-09-22T02:22:23Z"
        },
        "body": "This (very minor) PR slightly improves the style of the Cassandra vector store test file by\r\n- avoiding an ambiguous type for a the `cassio` package name (which was set to None to skip tests, now done through a boolean)\r\n- adding `# noqa` to silence complaints about repeated imports in each test function\r\n\r\n\r\nThanks!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7771/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7771/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7770",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7770/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7770/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7770/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7770",
        "id": 1907775745,
        "node_id": "PR_kwDOIWuq585a7qep",
        "number": 7770,
        "title": "Add semantic similarity evaluator",
        "user": {
            "login": "Disiok",
            "id": 5567282,
            "node_id": "MDQ6VXNlcjU1NjcyODI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5567282?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Disiok",
            "html_url": "https://github.com/Disiok",
            "followers_url": "https://api.github.com/users/Disiok/followers",
            "following_url": "https://api.github.com/users/Disiok/following{/other_user}",
            "gists_url": "https://api.github.com/users/Disiok/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Disiok/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Disiok/subscriptions",
            "organizations_url": "https://api.github.com/users/Disiok/orgs",
            "repos_url": "https://api.github.com/users/Disiok/repos",
            "events_url": "https://api.github.com/users/Disiok/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Disiok/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T21:15:17Z",
        "updated_at": "2023-09-23T02:54:51Z",
        "closed_at": "2023-09-23T02:54:51Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7770",
            "html_url": "https://github.com/run-llama/llama_index/pull/7770",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7770.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7770.patch",
            "merged_at": "2023-09-23T02:54:51Z"
        },
        "body": "# Description\r\nAdd semantic similarity evaluator (i.e. calculate embedding similarity between generated answer and reference answer)\r\n\r\n### Additional changes\r\n* Expose`aget_text_embedding` function for `BaseEmbedding` ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7770/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7770/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7769",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7769/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7769/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7769/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7769",
        "id": 1907716203,
        "node_id": "PR_kwDOIWuq585a7dHp",
        "number": 7769,
        "title": "[DRAFT] JSON splitter ",
        "user": {
            "login": "ajhofmann",
            "id": 10040285,
            "node_id": "MDQ6VXNlcjEwMDQwMjg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10040285?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajhofmann",
            "html_url": "https://github.com/ajhofmann",
            "followers_url": "https://api.github.com/users/ajhofmann/followers",
            "following_url": "https://api.github.com/users/ajhofmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajhofmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajhofmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajhofmann/subscriptions",
            "organizations_url": "https://api.github.com/users/ajhofmann/orgs",
            "repos_url": "https://api.github.com/users/ajhofmann/repos",
            "events_url": "https://api.github.com/users/ajhofmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajhofmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T20:35:07Z",
        "updated_at": "2023-09-28T18:29:43Z",
        "closed_at": "2023-09-28T18:29:43Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7769",
            "html_url": "https://github.com/run-llama/llama_index/pull/7769",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7769.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7769.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\n- Json based text splitter\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7769/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7769/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7768",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7768/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7768/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7768/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7768",
        "id": 1907679272,
        "node_id": "PR_kwDOIWuq585a7VEX",
        "number": 7768,
        "title": "Docs: App showcase has broken link, removing",
        "user": {
            "login": "bmax",
            "id": 158370,
            "node_id": "MDQ6VXNlcjE1ODM3MA==",
            "avatar_url": "https://avatars.githubusercontent.com/u/158370?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bmax",
            "html_url": "https://github.com/bmax",
            "followers_url": "https://api.github.com/users/bmax/followers",
            "following_url": "https://api.github.com/users/bmax/following{/other_user}",
            "gists_url": "https://api.github.com/users/bmax/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bmax/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bmax/subscriptions",
            "organizations_url": "https://api.github.com/users/bmax/orgs",
            "repos_url": "https://api.github.com/users/bmax/repos",
            "events_url": "https://api.github.com/users/bmax/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bmax/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T20:05:15Z",
        "updated_at": "2023-09-21T20:16:23Z",
        "closed_at": "2023-09-21T20:16:22Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7768",
            "html_url": "https://github.com/run-llama/llama_index/pull/7768",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7768.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7768.patch",
            "merged_at": "2023-09-21T20:16:22Z"
        },
        "body": "# Description\r\n\r\nhttps://gpt-index.readthedocs.io/en/stable/community/app_showcase.html#chatgpt-llamaindex\r\n\r\nFixes #7715 \r\n\r\n## Type of Change\r\n- [x] Documentation update\r\n\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7768/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7768/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7767",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7767/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7767/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7767/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7767",
        "id": 1907561317,
        "node_id": "PR_kwDOIWuq585a67Fp",
        "number": 7767,
        "title": "\ud83d\udcdddocs: Update Chatbot Tutorial and Notebook",
        "user": {
            "login": "Javtor",
            "id": 8462127,
            "node_id": "MDQ6VXNlcjg0NjIxMjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8462127?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Javtor",
            "html_url": "https://github.com/Javtor",
            "followers_url": "https://api.github.com/users/Javtor/followers",
            "following_url": "https://api.github.com/users/Javtor/following{/other_user}",
            "gists_url": "https://api.github.com/users/Javtor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Javtor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Javtor/subscriptions",
            "organizations_url": "https://api.github.com/users/Javtor/orgs",
            "repos_url": "https://api.github.com/users/Javtor/repos",
            "events_url": "https://api.github.com/users/Javtor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Javtor/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T18:42:59Z",
        "updated_at": "2023-09-22T19:32:41Z",
        "closed_at": "2023-09-22T18:08:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7767",
            "html_url": "https://github.com/run-llama/llama_index/pull/7767",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7767.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7767.patch",
            "merged_at": "2023-09-22T18:08:20Z"
        },
        "body": "# Description\r\n\r\nUpdates the \ud83d\udcac\ud83e\udd16 How to Build a Chatbot end-to-end tutorial to use Sub Question Query Engine instead of graph and LlamaIndex's own agent implementation instead of LangChain's.\r\n\r\nFixes #7732\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Doc update",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7767/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7767/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7766",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7766/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7766/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7766/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7766",
        "id": 1907527236,
        "node_id": "I_kwDOIWuq585xso5E",
        "number": 7766,
        "title": "[Question]: Does Llama_index support other image readers except DONUT?",
        "user": {
            "login": "zebleck",
            "id": 10833180,
            "node_id": "MDQ6VXNlcjEwODMzMTgw",
            "avatar_url": "https://avatars.githubusercontent.com/u/10833180?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zebleck",
            "html_url": "https://github.com/zebleck",
            "followers_url": "https://api.github.com/users/zebleck/followers",
            "following_url": "https://api.github.com/users/zebleck/following{/other_user}",
            "gists_url": "https://api.github.com/users/zebleck/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zebleck/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zebleck/subscriptions",
            "organizations_url": "https://api.github.com/users/zebleck/orgs",
            "repos_url": "https://api.github.com/users/zebleck/repos",
            "events_url": "https://api.github.com/users/zebleck/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zebleck/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T18:21:59Z",
        "updated_at": "2023-09-21T18:47:22Z",
        "closed_at": "2023-09-21T18:47:22Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi!\r\n\r\nI was playing around with the Multimodality notebook and was trying to see if it can detect things such as screenshots of the screen showing it different things such as Youtube screenshots. Sadly, it was not able to parse anything useful out of those. Is that due to the DONUT Document processor that is used? Do you support other vision models or should I go about this in a different way entirely if I want to index different kinds of images that are not necessarily documents?\r\n\r\nThanks.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7766/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7766/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7765",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7765/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7765/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7765/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7765",
        "id": 1907344842,
        "node_id": "I_kwDOIWuq585xr8XK",
        "number": 7765,
        "title": "[Bug]: Context length errors after a couple of chats using chat engine",
        "user": {
            "login": "rchan26",
            "id": 44200705,
            "node_id": "MDQ6VXNlcjQ0MjAwNzA1",
            "avatar_url": "https://avatars.githubusercontent.com/u/44200705?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/rchan26",
            "html_url": "https://github.com/rchan26",
            "followers_url": "https://api.github.com/users/rchan26/followers",
            "following_url": "https://api.github.com/users/rchan26/following{/other_user}",
            "gists_url": "https://api.github.com/users/rchan26/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/rchan26/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/rchan26/subscriptions",
            "organizations_url": "https://api.github.com/users/rchan26/orgs",
            "repos_url": "https://api.github.com/users/rchan26/repos",
            "events_url": "https://api.github.com/users/rchan26/events{/privacy}",
            "received_events_url": "https://api.github.com/users/rchan26/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-21T16:24:12Z",
        "updated_at": "2023-10-27T15:49:06Z",
        "closed_at": "2023-09-22T21:32:16Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI've been using the `LlamaCPP` model as the LLM for a chat engine and typically set the context length to just be 4096. I am also using the [messages_to_prompt function](https://github.com/jerryjliu/llama_index/blob/2f95b888746e0509244029a894ab4f67080f0fc4/llama_index/llms/llama_utils.py#L49) in the library.\r\n\r\nAfter a couple of chats with the engine, the chat history will fill up and eventually we'll get a `ValueError('Requested tokens (...) exceed context window of 4096')` error. This is expected, but I feel that there could be better chat history management and maybe some sort of automatic chat forgetting. I think you'd get a similar kind of error with a few different LLMs too - I assume maybe LLMs using the OpenAI API or similar could have things to avoid these though?\r\n\r\nFurthermore, any chats _after_ will return a `AssertionError()` (this is because in [messages_to_prompt](https://github.com/jerryjliu/llama_index/blob/2f95b888746e0509244029a894ab4f67080f0fc4/llama_index/llms/llama_utils.py#L49), it expects that we have alternating user and assistant chat messages and has assert statements to check this). Again, this is expected behavior and I think this works fine, but maybe this needs changing too if we have some sort of chat forgetting.\r\n\r\nI'm happy to make a PR to try address this, but thought I'd post an issue to get some thoughts on what the solution should be. I'm thinking that we could maybe just do some automatic cutting of the history before feeding into the LLM?\n\n### Version\n\nv0.8.29.post1\n\n### Steps to Reproduce\n\n- Imports:\r\n\r\n```\r\nfrom llama_index import (\r\n    VectorStoreIndex,\r\n    PromptHelper,\r\n    ServiceContext,\r\n    Document\r\n)\r\nfrom llama_index.llms import LlamaCPP\r\nfrom llama_index.llms.llama_utils import messages_to_prompt, completion_to_prompt\r\n```\r\n\r\n- Set up `LlamaCPP` model (for purposes of this example, I'll set the context window a bit lower than usual to just highlight the error earlier):\r\n\r\n```\r\nllm = LlamaCPP(\r\n    model_path=llama_2_path,\r\n    temperature=0.1,\r\n    max_new_tokens=1024,\r\n    context_window=2048,\r\n    # kwargs to pass to __call__()\r\n    generate_kwargs={},\r\n    # kwargs to pass to __init__()\r\n    # set to at least 1 to use GPU\r\n    model_kwargs={\"n_gpu_layers\": 1},\r\n    # transform inputs into Llama2 format\r\n    messages_to_prompt=messages_to_prompt,\r\n    completion_to_prompt=completion_to_prompt,\r\n    verbose=True,\r\n)\r\n```\r\n\r\n- Set up embedding model:\r\n\r\n```\r\nhfemb = HuggingFaceEmbeddings()\r\nembed_model = LangchainEmbedding(hfemb)\r\n```\r\n\r\n- Set up prompt helper:\r\n\r\n```\r\n# set number of output tokens\r\nnum_output = 1024\r\n# set maximum input size\r\ncontext_window = 2048\r\n# set maximum chunk overlap\r\nchunk_size = 512\r\nchunk_overlap_ratio = 0.1\r\n\r\nprompt_helper = PromptHelper(\r\n    context_window=context_window,\r\n    num_output=num_output,\r\n    chunk_size_limit=chunk_size,\r\n    chunk_overlap_ratio=chunk_overlap_ratio,\r\n)\r\n```\r\n\r\n- Set up service_context:\r\n\r\n```\r\nservice_context = ServiceContext.from_defaults(\r\n    llm_predictor=LLMPredictor(llm=llm),\r\n    embed_model=embed_model,\r\n    prompt_helper=prompt_helper,\r\n    chunk_size=chunk_size,\r\n)\r\n\r\ntext_list = [] # some list of strings\r\ndocuments = [Document(text=t) for t in text_list]\r\n\r\nindex = VectorStoreIndex.from_documents(\r\n    documents, service_context=service_context\r\n)\r\n```\r\n\r\n- Set up chat engine:\r\n\r\n```\r\nchat_engine = index.as_chat_engine(\r\n    chat_mode=\"context\",\r\n)\r\n```\r\n\r\n- Just do multiple chats until you fill up the chat history sufficiently:\r\n\r\n```\r\nresponse = chat_engine.chat(\r\n    \"some message\"\r\n)\r\nprint(response)\r\n```\r\n\r\nOnce you get `ValueError('Requested tokens (...) exceed context window of 2048')`, you can inspect the chat history with `chat_engine.chat_history` and you can see that there are two user messages there now which will result in `AssertionError()` if you try to get another response afterwards.\n\n### Relevant Logs/Tracbacks\n\n```shell\nValueError                                Traceback (most recent call last)\r\nCell In[82], line 1\r\n----> 1 response = chat_engine.chat(\r\n      2     \"I've already completed my inductions and uploaded my \"\r\n      3     \"documents for Cezanne and the ATI website, what else is there to do?\"\r\n      4 )\r\n      5 print(response)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/callbacks/utils.py:38, in trace_method.<locals>.decorator.<locals>.wrapper(self, *args, **kwargs)\r\n     36 callback_manager = cast(CallbackManager, callback_manager)\r\n     37 with callback_manager.as_trace(trace_id):\r\n---> 38     return func(self, *args, **kwargs)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/chat_engine/context.py:155, in ContextChatEngine.chat(self, message, chat_history)\r\n    152 prefix_messages = self._get_prefix_messages_with_context(context_str_template)\r\n    153 all_messages = prefix_messages + self._memory.get()\r\n--> 155 chat_response = self._llm.chat(all_messages)\r\n    156 ai_message = chat_response.message\r\n    157 self._memory.put(ai_message)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/base.py:151, in llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat(_self, messages, **kwargs)\r\n    142 with wrapper_logic(_self) as callback_manager:\r\n    143     event_id = callback_manager.on_event_start(\r\n    144         CBEventType.LLM,\r\n    145         payload={\r\n   (...)\r\n    149         },\r\n    150     )\r\n--> 151     f_return_val = f(_self, messages, **kwargs)\r\n    153     if isinstance(f_return_val, Generator):\r\n    154         # intercept the generator and add a callback to the end\r\n    155         def wrapped_gen() -> ChatResponseGen:\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/llama_cpp.py:197, in LlamaCPP.chat(self, messages, **kwargs)\r\n    194 @llm_chat_callback()\r\n    195 def chat(self, messages: Sequence[ChatMessage], **kwargs: Any) -> ChatResponse:\r\n    196     prompt = self.messages_to_prompt(messages)\r\n--> 197     completion_response = self.complete(prompt, formatted=True, **kwargs)\r\n    198     return completion_response_to_chat_response(completion_response)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/base.py:277, in llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict(_self, *args, **kwargs)\r\n    267 with wrapper_logic(_self) as callback_manager:\r\n    268     event_id = callback_manager.on_event_start(\r\n    269         CBEventType.LLM,\r\n    270         payload={\r\n   (...)\r\n    274         },\r\n    275     )\r\n--> 277     f_return_val = f(_self, *args, **kwargs)\r\n    278     if isinstance(f_return_val, Generator):\r\n    279         # intercept the generator and add a callback to the end\r\n    280         def wrapped_gen() -> CompletionResponseGen:\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/llama_cpp.py:216, in LlamaCPP.complete(self, prompt, **kwargs)\r\n    213 if not is_formatted:\r\n    214     prompt = self.completion_to_prompt(prompt)\r\n--> 216 response = self._model(prompt=prompt, **self.generate_kwargs)\r\n    218 return CompletionResponse(text=response[\"choices\"][0][\"text\"], raw=response)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_cpp/llama.py:1453, in Llama.__call__(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\r\n   1407 def __call__(\r\n   1408     self,\r\n   1409     prompt: str,\r\n   (...)\r\n   1429     grammar: Optional[LlamaGrammar] = None,\r\n   1430 ) -> Union[Completion, Iterator[CompletionChunk]]:\r\n   1431     \"\"\"Generate text from a prompt.\r\n   1432 \r\n   1433     Args:\r\n   (...)\r\n   1451         Response object containing the generated text.\r\n   1452     \"\"\"\r\n-> 1453     return self.create_completion(\r\n   1454         prompt=prompt,\r\n   1455         suffix=suffix,\r\n   1456         max_tokens=max_tokens,\r\n   1457         temperature=temperature,\r\n   1458         top_p=top_p,\r\n   1459         logprobs=logprobs,\r\n   1460         echo=echo,\r\n   1461         stop=stop,\r\n   1462         frequency_penalty=frequency_penalty,\r\n   1463         presence_penalty=presence_penalty,\r\n   1464         repeat_penalty=repeat_penalty,\r\n   1465         top_k=top_k,\r\n   1466         stream=stream,\r\n   1467         tfs_z=tfs_z,\r\n   1468         mirostat_mode=mirostat_mode,\r\n   1469         mirostat_tau=mirostat_tau,\r\n   1470         mirostat_eta=mirostat_eta,\r\n   1471         model=model,\r\n   1472         stopping_criteria=stopping_criteria,\r\n   1473         logits_processor=logits_processor,\r\n   1474         grammar=grammar,\r\n   1475     )\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_cpp/llama.py:1404, in Llama.create_completion(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\r\n   1402     chunks: Iterator[CompletionChunk] = completion_or_chunks\r\n   1403     return chunks\r\n-> 1404 completion: Completion = next(completion_or_chunks)  # type: ignore\r\n   1405 return completion\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_cpp/llama.py:913, in Llama._create_completion(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\r\n    910     llama_cpp.llama_reset_timings(self.ctx)\r\n    912 if len(prompt_tokens) >= llama_cpp.llama_n_ctx(self.ctx):\r\n--> 913     raise ValueError(\r\n    914         f\"Requested tokens ({len(prompt_tokens)}) exceed context window of {llama_cpp.llama_n_ctx(self.ctx)}\"\r\n    915     )\r\n    917 if max_tokens <= 0:\r\n    918     # Unlimited, depending on n_ctx.\r\n    919     max_tokens = llama_cpp.llama_n_ctx(self.ctx) - len(prompt_tokens)\r\n\r\nValueError: Requested tokens (2109) exceed context window of 2048\r\n\r\n---------- For the AssertionError(): ----------\r\n\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\nCell In[84], line 1\r\n----> 1 response = chat_engine.chat(\r\n      2     \"thanks! what is the link to the project tracker?\"\r\n      3 )\r\n      4 print(response)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/callbacks/utils.py:38, in trace_method.<locals>.decorator.<locals>.wrapper(self, *args, **kwargs)\r\n     36 callback_manager = cast(CallbackManager, callback_manager)\r\n     37 with callback_manager.as_trace(trace_id):\r\n---> 38     return func(self, *args, **kwargs)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/chat_engine/context.py:155, in ContextChatEngine.chat(self, message, chat_history)\r\n    152 prefix_messages = self._get_prefix_messages_with_context(context_str_template)\r\n    153 all_messages = prefix_messages + self._memory.get()\r\n--> 155 chat_response = self._llm.chat(all_messages)\r\n    156 ai_message = chat_response.message\r\n    157 self._memory.put(ai_message)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/base.py:151, in llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat(_self, messages, **kwargs)\r\n    142 with wrapper_logic(_self) as callback_manager:\r\n    143     event_id = callback_manager.on_event_start(\r\n    144         CBEventType.LLM,\r\n    145         payload={\r\n   (...)\r\n    149         },\r\n    150     )\r\n--> 151     f_return_val = f(_self, messages, **kwargs)\r\n    153     if isinstance(f_return_val, Generator):\r\n    154         # intercept the generator and add a callback to the end\r\n    155         def wrapped_gen() -> ChatResponseGen:\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/llama_cpp.py:196, in LlamaCPP.chat(self, messages, **kwargs)\r\n    194 @llm_chat_callback()\r\n    195 def chat(self, messages: Sequence[ChatMessage], **kwargs: Any) -> ChatResponse:\r\n--> 196     prompt = self.messages_to_prompt(messages)\r\n    197     completion_response = self.complete(prompt, formatted=True, **kwargs)\r\n    198     return completion_response_to_chat_response(completion_response)\r\n\r\nFile ~/opt/miniconda3/envs/reginald/lib/python3.11/site-packages/llama_index/llms/llama_utils.py:49, in messages_to_prompt(messages, system_prompt)\r\n     46 if len(messages) > (i + 1):\r\n     47     # if assistant message exists, add to str_message\r\n     48     assistant_message = messages[i + 1]\r\n---> 49     assert assistant_message.role == MessageRole.ASSISTANT\r\n     50     str_message += f\" {assistant_message.content}\"\r\n     52 string_messages.append(str_message)\r\n\r\nAssertionError:\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7765/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7765/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7764",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7764/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7764/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7764/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7764",
        "id": 1907326967,
        "node_id": "PR_kwDOIWuq585a6II3",
        "number": 7764,
        "title": "avoid raising error in auto retriever parser",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T16:13:43Z",
        "updated_at": "2023-09-21T16:26:16Z",
        "closed_at": "2023-09-21T16:26:15Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7764",
            "html_url": "https://github.com/run-llama/llama_index/pull/7764",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7764.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7764.patch",
            "merged_at": "2023-09-21T16:26:15Z"
        },
        "body": "# Description\r\n\r\nThere was a small issue with the auto vector query engine where the output parser was raising a `NotImplementedError()` in the `format()` function.\r\n\r\nCouldn't track down what caused this to happen, but changing the function to just return the input seems to be a good fix.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7764/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7764/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7763",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7763/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7763/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7763/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7763",
        "id": 1907326750,
        "node_id": "PR_kwDOIWuq585a6IFs",
        "number": 7763,
        "title": "Multiple kwargs values in \"KnowledgeGraphQueryEngine\" bug-fix",
        "user": {
            "login": "barvhaim",
            "id": 16198896,
            "node_id": "MDQ6VXNlcjE2MTk4ODk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/16198896?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/barvhaim",
            "html_url": "https://github.com/barvhaim",
            "followers_url": "https://api.github.com/users/barvhaim/followers",
            "following_url": "https://api.github.com/users/barvhaim/following{/other_user}",
            "gists_url": "https://api.github.com/users/barvhaim/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/barvhaim/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/barvhaim/subscriptions",
            "organizations_url": "https://api.github.com/users/barvhaim/orgs",
            "repos_url": "https://api.github.com/users/barvhaim/repos",
            "events_url": "https://api.github.com/users/barvhaim/events{/privacy}",
            "received_events_url": "https://api.github.com/users/barvhaim/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T16:13:35Z",
        "updated_at": "2023-09-21T20:06:24Z",
        "closed_at": "2023-09-21T20:06:24Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7763",
            "html_url": "https://github.com/run-llama/llama_index/pull/7763",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7763.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7763.patch",
            "merged_at": "2023-09-21T20:06:24Z"
        },
        "body": "# Description\r\n\r\nIn `KnowledgeGraphRAGRetriever` code, it will get the `graph_query_synthesis_prompt` into `KnowledgeGraphQueryEngine` from `kwargs` but will also leave it in the `kwargs`. \r\n\r\nThus result in `TypeError: llama_index.query_engine.knowledge_graph_query_engine.KnowledgeGraphQueryEngine() got multiple values for keyword argument 'graph_query_synthesis_prompt'`\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n- [X] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\nI've run e2e flow of `KnowledgeGraphRAGRetriever`\r\n\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n- [X] My changes generate no new warnings\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7763/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7763/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7762",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7762/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7762/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7762/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7762",
        "id": 1907257403,
        "node_id": "I_kwDOIWuq585xrnA7",
        "number": 7762,
        "title": "[Documentation]: Cost Analysis Documentation doesnt work.",
        "user": {
            "login": "GinoWoz1",
            "id": 17535345,
            "node_id": "MDQ6VXNlcjE3NTM1MzQ1",
            "avatar_url": "https://avatars.githubusercontent.com/u/17535345?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/GinoWoz1",
            "html_url": "https://github.com/GinoWoz1",
            "followers_url": "https://api.github.com/users/GinoWoz1/followers",
            "following_url": "https://api.github.com/users/GinoWoz1/following{/other_user}",
            "gists_url": "https://api.github.com/users/GinoWoz1/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/GinoWoz1/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/GinoWoz1/subscriptions",
            "organizations_url": "https://api.github.com/users/GinoWoz1/orgs",
            "repos_url": "https://api.github.com/users/GinoWoz1/repos",
            "events_url": "https://api.github.com/users/GinoWoz1/events{/privacy}",
            "received_events_url": "https://api.github.com/users/GinoWoz1/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-21T15:32:44Z",
        "updated_at": "2023-09-21T19:23:16Z",
        "closed_at": "2023-09-21T16:47:38Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\r\n\r\nI really need to calculate token usage but I follow this documentation to a T and it does not work, any idea? If you go to MockLLMPredictor, there is no attribute last_token_usage.\r\n\r\nMockLLMPredictor Class: https://github.com/jerryjliu/llama_index/blob/2f95b888746e0509244029a894ab4f67080f0fc4/llama_index/llm_predictor/mock.py#L87\r\n\r\n### Documenation Link\r\n\r\nhttps://gpt-index.readthedocs.io/en/v0.6.31/how_to/analysis/cost_analysis.html",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7762/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7762/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7761",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7761/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7761/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7761/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7761",
        "id": 1907253900,
        "node_id": "PR_kwDOIWuq585a54NY",
        "number": 7761,
        "title": "[version] bump version to 0.8.30",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T15:30:55Z",
        "updated_at": "2023-09-21T15:41:15Z",
        "closed_at": "2023-09-21T15:41:14Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7761",
            "html_url": "https://github.com/run-llama/llama_index/pull/7761",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7761.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7761.patch",
            "merged_at": "2023-09-21T15:41:14Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7761/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7761/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7760",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7760/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7760/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7760/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7760",
        "id": 1907237662,
        "node_id": "PR_kwDOIWuq585a50n_",
        "number": 7760,
        "title": "[Draft] Suchme19/MyScale Intergration",
        "user": {
            "login": "suchme19",
            "id": 85013118,
            "node_id": "MDQ6VXNlcjg1MDEzMTE4",
            "avatar_url": "https://avatars.githubusercontent.com/u/85013118?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/suchme19",
            "html_url": "https://github.com/suchme19",
            "followers_url": "https://api.github.com/users/suchme19/followers",
            "following_url": "https://api.github.com/users/suchme19/following{/other_user}",
            "gists_url": "https://api.github.com/users/suchme19/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/suchme19/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/suchme19/subscriptions",
            "organizations_url": "https://api.github.com/users/suchme19/orgs",
            "repos_url": "https://api.github.com/users/suchme19/repos",
            "events_url": "https://api.github.com/users/suchme19/events{/privacy}",
            "received_events_url": "https://api.github.com/users/suchme19/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T15:22:43Z",
        "updated_at": "2023-09-22T02:18:55Z",
        "closed_at": "2023-09-22T02:18:55Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7760",
            "html_url": "https://github.com/run-llama/llama_index/pull/7760",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7760.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7760.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7760/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7760/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7759",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7759/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7759/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7759/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7759",
        "id": 1907052103,
        "node_id": "PR_kwDOIWuq585a5L2y",
        "number": 7759,
        "title": "add links for extended free trial for TimescaleVector",
        "user": {
            "login": "cevian",
            "id": 112245,
            "node_id": "MDQ6VXNlcjExMjI0NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/112245?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cevian",
            "html_url": "https://github.com/cevian",
            "followers_url": "https://api.github.com/users/cevian/followers",
            "following_url": "https://api.github.com/users/cevian/following{/other_user}",
            "gists_url": "https://api.github.com/users/cevian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cevian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cevian/subscriptions",
            "organizations_url": "https://api.github.com/users/cevian/orgs",
            "repos_url": "https://api.github.com/users/cevian/repos",
            "events_url": "https://api.github.com/users/cevian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cevian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T13:56:54Z",
        "updated_at": "2023-09-21T20:06:55Z",
        "closed_at": "2023-09-21T20:06:55Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7759",
            "html_url": "https://github.com/run-llama/llama_index/pull/7759",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7759.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7759.patch",
            "merged_at": "2023-09-21T20:06:55Z"
        },
        "body": "# Description\r\n\r\nModified timescale vector notebook with links for extended free trial for llamaindex users\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7759/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7759/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7758",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7758/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7758/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7758/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7758",
        "id": 1906910538,
        "node_id": "I_kwDOIWuq585xqSVK",
        "number": 7758,
        "title": "does Joint Text-to-SQL and Semantic Search support using an external SQL table(Snowflake)[Question]: ",
        "user": {
            "login": "lewis-ljh",
            "id": 95704635,
            "node_id": "U_kgDOBbRWOw",
            "avatar_url": "https://avatars.githubusercontent.com/u/95704635?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lewis-ljh",
            "html_url": "https://github.com/lewis-ljh",
            "followers_url": "https://api.github.com/users/lewis-ljh/followers",
            "following_url": "https://api.github.com/users/lewis-ljh/following{/other_user}",
            "gists_url": "https://api.github.com/users/lewis-ljh/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lewis-ljh/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lewis-ljh/subscriptions",
            "organizations_url": "https://api.github.com/users/lewis-ljh/orgs",
            "repos_url": "https://api.github.com/users/lewis-ljh/repos",
            "events_url": "https://api.github.com/users/lewis-ljh/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lewis-ljh/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T12:54:08Z",
        "updated_at": "2023-10-24T06:31:34Z",
        "closed_at": "2023-10-24T06:31:34Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHi I'm trying to implement the Joint Text-to-SQL and Semantic Search feature combining structured and unstructured data. In the example provided you natively create the SQL table but I was wondering is a way to import and use a pre-built schema with data already in it. Would It be through using the database tool?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7758/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7758/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7757",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7757/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7757/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7757/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7757",
        "id": 1906873263,
        "node_id": "I_kwDOIWuq585xqJOv",
        "number": 7757,
        "title": "[Question]: Seeking Feedback on Using LLMs for Hierarchical Multi-Label Text Classification on Large Archive Files (warc)",
        "user": {
            "login": "reversingentropy",
            "id": 68902907,
            "node_id": "MDQ6VXNlcjY4OTAyOTA3",
            "avatar_url": "https://avatars.githubusercontent.com/u/68902907?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/reversingentropy",
            "html_url": "https://github.com/reversingentropy",
            "followers_url": "https://api.github.com/users/reversingentropy/followers",
            "following_url": "https://api.github.com/users/reversingentropy/following{/other_user}",
            "gists_url": "https://api.github.com/users/reversingentropy/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/reversingentropy/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/reversingentropy/subscriptions",
            "organizations_url": "https://api.github.com/users/reversingentropy/orgs",
            "repos_url": "https://api.github.com/users/reversingentropy/repos",
            "events_url": "https://api.github.com/users/reversingentropy/events{/privacy}",
            "received_events_url": "https://api.github.com/users/reversingentropy/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T12:33:34Z",
        "updated_at": "2023-10-24T06:31:33Z",
        "closed_at": "2023-10-24T06:31:33Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI'm new to LLMs and would like feedback on using them for hierarchical multi-label text classification on extensive archive files (.warc). I have training abstracts with over 1000 target categories, and each abstract can have up to 10 labels. \r\n\r\n**Plan**\r\n1) Create embeddings for the warc files or create an abstract.\r\n2) Create embeddings for all 1000 hierarchical target classes.\r\n3) Use Retrieval Augmented Generation to prompt the LLM to select up to 10 labels based on embeddings\r\n4) Fine-tune the model with my training data.\r\n\r\n\r\n**Question**\r\n1. Is my proposed workflow realistic?\r\n2. Can I fine-tune either the model or the embeddings?\r\n3. Which is better for my project: LLama or ChatGPT?\r\n4. Can I train the LLM by supplying both the abstract and target category classes within the prompt?\r\n5. Are agents more effective? \r\n6. Would using an agent for recursive category selection from root to leaf nodes be more realistic? Is it worth exploring agents?\r\n\r\nThank you!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7757/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7757/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7756",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7756/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7756/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7756/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7756",
        "id": 1906737087,
        "node_id": "I_kwDOIWuq585xpn-_",
        "number": 7756,
        "title": "[Question]:node strategy ",
        "user": {
            "login": "ddealwis09",
            "id": 115846150,
            "node_id": "U_kgDOBuesBg",
            "avatar_url": "https://avatars.githubusercontent.com/u/115846150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ddealwis09",
            "html_url": "https://github.com/ddealwis09",
            "followers_url": "https://api.github.com/users/ddealwis09/followers",
            "following_url": "https://api.github.com/users/ddealwis09/following{/other_user}",
            "gists_url": "https://api.github.com/users/ddealwis09/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ddealwis09/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ddealwis09/subscriptions",
            "organizations_url": "https://api.github.com/users/ddealwis09/orgs",
            "repos_url": "https://api.github.com/users/ddealwis09/repos",
            "events_url": "https://api.github.com/users/ddealwis09/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ddealwis09/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T11:19:20Z",
        "updated_at": "2023-09-21T16:55:50Z",
        "closed_at": "2023-09-21T16:55:49Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHello,\r\nDoes llama-index have any abstractions for optimizing the node chunking - chunk size and overall for a specific document? \r\n\r\nThanks! ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7756/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7756/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7755",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7755/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7755/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7755/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7755",
        "id": 1906385260,
        "node_id": "PR_kwDOIWuq585a253S",
        "number": 7755,
        "title": "llms/openai: fix Azure OpenAI by considering `prompt_filter_results` field",
        "user": {
            "login": "ret2libc",
            "id": 562321,
            "node_id": "MDQ6VXNlcjU2MjMyMQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/562321?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ret2libc",
            "html_url": "https://github.com/ret2libc",
            "followers_url": "https://api.github.com/users/ret2libc/followers",
            "following_url": "https://api.github.com/users/ret2libc/following{/other_user}",
            "gists_url": "https://api.github.com/users/ret2libc/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ret2libc/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ret2libc/subscriptions",
            "organizations_url": "https://api.github.com/users/ret2libc/orgs",
            "repos_url": "https://api.github.com/users/ret2libc/repos",
            "events_url": "https://api.github.com/users/ret2libc/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ret2libc/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-21T08:16:43Z",
        "updated_at": "2023-09-21T20:07:58Z",
        "closed_at": "2023-09-21T20:07:48Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7755",
            "html_url": "https://github.com/run-llama/llama_index/pull/7755",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7755.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7755.patch",
            "merged_at": "2023-09-21T20:07:48Z"
        },
        "body": "# Description\r\n\r\nFunctions in OpenAI are only supported in preview API versions for now, and as such things might actually change. What before was `prompt_annotations` now seems to be `prompt_filter_results`.\r\n\r\nWithout this patch you get essentially the same problem explained in #7677\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7755/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7755/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7754",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7754/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7754/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7754/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7754",
        "id": 1906148894,
        "node_id": "PR_kwDOIWuq585a2G3Z",
        "number": 7754,
        "title": "Correcting LanceDBVectorStore to avoid KeyError: 'score'",
        "user": {
            "login": "stephenwebel",
            "id": 13646076,
            "node_id": "MDQ6VXNlcjEzNjQ2MDc2",
            "avatar_url": "https://avatars.githubusercontent.com/u/13646076?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/stephenwebel",
            "html_url": "https://github.com/stephenwebel",
            "followers_url": "https://api.github.com/users/stephenwebel/followers",
            "following_url": "https://api.github.com/users/stephenwebel/following{/other_user}",
            "gists_url": "https://api.github.com/users/stephenwebel/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/stephenwebel/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/stephenwebel/subscriptions",
            "organizations_url": "https://api.github.com/users/stephenwebel/orgs",
            "repos_url": "https://api.github.com/users/stephenwebel/repos",
            "events_url": "https://api.github.com/users/stephenwebel/events{/privacy}",
            "received_events_url": "https://api.github.com/users/stephenwebel/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-21T05:38:17Z",
        "updated_at": "2023-09-22T18:52:07Z",
        "closed_at": "2023-09-22T18:52:07Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7754",
            "html_url": "https://github.com/run-llama/llama_index/pull/7754",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7754.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7754.patch",
            "merged_at": "2023-09-22T18:52:07Z"
        },
        "body": "# Description\r\n\r\nLanceDBVectorStore currently fails when being queried on a KeyError due to accessing `results[\"score\"]` which does not exist. \r\n\r\nUpdating lancedb.py to reference \"_distance\" to specify similarity. Currently, \"score\" is being used but returns a KeyError. The \"_distance\" column is specified in LanceDB's docs: https://github.com/lancedb/lancedb/blob/74004161ff1a90ae11a7fa531b551b2bc891e6ed/python/lancedb/query.py#L131\r\n\r\nMinor changes to the corresponding notebook for easier openai key management, correctly referencing the data directory location, and Document.doc_has is now simply Document.hash. Updated the questions to be a little more interesting and including response from my local test validating the updated lancedb.py\r\n\r\nFixes # ([7520](https://github.com/jerryjliu/llama_index/issues/7520))\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] This change requires a documentation update\r\n^ leaving the last given the updates to the notebook but technically the docs do not need to be changed.\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Updated and ran existing notebook that was failing on checkout (see below)\r\n- [x] I stared at the code with great intensity and made sure it makes sense, and checked the lancedb source\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n\r\n# Receipts\r\nFailing notebook:\r\n![Screenshot from 2023-09-20 23-40-44](https://github.com/jerryjliu/llama_index/assets/13646076/3fde2f8b-f33a-443e-81c6-900067742bf9)\r\n\r\nWorking notebook:\r\n![Screenshot from 2023-09-21 01-33-30](https://github.com/jerryjliu/llama_index/assets/13646076/904d48f5-9e68-4cd4-b6fc-b7c4b596c79c)\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7754/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7754/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7753",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7753/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7753/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7753/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7753",
        "id": 1905985933,
        "node_id": "I_kwDOIWuq585xmwmN",
        "number": 7753,
        "title": "[Question]: Getting the TokenCounter from a StorageContext",
        "user": {
            "login": "XariZaru",
            "id": 18338434,
            "node_id": "MDQ6VXNlcjE4MzM4NDM0",
            "avatar_url": "https://avatars.githubusercontent.com/u/18338434?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/XariZaru",
            "html_url": "https://github.com/XariZaru",
            "followers_url": "https://api.github.com/users/XariZaru/followers",
            "following_url": "https://api.github.com/users/XariZaru/following{/other_user}",
            "gists_url": "https://api.github.com/users/XariZaru/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/XariZaru/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/XariZaru/subscriptions",
            "organizations_url": "https://api.github.com/users/XariZaru/orgs",
            "repos_url": "https://api.github.com/users/XariZaru/repos",
            "events_url": "https://api.github.com/users/XariZaru/events{/privacy}",
            "received_events_url": "https://api.github.com/users/XariZaru/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-21T02:44:29Z",
        "updated_at": "2023-09-21T14:55:16Z",
        "closed_at": "2023-09-21T14:55:15Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### Question\r\n\r\nI've got the tokenizer working with a ServiceContext. However, when I went through the API, I couldn't see a way to access this tokenizer if loading from a **StorageContext**. \r\n\r\n```python\r\nimport openai\r\nimport streamlit as st\r\nfrom streamlit_pills import pills\r\nimport streamlit_scrollable_textbox as stx\r\nfrom llama_index import SimpleDirectoryReader, VectorStoreIndex, LLMPredictor\r\nfrom datetime import datetime\r\nimport tiktoken\r\nfrom llama_index.callbacks import CallbackManager, TokenCountingHandler\r\nfrom llama_index import StorageContext, load_index_from_storage\r\n\r\n@st.cache_resource\r\ndef load_index():\r\n    #token_counter = TokenCountingHandler(\r\n    #    tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\r\n    #)\r\n    \r\n    #callback_manager = CallbackManager([token_counter])\r\n\r\n    sc = StorageContext.from_defaults(persist_dir='kinection_demo')\r\n    index = load_index_from_storage(sc, 'vector_index')\r\n    return sc, index\r\n```\r\n\r\nHow do I grab the token counter when using a StorageContext? Does it have a reference to the ServiceContext?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7753/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7753/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7752",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7752/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7752/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7752/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7752",
        "id": 1905931139,
        "node_id": "PR_kwDOIWuq585a1Xpz",
        "number": 7752,
        "title": "add docs, notebook, imports for LongContextReorder",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-21T01:35:28Z",
        "updated_at": "2023-09-21T02:40:23Z",
        "closed_at": "2023-09-21T02:40:23Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7752",
            "html_url": "https://github.com/run-llama/llama_index/pull/7752",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7752.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7752.patch",
            "merged_at": "2023-09-21T02:40:22Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7752/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7752/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7751",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7751/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7751/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7751/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7751",
        "id": 1905895218,
        "node_id": "I_kwDOIWuq585xmacy",
        "number": 7751,
        "title": "[Question]: Are there any restrictions on where files can be placed when creating an index from a file?",
        "user": {
            "login": "Ma-Fukudama",
            "id": 76037787,
            "node_id": "MDQ6VXNlcjc2MDM3Nzg3",
            "avatar_url": "https://avatars.githubusercontent.com/u/76037787?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Ma-Fukudama",
            "html_url": "https://github.com/Ma-Fukudama",
            "followers_url": "https://api.github.com/users/Ma-Fukudama/followers",
            "following_url": "https://api.github.com/users/Ma-Fukudama/following{/other_user}",
            "gists_url": "https://api.github.com/users/Ma-Fukudama/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Ma-Fukudama/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Ma-Fukudama/subscriptions",
            "organizations_url": "https://api.github.com/users/Ma-Fukudama/orgs",
            "repos_url": "https://api.github.com/users/Ma-Fukudama/repos",
            "events_url": "https://api.github.com/users/Ma-Fukudama/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Ma-Fukudama/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-21T00:47:05Z",
        "updated_at": "2023-09-21T16:57:39Z",
        "closed_at": "2023-09-21T16:57:39Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nEven if you specify the path where the file is located when creating an index from a file, it will not be created successfully.\r\nWill the index not be created unless the file is placed in the data directory under the path where the python file is located?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7751/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7751/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7750",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7750/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7750/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7750/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7750",
        "id": 1905838013,
        "node_id": "I_kwDOIWuq585xmMe9",
        "number": 7750,
        "title": "[Question]: How do I get the exact and full prompt that was passed to the LLM? ",
        "user": {
            "login": "sia-cerebras",
            "id": 101586439,
            "node_id": "U_kgDOBg4WBw",
            "avatar_url": "https://avatars.githubusercontent.com/u/101586439?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sia-cerebras",
            "html_url": "https://github.com/sia-cerebras",
            "followers_url": "https://api.github.com/users/sia-cerebras/followers",
            "following_url": "https://api.github.com/users/sia-cerebras/following{/other_user}",
            "gists_url": "https://api.github.com/users/sia-cerebras/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sia-cerebras/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sia-cerebras/subscriptions",
            "organizations_url": "https://api.github.com/users/sia-cerebras/orgs",
            "repos_url": "https://api.github.com/users/sia-cerebras/repos",
            "events_url": "https://api.github.com/users/sia-cerebras/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sia-cerebras/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T23:16:51Z",
        "updated_at": "2023-10-24T06:31:32Z",
        "closed_at": "2023-10-24T06:31:32Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\r\n\r\n- [X] I have searched both the documentation and discord for an answer.\r\n\r\n### context\r\n\r\nI'm not sure `query_wrapper_prompt` is actually being used, as I see some conflicting information from `llama_debug`. \r\nSo I would like to know exactly what prompt is passed to the LLM when `query_engine.query(...)` method is called.\r\n\r\nExample: \r\nI first call `query_engine.query(\"My query\")`\r\n\r\nThen I call `llama_debug.get_llm_inputs_outputs()` which returns: \r\n```\r\n[[\r\nCBEvent(event_type=<CBEventType.LLM: 'llm'>, payload={\r\n<EventPayload.PROMPT: 'formatted_prompt'>: 'Context information is below.\\n---------------------\\n[retrieved documents]---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: My query\\nAnswer: ', \r\n<EventPayload.ADDITIONAL_KWARGS: 'additional_kwargs'>: {}, \r\n<EventPayload.SERIALIZED: 'serialized'>: {'model_name': 'StabilityAI/stablelm-tuned-alpha-3b', 'context_window': 4096, 'max_new_tokens': 512, 'system_prompt': '', 'query_wrapper_prompt': \"[INST]<<SYS>>\\nYou are an AI assistant that answers questions in a friendly manner, based on the given source documents. <</SYS>>\\n\\n{query_str}[/INST]\", 'tokenizer_name': 'StabilityAI/stablelm-tuned-alpha-3b', 'device_map': 'auto', 'stopping_ids': [], 'tokenizer_outputs_to_remove': [], 'tokenizer_kwargs': {'max_length': 4096}, 'model_kwargs': {'torch_dtype': torch.float16, 'load_in_8bit': True}, 'generate_kwargs': {'temperature': 0.0, 'do_sample': False}, 'class_name': 'HuggingFace_LLM'}}, time='09/20/2023, 15:11:02.595113', id_='c97ad2ff-f873-4f24-a525-bf5690521fa8'),\r\n  \r\nCBEvent(event_type=<CBEventType.LLM: 'llm'>, payload={\r\n<EventPayload.PROMPT: 'formatted_prompt'>: 'Context information is below.\\n---------------------\\n[retrieved documents]---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: My query\\nAnswer: ', \r\n<EventPayload.COMPLETION: 'completion'>: CompletionResponse(text='<<SYS>>\\n\\n[LLM response]', additional_kwargs={}, raw={'model_output': tensor([[    1,   518, ...,  287, 24413]], device='cuda:0')}, delta=None)}, time='09/20/2023, 15:11:21.680252', id_='c97ad2ff-f873-4f24-a525-bf5690521fa8')\r\n]]\r\n```\r\n\r\nYou can see that I have a `query_wrapper_prompt` that says `[INST]<<SYS>>\\nYou are an AI assistant that answers questions in a friendly manner, based on the given source documents. <</SYS>>\\n\\n{query_str}[/INST]\"`\r\n\r\nWhile the `'formatted_prompt'` is `'Context information is below.\\n---------------------\\n[retrieved documents]---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: My query\\nAnswer: '`\r\n\r\nSo it looks like different template is being used. \r\n\r\n### Question:\r\nIs `'formatted_prompt'` the prompt that is passed to the LLM? \r\nIf yes, why does it not use my `query_wrapper_prompt`?\r\nIf no, then what is the point of `query_wrapper_prompt`? where does it get used?\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7750/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7750/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7749",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7749/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7749/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7749/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7749",
        "id": 1905774100,
        "node_id": "I_kwDOIWuq585xl84U",
        "number": 7749,
        "title": "[Bug]: Recursive Retriever drops TextNode objects",
        "user": {
            "login": "tlongatalaya",
            "id": 98911650,
            "node_id": "U_kgDOBeVFog",
            "avatar_url": "https://avatars.githubusercontent.com/u/98911650?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tlongatalaya",
            "html_url": "https://github.com/tlongatalaya",
            "followers_url": "https://api.github.com/users/tlongatalaya/followers",
            "following_url": "https://api.github.com/users/tlongatalaya/following{/other_user}",
            "gists_url": "https://api.github.com/users/tlongatalaya/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tlongatalaya/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tlongatalaya/subscriptions",
            "organizations_url": "https://api.github.com/users/tlongatalaya/orgs",
            "repos_url": "https://api.github.com/users/tlongatalaya/repos",
            "events_url": "https://api.github.com/users/tlongatalaya/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tlongatalaya/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T21:58:43Z",
        "updated_at": "2023-09-26T23:50:05Z",
        "closed_at": "2023-09-26T23:50:05Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nThe recursive retriever iterates over the Nodes in the _query_retrieved_nodes method, however as currently implemented it drops any TextNodes and only queries the IndexNodes.\r\n\r\nThe relevant code is here: https://github.com/jerryjliu/llama_index/blob/fdf0d7ff194f6fc9c6ecb2c5a43e2c122a7e8dca/llama_index/retrievers/recursive_retriever.py#L78C1-L86C48\r\n\r\n```   \r\n# dedup index nodes that reference same index id\r\nnew_nodes_with_score = []\r\nfor node_with_score in nodes_with_score:\r\n    node = node_with_score.node\r\n    if isinstance(node, IndexNode):\r\n        if node.index_id not in visited_ids:\r\n            visited_ids.add(node.index_id)\r\n            new_nodes_with_score.append(node_with_score)\r\nnodes_with_score = new_nodes_with_score\r\n```\r\n\r\nnodes_with_score is overwritten by the new_nodes_with_score list, which will only include IndexNode objects due to the if statement.\n\n### Version\n\n0.8.29\n\n### Steps to Reproduce\n\nInstantiate a RecursiveRetriever object which has both IndexNode and TextNode objects in the index and call retrieve.\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7749/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7749/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7748",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7748/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7748/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7748/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7748",
        "id": 1905771484,
        "node_id": "PR_kwDOIWuq585a016X",
        "number": 7748,
        "title": "Fix DatasetGenerator.generate_questions_from_nodes method",
        "user": {
            "login": "dkuryakin",
            "id": 1270109,
            "node_id": "MDQ6VXNlcjEyNzAxMDk=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1270109?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/dkuryakin",
            "html_url": "https://github.com/dkuryakin",
            "followers_url": "https://api.github.com/users/dkuryakin/followers",
            "following_url": "https://api.github.com/users/dkuryakin/following{/other_user}",
            "gists_url": "https://api.github.com/users/dkuryakin/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/dkuryakin/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/dkuryakin/subscriptions",
            "organizations_url": "https://api.github.com/users/dkuryakin/orgs",
            "repos_url": "https://api.github.com/users/dkuryakin/repos",
            "events_url": "https://api.github.com/users/dkuryakin/events{/privacy}",
            "received_events_url": "https://api.github.com/users/dkuryakin/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-20T21:55:43Z",
        "updated_at": "2023-09-21T16:25:38Z",
        "closed_at": "2023-09-21T16:25:38Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7748",
            "html_url": "https://github.com/run-llama/llama_index/pull/7748",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7748.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7748.patch",
            "merged_at": "2023-09-21T16:25:38Z"
        },
        "body": "Pass local service_context to QA-generator, not global one.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7748/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7748/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7747",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7747/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7747/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7747/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7747",
        "id": 1905505733,
        "node_id": "I_kwDOIWuq585xk7XF",
        "number": 7747,
        "title": "[Bug]: JSONQueryEngine Exception - Parse Error at $s near token",
        "user": {
            "login": "thanh-cnguyen",
            "id": 78707327,
            "node_id": "MDQ6VXNlcjc4NzA3MzI3",
            "avatar_url": "https://avatars.githubusercontent.com/u/78707327?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/thanh-cnguyen",
            "html_url": "https://github.com/thanh-cnguyen",
            "followers_url": "https://api.github.com/users/thanh-cnguyen/followers",
            "following_url": "https://api.github.com/users/thanh-cnguyen/following{/other_user}",
            "gists_url": "https://api.github.com/users/thanh-cnguyen/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/thanh-cnguyen/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/thanh-cnguyen/subscriptions",
            "organizations_url": "https://api.github.com/users/thanh-cnguyen/orgs",
            "repos_url": "https://api.github.com/users/thanh-cnguyen/repos",
            "events_url": "https://api.github.com/users/thanh-cnguyen/events{/privacy}",
            "received_events_url": "https://api.github.com/users/thanh-cnguyen/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T18:19:46Z",
        "updated_at": "2023-10-02T15:55:18Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThe parameter `llm_output` of function `default_output_processor` can be a string of:\r\n- query instructions (\"JSONPath Instructions...\") \r\n- the final response from the engine, not the expected JSON Path (E.g. $.pages[*].url).\r\n\r\nException: `jsonpath_ng: Exception: Parse error at 1:5 near token task (ID)`\r\n\r\n\r\n\r\n\r\n### Version\r\n\r\n0.8.14\r\n\r\n### Steps to Reproduce\r\n\r\n1. Setup JSONQueryEngine as usual with json_value, json_schema, and service context\r\n2. Perform querying using `.query()`\r\n\r\nThe bug doesn't occur often, so that it might take some time.\r\nPay attention to the llm_output of  `default_output_processor`\r\n\r\nNote: I have to use a custom output processor that mimics the default function to see the issue.\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/tools/query_engine.py\", line 54, in call\r\n    response = self._query_engine.query(query_str)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/query_engine/transform_query_engine.py\", line 79, in _query\r\n    return self._query_engine.query(query_bundle)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/indices/query/base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/indices/struct_store/json_query.py\", line 116, in _query\r\n    json_path_output = self._output_processor(\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/llama_index/indices/struct_store/json_query.py\", line 48, in default_output_processor\r\n    datum: List[DatumInContext] = parse(llm_output).find(json_value)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/jsonpath_ng/ext/parser.py\", line 172, in parse\r\n    return ExtentedJsonPathParser(debug=debug).parse(path)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/jsonpath_ng/parser.py\", line 45, in parse\r\n    return self.parse_token_stream(lexer.tokenize(string))\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/jsonpath_ng/parser.py\", line 69, in parse_token_stream\r\n    return new_parser.parse(lexer = IteratorToTokenStream(token_iterator))\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/ply/yacc.py\", line 333, in parse\r\n    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/ply/yacc.py\", line 1201, in parseopt_notrack\r\n    tok = call_errorfunc(self.errorfunc, errtoken, self)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/ply/yacc.py\", line 192, in call_errorfunc\r\n    r = errorfunc(token)\r\n  File \"/virtualenv/texasfile/lib/python3.8/site-packages/jsonpath_ng/parser.py\", line 83, in p_error\r\n    raise JsonPathParserError('Parse error at %s:%s near token %s (%s)'\r\njsonpath_ng.exceptions.JsonPathParserError: Parse error at 1:5 near token task (ID)\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7747/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7747/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7746",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7746/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7746/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7746/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7746",
        "id": 1905464411,
        "node_id": "PR_kwDOIWuq585azzJ0",
        "number": 7746,
        "title": "properly calculate score between 0 and 1",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-20T17:48:21Z",
        "updated_at": "2023-09-20T17:58:14Z",
        "closed_at": "2023-09-20T17:58:13Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7746",
            "html_url": "https://github.com/run-llama/llama_index/pull/7746",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7746.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7746.patch",
            "merged_at": "2023-09-20T17:58:13Z"
        },
        "body": "# Description\r\n\r\nSmall fix for the score calculation in chromadb. It's not perfect, the scores seem a little low, but they do make sense. Previously the calculation meant lower scores were more similar instead of higher scores.\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7007\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7746/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7746/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7745",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7745/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7745/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7745/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7745",
        "id": 1905448689,
        "node_id": "I_kwDOIWuq585xktbx",
        "number": 7745,
        "title": "Options to save the vector database locally (apart from Chroma and FAISS)",
        "user": {
            "login": "zzadiues",
            "id": 64059206,
            "node_id": "MDQ6VXNlcjY0MDU5MjA2",
            "avatar_url": "https://avatars.githubusercontent.com/u/64059206?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/zzadiues",
            "html_url": "https://github.com/zzadiues",
            "followers_url": "https://api.github.com/users/zzadiues/followers",
            "following_url": "https://api.github.com/users/zzadiues/following{/other_user}",
            "gists_url": "https://api.github.com/users/zzadiues/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/zzadiues/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/zzadiues/subscriptions",
            "organizations_url": "https://api.github.com/users/zzadiues/orgs",
            "repos_url": "https://api.github.com/users/zzadiues/repos",
            "events_url": "https://api.github.com/users/zzadiues/events{/privacy}",
            "received_events_url": "https://api.github.com/users/zzadiues/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T17:37:23Z",
        "updated_at": "2023-09-21T16:58:30Z",
        "closed_at": "2023-09-21T16:58:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am searching for vector database options that let you save the vector database on disk locally. I know that ChromaDB and FAISS let you do that but I am unable to use either due to some complications. \r\n\r\nAre there any other vector databases that allow you to save locally ? \r\n\r\nIt seems that options like epsilla or weaviate only keep the database in memory and we need to regenerate those every time\r\nwe restart the application. Amiright?\r\nFolks kindly help me out im a newbie in all this..\r\nThanks a ton",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7745/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7745/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7744",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7744/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7744/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7744/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7744",
        "id": 1905403705,
        "node_id": "I_kwDOIWuq585xkic5",
        "number": 7744,
        "title": "[Bug]: Adding nodes to a keyword index generates quota exceeded error",
        "user": {
            "login": "axgabs",
            "id": 78040073,
            "node_id": "MDQ6VXNlcjc4MDQwMDcz",
            "avatar_url": "https://avatars.githubusercontent.com/u/78040073?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axgabs",
            "html_url": "https://github.com/axgabs",
            "followers_url": "https://api.github.com/users/axgabs/followers",
            "following_url": "https://api.github.com/users/axgabs/following{/other_user}",
            "gists_url": "https://api.github.com/users/axgabs/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axgabs/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axgabs/subscriptions",
            "organizations_url": "https://api.github.com/users/axgabs/orgs",
            "repos_url": "https://api.github.com/users/axgabs/repos",
            "events_url": "https://api.github.com/users/axgabs/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axgabs/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-20T17:04:59Z",
        "updated_at": "2023-09-20T17:11:36Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nDifferent from vector index, when I try to add several nodes to a keyword index, it returns me a quota exceeded error. I wonder if it is possible to add a exception treatment which will wait some time and try again to add the remaining nodes.\n\n### Version\n\nllama-index-0.8.29.post1\n\n### Steps to Reproduce\n\nUse index.insert_nodes(node) several times.\n\n### Relevant Logs/Tracbacks\n\n```shell\n/opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/indices/base.py:181 in         \u2502\r\n\u2502 insert_nodes                                                                                     \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   178 \u2502   \u2502   \"\"\"Insert nodes.\"\"\"                                                                \u2502\r\n\u2502   179 \u2502   \u2502   with self._service_context.callback_manager.as_trace(\"insert_nodes\"):              \u2502\r\n\u2502   180 \u2502   \u2502   \u2502   self.docstore.add_documents(nodes, allow_update=True)                          \u2502\r\n\u2502 \u2771 181 \u2502   \u2502   \u2502   self._insert(nodes, **insert_kwargs)                                           \u2502\r\n\u2502   182 \u2502   \u2502   \u2502   self._storage_context.index_store.add_index_struct(self._index_struct)         \u2502\r\n\u2502   183 \u2502                                                                                          \u2502\r\n\u2502   184 \u2502   def insert(self, document: Document, **insert_kwargs: Any) -> None:                    \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/indices/keyword_table/base.py: \u2502\r\n\u2502 173 in _insert                                                                                   \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   170 \u2502   def _insert(self, nodes: Sequence[BaseNode], **insert_kwargs: Any) -> None:            \u2502\r\n\u2502   171 \u2502   \u2502   \"\"\"Insert nodes.\"\"\"                                                                \u2502\r\n\u2502   172 \u2502   \u2502   for n in nodes:                                                                    \u2502\r\n\u2502 \u2771 173 \u2502   \u2502   \u2502   keywords = self._extract_keywords(                                             \u2502\r\n\u2502   174 \u2502   \u2502   \u2502   \u2502   n.get_content(metadata_mode=MetadataMode.LLM)                              \u2502\r\n\u2502   175 \u2502   \u2502   \u2502   )                                                                              \u2502\r\n\u2502   176 \u2502   \u2502   \u2502   self._index_struct.add_node(list(keywords), n)                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/indices/keyword_table/base.py: \u2502\r\n\u2502 222 in _extract_keywords                                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   219 \u2502                                                                                          \u2502\r\n\u2502   220 \u2502   def _extract_keywords(self, text: str) -> Set[str]:                                    \u2502\r\n\u2502   221 \u2502   \u2502   \"\"\"Extract keywords from text.\"\"\"                                                  \u2502\r\n\u2502 \u2771 222 \u2502   \u2502   response = self._service_context.llm_predictor.predict(                            \u2502\r\n\u2502   223 \u2502   \u2502   \u2502   self.keyword_extract_template,                                                 \u2502\r\n\u2502   224 \u2502   \u2502   \u2502   text=text,                                                                     \u2502\r\n\u2502   225 \u2502   \u2502   )                                                                                  \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/llm_predictor/base.py:142 in   \u2502\r\n\u2502 predict                                                                                          \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   139 \u2502   \u2502   if self._llm.metadata.is_chat_model:                                               \u2502\r\n\u2502   140 \u2502   \u2502   \u2502   messages = prompt.format_messages(llm=self._llm, **prompt_args)                \u2502\r\n\u2502   141 \u2502   \u2502   \u2502   messages = self._extend_messages(messages)                                     \u2502\r\n\u2502 \u2771 142 \u2502   \u2502   \u2502   chat_response = self._llm.chat(messages)                                       \u2502\r\n\u2502   143 \u2502   \u2502   \u2502   output = chat_response.message.content or \"\"                                   \u2502\r\n\u2502   144 \u2502   \u2502   \u2502   # NOTE: this is an approximation, only for token counting                      \u2502\r\n\u2502   145 \u2502   \u2502   \u2502   formatted_prompt = messages_to_prompt(messages)                                \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/llms/base.py:151 in            \u2502\r\n\u2502 wrapped_llm_chat                                                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   148 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   EventPayload.SERIALIZED: _self.to_dict(),                          \u2502\r\n\u2502   149 \u2502   \u2502   \u2502   \u2502   \u2502   },                                                                     \u2502\r\n\u2502   150 \u2502   \u2502   \u2502   \u2502   )                                                                          \u2502\r\n\u2502 \u2771 151 \u2502   \u2502   \u2502   \u2502   f_return_val = f(_self, messages, **kwargs)                                \u2502\r\n\u2502   152 \u2502   \u2502   \u2502   \u2502                                                                              \u2502\r\n\u2502   153 \u2502   \u2502   \u2502   \u2502   if isinstance(f_return_val, Generator):                                    \u2502\r\n\u2502   154 \u2502   \u2502   \u2502   \u2502   \u2502   # intercept the generator and add a callback to the end                \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/llama_index/llms/langchain.py:57 in chat   \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    54 \u2502   @llm_chat_callback()                                                                   \u2502\r\n\u2502    55 \u2502   def chat(self, messages: Sequence[ChatMessage], **kwargs: Any) -> ChatResponse:        \u2502\r\n\u2502    56 \u2502   \u2502   lc_messages = to_lc_messages(messages)                                             \u2502\r\n\u2502 \u2771  57 \u2502   \u2502   lc_message = self._llm.predict_messages(messages=lc_messages, **kwargs)            \u2502\r\n\u2502    58 \u2502   \u2502   message = from_lc_messages([lc_message])[0]                                        \u2502\r\n\u2502    59 \u2502   \u2502   return ChatResponse(message=message)                                               \u2502\r\n\u2502    60                                                                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/base.py:601 in       \u2502\r\n\u2502 predict_messages                                                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   598 \u2502   \u2502   \u2502   _stop = None                                                                   \u2502\r\n\u2502   599 \u2502   \u2502   else:                                                                              \u2502\r\n\u2502   600 \u2502   \u2502   \u2502   _stop = list(stop)                                                             \u2502\r\n\u2502 \u2771 601 \u2502   \u2502   return self(messages, stop=_stop, **kwargs)                                        \u2502\r\n\u2502   602 \u2502                                                                                          \u2502\r\n\u2502   603 \u2502   async def apredict(                                                                    \u2502\r\n\u2502   604 \u2502   \u2502   self, text: str, *, stop: Optional[Sequence[str]] = None, **kwargs: Any            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/base.py:551 in       \u2502\r\n\u2502 __call__                                                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   548 \u2502   \u2502   callbacks: Callbacks = None,                                                       \u2502\r\n\u2502   549 \u2502   \u2502   **kwargs: Any,                                                                     \u2502\r\n\u2502   550 \u2502   ) -> BaseMessage:                                                                      \u2502\r\n\u2502 \u2771 551 \u2502   \u2502   generation = self.generate(                                                        \u2502\r\n\u2502   552 \u2502   \u2502   \u2502   [messages], stop=stop, callbacks=callbacks, **kwargs                           \u2502\r\n\u2502   553 \u2502   \u2502   ).generations[0][0]                                                                \u2502\r\n\u2502   554 \u2502   \u2502   if isinstance(generation, ChatGeneration):                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/base.py:309 in       \u2502\r\n\u2502 generate                                                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   306 \u2502   \u2502   \u2502   except BaseException as e:                                                     \u2502\r\n\u2502   307 \u2502   \u2502   \u2502   \u2502   if run_managers:                                                           \u2502\r\n\u2502   308 \u2502   \u2502   \u2502   \u2502   \u2502   run_managers[i].on_llm_error(e)                                        \u2502\r\n\u2502 \u2771 309 \u2502   \u2502   \u2502   \u2502   raise e                                                                    \u2502\r\n\u2502   310 \u2502   \u2502   flattened_outputs = [                                                              \u2502\r\n\u2502   311 \u2502   \u2502   \u2502   LLMResult(generations=[res.generations], llm_output=res.llm_output)            \u2502\r\n\u2502   312 \u2502   \u2502   \u2502   for res in results                                                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/base.py:299 in       \u2502\r\n\u2502 generate                                                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   296 \u2502   \u2502   for i, m in enumerate(messages):                                                   \u2502\r\n\u2502   297 \u2502   \u2502   \u2502   try:                                                                           \u2502\r\n\u2502   298 \u2502   \u2502   \u2502   \u2502   results.append(                                                            \u2502\r\n\u2502 \u2771 299 \u2502   \u2502   \u2502   \u2502   \u2502   self._generate_with_cache(                                             \u2502\r\n\u2502   300 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   m,                                                                 \u2502\r\n\u2502   301 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   stop=stop,                                                         \u2502\r\n\u2502   302 \u2502   \u2502   \u2502   \u2502   \u2502   \u2502   run_manager=run_managers[i] if run_managers else None,             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/base.py:446 in       \u2502\r\n\u2502 _generate_with_cache                                                                             \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   443 \u2502   \u2502   \u2502   \u2502   \u2502   \"Asked to cache, but no cache found at `langchain.cache`.\"             \u2502\r\n\u2502   444 \u2502   \u2502   \u2502   \u2502   )                                                                          \u2502\r\n\u2502   445 \u2502   \u2502   \u2502   if new_arg_supported:                                                          \u2502\r\n\u2502 \u2771 446 \u2502   \u2502   \u2502   \u2502   return self._generate(                                                     \u2502\r\n\u2502   447 \u2502   \u2502   \u2502   \u2502   \u2502   messages, stop=stop, run_manager=run_manager, **kwargs                 \u2502\r\n\u2502   448 \u2502   \u2502   \u2502   \u2502   )                                                                          \u2502\r\n\u2502   449 \u2502   \u2502   \u2502   else:                                                                          \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/langchain/chat_models/vertexai.py:158 in   \u2502\r\n\u2502 _generate                                                                                        \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   155 \u2502   \u2502   \u2502   )                                                                              \u2502\r\n\u2502   156 \u2502   \u2502   else:                                                                              \u2502\r\n\u2502   157 \u2502   \u2502   \u2502   chat = self.client.start_chat(message_history=history.history, **params)       \u2502\r\n\u2502 \u2771 158 \u2502   \u2502   response = chat.send_message(question.content)                                     \u2502\r\n\u2502   159 \u2502   \u2502   text = self._enforce_stop_words(response.text, stop)                               \u2502\r\n\u2502   160 \u2502   \u2502   return ChatResult(generations=[ChatGeneration(message=AIMessage(content=text))])   \u2502\r\n\u2502   161                                                                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/vertexai/language_models/_language_models. \u2502\r\n\u2502 py:855 in send_message                                                                           \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    852 \u2502   \u2502   \u2502   \u2502   for example in self._examples                                             \u2502\r\n\u2502    853 \u2502   \u2502   \u2502   ]                                                                             \u2502\r\n\u2502    854 \u2502   \u2502                                                                                     \u2502\r\n\u2502 \u2771  855 \u2502   \u2502   prediction_response = self._model._endpoint.predict(                              \u2502\r\n\u2502    856 \u2502   \u2502   \u2502   instances=[prediction_instance],                                              \u2502\r\n\u2502    857 \u2502   \u2502   \u2502   parameters=prediction_parameters,                                             \u2502\r\n\u2502    858 \u2502   \u2502   )                                                                                 \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/google/cloud/aiplatform/models.py:1564 in  \u2502\r\n\u2502 predict                                                                                          \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   1561 \u2502   \u2502   \u2502   \u2502   ),                                                                        \u2502\r\n\u2502   1562 \u2502   \u2502   \u2502   )                                                                             \u2502\r\n\u2502   1563 \u2502   \u2502   else:                                                                             \u2502\r\n\u2502 \u2771 1564 \u2502   \u2502   \u2502   prediction_response = self._prediction_client.predict(                        \u2502\r\n\u2502   1565 \u2502   \u2502   \u2502   \u2502   endpoint=self._gca_resource.name,                                         \u2502\r\n\u2502   1566 \u2502   \u2502   \u2502   \u2502   instances=instances,                                                      \u2502\r\n\u2502   1567 \u2502   \u2502   \u2502   \u2502   parameters=parameters,                                                    \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/predic \u2502\r\n\u2502 tion_service/client.py:606 in predict                                                            \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    603 \u2502   \u2502   )                                                                                 \u2502\r\n\u2502    604 \u2502   \u2502                                                                                     \u2502\r\n\u2502    605 \u2502   \u2502   # Send the request.                                                               \u2502\r\n\u2502 \u2771  606 \u2502   \u2502   response = rpc(                                                                   \u2502\r\n\u2502    607 \u2502   \u2502   \u2502   request,                                                                      \u2502\r\n\u2502    608 \u2502   \u2502   \u2502   retry=retry,                                                                  \u2502\r\n\u2502    609 \u2502   \u2502   \u2502   timeout=timeout,                                                              \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:113 in  \u2502\r\n\u2502 __call__                                                                                         \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502   110 \u2502   \u2502   \u2502   metadata.extend(self._metadata)                                                \u2502\r\n\u2502   111 \u2502   \u2502   \u2502   kwargs[\"metadata\"] = metadata                                                  \u2502\r\n\u2502   112 \u2502   \u2502                                                                                      \u2502\r\n\u2502 \u2771 113 \u2502   \u2502   return wrapped_func(*args, **kwargs)                                               \u2502\r\n\u2502   114                                                                                            \u2502\r\n\u2502   115                                                                                            \u2502\r\n\u2502   116 def wrap_method(                                                                           \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502 /opt/conda/envs/whirlpalm/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:74 in      \u2502\r\n\u2502 error_remapped_callable                                                                          \u2502\r\n\u2502                                                                                                  \u2502\r\n\u2502    71 \u2502   \u2502   try:                                                                               \u2502\r\n\u2502    72 \u2502   \u2502   \u2502   return callable_(*args, **kwargs)                                              \u2502\r\n\u2502    73 \u2502   \u2502   except grpc.RpcError as exc:                                                       \u2502\r\n\u2502 \u2771  74 \u2502   \u2502   \u2502   raise exceptions.from_grpc_error(exc) from exc                                 \u2502\r\n\u2502    75 \u2502                                                                                          \u2502\r\n\u2502    76 \u2502   return error_remapped_callable                                                         \u2502\r\n\u2502    77\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7744/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7744/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7743",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7743/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7743/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7743/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7743",
        "id": 1905385498,
        "node_id": "PR_kwDOIWuq585azimS",
        "number": 7743,
        "title": "Update node_to_metadata_dict",
        "user": {
            "login": "RobbieL-nlp",
            "id": 123534815,
            "node_id": "U_kgDOB1z93w",
            "avatar_url": "https://avatars.githubusercontent.com/u/123534815?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobbieL-nlp",
            "html_url": "https://github.com/RobbieL-nlp",
            "followers_url": "https://api.github.com/users/RobbieL-nlp/followers",
            "following_url": "https://api.github.com/users/RobbieL-nlp/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobbieL-nlp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobbieL-nlp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobbieL-nlp/subscriptions",
            "organizations_url": "https://api.github.com/users/RobbieL-nlp/orgs",
            "repos_url": "https://api.github.com/users/RobbieL-nlp/repos",
            "events_url": "https://api.github.com/users/RobbieL-nlp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobbieL-nlp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-20T16:51:37Z",
        "updated_at": "2023-09-27T17:00:36Z",
        "closed_at": "2023-09-20T17:50:56Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7743",
            "html_url": "https://github.com/run-llama/llama_index/pull/7743",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7743.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7743.patch",
            "merged_at": "2023-09-20T17:50:56Z"
        },
        "body": "change the dict-fy order inside the function to avoid using shallow copy for better compatibility and also potentially less computation.\r\n\r\nDescription\r\nBefore last patch It directly alters the dict object associated with the node object, and it would cause problems if re-use the same node object to index again. Last patch already fixed this by using copy method of the dict. However, if the dict were nested it might still be a problem, and since the dict conversion of node is called anyway, it may be a repetition to use copy here. Now change the order of the node.dict() so that the metadata is from the new dict object.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7743/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7743/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7742",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7742/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7742/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7742/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7742",
        "id": 1905372703,
        "node_id": "PR_kwDOIWuq585azf3W",
        "number": 7742,
        "title": "update node_to_metadata_dict",
        "user": {
            "login": "RobbieL-nlp",
            "id": 123534815,
            "node_id": "U_kgDOB1z93w",
            "avatar_url": "https://avatars.githubusercontent.com/u/123534815?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobbieL-nlp",
            "html_url": "https://github.com/RobbieL-nlp",
            "followers_url": "https://api.github.com/users/RobbieL-nlp/followers",
            "following_url": "https://api.github.com/users/RobbieL-nlp/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobbieL-nlp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobbieL-nlp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobbieL-nlp/subscriptions",
            "organizations_url": "https://api.github.com/users/RobbieL-nlp/orgs",
            "repos_url": "https://api.github.com/users/RobbieL-nlp/repos",
            "events_url": "https://api.github.com/users/RobbieL-nlp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobbieL-nlp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-20T16:42:10Z",
        "updated_at": "2023-09-20T16:45:15Z",
        "closed_at": "2023-09-20T16:45:03Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7742",
            "html_url": "https://github.com/run-llama/llama_index/pull/7742",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7742.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7742.patch",
            "merged_at": null
        },
        "body": "change the serialization order inside the function to avoid using shallow copy for better compatibility and also potentially less computation.\r\n\r\n# Description\r\n\r\nBefore last patch It directly alters the dict object associated with the node object, and it would cause problems if re-use the same node object to index again. Last patch already fixed this by using copy method of the dict. However, if the dict were nested it might still be a problem, and since the serialization of node is called anyway, it may be a repetition to use copy here. Now change the order of the serialization process so that the metadata is from the new serialized dict object.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7742/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7742/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7741",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7741/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7741/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7741/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7741",
        "id": 1904765137,
        "node_id": "PR_kwDOIWuq585axcGE",
        "number": 7741,
        "title": "Update postgres.py",
        "user": {
            "login": "bogdanalexandrutreica",
            "id": 78951696,
            "node_id": "MDQ6VXNlcjc4OTUxNjk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/78951696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bogdanalexandrutreica",
            "html_url": "https://github.com/bogdanalexandrutreica",
            "followers_url": "https://api.github.com/users/bogdanalexandrutreica/followers",
            "following_url": "https://api.github.com/users/bogdanalexandrutreica/following{/other_user}",
            "gists_url": "https://api.github.com/users/bogdanalexandrutreica/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bogdanalexandrutreica/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bogdanalexandrutreica/subscriptions",
            "organizations_url": "https://api.github.com/users/bogdanalexandrutreica/orgs",
            "repos_url": "https://api.github.com/users/bogdanalexandrutreica/repos",
            "events_url": "https://api.github.com/users/bogdanalexandrutreica/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bogdanalexandrutreica/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-20T11:15:17Z",
        "updated_at": "2023-09-20T19:12:36Z",
        "closed_at": "2023-09-20T19:12:36Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7741",
            "html_url": "https://github.com/run-llama/llama_index/pull/7741",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7741.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7741.patch",
            "merged_at": "2023-09-20T19:12:36Z"
        },
        "body": "Index value hardcoded to indexname\r\n\r\n# Description\r\n\r\nIndex value was hardcoded\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7741/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7741/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7740",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7740/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7740/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7740/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7740",
        "id": 1904745873,
        "node_id": "I_kwDOIWuq585xiB2R",
        "number": 7740,
        "title": "[Bug]: Hybrid Postgresql hardcoded \"text_search_tsv_idx\"",
        "user": {
            "login": "bogdanalexandrutreica",
            "id": 78951696,
            "node_id": "MDQ6VXNlcjc4OTUxNjk2",
            "avatar_url": "https://avatars.githubusercontent.com/u/78951696?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bogdanalexandrutreica",
            "html_url": "https://github.com/bogdanalexandrutreica",
            "followers_url": "https://api.github.com/users/bogdanalexandrutreica/followers",
            "following_url": "https://api.github.com/users/bogdanalexandrutreica/following{/other_user}",
            "gists_url": "https://api.github.com/users/bogdanalexandrutreica/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bogdanalexandrutreica/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bogdanalexandrutreica/subscriptions",
            "organizations_url": "https://api.github.com/users/bogdanalexandrutreica/orgs",
            "repos_url": "https://api.github.com/users/bogdanalexandrutreica/repos",
            "events_url": "https://api.github.com/users/bogdanalexandrutreica/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bogdanalexandrutreica/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T11:03:18Z",
        "updated_at": "2023-09-20T22:22:47Z",
        "closed_at": "2023-09-20T22:22:46Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nWhen I want to create a new table with embeddings I get this error\r\n\r\nError: CREATE INDEX text_search_tsv_idx ON data_test_folder_2 USING gin (text_search_tsv)\r\n\r\nbecause of the \"text_search_tsv_idx\" is hardcoded in the file /vector_store/postgres.py\r\n\r\nPyhton version: Python 3.10.12\n\n### Version\n\n0.8.29.post1\n\n### Steps to Reproduce\n\nJust try to create a new table with a different name using PGVectorStore + hybrid_search = True\r\n\r\nI solved the problem locally by using\r\n\r\nlike line 45 in postgres.py\r\n**indexname = \"idx_%s\"  % index_name  # dynamic index name**\r\n\r\n\r\nand on line 67\r\nIndex(\r\n            **indexname,**\r\n            model.text_search_tsv,  # type: ignore\r\n            postgresql_using=\"gin\",\r\n        )\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7740/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7740/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7739",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7739/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7739/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7739/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7739",
        "id": 1904644232,
        "node_id": "I_kwDOIWuq585xhpCI",
        "number": 7739,
        "title": "[Question]: How can I configure the number of retries while making queries to Llama Index?",
        "user": {
            "login": "prabhupant",
            "id": 19776278,
            "node_id": "MDQ6VXNlcjE5Nzc2Mjc4",
            "avatar_url": "https://avatars.githubusercontent.com/u/19776278?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/prabhupant",
            "html_url": "https://github.com/prabhupant",
            "followers_url": "https://api.github.com/users/prabhupant/followers",
            "following_url": "https://api.github.com/users/prabhupant/following{/other_user}",
            "gists_url": "https://api.github.com/users/prabhupant/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/prabhupant/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/prabhupant/subscriptions",
            "organizations_url": "https://api.github.com/users/prabhupant/orgs",
            "repos_url": "https://api.github.com/users/prabhupant/repos",
            "events_url": "https://api.github.com/users/prabhupant/events{/privacy}",
            "received_events_url": "https://api.github.com/users/prabhupant/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-20T10:05:02Z",
        "updated_at": "2023-09-21T17:00:29Z",
        "closed_at": "2023-09-21T17:00:29Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFor my use case, I want to be able to configure the number of retries that Llama Index makes while calling OpenAI. Currently, the number of retries for OpenAI calls are defined like this in the code\r\n\r\n```python\r\n@retry(\r\n    wait=wait_random_exponential(min=1, max=20),\r\n    stop=stop_all(stop_after_attempt(6), stop_after_delay(60)),\r\n)\r\ndef get_embeddings(\r\n    list_of_text: List[str], engine: Optional[str] = None, **kwargs: Any\r\n) -> List[List[float]]:\r\n```\r\n\r\nIs there a way I can configure the number of retries or the wait time between each call? \r\n\r\nI looked at `RetryQueryEngine` but this is more of a query engine that retries and uses a query response evaluator to improve the response.  And we can't use it without the evaluator.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7739/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7739/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7738",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7738/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7738/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7738/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7738",
        "id": 1904278257,
        "node_id": "PR_kwDOIWuq585avyJ_",
        "number": 7738,
        "title": "Add retrieval evals",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-20T06:47:41Z",
        "updated_at": "2023-09-21T15:28:50Z",
        "closed_at": "2023-09-21T15:28:49Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7738",
            "html_url": "https://github.com/run-llama/llama_index/pull/7738",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7738.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7738.patch",
            "merged_at": "2023-09-21T15:28:49Z"
        },
        "body": "# Description\r\n\r\nNot fully ready for review yet.\r\n\r\nWIP PR to add retrieval evaluation. Added a `BaseRetrievalEvaluator` class and an initial `RetrieverEvaluator` subclass, which will take in a retriever, and allows it to compute any set of metrics. \r\n\r\nAs a result also added RetrievalMetric abstractions `BaseRetrievalMetric` (subclasses hitrate, MRR). \r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7738/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7738/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7737",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7737/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7737/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7737/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7737",
        "id": 1903901377,
        "node_id": "PR_kwDOIWuq585augWK",
        "number": 7737,
        "title": "add gradient llms and example",
        "user": {
            "login": "lilwilsond2",
            "id": 13373810,
            "node_id": "MDQ6VXNlcjEzMzczODEw",
            "avatar_url": "https://avatars.githubusercontent.com/u/13373810?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/lilwilsond2",
            "html_url": "https://github.com/lilwilsond2",
            "followers_url": "https://api.github.com/users/lilwilsond2/followers",
            "following_url": "https://api.github.com/users/lilwilsond2/following{/other_user}",
            "gists_url": "https://api.github.com/users/lilwilsond2/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/lilwilsond2/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/lilwilsond2/subscriptions",
            "organizations_url": "https://api.github.com/users/lilwilsond2/orgs",
            "repos_url": "https://api.github.com/users/lilwilsond2/repos",
            "events_url": "https://api.github.com/users/lilwilsond2/events{/privacy}",
            "received_events_url": "https://api.github.com/users/lilwilsond2/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-20T00:42:18Z",
        "updated_at": "2023-09-20T00:44:52Z",
        "closed_at": "2023-09-20T00:42:57Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7737",
            "html_url": "https://github.com/run-llama/llama_index/pull/7737",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7737.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7737.patch",
            "merged_at": null
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7737/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7737/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7736",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7736/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7736/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7736/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7736",
        "id": 1903874189,
        "node_id": "I_kwDOIWuq585xetCN",
        "number": 7736,
        "title": "[Documentation]: overview of `examples/`",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-20T00:00:55Z",
        "updated_at": "2023-09-21T19:27:18Z",
        "closed_at": "2023-09-21T19:27:17Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nIt would be nice to make either a:\r\n\r\n- `README.md` within [`examples/`](https://github.com/jerryjliu/llama_index/tree/main/examples)\r\n- Page in the ReadTheDocs\r\n\r\nExplaining the various `examples/`, and what's significant/notable about each of them\n\n### Documenation Link\n\nhttps://github.com/jerryjliu/llama_index/tree/main/examples",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7736/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7736/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7735",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7735/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7735/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7735/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7735",
        "id": 1903832482,
        "node_id": "PR_kwDOIWuq585auRy0",
        "number": 7735,
        "title": "add a small gpt-3.5-turbo-instruct example to ReAct agent",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T22:56:55Z",
        "updated_at": "2023-09-19T23:54:06Z",
        "closed_at": "2023-09-19T23:54:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7735",
            "html_url": "https://github.com/run-llama/llama_index/pull/7735",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7735.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7735.patch",
            "merged_at": "2023-09-19T23:54:05Z"
        },
        "body": "This is an initial exploration towards adding gpt-3.5-turbo-instruct. From initial analysis doesn't seem like it work super well. ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7735/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7735/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7734",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7734/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7734/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7734/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7734",
        "id": 1903820109,
        "node_id": "PR_kwDOIWuq585auPJA",
        "number": 7734,
        "title": "Allow setting azure cognitive search dimensionality",
        "user": {
            "login": "ssainz",
            "id": 8454123,
            "node_id": "MDQ6VXNlcjg0NTQxMjM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8454123?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ssainz",
            "html_url": "https://github.com/ssainz",
            "followers_url": "https://api.github.com/users/ssainz/followers",
            "following_url": "https://api.github.com/users/ssainz/following{/other_user}",
            "gists_url": "https://api.github.com/users/ssainz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ssainz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ssainz/subscriptions",
            "organizations_url": "https://api.github.com/users/ssainz/orgs",
            "repos_url": "https://api.github.com/users/ssainz/repos",
            "events_url": "https://api.github.com/users/ssainz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ssainz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T22:39:44Z",
        "updated_at": "2023-09-21T20:39:14Z",
        "closed_at": "2023-09-21T20:39:14Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7734",
            "html_url": "https://github.com/run-llama/llama_index/pull/7734",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7734.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7734.patch",
            "merged_at": "2023-09-21T20:39:14Z"
        },
        "body": "# Description\r\n\r\nSometimes users want to use Cognitive Search with an embedding that has different dimensions of 1536. Allow user to set the embedding's dimension.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7734/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7734/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7733",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7733/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7733/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7733/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7733",
        "id": 1903525732,
        "node_id": "I_kwDOIWuq585xdX9k",
        "number": 7733,
        "title": "[Question]: Metadata exclusion",
        "user": {
            "login": "ddealwis09",
            "id": 115846150,
            "node_id": "U_kgDOBuesBg",
            "avatar_url": "https://avatars.githubusercontent.com/u/115846150?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ddealwis09",
            "html_url": "https://github.com/ddealwis09",
            "followers_url": "https://api.github.com/users/ddealwis09/followers",
            "following_url": "https://api.github.com/users/ddealwis09/following{/other_user}",
            "gists_url": "https://api.github.com/users/ddealwis09/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ddealwis09/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ddealwis09/subscriptions",
            "organizations_url": "https://api.github.com/users/ddealwis09/orgs",
            "repos_url": "https://api.github.com/users/ddealwis09/repos",
            "events_url": "https://api.github.com/users/ddealwis09/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ddealwis09/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-19T18:33:20Z",
        "updated_at": "2023-09-21T16:36:57Z",
        "closed_at": "2023-09-21T16:36:57Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nUsing SimpleDirectoryReader, is there a way to pass only certain metadata applied to the document to the nodes using the metadataextractors? i.e. I want some metadata on the document to only be used for metadata filtering in my app but do not want to include them on the nodes and embeddings. Thanks! ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7733/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7733/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7732",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7732/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7732/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7732/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7732",
        "id": 1903468909,
        "node_id": "I_kwDOIWuq585xdKFt",
        "number": 7732,
        "title": "[Documentation]: Update \ud83d\udcac\ud83e\udd16 How to Build a Chatbot",
        "user": {
            "login": "Javtor",
            "id": 8462127,
            "node_id": "MDQ6VXNlcjg0NjIxMjc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8462127?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/Javtor",
            "html_url": "https://github.com/Javtor",
            "followers_url": "https://api.github.com/users/Javtor/followers",
            "following_url": "https://api.github.com/users/Javtor/following{/other_user}",
            "gists_url": "https://api.github.com/users/Javtor/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/Javtor/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/Javtor/subscriptions",
            "organizations_url": "https://api.github.com/users/Javtor/orgs",
            "repos_url": "https://api.github.com/users/Javtor/repos",
            "events_url": "https://api.github.com/users/Javtor/events{/privacy}",
            "received_events_url": "https://api.github.com/users/Javtor/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T17:50:43Z",
        "updated_at": "2023-09-22T18:08:22Z",
        "closed_at": "2023-09-22T18:08:21Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nThe \ud83d\udcac\ud83e\udd16 How to Build a Chatbot end-to-end tutorial needs to be updated to use LlamaIndex's own agent implementation instead of LangChain's.\r\n\r\nChanges to be made:\r\n1. Replace all references to LangChain with LlamaIndex in the tutorial's introduction and throughout the document.\r\n2. Modify the code snippets in the tutorial that involve LangChain integration to use LlamaIndex's agent implementation instead.\r\n3. Update the corresponding notebook for the tutorial.\n\n### Documenation Link\n\nhttps://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/chatbots/building_a_chatbot.html",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7732/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7732/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7731",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7731/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7731/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7731/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7731",
        "id": 1903399382,
        "node_id": "PR_kwDOIWuq585asz0I",
        "number": 7731,
        "title": "async context generation add post processor",
        "user": {
            "login": "RobbieL-nlp",
            "id": 123534815,
            "node_id": "U_kgDOB1z93w",
            "avatar_url": "https://avatars.githubusercontent.com/u/123534815?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/RobbieL-nlp",
            "html_url": "https://github.com/RobbieL-nlp",
            "followers_url": "https://api.github.com/users/RobbieL-nlp/followers",
            "following_url": "https://api.github.com/users/RobbieL-nlp/following{/other_user}",
            "gists_url": "https://api.github.com/users/RobbieL-nlp/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/RobbieL-nlp/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/RobbieL-nlp/subscriptions",
            "organizations_url": "https://api.github.com/users/RobbieL-nlp/orgs",
            "repos_url": "https://api.github.com/users/RobbieL-nlp/repos",
            "events_url": "https://api.github.com/users/RobbieL-nlp/events{/privacy}",
            "received_events_url": "https://api.github.com/users/RobbieL-nlp/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-19T17:03:41Z",
        "updated_at": "2023-09-19T22:19:55Z",
        "closed_at": "2023-09-19T22:19:54Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7731",
            "html_url": "https://github.com/run-llama/llama_index/pull/7731",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7731.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7731.patch",
            "merged_at": "2023-09-19T22:19:54Z"
        },
        "body": "async context generation add post processor for context chat engine\r\n\r\n# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\nThe previous async context generation process does not include node post processing as the sync version does, now add the code to post process the nodes. \r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7731/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7731/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7730",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7730/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7730/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7730/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7730",
        "id": 1903376068,
        "node_id": "PR_kwDOIWuq585asuwH",
        "number": 7730,
        "title": "BeforeAfterContext_SentenceEmbeddingOptimizer",
        "user": {
            "login": "JainVidit12",
            "id": 123282527,
            "node_id": "U_kgDOB1kkXw",
            "avatar_url": "https://avatars.githubusercontent.com/u/123282527?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/JainVidit12",
            "html_url": "https://github.com/JainVidit12",
            "followers_url": "https://api.github.com/users/JainVidit12/followers",
            "following_url": "https://api.github.com/users/JainVidit12/following{/other_user}",
            "gists_url": "https://api.github.com/users/JainVidit12/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/JainVidit12/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/JainVidit12/subscriptions",
            "organizations_url": "https://api.github.com/users/JainVidit12/orgs",
            "repos_url": "https://api.github.com/users/JainVidit12/repos",
            "events_url": "https://api.github.com/users/JainVidit12/events{/privacy}",
            "received_events_url": "https://api.github.com/users/JainVidit12/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-19T16:48:31Z",
        "updated_at": "2023-09-22T00:09:44Z",
        "closed_at": "2023-09-22T00:09:44Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7730",
            "html_url": "https://github.com/run-llama/llama_index/pull/7730",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7730.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7730.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nAdding before/after context for issue #6842\r\n\r\n\r\nFixes # \r\n\r\nAdds before/after context, default value of 1 node each side\r\n\r\n## Type of Change\r\n\r\n\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n\r\n- [ ] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7730/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7730/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7729",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7729/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7729/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7729/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7729",
        "id": 1903313272,
        "node_id": "PR_kwDOIWuq585ashKG",
        "number": 7729,
        "title": "add support for gpt-3.5-turbo-instruct",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T16:07:54Z",
        "updated_at": "2023-09-19T16:32:48Z",
        "closed_at": "2023-09-19T16:32:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7729",
            "html_url": "https://github.com/run-llama/llama_index/pull/7729",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7729.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7729.patch",
            "merged_at": "2023-09-19T16:32:47Z"
        },
        "body": "# Description\r\n\r\nSimple PR to support gpt-3.5-turbo-instruct\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7723\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7729/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7729/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7728",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7728/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7728/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7728/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7728",
        "id": 1903269251,
        "node_id": "PR_kwDOIWuq585asXuO",
        "number": 7728,
        "title": "nit: add eval guide to docs",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T15:43:52Z",
        "updated_at": "2023-09-19T15:53:48Z",
        "closed_at": "2023-09-19T15:53:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7728",
            "html_url": "https://github.com/run-llama/llama_index/pull/7728",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7728.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7728.patch",
            "merged_at": "2023-09-19T15:53:47Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7728/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7728/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7727",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7727/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7727/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7727/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7727",
        "id": 1902871865,
        "node_id": "PR_kwDOIWuq585arA5-",
        "number": 7727,
        "title": "Add integration for Timescale Vector(Postgres)",
        "user": {
            "login": "cevian",
            "id": 112245,
            "node_id": "MDQ6VXNlcjExMjI0NQ==",
            "avatar_url": "https://avatars.githubusercontent.com/u/112245?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cevian",
            "html_url": "https://github.com/cevian",
            "followers_url": "https://api.github.com/users/cevian/followers",
            "following_url": "https://api.github.com/users/cevian/following{/other_user}",
            "gists_url": "https://api.github.com/users/cevian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cevian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cevian/subscriptions",
            "organizations_url": "https://api.github.com/users/cevian/orgs",
            "repos_url": "https://api.github.com/users/cevian/repos",
            "events_url": "https://api.github.com/users/cevian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cevian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-19T12:27:12Z",
        "updated_at": "2023-09-19T18:45:18Z",
        "closed_at": "2023-09-19T18:45:18Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7727",
            "html_url": "https://github.com/run-llama/llama_index/pull/7727",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7727.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7727.patch",
            "merged_at": "2023-09-19T18:45:18Z"
        },
        "body": "# Description\r\n\r\nThis commit adds a VectorStore for the Postgres-based vector database (`TimescaleVector`).\r\n\r\nTimescale Vector(https://www.timescale.com/ai) is PostgreSQL++ for AI applications. It enables you to efficiently store and query billions of vector embeddings in `PostgreSQL`:\r\n- Enhances `pgvector` with faster and more accurate similarity search on 1B+ vectors via DiskANN inspired indexing algorithm.\r\n- Enables fast time-based vector search via automatic time-based partitioning and indexing.\r\n- Provides a familiar SQL interface for querying vector embeddings and relational data.\r\n\r\nTimescale Vector scales with you from POC to production:\r\n- Simplifies operations by enabling you to store relational metadata, vector embeddings, and time-series data in a single database.\r\n- Benefits from rock-solid PostgreSQL foundation with enterprise-grade feature liked streaming backups and replication, high-availability and row-level security.\r\n- Enables a worry-free experience with enterprise-grade security and compliance.\r\n\r\nTimescale Vector is available on Timescale, the cloud PostgreSQL platform. (There is no self-hosted version at this time.) Llama index users get a 90-day free trial for Timescale Vector.\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7727/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7727/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7726",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7726/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7726/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7726/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7726",
        "id": 1902714952,
        "node_id": "I_kwDOIWuq585xaSBI",
        "number": 7726,
        "title": "[Bug]: TypeError: 'NoneType' object is not callable",
        "user": {
            "login": "tekntrash",
            "id": 102220086,
            "node_id": "U_kgDOBhfBNg",
            "avatar_url": "https://avatars.githubusercontent.com/u/102220086?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tekntrash",
            "html_url": "https://github.com/tekntrash",
            "followers_url": "https://api.github.com/users/tekntrash/followers",
            "following_url": "https://api.github.com/users/tekntrash/following{/other_user}",
            "gists_url": "https://api.github.com/users/tekntrash/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tekntrash/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tekntrash/subscriptions",
            "organizations_url": "https://api.github.com/users/tekntrash/orgs",
            "repos_url": "https://api.github.com/users/tekntrash/repos",
            "events_url": "https://api.github.com/users/tekntrash/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tekntrash/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-19T10:54:33Z",
        "updated_at": "2023-09-21T12:05:55Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nsqlalchemy.exc.ProgrammingError: (pymysql.err.ProgrammingError) (1064, 'You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near \\'This query will count the number of rows in the \"pictures\" table.\\n\\nNow, let m...\\' at line 3')\r\n[SQL: SELECT COUNT(*) FROM pictures;\r\n\r\nThis query will count the number of rows in the \"pictures\" table.\r\n\r\nNow, let me run the query and get the result...]\r\n(Background on this error at: https://sqlalche.me/e/20/f405)\r\nException ignored in: <function Llama.__del__ at 0x7fc890166700>\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/lib/python3.9/site-packages/llama_cpp/llama.py\", line 1611, in __del__\r\nTypeError: 'NoneType' object is not callable\r\n\n\n### Version\n\nlatest\n\n### Steps to Reproduce\n\nHere is the complete code\r\n\r\nfrom sqlalchemy import select, create_engine, MetaData, Table\r\nengine = create_engine('mariadb+pymysql://xxxxxx')\r\nmetadata = MetaData()\r\ntable = Table(\"pictures\", metadata, autoload_with=engine)\r\nstmt = select(table.columns)\r\nwith engine.connect() as connection:\r\n    results = connection.execute(stmt).fetchone()\r\n    print(results)\r\n    #print(results.keys())\r\n\r\nfrom llama_index import SQLDatabase\r\nsql_database = SQLDatabase(engine)\r\n\r\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\r\nfrom IPython.display import Markdown, display\r\n\r\nquery_engine = NLSQLTableQueryEngine(sql_database=sql_database,tables=[\"pictures\"],)\r\nquery_str = (\"how many pictures are there in the database?\")\r\n\r\nresponse = query_engine.query(query_str)\r\nsql_query = response.metadata[\"sql_query\"]\r\ndisplay(Markdown(f\"<b>{sql_query}</b>\"))\r\ndisplay(Markdown(f\"<b>{response}</b>\"))\r\n\r\nIt connects well and shows a line from the database, and even creates a correct SQL, but LLaMA is unable to show results\r\n\r\n\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7726/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7726/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7725",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7725/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7725/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7725/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7725",
        "id": 1902650663,
        "node_id": "I_kwDOIWuq585xaCUn",
        "number": 7725,
        "title": "[Question]: Compatibility issue with snowflake-sqlalchemy",
        "user": {
            "login": "arsentievalex",
            "id": 108185255,
            "node_id": "U_kgDOBnLGpw",
            "avatar_url": "https://avatars.githubusercontent.com/u/108185255?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/arsentievalex",
            "html_url": "https://github.com/arsentievalex",
            "followers_url": "https://api.github.com/users/arsentievalex/followers",
            "following_url": "https://api.github.com/users/arsentievalex/following{/other_user}",
            "gists_url": "https://api.github.com/users/arsentievalex/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/arsentievalex/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/arsentievalex/subscriptions",
            "organizations_url": "https://api.github.com/users/arsentievalex/orgs",
            "repos_url": "https://api.github.com/users/arsentievalex/repos",
            "events_url": "https://api.github.com/users/arsentievalex/events{/privacy}",
            "received_events_url": "https://api.github.com/users/arsentievalex/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-19T10:12:07Z",
        "updated_at": "2023-09-21T19:47:22Z",
        "closed_at": "2023-09-21T19:47:21Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHello, I'm running into what it seems to be a version compatibility issue between llama-index and snowflake-sqlalchemy. I'd like to use a DatabaseReader to read the data from Snowflake.\r\nWhen trying to deploy an app to the Streamlit cloud I get the following message:\r\n\r\n```\r\nllama-index 0.8.29 depends on sqlalchemy>=2.0.15\r\nsnowflake-sqlalchemy 1.5.0 depends on sqlalchemy<2.0.0 and >=1.4.0\r\n```\r\n\r\nIs there a way to introduce support for sqlalchemy <2? maybe an earlier version of llama-index?\r\n\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7725/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7725/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7724",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7724/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7724/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7724/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7724",
        "id": 1902566083,
        "node_id": "I_kwDOIWuq585xZtrD",
        "number": 7724,
        "title": "[Bug]: Changes between 0.7.23 and 0.7.24.post1 cause async streaming response to hang",
        "user": {
            "login": "alrooney",
            "id": 1009422,
            "node_id": "MDQ6VXNlcjEwMDk0MjI=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1009422?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/alrooney",
            "html_url": "https://github.com/alrooney",
            "followers_url": "https://api.github.com/users/alrooney/followers",
            "following_url": "https://api.github.com/users/alrooney/following{/other_user}",
            "gists_url": "https://api.github.com/users/alrooney/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/alrooney/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/alrooney/subscriptions",
            "organizations_url": "https://api.github.com/users/alrooney/orgs",
            "repos_url": "https://api.github.com/users/alrooney/repos",
            "events_url": "https://api.github.com/users/alrooney/events{/privacy}",
            "received_events_url": "https://api.github.com/users/alrooney/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-19T09:25:13Z",
        "updated_at": "2023-09-19T22:00:14Z",
        "closed_at": "2023-09-19T16:23:59Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nI have been using llama-index for a while in my project.  Thanks for an awesome library!  I tried upgrading yesterday to a newer version of the library and noticed that my querys were hanging.  After doing a binary search through releases I discovered that changes between 0.7.23 and 0.7.24.post1 were the issue.  Not sure what is causing it but here is a description of what I am using and a reproduction scenario:\n\n### Version\n\nany version after 0.7.24.post1 exhibits the issue\n\n### Steps to Reproduce\n\nI am using the QdrantVectorStore, the OpenAI llm and openai chat mode with the gpt-3.5-turbo model and I am streaming the response in a fastapi streaming response as follows:\r\n```\r\n@app.post(\"/collections/{collection_name}/query\")\r\nasync def query(collection_name: str,\r\n                query: Query,\r\n                temperature: float = 0.0,\r\n                model: str = \"gpt-3.5-turbo\"):\r\n    logging.info(f\"Query: {query}\")\r\n\r\n    vector_store = QdrantVectorStore(\r\n        client=QDRANT_CLIENT,\r\n        collection_name=collection_name,\r\n    )\r\n\r\n    token_counter = TokenCountingHandler()\r\n    callback_manager = CallbackManager([token_counter])\r\n\r\n    service_context = ServiceContext.from_defaults(callback_manager=callback_manager,\r\n                                                   llm=OpenAI(model=model,\r\n                                                              temperature=temperature))\r\n\r\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\r\n\r\n    index = VectorStoreIndex.from_documents(documents,\r\n                                            storage_context = storage_context,\r\n                                            service_context = service_context)\r\n\r\n    async def _generate_streaming_response(chat_engine: BaseChatEngine,\r\n                                           query: Query,\r\n                                           token_counter: TokenCountingHandler):\r\n        response = await chat_engine.astream_chat(message=query.query_str,\r\n                                                  chat_history=query.chat_history)\r\n    \r\n        for token in response.response_gen:\r\n            logging.debug(f\"Token: {token}\")\r\n            yield json.dumps(token)[1:-1]\r\n\r\n    chat_engine = index.as_chat_engine(chat_mode=\"openai\", verbose=True)\r\n    return StreamingResponse(\r\n            _generate_streaming_response(chat_engine=chat_engine,\r\n                                         query=query,\r\n                                         token_counter=token_counter)\r\n                                 )\r\n```\r\nIn 0.7.23 this streams a response but in 0.7.24.post1 (or any later version that I checked including 0.8.29) it hangs indefinitely and never prints any of the Tokens in the response.  Debug logs attached below.\n\n### Relevant Logs/Tracbacks\n\n```shell\n--------------------------------------- 0.7.23 debug output ------------------------------------\r\nINFO:root:Query: query_str='I am alec. Who is George Washington?' chat_history=[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"Always check the knowledge base before answering questions. If a question can't be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:45:59Z. \", additional_kwargs={})]\r\nDEBUG:httpcore.connection:close.started\r\nDEBUG:httpcore.connection:close.complete\r\nDEBUG:httpcore.connection:connect_tcp.started host='12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io' port=6333 local_address=None timeout=5.0 socket_options=None\r\nDEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x13547f2d0>\r\nDEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x134fdef00> server_hostname='12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io' timeout=5.0\r\nDEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x13547ec10>\r\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:send_request_headers.complete\r\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:send_request_body.complete\r\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Sep 2023 07:46:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers')])\r\nINFO:httpx:HTTP Request: GET https://12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io:6333/collections/4f7c021f-c299-4440-b77a-b15e69a93de8 \"HTTP/1.1 200 OK\"\r\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:receive_response_body.complete\r\nDEBUG:httpcore.http11:response_closed.started\r\nDEBUG:httpcore.http11:response_closed.complete\r\nDEBUG:asyncio:Using selector: KqueueSelector\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Always check the knowledge base before answering questions. If a question can\\'t be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:45:59Z. \"}, {\"role\": \"user\", \"content\": \"I am alec. Who is George Washington?\"}], \"stream\": true, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null, \"functions\": [{\"name\": \"query_engine_tool\", \"description\": \"Useful for running a natural language query\\\\nagainst a knowledge base and get back a natural language response.\\\\n\", \"parameters\": {\"title\": \"DefaultToolFnSchema\", \"description\": \"Default tool function Schema.\", \"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}}], \"function_call\": \"auto\"}' message='Post details'\r\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12 request_id=6db902d3d5052d128b46f99b9364f1cc response_code=200\r\n=== Calling Function ===\r\nCalling function: query_engine_tool with args: {\r\n  \"input\": \"Who is George Washington?\"\r\n}\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/embeddings\r\nDEBUG:openai:api_version=None data='{\"input\": [\"Who is George Washington?\"], \"model\": \"text-embedding-ada-002\", \"encoding_format\": \"base64\"}' message='Post details'\r\nDEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\r\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443\r\nDEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/embeddings HTTP/1.1\" 200 None\r\nDEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=79 request_id=6d24413f8425c5ecad833b90b45c1b76 response_code=200\r\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_headers.complete\r\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_body.complete\r\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Sep 2023 07:46:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers')])\r\nINFO:httpx:HTTP Request: POST https://12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io:6333/collections/4f7c021f-c299-4440-b77a-b15e69a93de8/points/search \"HTTP/1.1 200 OK\"\r\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_body.complete\r\nDEBUG:httpcore.http11:response_closed.started\r\nDEBUG:httpcore.http11:response_closed.complete\r\nDEBUG:llama_index.vector_stores.qdrant:> Top 2 nodes:\r\nDEBUG:llama_index.indices.utils:> Top 2 nodes:\r\n> [Node c3d3d254-cea6-41ab-81a1-de77bf7d20e4] [Similarity score:             0.818814] George Washington was the first President of the United States, serving from 1789 to 1797. He pla...\r\n> [Node 22884950-dea9-4218-97e8-5ae25b69267d] [Similarity score:             0.788889] Shakespeare, also known as William Shakespeare, was an English playwright, poet, and actor. He is...\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Context information is below.\\\\n---------------------\\\\nchannel: C1234567890\\\\n\\\\n\\\\n\\\\nGeorge Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \\\\\"Father of His Country.\\\\\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history. Richard Nixon was the 37th President of the United States, serving from 1969 to 1974. He is known for his involvement in the Watergate scandal, which ultimately led to his resignation from office. Nixon was also known for his foreign policy initiatives, including the normalization of relations with China.\\\\n\\\\nHamnet is one of the three children of William Shakespeare and Anne Hathaway.\\\\n\\\\nchannel: C1234567890\\\\n\\\\nShakespeare, also known as William Shakespeare, was an English playwright, poet, and actor. He is widely regarded as the greatest writer in the English language and the world\\'s pre-eminent dramatist.\\\\n\\\\nFDR typically refers to Franklin D. Roosevelt, who was the 32nd President of the United States. He served from 1933 to 1945 and is known for his leadership during the Great Depression and World War II.\\\\n\\\\nRichard Nixon was the 37th President of the United States, serving from 1969 to 1974. He is known for his involvement in the Watergate scandal, which ultimately led to his resignation from office. Nixon was also known for his foreign policy initiatives, including the normalization of relations with China.\\\\nHamnet is one of the three children of William Shakespeare and Anne Hathaway.\\\\n---------------------\\\\nGiven the context information and not prior knowledge, answer the question: Who is George Washington?\\\\n\"}], \"stream\": false, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null}' message='Post details'\r\nDEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\r\nDEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3381 request_id=a5799aebf0b1e03d692d1abc5ffd87fb response_code=200\r\nDEBUG:llama_index.llm_predictor.base:George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \"Father of His Country.\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\r\nGot output: George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \"Father of His Country.\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\r\n========================\r\nDEBUG:asyncio:Using selector: KqueueSelector\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Always check the knowledge base before answering questions. If a question can\\'t be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:45:59Z. \"}, {\"role\": \"user\", \"content\": \"I am alec. Who is George Washington?\"}, {\"role\": \"assistant\", \"content\": \"\", \"function_call\": {\"name\": \"query_engine_tool\", \"arguments\": \"{\\\\n  \\\\\"input\\\\\": \\\\\"Who is George Washington?\\\\\"\\\\n}\"}}, {\"role\": \"function\", \"content\": \"George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \\\\\"Father of His Country.\\\\\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\", \"name\": \"query_engine_tool\"}], \"stream\": true, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null, \"functions\": [{\"name\": \"query_engine_tool\", \"description\": \"Useful for running a natural language query\\\\nagainst a knowledge base and get back a natural language response.\\\\n\", \"parameters\": {\"title\": \"DefaultToolFnSchema\", \"description\": \"Default tool function Schema.\", \"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}}]}' message='Post details'\r\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=13 request_id=a7249bfba8076ccdc93f8d9ef50cf9fa response_code=200\r\nINFO:     127.0.0.1:61930 - \"POST /collections/4f7c021f-c299-4440-b77a-b15e69a93de8/query?model=gpt-3.5-turbo&temperature=0.0 HTTP/1.1\" 200 OK\r\nDEBUG:root:Token:\r\nDEBUG:root:Token: George\r\nDEBUG:root:Token:  Washington\r\nDEBUG:root:Token:  was\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  first\r\nDEBUG:root:Token:  President\r\nDEBUG:root:Token:  of\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  United\r\nDEBUG:root:Token:  States\r\nDEBUG:root:Token: ,\r\nDEBUG:root:Token:  serving\r\nDEBUG:root:Token:  from\r\nDEBUG:root:Token:\r\nDEBUG:root:Token: 178\r\nDEBUG:root:Token: 9\r\nDEBUG:root:Token:  to\r\nDEBUG:root:Token:\r\nDEBUG:root:Token: 179\r\nDEBUG:root:Token: 7\r\nDEBUG:root:Token: .\r\nDEBUG:root:Token:  He\r\nDEBUG:root:Token:  played\r\nDEBUG:root:Token:  a\r\nDEBUG:root:Token:  crucial\r\nDEBUG:root:Token:  role\r\nDEBUG:root:Token:  in\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  American\r\nDEBUG:root:Token:  Revolutionary\r\nDEBUG:root:Token:  War\r\nDEBUG:root:Token:  and\r\nDEBUG:root:Token:  is\r\nDEBUG:root:Token:  often\r\nDEBUG:root:Token:  referred\r\nDEBUG:root:Token:  to\r\nDEBUG:root:Token:  as\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  \"\r\nDEBUG:root:Token: Father\r\nDEBUG:root:Token:  of\r\nDEBUG:root:Token:  His\r\nDEBUG:root:Token:  Country\r\nDEBUG:root:Token: .\"\r\nDEBUG:root:Token:  Washington\r\nDEBUG:root:Token:  was\r\nDEBUG:root:Token:  known\r\nDEBUG:root:Token:  for\r\nDEBUG:root:Token:  his\r\nDEBUG:root:Token:  leadership\r\nDEBUG:root:Token: ,\r\nDEBUG:root:Token:  integrity\r\nDEBUG:root:Token: ,\r\nDEBUG:root:Token:  and\r\nDEBUG:root:Token:  commitment\r\nDEBUG:root:Token:  to\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  principles\r\nDEBUG:root:Token:  of\r\nDEBUG:root:Token:  democracy\r\nDEBUG:root:Token: .\r\nDEBUG:root:Token:  He\r\nDEBUG:root:Token:  is\r\nDEBUG:root:Token:  widely\r\nDEBUG:root:Token:  regarded\r\nDEBUG:root:Token:  as\r\nDEBUG:root:Token:  one\r\nDEBUG:root:Token:  of\r\nDEBUG:root:Token:  the\r\nDEBUG:root:Token:  most\r\nDEBUG:root:Token:  influential\r\nDEBUG:root:Token:  figures\r\nDEBUG:root:Token:  in\r\nDEBUG:root:Token:  American\r\nDEBUG:root:Token:  history\r\nDEBUG:root:Token: .\r\nDEBUG:root:Token:\r\n\r\n--------------------------------------- 0.7.24.post1 debug output -----------------------------\r\nINFO:root:Query: query_str='I am alec. Who is George Washington?' chat_history=[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content=\"Always check the knowledge base before answering questions. If a question can't be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:50:33Z. \", additional_kwargs={})]\r\nDEBUG:httpcore.connection:connect_tcp.started host='12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io' port=6333 local_address=None timeout=5.0 socket_options=None\r\nDEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x13579c250>\r\nDEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x13559f380> server_hostname='12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io' timeout=5.0\r\nDEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1356d4f90>\r\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:send_request_headers.complete\r\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:send_request_body.complete\r\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Sep 2023 07:50:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers')])\r\nINFO:httpx:HTTP Request: GET https://12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io:6333/collections/4f7c021f-c299-4440-b77a-b15e69a93de8 \"HTTP/1.1 200 OK\"\r\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'GET']>\r\nDEBUG:httpcore.http11:receive_response_body.complete\r\nDEBUG:httpcore.http11:response_closed.started\r\nDEBUG:httpcore.http11:response_closed.complete\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Always check the knowledge base before answering questions. If a question can't be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:50:33Z. \"}, {\"role\": \"user\", \"content\": \"I am alec. Who is George Washington?\"}], \"stream\": true, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null, \"functions\": [{\"name\": \"query_engine_tool\", \"description\": \"Useful for running a natural language query\\\\nagainst a knowledge base and get back a natural language response.\\\\n\", \"parameters\": {\"title\": \"DefaultToolFnSchema\", \"description\": \"Default tool function Schema.\", \"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}}], \"function_call\": \"auto\"}' message='Post details'\r\nINFO:     127.0.0.1:62041 - \"POST /collections/4f7c021f-c299-4440-b77a-b15e69a93de8/query?model=gpt-3.5-turbo&temperature=0.0 HTTP/1.1\" 200 OK\r\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9 request_id=2dc0127afd53fc239cc9405c50ff548d response_code=200\r\n=== Calling Function ===\r\nCalling function: query_engine_tool with args: {\r\n  \"input\": \"Who is George Washington?\"\r\n}\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/embeddings\r\nDEBUG:openai:api_version=None data='{\"input\": [\"Who is George Washington?\"], \"model\": \"text-embedding-ada-002\", \"encoding_format\": \"base64\"}' message='Post details'\r\nDEBUG:urllib3.util.retry:Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\r\nDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.openai.com:443\r\nDEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/embeddings HTTP/1.1\" 200 None\r\nDEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=152 request_id=5696203f7e33bc3d553c6688d78f0e28 response_code=200\r\nDEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_headers.complete\r\nDEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:send_request_body.complete\r\nDEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 19 Sep 2023 07:50:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers')])\r\nINFO:httpx:HTTP Request: POST https://12345678-1234-1234-1234-123456789012.us-east-1-0.aws.cloud.qdrant.io:6333/collections/4f7c021f-c299-4440-b77a-b15e69a93de8/points/search \"HTTP/1.1 200 OK\"\r\nDEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\r\nDEBUG:httpcore.http11:receive_response_body.complete\r\nDEBUG:httpcore.http11:response_closed.started\r\nDEBUG:httpcore.http11:response_closed.complete\r\nDEBUG:llama_index.vector_stores.qdrant:> Top 2 nodes:\r\nDEBUG:llama_index.indices.utils:> Top 2 nodes:\r\n> [Node c3d3d254-cea6-41ab-81a1-de77bf7d20e4] [Similarity score:             0.818809] George Washington was the first President of the United States, serving from 1789 to 1797. He pla...\r\n> [Node 22884950-dea9-4218-97e8-5ae25b69267d] [Similarity score:             0.788878] Shakespeare, also known as William Shakespeare, was an English playwright, poet, and actor. He is...\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Context information is below.\\\\n---------------------\\\\nchannel: C1234567890\\\\n\\\\n\\\\n\\\\nGeorge Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \\\\\"Father of His Country.\\\\\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history. Richard Nixon was the 37th President of the United States, serving from 1969 to 1974. He is known for his involvement in the Watergate scandal, which ultimately led to his resignation from office. Nixon was also known for his foreign policy initiatives, including the normalization of relations with China.\\\\n\\\\nHamnet is one of the three children of William Shakespeare and Anne Hathaway.\\\\n\\\\nchannel: C1234567890\\\\n\\\\nShakespeare, also known as William Shakespeare, was an English playwright, poet, and actor. He is widely regarded as the greatest writer in the English language and the world\\'s pre-eminent dramatist.\\\\n\\\\nFDR typically refers to Franklin D. Roosevelt, who was the 32nd President of the United States. He served from 1933 to 1945 and is known for his leadership during the Great Depression and World War II.\\\\n\\\\nRichard Nixon was the 37th President of the United States, serving from 1969 to 1974. He is known for his involvement in the Watergate scandal, which ultimately led to his resignation from office. Nixon was also known for his foreign policy initiatives, including the normalization of relations with China.\\\\nHamnet is one of the three children of William Shakespeare and Anne Hathaway.\\\\n---------------------\\\\nGiven the context information and not prior knowledge, answer the question: Who is George Washington?\\\\n\"}], \"stream\": false, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null}' message='Post details'\r\nDEBUG:urllib3.connectionpool:https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\r\nDEBUG:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3585 request_id=cad5954c2fc519cf458f64538f83403b response_code=200\r\nDEBUG:llama_index.llm_predictor.base:George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \"Father of His Country.\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\r\nGot output: George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \"Father of His Country.\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\r\n========================\r\nDEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\r\nDEBUG:openai:api_version=None data='{\"messages\": [{\"role\": \"system\", \"content\": \"Always check the knowledge base before answering questions. If a question can\\'t be answered from the knowledge base, answer it using your general knowledge but tell the user you are answering based on general knowledge and not the knowledge base. The current time and date is: 2023-09-19T07:50:33Z. \"}, {\"role\": \"user\", \"content\": \"I am alec. Who is George Washington?\"}, {\"role\": \"assistant\", \"content\": \"\", \"function_call\": {\"name\": \"query_engine_tool\", \"arguments\": \"{\\\\n  \\\\\"input\\\\\": \\\\\"Who is George Washington?\\\\\"\\\\n}\"}}, {\"role\": \"function\", \"content\": \"George Washington was the first President of the United States, serving from 1789 to 1797. He played a crucial role in the American Revolutionary War and is often referred to as the \\\\\"Father of His Country.\\\\\" Washington was known for his leadership, integrity, and commitment to the principles of democracy. He is widely regarded as one of the most influential figures in American history.\", \"name\": \"query_engine_tool\"}], \"stream\": true, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.0, \"max_tokens\": null, \"functions\": [{\"name\": \"query_engine_tool\", \"description\": \"Useful for running a natural language query\\\\nagainst a knowledge base and get back a natural language response.\\\\n\", \"parameters\": {\"title\": \"DefaultToolFnSchema\", \"description\": \"Default tool function Schema.\", \"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}}], \"function_call\": \"auto\"}' message='Post details'\r\nINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12 request_id=a7ebc8fd090d17cf5d34a72f86183ff5 response_code=200\r\n===> Just hangs here and never prints out Tokens or returns FastAPI call <===\n```\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7724/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7724/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7723",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7723/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7723/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7723/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7723",
        "id": 1902456857,
        "node_id": "I_kwDOIWuq585xZTAZ",
        "number": 7723,
        "title": "[Feature Request]: Support gpt-3.5-turbo-instruct",
        "user": {
            "login": "marco-ve",
            "id": 6614947,
            "node_id": "MDQ6VXNlcjY2MTQ5NDc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/6614947?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/marco-ve",
            "html_url": "https://github.com/marco-ve",
            "followers_url": "https://api.github.com/users/marco-ve/followers",
            "following_url": "https://api.github.com/users/marco-ve/following{/other_user}",
            "gists_url": "https://api.github.com/users/marco-ve/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/marco-ve/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/marco-ve/subscriptions",
            "organizations_url": "https://api.github.com/users/marco-ve/orgs",
            "repos_url": "https://api.github.com/users/marco-ve/repos",
            "events_url": "https://api.github.com/users/marco-ve/events{/privacy}",
            "received_events_url": "https://api.github.com/users/marco-ve/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-19T08:20:58Z",
        "updated_at": "2023-09-19T16:32:48Z",
        "closed_at": "2023-09-19T16:32:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nopenai.py seems to be unaware of the newly released gpt-3.5.-turbo-instruct model and will throw a ValueError.\n\n### Reason\n\nI can't see any reason why this shouldn't just work. What's the idea behind doing a hard check on a manually kept list of OpenAI models? Just forward the string to OpenAI and catch their error to make the interface more dynamic.\n\n### Value of Feature\n\nSupport all valid models offered by OpenAI.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7723/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7723/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7722",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7722/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7722/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7722/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7722",
        "id": 1902430354,
        "node_id": "PR_kwDOIWuq585apiWh",
        "number": 7722,
        "title": "add eval tutorial (low-level) ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-19T08:04:08Z",
        "updated_at": "2023-09-19T15:25:47Z",
        "closed_at": "2023-09-19T15:25:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7722",
            "html_url": "https://github.com/run-llama/llama_index/pull/7722",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7722.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7722.patch",
            "merged_at": "2023-09-19T15:25:46Z"
        },
        "body": "shows how to do auto dataset generation and response synthesis",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7722/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7722/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7721",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7721/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7721/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7721/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7721",
        "id": 1902418238,
        "node_id": "I_kwDOIWuq585xZJk-",
        "number": 7721,
        "title": "[Question]: Does OpenAIAgent support the use of customllm",
        "user": {
            "login": "123zzw",
            "id": 65516153,
            "node_id": "MDQ6VXNlcjY1NTE2MTUz",
            "avatar_url": "https://avatars.githubusercontent.com/u/65516153?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/123zzw",
            "html_url": "https://github.com/123zzw",
            "followers_url": "https://api.github.com/users/123zzw/followers",
            "following_url": "https://api.github.com/users/123zzw/following{/other_user}",
            "gists_url": "https://api.github.com/users/123zzw/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/123zzw/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/123zzw/subscriptions",
            "organizations_url": "https://api.github.com/users/123zzw/orgs",
            "repos_url": "https://api.github.com/users/123zzw/repos",
            "events_url": "https://api.github.com/users/123zzw/events{/privacy}",
            "received_events_url": "https://api.github.com/users/123zzw/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-19T07:56:23Z",
        "updated_at": "2023-09-21T01:37:45Z",
        "closed_at": "2023-09-21T01:37:44Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nHello, the performance of OpenAIAgent is very impressive. I recently encountered a problem where when I use a local model, it seems that OpenAIAgent is not working and can only treat the local model as a conversation assistant.So I would like to ask if OpenAIAgent does not support loading local models, that is, openai must be used instead of customLLM. \r\nWhat should I do if I want to use customllm?",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7721/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7721/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7720",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7720/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7720/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7720/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7720",
        "id": 1902164345,
        "node_id": "I_kwDOIWuq585xYLl5",
        "number": 7720,
        "title": "[Bug]: Error when running MetadataExtractionSEC.ipynb",
        "user": {
            "login": "huangjia2019",
            "id": 48795276,
            "node_id": "MDQ6VXNlcjQ4Nzk1Mjc2",
            "avatar_url": "https://avatars.githubusercontent.com/u/48795276?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/huangjia2019",
            "html_url": "https://github.com/huangjia2019",
            "followers_url": "https://api.github.com/users/huangjia2019/followers",
            "following_url": "https://api.github.com/users/huangjia2019/following{/other_user}",
            "gists_url": "https://api.github.com/users/huangjia2019/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/huangjia2019/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/huangjia2019/subscriptions",
            "organizations_url": "https://api.github.com/users/huangjia2019/orgs",
            "repos_url": "https://api.github.com/users/huangjia2019/repos",
            "events_url": "https://api.github.com/users/huangjia2019/events{/privacy}",
            "received_events_url": "https://api.github.com/users/huangjia2019/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-19T04:00:52Z",
        "updated_at": "2023-09-21T11:37:39Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nllama_index\\docs\\examples\\metadata_extraction\\MetadataExtractionSEC.ipynb -- this is a demo program, my llama-index    version is    0.8.29.post1\r\n\r\nhitting error --- \r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\Users\\MetaData\\With_Metadata.py\", line 123, in <module>\r\n    response = final_engine.query(\r\n               ^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\indices\\query\\base.py\", line 23, in query\r\n    response = self._query(str_or_query_bundle)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\query_engine\\sub_question_query_engine.py\", line 126, in _query\r\n    sub_questions = self._question_gen.generate(self._metadatas, query_bundle)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\question_gen\\llm_generators.py\", line 56, in generate\r\n    prediction = self._llm_predictor.predict(\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\llm_predictor\\base.py\", line 140, in predict\r\n    messages = prompt.format_messages(llm=self._llm, **prompt_args)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\prompts\\base.py\", line 105, in format_messages\r\n    prompt = self.format(**kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\prompts\\base.py\", line 97, in format\r\n    prompt = self.output_parser.format(prompt)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"d:\\Venv\\llamaindex_venv\\Lib\\site-packages\\llama_index\\question_gen\\output_parser.py\", line 17, in format\r\n    raise NotImplementedError()\r\nNotImplementedError\r\n\r\n### Version\r\n\r\n0.8.29.post1\r\n\r\n### Steps to Reproduce\r\n\r\nJust run\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n```shell\r\nrefer to the main track\r\n```\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7720/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7720/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7719",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7719/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7719/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7719/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7719",
        "id": 1902056189,
        "node_id": "PR_kwDOIWuq585aoSKV",
        "number": 7719,
        "title": "Add LongContextReorder",
        "user": {
            "login": "netoferraz",
            "id": 8862797,
            "node_id": "MDQ6VXNlcjg4NjI3OTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8862797?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/netoferraz",
            "html_url": "https://github.com/netoferraz",
            "followers_url": "https://api.github.com/users/netoferraz/followers",
            "following_url": "https://api.github.com/users/netoferraz/following{/other_user}",
            "gists_url": "https://api.github.com/users/netoferraz/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/netoferraz/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/netoferraz/subscriptions",
            "organizations_url": "https://api.github.com/users/netoferraz/orgs",
            "repos_url": "https://api.github.com/users/netoferraz/repos",
            "events_url": "https://api.github.com/users/netoferraz/events{/privacy}",
            "received_events_url": "https://api.github.com/users/netoferraz/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-19T01:44:16Z",
        "updated_at": "2023-09-20T19:32:48Z",
        "closed_at": "2023-09-20T19:12:50Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7719",
            "html_url": "https://github.com/run-llama/llama_index/pull/7719",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7719.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7719.patch",
            "merged_at": "2023-09-20T19:12:50Z"
        },
        "body": "# Description\r\n\r\nA recent study (https://arxiv.org/abs/2307.03172) found that LLMs that receive long context struggle to access significant details found in the center of extended contexts, and the performance is often highest when relevant information occurs at the beginning or end of the input context.\r\n\r\nTo achieve that, our proposal includes a new `PostProcessorNode` named `LongContextReorder` that implements the logic described above.\r\n\r\n- [X] New feature (non-breaking change which adds functionality)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nWe created a unit test passing checking if the better scores arelocated at the beginning and ends of a list of  `NodeWithScore`.\r\n\r\n- [X] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [X] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [X] I have performed a self-review of my own code\r\n- [X] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [X] My changes generate no new warnings\r\n- [X] I have added tests that prove my fix is effective or that my feature works\r\n- [X] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7719/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7719/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7718",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7718/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7718/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7718/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7718",
        "id": 1901798537,
        "node_id": "PR_kwDOIWuq585anY-_",
        "number": 7718,
        "title": "[DRAFT] Addding HTML Splitter",
        "user": {
            "login": "ajhofmann",
            "id": 10040285,
            "node_id": "MDQ6VXNlcjEwMDQwMjg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10040285?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajhofmann",
            "html_url": "https://github.com/ajhofmann",
            "followers_url": "https://api.github.com/users/ajhofmann/followers",
            "following_url": "https://api.github.com/users/ajhofmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajhofmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajhofmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajhofmann/subscriptions",
            "organizations_url": "https://api.github.com/users/ajhofmann/orgs",
            "repos_url": "https://api.github.com/users/ajhofmann/repos",
            "events_url": "https://api.github.com/users/ajhofmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajhofmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T21:46:47Z",
        "updated_at": "2023-09-28T18:29:51Z",
        "closed_at": "2023-09-28T18:29:51Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7718",
            "html_url": "https://github.com/run-llama/llama_index/pull/7718",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7718.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7718.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\n- Introduce a HTMLSplitter for splitting HTML documents based on tags\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7718/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7718/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7717",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7717/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7717/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7717/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7717",
        "id": 1901796188,
        "node_id": "PR_kwDOIWuq585anYd8",
        "number": 7717,
        "title": "SPARQL Graph Store",
        "user": {
            "login": "danja",
            "id": 2303,
            "node_id": "MDQ6VXNlcjIzMDM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/2303?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/danja",
            "html_url": "https://github.com/danja",
            "followers_url": "https://api.github.com/users/danja/followers",
            "following_url": "https://api.github.com/users/danja/following{/other_user}",
            "gists_url": "https://api.github.com/users/danja/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/danja/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/danja/subscriptions",
            "organizations_url": "https://api.github.com/users/danja/orgs",
            "repos_url": "https://api.github.com/users/danja/repos",
            "events_url": "https://api.github.com/users/danja/events{/privacy}",
            "received_events_url": "https://api.github.com/users/danja/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-18T21:44:33Z",
        "updated_at": "2023-09-28T15:27:17Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7717",
            "html_url": "https://github.com/run-llama/llama_index/pull/7717",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7717.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7717.patch",
            "merged_at": null
        },
        "body": "# Description\r\n\r\nMinimal implementation of a graph_store using a SPARQL server as storage.\r\n\r\n## Type of Change\r\n\r\n* New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n`graph-rag-sparql-mini.py` does an end-to-end test which works.\r\n\r\n`graph-rag-sparql-mini.ipynb` has done too, but I keep breaking my Jupyter install\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7717/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7717/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7716",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7716/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7716/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7716/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7716",
        "id": 1901620703,
        "node_id": "PR_kwDOIWuq585amx-3",
        "number": 7716,
        "title": "[version] bump to 0.8.29.post1",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T19:39:10Z",
        "updated_at": "2023-09-18T19:42:28Z",
        "closed_at": "2023-09-18T19:42:27Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7716",
            "html_url": "https://github.com/run-llama/llama_index/pull/7716",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7716.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7716.patch",
            "merged_at": "2023-09-18T19:42:27Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7716/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7716/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7715",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7715/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7715/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7715/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7715",
        "id": 1901606330,
        "node_id": "I_kwDOIWuq585xWDW6",
        "number": 7715,
        "title": "[Documentation]: ChatGPT LlamaIndex Tweet broken link",
        "user": {
            "login": "jamesbraza",
            "id": 8990777,
            "node_id": "MDQ6VXNlcjg5OTA3Nzc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/8990777?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jamesbraza",
            "html_url": "https://github.com/jamesbraza",
            "followers_url": "https://api.github.com/users/jamesbraza/followers",
            "following_url": "https://api.github.com/users/jamesbraza/following{/other_user}",
            "gists_url": "https://api.github.com/users/jamesbraza/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jamesbraza/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jamesbraza/subscriptions",
            "organizations_url": "https://api.github.com/users/jamesbraza/orgs",
            "repos_url": "https://api.github.com/users/jamesbraza/repos",
            "events_url": "https://api.github.com/users/jamesbraza/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jamesbraza/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318866,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/documentation",
                "name": "documentation",
                "color": "0075ca",
                "default": true,
                "description": "Improvements or additions to documentation"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T19:29:00Z",
        "updated_at": "2023-09-21T20:16:23Z",
        "closed_at": "2023-09-21T20:16:23Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "body": "### Documentation Issue Description\n\nThe Tweet thread [from here](https://gpt-index.readthedocs.io/en/stable/community/app_showcase.html#chatgpt-llamaindex): https://twitter.com/s_jobs6/status/1618346125697875968?s=20&t=RJhQu2mD0-zZNGfq65xodA\r\n\r\nThe link is broken, fyi\n\n### Documenation Link\n\nhttps://gpt-index.readthedocs.io/en/stable/community/app_showcase.html#chatgpt-llamaindex",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7715/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7715/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7714",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7714/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7714/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7714/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7714",
        "id": 1901552301,
        "node_id": "PR_kwDOIWuq585amjG4",
        "number": 7714,
        "title": "fix and bump langchain dependencies",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T18:51:44Z",
        "updated_at": "2023-09-18T19:36:48Z",
        "closed_at": "2023-09-18T19:36:47Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7714",
            "html_url": "https://github.com/run-llama/llama_index/pull/7714",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7714.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7714.patch",
            "merged_at": "2023-09-18T19:36:47Z"
        },
        "body": "# Description\r\n\r\nLangchain moved their base class for embeddings\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7713\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7714/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7714/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7713",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7713/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7713/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7713/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7713",
        "id": 1901293225,
        "node_id": "I_kwDOIWuq585xU26p",
        "number": 7713,
        "title": "[Bug]: langchain.embeddings.base not found",
        "user": {
            "login": "wingsuiting",
            "id": 11816832,
            "node_id": "MDQ6VXNlcjExODE2ODMy",
            "avatar_url": "https://avatars.githubusercontent.com/u/11816832?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/wingsuiting",
            "html_url": "https://github.com/wingsuiting",
            "followers_url": "https://api.github.com/users/wingsuiting/followers",
            "following_url": "https://api.github.com/users/wingsuiting/following{/other_user}",
            "gists_url": "https://api.github.com/users/wingsuiting/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/wingsuiting/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/wingsuiting/subscriptions",
            "organizations_url": "https://api.github.com/users/wingsuiting/orgs",
            "repos_url": "https://api.github.com/users/wingsuiting/repos",
            "events_url": "https://api.github.com/users/wingsuiting/events{/privacy}",
            "received_events_url": "https://api.github.com/users/wingsuiting/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-18T16:16:34Z",
        "updated_at": "2023-09-18T22:36:43Z",
        "closed_at": "2023-09-18T19:36:48Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-32-2911fa256dd2>](https://localhost:8080/#) in <cell line: 2>()\r\n      1 get_ipython().system('pip install llama-index')\r\n----> 2 import llama_index\r\n\r\n4 frames\r\n[/usr/local/lib/python3.10/dist-packages/llama_index/bridge/langchain.py](https://localhost:8080/#) in <module>\r\n     18 \r\n     19 # embeddings\r\n---> 20 from langchain.embeddings.base import Embeddings\r\n     21 from langchain.embeddings import HuggingFaceBgeEmbeddings, HuggingFaceEmbeddings\r\n     22 \r\n\r\nModuleNotFoundError: No module named 'langchain.embeddings.base'\r\n\r\n---------------------------------------------------------------------------\r\nNOTE: If your import is failing due to a missing package, you can\r\nmanually install dependencies using either !pip or !apt.\r\n\r\nTo view examples of installing some common dependencies, click the\r\n\"Open Examples\" button below.\r\n---------------------------------------------------------------------------\n\n### Version\n\n0.8.29\n\n### Steps to Reproduce\n\nRan the following code in a Google colab instance:\r\n\r\n!pip install llama-index\r\nimport llama_index\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7713/reactions",
            "total_count": 4,
            "+1": 3,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 1
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7713/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7712",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7712/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7712/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7712/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7712",
        "id": 1901280601,
        "node_id": "I_kwDOIWuq585xUz1Z",
        "number": 7712,
        "title": "[Question]: Backend considerations",
        "user": {
            "login": "kylemassimilian",
            "id": 31603204,
            "node_id": "MDQ6VXNlcjMxNjAzMjA0",
            "avatar_url": "https://avatars.githubusercontent.com/u/31603204?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/kylemassimilian",
            "html_url": "https://github.com/kylemassimilian",
            "followers_url": "https://api.github.com/users/kylemassimilian/followers",
            "following_url": "https://api.github.com/users/kylemassimilian/following{/other_user}",
            "gists_url": "https://api.github.com/users/kylemassimilian/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/kylemassimilian/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/kylemassimilian/subscriptions",
            "organizations_url": "https://api.github.com/users/kylemassimilian/orgs",
            "repos_url": "https://api.github.com/users/kylemassimilian/repos",
            "events_url": "https://api.github.com/users/kylemassimilian/events{/privacy}",
            "received_events_url": "https://api.github.com/users/kylemassimilian/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-18T16:09:31Z",
        "updated_at": "2023-09-18T17:08:35Z",
        "closed_at": "2023-09-18T17:05:50Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nFor a production ready RAG application, would there be a noticeable difference in performance if I were to use an S3 bucket to store a knowledge graph and vector index instead of a combination of managed solutions such as Neo4j and Pinecone? I'm trying to create something that's fast and can manage ~40GB of data. Are there other considerations here?     ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7712/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7712/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7711",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7711/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7711/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7711/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7711",
        "id": 1901225119,
        "node_id": "PR_kwDOIWuq585albqn",
        "number": 7711,
        "title": "Update Chatbot_SEC.ipynb",
        "user": {
            "login": "nicholas-leonard",
            "id": 3520613,
            "node_id": "MDQ6VXNlcjM1MjA2MTM=",
            "avatar_url": "https://avatars.githubusercontent.com/u/3520613?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/nicholas-leonard",
            "html_url": "https://github.com/nicholas-leonard",
            "followers_url": "https://api.github.com/users/nicholas-leonard/followers",
            "following_url": "https://api.github.com/users/nicholas-leonard/following{/other_user}",
            "gists_url": "https://api.github.com/users/nicholas-leonard/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/nicholas-leonard/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/nicholas-leonard/subscriptions",
            "organizations_url": "https://api.github.com/users/nicholas-leonard/orgs",
            "repos_url": "https://api.github.com/users/nicholas-leonard/repos",
            "events_url": "https://api.github.com/users/nicholas-leonard/events{/privacy}",
            "received_events_url": "https://api.github.com/users/nicholas-leonard/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 5,
        "created_at": "2023-09-18T15:40:58Z",
        "updated_at": "2023-09-28T19:42:08Z",
        "closed_at": "2023-09-21T20:47:10Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7711",
            "html_url": "https://github.com/run-llama/llama_index/pull/7711",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7711.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7711.patch",
            "merged_at": "2023-09-21T20:47:10Z"
        },
        "body": "Fix the chatbot tutorial. The create_llama_chat_agent only works with the langchain OpenAI which is different from the llama OpenAI class.\r\n\r\n# Description\r\n\r\nPlease include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [ ] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [ ] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7711/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7711/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7710",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7710/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7710/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7710/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7710",
        "id": 1900924973,
        "node_id": "I_kwDOIWuq585xTdAt",
        "number": 7710,
        "title": "[Question]: Is token count correct?",
        "user": {
            "login": "uzumakinaruto19",
            "id": 99479748,
            "node_id": "U_kgDOBe3wxA",
            "avatar_url": "https://avatars.githubusercontent.com/u/99479748?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/uzumakinaruto19",
            "html_url": "https://github.com/uzumakinaruto19",
            "followers_url": "https://api.github.com/users/uzumakinaruto19/followers",
            "following_url": "https://api.github.com/users/uzumakinaruto19/following{/other_user}",
            "gists_url": "https://api.github.com/users/uzumakinaruto19/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/uzumakinaruto19/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/uzumakinaruto19/subscriptions",
            "organizations_url": "https://api.github.com/users/uzumakinaruto19/orgs",
            "repos_url": "https://api.github.com/users/uzumakinaruto19/repos",
            "events_url": "https://api.github.com/users/uzumakinaruto19/events{/privacy}",
            "received_events_url": "https://api.github.com/users/uzumakinaruto19/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 10,
        "created_at": "2023-09-18T13:18:09Z",
        "updated_at": "2023-09-26T18:46:24Z",
        "closed_at": "2023-09-18T22:36:56Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\ni was trying to get the token usage using the token counter, while printing the \r\n\r\n`token_counter.prompt_llm_token_count` \r\nI'm getting around 5000 or more tokens , but I am using gpt-3.5-turbo as my model and that has a token limit of  4,096 ?\r\nam I doing some thing wrong or is the calculation wrong??\r\n\r\nps:I'm passing my previous answer with the servicecontext to the system prompt that's why the input prompt is so big,, as of my understanding the input +completion should have 4096 tokens to be used, in my case still its Generates the response even if the input prompt is more than 4096\r\n\r\nAny help will be greatly appreciated\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7710/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7710/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7709",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7709/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7709/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7709/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7709",
        "id": 1900398716,
        "node_id": "PR_kwDOIWuq585aimzU",
        "number": 7709,
        "title": "[version] bump version to 0.8.29",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T08:10:11Z",
        "updated_at": "2023-09-18T08:27:16Z",
        "closed_at": "2023-09-18T08:27:15Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7709",
            "html_url": "https://github.com/run-llama/llama_index/pull/7709",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7709.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7709.patch",
            "merged_at": "2023-09-18T08:27:15Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7709/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7709/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7708",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7708/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7708/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7708/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7708",
        "id": 1900331501,
        "node_id": "PR_kwDOIWuq585aiYHW",
        "number": 7708,
        "title": "add low-level router guide",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-18T07:27:46Z",
        "updated_at": "2023-09-18T07:47:27Z",
        "closed_at": "2023-09-18T07:47:25Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7708",
            "html_url": "https://github.com/run-llama/llama_index/pull/7708",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7708.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7708.patch",
            "merged_at": "2023-09-18T07:47:25Z"
        },
        "body": "Latest addition to low-level \"Build rag from scratch\" series:\r\n- Learn how to craft a router prompt\r\n- Learn how to build output parser\r\n- Learn how to use pydantic program\r\n- Learn how to define a custom query engine ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7708/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7708/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7707",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7707/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7707/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7707/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7707",
        "id": 1900210633,
        "node_id": "I_kwDOIWuq585xQunJ",
        "number": 7707,
        "title": "[Question]: how to qurey based on particle embedding in database ",
        "user": {
            "login": "axz91",
            "id": 100378946,
            "node_id": "U_kgDOBfupQg",
            "avatar_url": "https://avatars.githubusercontent.com/u/100378946?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/axz91",
            "html_url": "https://github.com/axz91",
            "followers_url": "https://api.github.com/users/axz91/followers",
            "following_url": "https://api.github.com/users/axz91/following{/other_user}",
            "gists_url": "https://api.github.com/users/axz91/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/axz91/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/axz91/subscriptions",
            "organizations_url": "https://api.github.com/users/axz91/orgs",
            "repos_url": "https://api.github.com/users/axz91/repos",
            "events_url": "https://api.github.com/users/axz91/events{/privacy}",
            "received_events_url": "https://api.github.com/users/axz91/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": true,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 3,
        "created_at": "2023-09-18T05:43:49Z",
        "updated_at": "2023-10-24T06:31:30Z",
        "closed_at": "2023-10-24T06:31:30Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\ncollection.get(\r\n    ids=[\"id1\", \"id2\", \"id3\", ...],\r\n    where={\"style\": \"style1\"}\r\n)\r\n\r\nhttps://docs.trychroma.com/usage-guide#querying-a-collection\r\n\r\ngot the particular embedding then do LLM query , how to do this? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7707/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7707/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7706",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7706/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7706/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7706/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7706",
        "id": 1900170231,
        "node_id": "I_kwDOIWuq585xQkv3",
        "number": 7706,
        "title": "[Bug]: Selection output parser does not use prompt formatter, breaks LLMs with specific prompt formats",
        "user": {
            "login": "cyberkaida",
            "id": 118712366,
            "node_id": "U_kgDOBxNoLg",
            "avatar_url": "https://avatars.githubusercontent.com/u/118712366?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/cyberkaida",
            "html_url": "https://github.com/cyberkaida",
            "followers_url": "https://api.github.com/users/cyberkaida/followers",
            "following_url": "https://api.github.com/users/cyberkaida/following{/other_user}",
            "gists_url": "https://api.github.com/users/cyberkaida/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/cyberkaida/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/cyberkaida/subscriptions",
            "organizations_url": "https://api.github.com/users/cyberkaida/orgs",
            "repos_url": "https://api.github.com/users/cyberkaida/repos",
            "events_url": "https://api.github.com/users/cyberkaida/events{/privacy}",
            "received_events_url": "https://api.github.com/users/cyberkaida/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-18T04:56:33Z",
        "updated_at": "2023-09-18T05:02:00Z",
        "closed_at": null,
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nThe prompt here:\r\n\r\nhttps://github.com/jerryjliu/llama_index/blob/913349211b3ab25c942f5a1edaf560fa9db2f4ad/llama_index/selectors/prompts.py#L26\r\n\r\nshould contain a format arg instead of being concatenated here:\r\n\r\nhttps://github.com/jerryjliu/llama_index/blob/913349211b3ab25c942f5a1edaf560fa9db2f4ad/llama_index/output_parsers/selection.py#L101\r\n\r\nI am using llama2 instruct to implement some basic tools and the query format I have set in the context is being ignored. I tried altering the prompt, but there is no way to get `FORMAT_STR` into the correct place in the prompt (In the `<<SYS>>` section).\r\n\r\n### Version\r\n\r\n0.8.2.post1\r\n\r\n### Steps to Reproduce\r\n\r\nBelow I am customising the prompt for the router to try to work around the issue.\r\nI would have expected a format option for `{schema}` or something that I could place\r\nin the system part of the prompt.\r\n\r\n```python3\r\n        router_prompt = \"\"\"<<SYS>>\r\n        Some choices are given below. It is provided in a numbered list\r\n        (1 to {num_choices}),\r\n        where each item in the list corresponds to a summary.\r\n        ---------------------\r\n        {context_list}\r\n        ---------------------\r\n        Using only the choices above and not prior knowledge, return \r\n        the choice that is most relevant to the question\r\n        <</SYS>>\r\n        [INST]'{query_str}'\r\n        [/INST]\r\n        \"\"\"\r\n        base_query_engine = RouterQueryEngine(\r\n            selector=LLMSingleSelector.from_defaults(\r\n                prompt_template_str=router_prompt,\r\n                service_context=self.service_context,\r\n            ),\r\n            query_engine_tools=[\r\n                decompilation_tool,\r\n                cross_reference_tool,\r\n            ],\r\n            service_context=self.service_context,\r\n        )\r\n```\r\n\r\nMy `self.service_context` points to a local llama2.\r\nIf you'd like to see the [surrounding code I have pushed it here](https://github.com/cyberkaida/reverse-engineering-assistant/blob/513d0f1fb40c2feb5af60c5824f1c5cf49983d06/reverse-engineering-assistant/reverse_engineering_assistant/assistant.py#L302)\r\n\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\nHere you can see the format I specified above is being concatenated with\r\nthe JSON schema:\r\n\r\nhttps://github.com/jerryjliu/llama_index/blob/913349211b3ab25c942f5a1edaf560fa9db2f4ad/llama_index/output_parsers/selection.py#L101\r\n\r\n```shell\r\nPrompt being sent to the model:\r\n\r\n<<SYS>>\r\n        Some choices are given below. It is provided in a numbered list\r\n        (1 to 2),\r\n        where each item in the list corresponds to a summary.\r\n        ---------------------\r\n        (1) Useful for retrieving decompilation\r\n\r\n(2) Useful for retrieving cross references to and from addresses\r\n        ---------------------\r\n        Using only the choices above and not prior knowledge, return\r\n        the choice that is most relevant to the question\r\n        <</SYS>>\r\n        [INST]' Can you identify any functions or methods in the program that\r\nrefer directly or indirectly to the 'main' function?'\r\n        [/INST]\r\n\r\n\r\nThe output should be formatted as a JSON instance that conforms to\r\nthe JSON schema below.\r\n\r\nHere is the output schema:\r\n{\r\n  \"type\": \"array\",\r\n  \"items\": {\r\n    \"type\": \"object\",\r\n    \"properties\": {\r\n      \"choice\": {\r\n        \"type\": \"integer\"\r\n      },\r\n      \"reason\": {\r\n        \"type\": \"string\"\r\n      }\r\n    },\r\n    \"required\": [\r\n      \"choice\",\r\n      \"reason\"\r\n    ],\r\n    \"additionalProperties\": false\r\n  }\r\n}\r\n\r\nThe output will consist of a list of objects, where each object represents\r\na choice made by the user. Each object has two properties: \"choice\" and\r\n\"reason\". The \"choice\" property is an integer that corresponds to one of\r\nthe choices listed in the question (1 or 2). The \"reason\" property is a\r\nstring that provides a brief explanation for why the user chose that\r\nparticular option.\r\n```\r\n\r\nIn the end this results in my model not responding with appropriate JSON,\r\na `JSONDecode` error is thrown here:\r\n\r\nhttps://github.com/jerryjliu/llama_index/blob/913349211b3ab25c942f5a1edaf560fa9db2f4ad/llama_index/output_parsers/selection.py#L92\r\n\r\nand tool selection fails.\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7706/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7706/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7705",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7705/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7705/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7705/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7705",
        "id": 1899924137,
        "node_id": "PR_kwDOIWuq585ahATI",
        "number": 7705,
        "title": "Add Cross-encoder finetuning support and dataset generation functions for generating dataset",
        "user": {
            "login": "bhavishpahwa",
            "id": 108733252,
            "node_id": "U_kgDOBnsjRA",
            "avatar_url": "https://avatars.githubusercontent.com/u/108733252?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/bhavishpahwa",
            "html_url": "https://github.com/bhavishpahwa",
            "followers_url": "https://api.github.com/users/bhavishpahwa/followers",
            "following_url": "https://api.github.com/users/bhavishpahwa/following{/other_user}",
            "gists_url": "https://api.github.com/users/bhavishpahwa/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/bhavishpahwa/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/bhavishpahwa/subscriptions",
            "organizations_url": "https://api.github.com/users/bhavishpahwa/orgs",
            "repos_url": "https://api.github.com/users/bhavishpahwa/repos",
            "events_url": "https://api.github.com/users/bhavishpahwa/events{/privacy}",
            "received_events_url": "https://api.github.com/users/bhavishpahwa/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 7,
        "created_at": "2023-09-17T21:28:27Z",
        "updated_at": "2023-10-13T02:53:14Z",
        "closed_at": "2023-10-12T17:17:00Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7705",
            "html_url": "https://github.com/run-llama/llama_index/pull/7705",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7705.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7705.patch",
            "merged_at": "2023-10-12T17:17:00Z"
        },
        "body": "# Description\r\nThis PR adds support to fine-tune cross-encoder models and also adds dataset generation functions to generate a training dataset over a large corpus of documents using LLMs. Based on my reading of the below blogs and cookbooks https://www.sbert.net/examples/applications/cross-encoder/README.html , https://github.com/openai/openai-cookbook/blob/main/examples/Search_reranking_with_cross-encoders.ipynb , https://weaviate.io/blog/cross-encoders-as-reranker . As I was inspired by the embedding-adapter approach by LLamaIndex team to boost the performance of proprietary embeddings like OpenAI Embeddings which don't support domain/data specific finetuning currently, I also wanted to add support for fine-tuning specific cross-encoder models as re-rankers which can also be used to boost performance of proprietary embeddings.\r\n\r\nFixes # (issue)\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [ ] Bug fix (non-breaking change which fixes an issue)\r\n- [x] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [ ] Added new unit/integration tests\r\n- [ ] Added new notebook (that tests end-to-end)\r\n- [x] Added a sample code python script\r\n- [ ] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [ ] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [ ] I have added tests that prove my fix is effective or that my feature works\r\n- [ ] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7705/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7705/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7704",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7704/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7704/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7704/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7704",
        "id": 1899744311,
        "node_id": "I_kwDOIWuq585xO8w3",
        "number": 7704,
        "title": "[Feature Request]: ",
        "user": {
            "login": "gich2009",
            "id": 83756959,
            "node_id": "MDQ6VXNlcjgzNzU2OTU5",
            "avatar_url": "https://avatars.githubusercontent.com/u/83756959?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/gich2009",
            "html_url": "https://github.com/gich2009",
            "followers_url": "https://api.github.com/users/gich2009/followers",
            "following_url": "https://api.github.com/users/gich2009/following{/other_user}",
            "gists_url": "https://api.github.com/users/gich2009/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/gich2009/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/gich2009/subscriptions",
            "organizations_url": "https://api.github.com/users/gich2009/orgs",
            "repos_url": "https://api.github.com/users/gich2009/repos",
            "events_url": "https://api.github.com/users/gich2009/events{/privacy}",
            "received_events_url": "https://api.github.com/users/gich2009/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318869,
                "node_id": "LA_kwDOIWuq588AAAABGzNfVQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/enhancement",
                "name": "enhancement",
                "color": "a2eeef",
                "default": true,
                "description": "New feature or request"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-17T11:03:28Z",
        "updated_at": "2023-10-30T20:55:51Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Feature Description\n\nMake llama-index compartible with nemoguardrails. \r\n\r\nLink: https://github.com/NVIDIA/NeMo-Guardrails\n\n### Reason\n\nGuardrails add a layer before the input prompt is passed to the LLM where the programmer can design a conversational flow in a deterministic manner. Especially for applications like abusive language and inappropriate prompts. The layer added before the query_engine class wrapping the llm could give developers using llama-index freedom to do much more. It will also give the library a competitive edge. \r\nThe library is compartible with langchain llms already.\r\n\r\n\n\n### Value of Feature\n\nIt will offer developers a way to handle some user input in a predictable or deterministic way instead of relying on system messages which may not work in every case or fine-tuning which is expensive. Developers can also design their own conversational flows using the library!",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7704/reactions",
            "total_count": 2,
            "+1": 2,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7704/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7703",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7703/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7703/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7703/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7703",
        "id": 1899680115,
        "node_id": "PR_kwDOIWuq585agR50",
        "number": 7703,
        "title": "Add CustomQueryEngine class",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-17T06:51:48Z",
        "updated_at": "2023-09-18T01:12:47Z",
        "closed_at": "2023-09-18T01:12:46Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7703",
            "html_url": "https://github.com/run-llama/llama_index/pull/7703",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7703.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7703.patch",
            "merged_at": "2023-09-18T01:12:46Z"
        },
        "body": "unlike #7695 this PR makes the customqueryengine a pydantic object, meaning it's easy for users to define new fields without the hacky `init_params` initialization\r\n\r\nwe should probably just make the base class a pydantic object, but that's a TODO for a later PR ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7703/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7703/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7702",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7702/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7702/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7702/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7702",
        "id": 1899674068,
        "node_id": "PR_kwDOIWuq585agQ1r",
        "number": 7702,
        "title": "low-level guide on creating a vector store",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-17T06:24:24Z",
        "updated_at": "2023-09-17T08:04:36Z",
        "closed_at": "2023-09-17T08:04:35Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7702",
            "html_url": "https://github.com/run-llama/llama_index/pull/7702",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7702.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7702.patch",
            "merged_at": "2023-09-17T08:04:35Z"
        },
        "body": "In this tutorial, we show users how to create a simple vector store from scratch",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7702/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7702/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7701",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7701/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7701/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7701/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7701",
        "id": 1899590051,
        "node_id": "PR_kwDOIWuq585agA_A",
        "number": 7701,
        "title": "[doc] update LlamaIndex SQL guide document",
        "user": {
            "login": "tonyz0x0",
            "id": 29159357,
            "node_id": "MDQ6VXNlcjI5MTU5MzU3",
            "avatar_url": "https://avatars.githubusercontent.com/u/29159357?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/tonyz0x0",
            "html_url": "https://github.com/tonyz0x0",
            "followers_url": "https://api.github.com/users/tonyz0x0/followers",
            "following_url": "https://api.github.com/users/tonyz0x0/following{/other_user}",
            "gists_url": "https://api.github.com/users/tonyz0x0/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/tonyz0x0/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/tonyz0x0/subscriptions",
            "organizations_url": "https://api.github.com/users/tonyz0x0/orgs",
            "repos_url": "https://api.github.com/users/tonyz0x0/repos",
            "events_url": "https://api.github.com/users/tonyz0x0/events{/privacy}",
            "received_events_url": "https://api.github.com/users/tonyz0x0/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-16T22:54:10Z",
        "updated_at": "2023-09-17T02:48:08Z",
        "closed_at": "2023-09-17T02:48:08Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7701",
            "html_url": "https://github.com/run-llama/llama_index/pull/7701",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7701.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7701.patch",
            "merged_at": "2023-09-17T02:48:08Z"
        },
        "body": "# Description\r\n\r\nUpdate document with few missing imports\r\n\r\n## Type of Change\r\n- [x] This change requires a documentation update\r\n\r\n# How Has This Been Tested?\r\n- [x] I stared at the code and made sure it makes sense\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7701/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7701/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7700",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7700/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7700/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7700/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7700",
        "id": 1899577958,
        "node_id": "PR_kwDOIWuq585af-0S",
        "number": 7700,
        "title": "update local llama2 notebook",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-16T21:54:20Z",
        "updated_at": "2023-09-16T21:54:30Z",
        "closed_at": "2023-09-16T21:54:30Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7700",
            "html_url": "https://github.com/run-llama/llama_index/pull/7700",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7700.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7700.patch",
            "merged_at": "2023-09-16T21:54:30Z"
        },
        "body": "# Description\r\n\r\nSmall fix to use service context\r\n\r\nFixes https://github.com/jerryjliu/llama_index/issues/7693\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7700/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7700/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7699",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7699/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7699/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7699/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7699",
        "id": 1899530895,
        "node_id": "I_kwDOIWuq585xOIqP",
        "number": 7699,
        "title": "[Question]: How do I stop the system from printing \"Llama.generate: prefix-match hit\" when using  query_engine.query?",
        "user": {
            "login": "robgon-art",
            "id": 1119357,
            "node_id": "MDQ6VXNlcjExMTkzNTc=",
            "avatar_url": "https://avatars.githubusercontent.com/u/1119357?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/robgon-art",
            "html_url": "https://github.com/robgon-art",
            "followers_url": "https://api.github.com/users/robgon-art/followers",
            "following_url": "https://api.github.com/users/robgon-art/following{/other_user}",
            "gists_url": "https://api.github.com/users/robgon-art/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/robgon-art/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/robgon-art/subscriptions",
            "organizations_url": "https://api.github.com/users/robgon-art/orgs",
            "repos_url": "https://api.github.com/users/robgon-art/repos",
            "events_url": "https://api.github.com/users/robgon-art/events{/privacy}",
            "received_events_url": "https://api.github.com/users/robgon-art/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318877,
                "node_id": "LA_kwDOIWuq588AAAABGzNfXQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/question",
                "name": "question",
                "color": "d876e3",
                "default": true,
                "description": "Further information is requested"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-16T18:35:59Z",
        "updated_at": "2023-09-17T03:22:54Z",
        "closed_at": "2023-09-17T03:22:54Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI am running the LlaMaCPP example from the notebook here, https://github.com/jerryjliu/llama_index/blob/main/docs/examples/llm/llama_2_llama_cpp.ipynb\r\n\r\nIt runs fine, but I keep getting this notification, \"Llama.generate: prefix-match hit\"\r\n\r\n```\r\n...\r\nquery_engine = index.as_query_engine()\r\nresponse = query_engine.query(\"What did the author do growing up?\")\r\nprint(response)\r\n\r\nLlama.generate: prefix-match hit\r\n  Based on the given context information, the author's childhood activities were writing short stories and programming. They wrote programs on punch cards using an early version of Fortran and later used a TRS-80 microcomputer to write simple games, a program to predict the height of model rockets, and a word processor that their father used to write at least one book.\r\n```\r\n\r\nHow do I disable this? I tried setting the logging level to CRITICAL, but it didn't help.\r\n\r\n```\r\nimport logging\r\nimport sys\r\n\r\nlogging.basicConfig(stream=sys.stdout, level=logging.CRITICAL)\r\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\r\n```\r\nI'm running llama_index v0.8.28.",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7699/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7699/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7698",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7698/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7698/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7698/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7698",
        "id": 1899380067,
        "node_id": "I_kwDOIWuq585xNj1j",
        "number": 7698,
        "title": "[Bug]: Query does not work when adding metadata using QdrantVectorStore",
        "user": {
            "login": "matteosdocsity",
            "id": 59953137,
            "node_id": "MDQ6VXNlcjU5OTUzMTM3",
            "avatar_url": "https://avatars.githubusercontent.com/u/59953137?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/matteosdocsity",
            "html_url": "https://github.com/matteosdocsity",
            "followers_url": "https://api.github.com/users/matteosdocsity/followers",
            "following_url": "https://api.github.com/users/matteosdocsity/following{/other_user}",
            "gists_url": "https://api.github.com/users/matteosdocsity/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/matteosdocsity/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/matteosdocsity/subscriptions",
            "organizations_url": "https://api.github.com/users/matteosdocsity/orgs",
            "repos_url": "https://api.github.com/users/matteosdocsity/repos",
            "events_url": "https://api.github.com/users/matteosdocsity/events{/privacy}",
            "received_events_url": "https://api.github.com/users/matteosdocsity/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "open",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 8,
        "created_at": "2023-09-16T10:02:11Z",
        "updated_at": "2023-09-27T20:22:11Z",
        "closed_at": null,
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nWhen adding metadata via every method listed [here](https://gpt-index.readthedocs.io/en/latest/core_modules/data_modules/documents_and_nodes/usage_documents.html#customizing-documents), the query does not return the correct node. Without metadata everything works fine.\r\n\r\n\r\n\r\n### Version\r\n\r\n0.8.27\r\n\r\n### Steps to Reproduce\r\n\r\nadding document.metadata = {'filename': '<doc_file_name>', 'id': '<doc_id>', 'subject': '<doc_subject>'}, makes the query not working anymore. Without passing metadata the retrieval from the query is fine and the result as expected.\r\nTried also to test via excluded_embed_metadata_keys and/or excluded_llm_metadata_keys, but nothing changed.\r\n\r\nUsing OpenAI completion_model=\"gpt-3.5-turbo\" and embed_model=\"text-embedding-ada-002\", and QdrantVectorStore\r\n\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7698/reactions",
            "total_count": 1,
            "+1": 1,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7698/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7697",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7697/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7697/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7697/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7697",
        "id": 1899348441,
        "node_id": "PR_kwDOIWuq585afS5j",
        "number": 7697,
        "title": "[version] bump version to 0.8.28",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-16T08:08:53Z",
        "updated_at": "2023-09-16T15:50:02Z",
        "closed_at": "2023-09-16T15:50:01Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7697",
            "html_url": "https://github.com/run-llama/llama_index/pull/7697",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7697.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7697.patch",
            "merged_at": "2023-09-16T15:50:01Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7697/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7697/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7696",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7696/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7696/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7696/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7696",
        "id": 1899333017,
        "node_id": "PR_kwDOIWuq585afP_g",
        "number": 7696,
        "title": "Fix LiteLLM Metadata",
        "user": {
            "login": "yujonglee",
            "id": 61503739,
            "node_id": "MDQ6VXNlcjYxNTAzNzM5",
            "avatar_url": "https://avatars.githubusercontent.com/u/61503739?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/yujonglee",
            "html_url": "https://github.com/yujonglee",
            "followers_url": "https://api.github.com/users/yujonglee/followers",
            "following_url": "https://api.github.com/users/yujonglee/following{/other_user}",
            "gists_url": "https://api.github.com/users/yujonglee/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/yujonglee/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/yujonglee/subscriptions",
            "organizations_url": "https://api.github.com/users/yujonglee/orgs",
            "repos_url": "https://api.github.com/users/yujonglee/repos",
            "events_url": "https://api.github.com/users/yujonglee/events{/privacy}",
            "received_events_url": "https://api.github.com/users/yujonglee/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-16T07:13:12Z",
        "updated_at": "2023-09-17T00:02:20Z",
        "closed_at": "2023-09-16T22:58:06Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7696",
            "html_url": "https://github.com/run-llama/llama_index/pull/7696",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7696.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7696.patch",
            "merged_at": "2023-09-16T22:58:06Z"
        },
        "body": "# Description\r\nFix wrong metadata of litellm, which cause Pydantic ValidationError.\r\n\r\n## Type of Change\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n\r\n# How Has This Been Tested?\r\n- [x] Added new unit/integration tests\r\n\r\n# Suggested Checklist:\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [ ] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7696/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7696/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7695",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7695/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7695/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7695/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7695",
        "id": 1899295098,
        "node_id": "PR_kwDOIWuq585afIq0",
        "number": 7695,
        "title": "[wip, feedback requested] custom query engine ",
        "user": {
            "login": "jerryjliu",
            "id": 4858925,
            "node_id": "MDQ6VXNlcjQ4NTg5MjU=",
            "avatar_url": "https://avatars.githubusercontent.com/u/4858925?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/jerryjliu",
            "html_url": "https://github.com/jerryjliu",
            "followers_url": "https://api.github.com/users/jerryjliu/followers",
            "following_url": "https://api.github.com/users/jerryjliu/following{/other_user}",
            "gists_url": "https://api.github.com/users/jerryjliu/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/jerryjliu/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/jerryjliu/subscriptions",
            "organizations_url": "https://api.github.com/users/jerryjliu/orgs",
            "repos_url": "https://api.github.com/users/jerryjliu/repos",
            "events_url": "https://api.github.com/users/jerryjliu/events{/privacy}",
            "received_events_url": "https://api.github.com/users/jerryjliu/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 4,
        "created_at": "2023-09-16T04:46:31Z",
        "updated_at": "2023-09-18T15:47:25Z",
        "closed_at": "2023-09-18T15:47:25Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7695",
            "html_url": "https://github.com/run-llama/llama_index/pull/7695",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7695.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7695.patch",
            "merged_at": null
        },
        "body": "Here's a prototype of a \"custom\" query engine to make it easier for users to define their own query engines.\r\n\r\nOpening this up to feedback\r\n\r\nSome thoughts:\r\n- `init_params` feels a bit awk\r\n- Picked the name `custom_query` so we could pass in a `string` type \r\n- User can still technically customize callback manager by passing it in as an arg\r\n- User needs to define a Response object which feels a bit heavy but also does include sources \r\n\r\nThoughts/feedback? ",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7695/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7695/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7694",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7694/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7694/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7694/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7694",
        "id": 1899220367,
        "node_id": "PR_kwDOIWuq585ae54m",
        "number": 7694,
        "title": "Fix text splitter ids for hierarchical node parsers",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-16T00:08:24Z",
        "updated_at": "2023-09-16T00:21:35Z",
        "closed_at": "2023-09-16T00:21:35Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7694",
            "html_url": "https://github.com/run-llama/llama_index/pull/7694",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7694.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7694.patch",
            "merged_at": "2023-09-16T00:21:34Z"
        },
        "body": "# Description\r\n\r\nQuick patch for setting up the text-splitter-ids to match the chunk sizes in `HierarchicalNodeParser`\r\n\r\n## Type of Change\r\n\r\n- [x] Bug fix (non-breaking change which fixes an issue)\r\n- [ ] New feature (non-breaking change which adds functionality)\r\n- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)\r\n- [ ] This change requires a documentation update\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7694/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7694/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7693",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7693/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7693/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7693/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7693",
        "id": 1899217482,
        "node_id": "I_kwDOIWuq585xM8JK",
        "number": 7693,
        "title": "[Bug]: Issues with the \"Local Llama2 + VectorStoreIndex\" notebook",
        "user": {
            "login": "sia-cerebras",
            "id": 101586439,
            "node_id": "U_kgDOBg4WBw",
            "avatar_url": "https://avatars.githubusercontent.com/u/101586439?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/sia-cerebras",
            "html_url": "https://github.com/sia-cerebras",
            "followers_url": "https://api.github.com/users/sia-cerebras/followers",
            "following_url": "https://api.github.com/users/sia-cerebras/following{/other_user}",
            "gists_url": "https://api.github.com/users/sia-cerebras/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/sia-cerebras/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/sia-cerebras/subscriptions",
            "organizations_url": "https://api.github.com/users/sia-cerebras/orgs",
            "repos_url": "https://api.github.com/users/sia-cerebras/repos",
            "events_url": "https://api.github.com/users/sia-cerebras/events{/privacy}",
            "received_events_url": "https://api.github.com/users/sia-cerebras/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 2,
        "created_at": "2023-09-16T00:02:01Z",
        "updated_at": "2023-09-16T21:54:55Z",
        "closed_at": "2023-09-16T21:54:31Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\n\nIssue is regarding this notebook: [https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/SimpleIndexDemoLlama-Local.ipynb](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/SimpleIndexDemoLlama-Local.ipynb)\r\n\r\nThe code creates a HuggingFaceLLM `llm` object but never uses it.\r\n\r\nFurther down when it called `index = VectorStoreIndex.from_documents(documents)`, it errors out asking for OpenAI\r\n\r\nWhen I add the OpenAI key, it work, BUT now my question is when I call `query_engine.query(\"blah?\")` is it using OpenAI API or is it using `llm`. I'm asking because `llm` is not referenced anywhere. \r\n\r\n\n\n### Version\n\n0.8.27\n\n### Steps to Reproduce\n\nRun this notebook [https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/SimpleIndexDemoLlama-Local.ipynb](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/SimpleIndexDemoLlama-Local.ipynb)\n\n### Relevant Logs/Tracbacks\n\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7693/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7693/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7692",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7692/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7692/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7692/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7692",
        "id": 1899177746,
        "node_id": "PR_kwDOIWuq585aexCg",
        "number": 7692,
        "title": "Add async and batch eval",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T23:04:43Z",
        "updated_at": "2023-09-16T00:46:28Z",
        "closed_at": "2023-09-16T00:07:11Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7692",
            "html_url": "https://github.com/run-llama/llama_index/pull/7692",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7692.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7692.patch",
            "merged_at": "2023-09-16T00:07:11Z"
        },
        "body": "# Description\r\n\r\nThis PR adds async evaluators, as well as a batch evaluator.\r\n\r\n## Type of Change\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\n- [x] Added new notebook (that tests end-to-end)\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7692/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7692/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7691",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7691/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7691/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7691/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7691",
        "id": 1899041489,
        "node_id": "PR_kwDOIWuq585aeTs-",
        "number": 7691,
        "title": "Text Splitter Refactor: Adding list functions for text splitters",
        "user": {
            "login": "ajhofmann",
            "id": 10040285,
            "node_id": "MDQ6VXNlcjEwMDQwMjg1",
            "avatar_url": "https://avatars.githubusercontent.com/u/10040285?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/ajhofmann",
            "html_url": "https://github.com/ajhofmann",
            "followers_url": "https://api.github.com/users/ajhofmann/followers",
            "following_url": "https://api.github.com/users/ajhofmann/following{/other_user}",
            "gists_url": "https://api.github.com/users/ajhofmann/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/ajhofmann/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/ajhofmann/subscriptions",
            "organizations_url": "https://api.github.com/users/ajhofmann/orgs",
            "repos_url": "https://api.github.com/users/ajhofmann/repos",
            "events_url": "https://api.github.com/users/ajhofmann/events{/privacy}",
            "received_events_url": "https://api.github.com/users/ajhofmann/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T20:29:26Z",
        "updated_at": "2023-09-15T21:50:14Z",
        "closed_at": "2023-09-15T21:50:14Z",
        "author_association": "CONTRIBUTOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7691",
            "html_url": "https://github.com/run-llama/llama_index/pull/7691",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7691.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7691.patch",
            "merged_at": "2023-09-15T21:50:14Z"
        },
        "body": "# Description\r\n\r\n- Add list methods to TextSplitter interface to allow chaining\r\n\r\n## Type of Change\r\n\r\nPlease delete options that are not relevant.\r\n\r\n- [x] New feature (non-breaking change which adds functionality)\r\n\r\n# How Has This Been Tested?\r\n\r\nPlease describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration\r\n\r\n- [x] Added new unit/integration tests\r\n- [x] I stared at the code and made sure it makes sense\r\n\r\n# Suggested Checklist:\r\n\r\n- [x] I have performed a self-review of my own code\r\n- [x] I have commented my code, particularly in hard-to-understand areas\r\n- [x] I have made corresponding changes to the documentation\r\n- [x] My changes generate no new warnings\r\n- [x] I have added tests that prove my fix is effective or that my feature works\r\n- [x] New and existing unit tests pass locally with my changes\r\n",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7691/reactions",
            "total_count": 1,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 1,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7691/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7690",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7690/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7690/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7690/events",
        "html_url": "https://github.com/run-llama/llama_index/issues/7690",
        "id": 1898979983,
        "node_id": "I_kwDOIWuq585xMCKP",
        "number": 7690,
        "title": "[Bug]: multi-line answer is empty from ReAct agent",
        "user": {
            "login": "vitalyford",
            "id": 5395250,
            "node_id": "MDQ6VXNlcjUzOTUyNTA=",
            "avatar_url": "https://avatars.githubusercontent.com/u/5395250?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/vitalyford",
            "html_url": "https://github.com/vitalyford",
            "followers_url": "https://api.github.com/users/vitalyford/followers",
            "following_url": "https://api.github.com/users/vitalyford/following{/other_user}",
            "gists_url": "https://api.github.com/users/vitalyford/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/vitalyford/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/vitalyford/subscriptions",
            "organizations_url": "https://api.github.com/users/vitalyford/orgs",
            "repos_url": "https://api.github.com/users/vitalyford/repos",
            "events_url": "https://api.github.com/users/vitalyford/events{/privacy}",
            "received_events_url": "https://api.github.com/users/vitalyford/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [
            {
                "id": 4751318865,
                "node_id": "LA_kwDOIWuq588AAAABGzNfUQ",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/bug",
                "name": "bug",
                "color": "d73a4a",
                "default": true,
                "description": "Something isn't working"
            },
            {
                "id": 5584919374,
                "node_id": "LA_kwDOIWuq588AAAABTOMbTg",
                "url": "https://api.github.com/repos/run-llama/llama_index/labels/triage",
                "name": "triage",
                "color": "FBCA04",
                "default": false,
                "description": "Issue needs to be triaged/prioritized"
            }
        ],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 1,
        "created_at": "2023-09-15T19:38:11Z",
        "updated_at": "2023-10-09T02:58:28Z",
        "closed_at": "2023-10-09T02:58:28Z",
        "author_association": "NONE",
        "active_lock_reason": null,
        "body": "### Bug Description\r\n\r\nBased on [ `extra_final_response()`](https://github.com/jerryjliu/llama_index/blob/424fdb689f8a8f87ca3ce1013ed8552777b4298b/llama_index/agent/react/output_parser.py#L33) from [`llama_index/agent/react/output_parser.py`](https://github.com/jerryjliu/llama_index/blob/424fdb689f8a8f87ca3ce1013ed8552777b4298b/llama_index/agent/react/output_parser.py), the answer will be extracted until a new line character is encountered or the end of the string. In cases when the final answer spans across multiple lines, it will return an empty response. \r\n\r\nA possible fix is to remove `\\n|` and just keep `$`. But then what's the usability of `$` there? Need to put more thinking into it though if anything else is affected by it; hence, no PR yet. Has someone encountered this before?\r\n\r\n### Version\r\n\r\n0.8.27\r\n\r\n### Steps to Reproduce\r\n\r\nQuery a ReAct agent to respond in an enumerated or bullet-list style.\r\n\r\n### Relevant Logs/Tracbacks\r\n\r\n_No response_",
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7690/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7690/timeline",
        "performed_via_github_app": null,
        "state_reason": "completed"
    },
    {
        "url": "https://api.github.com/repos/run-llama/llama_index/issues/7689",
        "repository_url": "https://api.github.com/repos/run-llama/llama_index",
        "labels_url": "https://api.github.com/repos/run-llama/llama_index/issues/7689/labels{/name}",
        "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/7689/comments",
        "events_url": "https://api.github.com/repos/run-llama/llama_index/issues/7689/events",
        "html_url": "https://github.com/run-llama/llama_index/pull/7689",
        "id": 1898801180,
        "node_id": "PR_kwDOIWuq585adf3r",
        "number": 7689,
        "title": "add lite llm to docs",
        "user": {
            "login": "logan-markewich",
            "id": 22285038,
            "node_id": "MDQ6VXNlcjIyMjg1MDM4",
            "avatar_url": "https://avatars.githubusercontent.com/u/22285038?v=4",
            "gravatar_id": "",
            "url": "https://api.github.com/users/logan-markewich",
            "html_url": "https://github.com/logan-markewich",
            "followers_url": "https://api.github.com/users/logan-markewich/followers",
            "following_url": "https://api.github.com/users/logan-markewich/following{/other_user}",
            "gists_url": "https://api.github.com/users/logan-markewich/gists{/gist_id}",
            "starred_url": "https://api.github.com/users/logan-markewich/starred{/owner}{/repo}",
            "subscriptions_url": "https://api.github.com/users/logan-markewich/subscriptions",
            "organizations_url": "https://api.github.com/users/logan-markewich/orgs",
            "repos_url": "https://api.github.com/users/logan-markewich/repos",
            "events_url": "https://api.github.com/users/logan-markewich/events{/privacy}",
            "received_events_url": "https://api.github.com/users/logan-markewich/received_events",
            "type": "User",
            "site_admin": false
        },
        "labels": [],
        "state": "closed",
        "locked": false,
        "assignee": null,
        "assignees": [],
        "milestone": null,
        "comments": 0,
        "created_at": "2023-09-15T17:12:09Z",
        "updated_at": "2023-09-15T17:17:06Z",
        "closed_at": "2023-09-15T17:17:05Z",
        "author_association": "COLLABORATOR",
        "active_lock_reason": null,
        "draft": false,
        "pull_request": {
            "url": "https://api.github.com/repos/run-llama/llama_index/pulls/7689",
            "html_url": "https://github.com/run-llama/llama_index/pull/7689",
            "diff_url": "https://github.com/run-llama/llama_index/pull/7689.diff",
            "patch_url": "https://github.com/run-llama/llama_index/pull/7689.patch",
            "merged_at": "2023-09-15T17:17:05Z"
        },
        "body": null,
        "reactions": {
            "url": "https://api.github.com/repos/run-llama/llama_index/issues/7689/reactions",
            "total_count": 0,
            "+1": 0,
            "-1": 0,
            "laugh": 0,
            "hooray": 0,
            "confused": 0,
            "heart": 0,
            "rocket": 0,
            "eyes": 0
        },
        "timeline_url": "https://api.github.com/repos/run-llama/llama_index/issues/7689/timeline",
        "performed_via_github_app": null,
        "state_reason": null
    }
]